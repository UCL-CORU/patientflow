{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"patientflow: a Python package for real-time predictions of hospital bed demand from current and incoming patients","text":""},{"location":"#summary","title":"Summary","text":"<p><code>patientflow</code>, a Python package for real-time prediction of hospital bed demand from current and incoming patients, creates output that is useful for bed managers in hospitals, allowing researchers to easily develop predictive models and demonstrate their utility to practitioners.</p> <p>We originally developed this code for University College London Hospitals (UCLH) to predict the number of emergency admissions they should expect within the next eight hours. Our method used real-time data from their Electronic Health Record (EHR) system. We wrote code to convert patient-level data, extracted from the EHR at a point in time, into predicted numbers of admissions in the following hours. We also wrote code to help us evaluate the predictions.</p> <p>We have created the <code>patientflow</code> python package to make it convenient for others to adopt our approach. Its purpose is to predict bed demand for groups of hospital patients at a point in time. The package is organised around the following concepts:</p> <ul> <li>Prediction time: A moment in the day at which predictions are to be made, for example 09:30.</li> <li>Patient snapshot: A summary of data from the EHR capturing what is known about a current patient at the prediction time. Each patient snapshot has a date and a prediction time associated with it.</li> <li>Group snapshot: The set of snapshots for a defined group of current patients. Each group snapshot has a date and a prediction time associated with it.</li> <li>Prediction window: A time period that begins at the prediction time.</li> </ul> <p>For current patients, the package includes functions to create patient and group snapshots, to generate patient-level predictions, and to aggregate patient-level predictions into predicted bed counts for a group snapshots. The aggregation functions in <code>patientflow</code> are designed to receive a group snapshot as an input, and to predict something about that group's demand for beds between the prediction moment and the end of the prediction window. For example, that group could be the patients currently in the Emergency Department (ED), and the predictions could be the number of beds needed by those patients in the prediction window. The snapshot-based approach to predicting demand generalises to other aspects of patient flow in hospitals, such as predictions of how many current patients will be discharged from a clinical specialty.</p> <p>For incoming patients, whose visits are not yet recorded in the EHR data (such as future arrivals to the ED) the aggregation functions make predictions based on past patterns of arrivals.</p> <p>In both cases the output is a probability distribution over the number of beds needed. It is possible to create output at different levels of aggregation (for example by sex, or by clinical area), which bed managers find more actionable than whole-hospital predictions. The package includes functions to visualise the predicted probability distributions, and to evaluate them.</p> <p>A series of notebooks demonstrates the use of the package. I show how to prepare your data and train models based on a snapshot approach. The repository includes a synthetic dataset, and an anonymised patient dataset, based on real data from UCLH is available on Zenodo. Both the synthetic and the real dataset have been prepared in a snapshot structure.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use this software in your research, please cite it as:</p> <p>King, Zella. (2025). PatientFlow: Code and training materials for predicting short-term hospital bed capacity using real-time data (v1.0.3). Zenodo. https://doi.org/10.5281/zenodo.15722296</p> <p>BibTeX:</p> <pre><code>@software{king_patientflow_2025,\n  title = {PatientFlow: Code and training materials for predicting short-term hospital bed capacity using real-time data},\n  author = {King, Zella},\n  year = {2025},\n  month = {6},\n  version = {v1.0.3},\n  doi = {10.5281/zenodo.15722296},\n  url = {https://doi.org/10.5281/zenodo.15722296},\n  publisher = {Zenodo}\n}\n</code></pre>"},{"location":"#dataset","title":"Dataset","text":"<p>The accompanying dataset is available at: https://doi.org/10.5281/zenodo.15311282</p> <p>King, Zella, University College London Hospitals NHS Foundation Trust, &amp; Crowe, Sonya. (2025). Patient visits to the Emergency Department of an Acute Hospital; dataset to accompany the patientflow repository (Version 1.1.1). Zenodo. https://doi.org/10.5281/zenodo.15311282</p> <p>BibTeX:</p> <pre><code>@dataset{king_patient_visits_2025,\n  title = {Patient visits to the Emergency Department of an Acute Hospital; dataset to accompany the patientflow repository},\n  author = {King, Zella and Crowe, Sonya},\n  year = {2025},\n  month = {4},\n  version = {1.1.1},\n  doi = {10.5281/zenodo.15311282},\n  url = {https://doi.org/10.5281/zenodo.15311282},\n  publisher = {Zenodo}\n}\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is available at ucl-coru.github.io/patientflow. The full API reference is here.</p>"},{"location":"#what-patientflow-is-for","title":"What <code>patientflow</code> is for:","text":"<ul> <li>Predicting patient flow in hospitals: The package can be used by researchers or analysts who want to predict numbers of emergency admissions, discharges, transfers between units or combinations of these</li> <li>Short-term operational planning: The predictions produced by this package are designed for bed managers who need to make decisions within a short timeframe (up to 24 hours, but not days or weeks).</li> <li>Working with real-time data: The design assumes that data from an electronic health record (EHR) is available in real-time, or near to real-time.</li> <li>Point-in-time analysis: For cohorts of hospital patients at different stages of a hospital visit, the package can be used to make mid-visit predictions about whether a non-clinical event like admission or discharge will occur within a short time horizon.</li> </ul>"},{"location":"#what-patientflow-is-not-for","title":"What <code>patientflow</code> is NOT for:","text":"<ul> <li>Long-term capacity planning: The package focuses on short-term operational demand (hours ahead), not strategic planning over weeks or months.</li> <li>Making decisions about individual patients: The package relies on data entered into the EHR by clinical staff looking after patients, but the patient-level predictions it generates cannot and should not be used to influence their decision-making.</li> <li>Predicting what happens after a hospital visit has finished: While historical data might train underlying models, the package itself focuses on patients currently in the hospital or soon to arrive.</li> <li>Replacing human judgment: The predictions are meant to augment the information available to bed managers, but not to automate bed management decisions.</li> </ul>"},{"location":"#this-package-will-help-you-if-you-want-to","title":"This package will help you if you want to:","text":"<ul> <li>Make predictions for unfinished patient visits, using real-time data.</li> <li>Attract the attention of hospital managers in your predictions; since the output is bed numbers, a currency they use daily, they may find it more actionable than typical predictive modelling output, especially if you can break it down by clinical area.</li> <li>Develop your own emergency bed modelling application - the repository includes a fully worked example of how we have used the package at UCLH - or an adjacent appplication such as one predicting how many patients will be discharged.</li> </ul>"},{"location":"#this-package-will-not-help-you-if","title":"This package will NOT help you if:","text":"<ul> <li>You work with time series data: <code>patientflow</code> works with snapshots of a hospital visit summarising what is in the patient record up to that point in time. It would need modification to accept time series data formats.</li> <li>You want to predict clinical outcomes: the approach is designed for the management of hospital sites, not the management of patient care.</li> </ul>"},{"location":"#mathematical-assumptions-underlying-the-conversion-from-individual-to-group-predictions","title":"Mathematical assumptions underlying the conversion from individual to group predictions:","text":"<ul> <li>Independence of patient journeys: The package assumes that an individual patient's presence in one part of ahospital system is independent of patients elsewhere</li> <li>Bernoulli outcome model: Each patient outcome is modelled as a Bernoulli trial with its own probability, and the package computes a probability distribution for the sum of these independent trials.</li> <li>Different levels of aggregation: The package can calculate probabilities for compound events (such as the probability of a patient being admitted, assigned to a specific specialty if admitted, and being admitted within the prediction window) and separate distributions for patient subgroups (like distributions by age or gender). In all cases, the independence assumption between patients is maintained.</li> </ul>"},{"location":"#getting-started","title":"Getting started","text":"<ul> <li>Exploration: Start with the notebooks README to get an outline of what is included in the notebooks, and read the package README or the documentation for an overview of the Python package.</li> <li>Installation: Follow the instructions below to set up the environment and install necessary dependencies in your own environment.</li> <li>Configuration: Repurpose config.yaml to configure the package to your own data and user requirements.</li> </ul>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p><code>patientflow</code> requires Python 3.10.</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install <code>patientflow</code> directly from PyPI:</p> <pre><code>pip install patientflow\n</code></pre> <p>To access the example notebooks and synthetic data, clone the repository:</p> <pre><code>git clone https://github.com/ucl-coru/patientflow.git\ncd patientflow\n</code></pre>"},{"location":"#development-installation-optional","title":"Development Installation (optional)","text":"<p>If you want to contribute or modify the code, or run documentation locally, install the development and documentation dependencies:</p> <pre><code># For contributors (includes development tools, documentation, and testing)\npip install -e \".[dev,docs,test]\"\n\n# For specific purposes only:\n# For development tools (linting, formatting, etc.)\npip install -e \".[dev]\"\n\n# For building documentation\npip install -e \".[docs]\"\n\n# For running tests\npip install -e \".[test]\"\n</code></pre> <p>Navigate to the patientflow folder and run tests to confirm that the installation worked correctly. This command will only work from the root repository. (To date, this has only been tested on Linux and Mac OS machines. If you are running Windows, there may be errors we don't know about. Please raise an issue on Github in that case.)</p> <pre><code>pytest\n</code></pre> <p>If you get errors running the pytest command, there may be other installations needed on your local machine.</p>"},{"location":"#building-and-viewing-documentation-optional","title":"Building and Viewing Documentation (optional)","text":"<p>After installing the documentation dependencies, you can build and view the documentation locally:</p> <pre><code># Build and serve the documentation with live reloading\nmkdocs serve\n\n# Or just build the documentation\nmkdocs build\n</code></pre> <p>The documentation will be available at http://127.0.0.1:8000/ when using <code>mkdocs serve</code>.</p>"},{"location":"#using-the-notebooks-in-this-repository","title":"Using the notebooks in this repository","text":"<p>The notebooks in this repository demonstrate the use of some of the functions provided in <code>patientflow</code>. The cell output shows the results of running the notebooks. If you want to run them yourself, you have two options</p> <ul> <li>step through the notebooks using the real patient datasets that were used to prepare them. For this you need to request access on Zenodo to real patient data</li> <li>step through the notebooks using synthetic data. You will need to copy the two csv files from <code>data-synthetic</code>into your <code>data-public</code> folder or change the source in the each notebook. If you use synthetic data, you will not see the same cell output.</li> </ul>"},{"location":"#about-the-uclh-implementation","title":"About the UCLH implementation","text":"<p>This repository includes a set of notebooks (prefixed with 4) that show a fully worked example of the implementation of the patientflow package at University College London Hospitals (UCLH). As noted above, please request access to the UCLH dataset via Zenodo.</p> <p>There is also a Python script that illustrates the training of the models that predict emergency demand at UCLH and saves them in your local environment using following commands (by default this will run with the synthetic data in its current location; change the <code>data_folder_name</code> parameter if you have downloaded the Zenodo dataset in <code>data-public</code>)</p> <pre><code>cd src\npython -m patientflow.train.emergency_demand --data_folder_name=data-synthetic\n</code></pre> <p>The <code>data_folder_name</code>argument specifies the name of the folder containing data. The function expects this folder to be directly below the root of the repository.</p>"},{"location":"#contributing-to-patientflow","title":"Contributing to PatientFlow","text":"<p>We welcome contributions to the patientflow project. To contribute, follow the instructions below.</p>"},{"location":"#development-workflow","title":"Development Workflow","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally and set up your development environment following the installation instructions above, making sure to install the development dependencies.</li> <li>Create a new branch for your changes:    <code>sh    git checkout -b feature/your-feature-name</code></li> <li>Make your changes following the code style guidelines</li> <li>Run tests as described in the installation section to ensure your changes don't break existing functionality</li> <li>Update documentation if needed using the documentation tools mentioned above</li> <li>Commit your changes with a descriptive message</li> </ol>"},{"location":"#code-style-guidelines","title":"Code Style Guidelines","text":"<ul> <li>Follow PEP 8 guidelines for Python code</li> <li>Use type hints where appropriate</li> <li>Write docstrings for all functions, classes, and modules</li> <li>Add unit tests for new functionality</li> </ul>"},{"location":"#submitting-your-contribution","title":"Submitting Your Contribution","text":"<ol> <li>Push your changes to your forked repository:    <code>sh    git push origin feature/your-feature-name</code></li> <li>Open a pull request from your fork to the main repository</li> <li>Provide a clear title and description</li> <li>Reference any relevant issues</li> <li>Include screenshots if applicable</li> <li>Address any feedback or review comments</li> </ol>"},{"location":"#reporting-issues","title":"Reporting Issues","text":"<p>If you find a bug or have a suggestion:</p> <ol> <li>Check existing issues to avoid duplicates</li> <li>Open a new issue describing:</li> <li>What you expected to happen</li> <li>What actually happened</li> <li>Steps to reproduce</li> <li>Your environment details (OS, Python version, etc.)</li> </ol> <p>Thank you for contributing!</p>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li> Initial Research</li> <li> Minimum viable product</li> <li> Alpha Release (PyPI Package) &lt;-- You are Here</li> <li> Feature-Complete Release</li> </ul>"},{"location":"#project-team","title":"Project Team","text":"<ul> <li>Dr Zella King, Clinical Operational Research Unit (CORU), University College London (UCL)(zella.king@ucl.ac.uk)</li> <li>Jon Gillham, Institute of Health Informatics, UCL</li> <li>Professor Martin Utley, Clinical Operational Research Unit, UCL</li> <li>Matt Graham, Advanced Research Computing, UCL</li> <li>Professor Sonya Crowe, Clinical Operational Research Unit, UCL</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>The py-pi template developed by Tom Monks inspired us to create a Python package. This repository is based on a template developed by the Centre for Advanced Research Computing, University College London. We are grateful to Lawrence Lai for creation of the synthetic dataset, and to Sara Lundell for her extensive work piloting the package for use at Sahlgrenska University Hospital, Gothenburg, Sweden.</p> <p>The development of this repository/package was funded by UCL's QR Policy Support Fund, which is funded by Research England.</p>"},{"location":"LICENSE/","title":"MIT License","text":"<p>Copyright (c) 2024 Zella King</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"api/","title":"API reference","text":"<p>PatientFlow: A package for predicting short-term hospital bed demand.</p> <p>This package provides tools and models for analysing patient flow data and making predictions about emergency demand, elective demand, and hospital discharges.</p>"},{"location":"api/#patientflow.aggregate","title":"<code>aggregate</code>","text":"<p>Aggregate Prediction From Patient-Level Probabilities</p> <p>This submodule provides functions to aggregate patient-level predicted probabilities into a probability distribution. The module uses symbolic mathematics to generate and manipulate expressions, enabling the computation of aggregate probabilities based on individual patient-level predictions.</p> <p>Functions:</p> Name Description <code>create_symbols : function</code> <p>Generate a sequence of symbolic objects intended for use in mathematical expressions.</p> <code>compute_core_expression : function</code> <p>Compute a symbolic expression involving a basic mathematical operation with a symbol and a constant.</p> <code>build_expression : function</code> <p>Construct a cumulative product expression by combining individual symbolic expressions.</p> <code>expression_subs : function</code> <p>Substitute values into a symbolic expression based on a mapping from symbols to predictions.</p> <code>return_coeff : function</code> <p>Extract the coefficient of a specified power from an expanded symbolic expression.</p> <code>model_input_to_pred_proba : function</code> <p>Use a predictive model to convert model input data into predicted probabilities.</p> <code>pred_proba_to_agg_predicted : function</code> <p>Convert individual probability predictions into aggregate predicted probability distribution using optional weights.</p> <code>get_prob_dist_for_prediction_moment : function</code> <p>Calculate both predicted distributions and observed values for a given date using test data.</p> <code>get_prob_dist : function</code> <p>Calculate probability distributions for each snapshot date based on given model predictions.</p> <code>get_prob_dist_without_patient_snapshots : function</code> <p>Calculate probability distributions for each snapshot date using an EmpiricalSurvivalPredictor.</p>"},{"location":"api/#patientflow.aggregate.build_expression","title":"<code>build_expression(syms, n)</code>","text":"<p>Construct a cumulative product expression by combining individual symbolic expressions.</p> <p>Parameters:</p> Name Type Description Default <code>syms</code> <code>iterable</code> <p>Iterable containing symbols to use in the expressions.</p> required <code>n</code> <code>int</code> <p>The number of terms to include in the cumulative product.</p> required <p>Returns:</p> Type Description <code>Expr</code> <p>The cumulative product of the expressions.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def build_expression(syms, n):\n    \"\"\"\n    Construct a cumulative product expression by combining individual symbolic expressions.\n\n    Parameters\n    ----------\n    syms : iterable\n        Iterable containing symbols to use in the expressions.\n    n : int\n        The number of terms to include in the cumulative product.\n\n    Returns\n    -------\n    Expr\n        The cumulative product of the expressions.\n\n    \"\"\"\n    s = sym.Symbol(\"s\")\n    expression = 1\n    for i in range(n):\n        expression *= compute_core_expression(syms[i], s)\n    return expression\n</code></pre>"},{"location":"api/#patientflow.aggregate.compute_core_expression","title":"<code>compute_core_expression(ri, s)</code>","text":"<p>Compute a symbolic expression involving a basic mathematical operation with a symbol and a constant.</p> <p>Parameters:</p> Name Type Description Default <code>ri</code> <code>float</code> <p>The constant value to substitute into the expression.</p> required <code>s</code> <code>Symbol</code> <p>The symbolic object used in the expression.</p> required <p>Returns:</p> Type Description <code>Expr</code> <p>The symbolic expression after substitution.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def compute_core_expression(ri, s):\n    \"\"\"\n    Compute a symbolic expression involving a basic mathematical operation with a symbol and a constant.\n\n    Parameters\n    ----------\n    ri : float\n        The constant value to substitute into the expression.\n    s : Symbol\n        The symbolic object used in the expression.\n\n    Returns\n    -------\n    Expr\n        The symbolic expression after substitution.\n\n    \"\"\"\n    r = sym.Symbol(\"r\")\n    core_expression = (1 - r) + r * s\n    return core_expression.subs({r: ri})\n</code></pre>"},{"location":"api/#patientflow.aggregate.create_symbols","title":"<code>create_symbols(n)</code>","text":"<p>Generate a sequence of symbolic objects intended for use in mathematical expressions.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of symbols to create.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple containing the generated symbolic objects.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def create_symbols(n):\n    \"\"\"\n    Generate a sequence of symbolic objects intended for use in mathematical expressions.\n\n    Parameters\n    ----------\n    n : int\n        Number of symbols to create.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the generated symbolic objects.\n\n    \"\"\"\n    return symbols(f\"r0:{n}\")\n</code></pre>"},{"location":"api/#patientflow.aggregate.expression_subs","title":"<code>expression_subs(expression, n, predictions)</code>","text":"<p>Substitute values into a symbolic expression based on a mapping from symbols to predictions.</p> <p>Parameters:</p> Name Type Description Default <code>expression</code> <code>Expr</code> <p>The symbolic expression to perform substitution on.</p> required <code>n</code> <code>int</code> <p>Number of symbols and corresponding predictions.</p> required <code>predictions</code> <code>list</code> <p>List of numerical predictions to substitute.</p> required <p>Returns:</p> Type Description <code>Expr</code> <p>The expression after performing the substitution.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def expression_subs(expression, n, predictions):\n    \"\"\"\n    Substitute values into a symbolic expression based on a mapping from symbols to predictions.\n\n    Parameters\n    ----------\n    expression : Expr\n        The symbolic expression to perform substitution on.\n    n : int\n        Number of symbols and corresponding predictions.\n    predictions : list\n        List of numerical predictions to substitute.\n\n    Returns\n    -------\n    Expr\n        The expression after performing the substitution.\n\n    \"\"\"\n    syms = create_symbols(n)\n    substitution = dict(zip(syms, predictions))\n    return expression.subs(substitution)\n</code></pre>"},{"location":"api/#patientflow.aggregate.get_prob_dist","title":"<code>get_prob_dist(snapshots_dict, X_test, y_test, model, weights=None, verbose=False, category_filter=None, normal_approx_threshold=30)</code>","text":"<p>Calculate probability distributions for each snapshot date based on given model predictions.</p> <p>Parameters:</p> Name Type Description Default <code>snapshots_dict</code> <code>dict</code> <p>A dictionary mapping snapshot dates to indices in <code>X_test</code> and <code>y_test</code>. Must have datetime.date objects as keys and lists of indices as values.</p> required <code>X_test</code> <code>DataFrame or array - like</code> <p>Input test data to be passed to the model.</p> required <code>y_test</code> <code>array - like</code> <p>Observed target values.</p> required <code>model</code> <code>object or TrainedClassifier</code> <p>Either a predictive model which provides a <code>predict_proba</code> method, or a TrainedClassifier object containing a pipeline.</p> required <code>weights</code> <code>Series</code> <p>A Series containing weights for the test data points, which may influence the prediction, by default None. If provided, the weights should be indexed similarly to <code>X_test</code> and <code>y_test</code>.</p> <code>None</code> <code>verbose</code> <code>(bool, optional(default=False))</code> <p>If True, print progress information.</p> <code>False</code> <code>category_filter</code> <code>array - like</code> <p>Boolean mask indicating which samples belong to the specific outcome category being analyzed. Should be the same length as y_test.</p> <code>None</code> <code>normal_approx_threshold</code> <code>(int, optional(default=30))</code> <p>If the number of rows in a snapshot exceeds this threshold, use a Normal distribution approximation. Set to None or a very large number to always use the exact symbolic computation.</p> <code>30</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary mapping snapshot dates to probability distributions.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If snapshots_dict is not properly formatted or empty. If model has no predict_proba method and is not a TrainedClassifier.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def get_prob_dist(\n    snapshots_dict,\n    X_test,\n    y_test,\n    model,\n    weights=None,\n    verbose=False,\n    category_filter=None,\n    normal_approx_threshold=30,\n):\n    \"\"\"\n    Calculate probability distributions for each snapshot date based on given model predictions.\n\n    Parameters\n    ----------\n    snapshots_dict : dict\n        A dictionary mapping snapshot dates to indices in `X_test` and `y_test`.\n        Must have datetime.date objects as keys and lists of indices as values.\n    X_test : DataFrame or array-like\n        Input test data to be passed to the model.\n    y_test : array-like\n        Observed target values.\n    model : object or TrainedClassifier\n        Either a predictive model which provides a `predict_proba` method,\n        or a TrainedClassifier object containing a pipeline.\n    weights : pandas.Series, optional\n        A Series containing weights for the test data points, which may influence the prediction,\n        by default None. If provided, the weights should be indexed similarly to `X_test` and `y_test`.\n    verbose : bool, optional (default=False)\n        If True, print progress information.\n    category_filter : array-like, optional\n        Boolean mask indicating which samples belong to the specific outcome category being analyzed.\n        Should be the same length as y_test.\n    normal_approx_threshold : int, optional (default=30)\n        If the number of rows in a snapshot exceeds this threshold, use a Normal distribution approximation.\n        Set to None or a very large number to always use the exact symbolic computation.\n\n    Returns\n    -------\n    dict\n        A dictionary mapping snapshot dates to probability distributions.\n\n    Raises\n    ------\n    ValueError\n        If snapshots_dict is not properly formatted or empty.\n        If model has no predict_proba method and is not a TrainedClassifier.\n    \"\"\"\n    # Validate snapshots_dict format\n    if not snapshots_dict:\n        raise ValueError(\"snapshots_dict cannot be empty\")\n\n    for dt, indices in snapshots_dict.items():\n        if not isinstance(dt, date):\n            raise ValueError(\n                f\"snapshots_dict keys must be datetime.date objects, got {type(dt)}\"\n            )\n        if not isinstance(indices, list):\n            raise ValueError(\n                f\"snapshots_dict values must be lists, got {type(indices)}\"\n            )\n        if indices and not all(isinstance(idx, int) for idx in indices):\n            raise ValueError(\"All indices in snapshots_dict must be integers\")\n\n    # Extract pipeline if model is a TrainedClassifier\n    if hasattr(model, \"calibrated_pipeline\") and model.calibrated_pipeline is not None:\n        model = model.calibrated_pipeline\n    elif hasattr(model, \"pipeline\"):\n        model = model.pipeline\n    # Validate that model has predict_proba method\n    elif not hasattr(model, \"predict_proba\"):\n        raise ValueError(\n            \"Model must either be a TrainedClassifier or have a predict_proba method\"\n        )\n\n    prob_dist_dict = {}\n    if verbose:\n        print(\n            f\"Calculating probability distributions for {len(snapshots_dict)} snapshot dates\"\n        )\n\n        if len(snapshots_dict) &gt; 10:\n            print(\"This may take a minute or more\")\n\n    # Initialize a counter for notifying the user every 10 snapshot dates processed\n    count = 0\n\n    for dt, snapshots_to_include in snapshots_dict.items():\n        if len(snapshots_to_include) == 0:\n            # Create an empty dictionary for the current snapshot date\n            prob_dist_dict[dt] = {\n                \"agg_predicted\": pd.DataFrame({\"agg_proba\": [1]}, index=[0]),\n                \"agg_observed\": 0,\n            }\n        else:\n            # Ensure the lengths of test features and outcomes are equal\n            assert len(X_test.loc[snapshots_to_include]) == len(\n                y_test.loc[snapshots_to_include]\n            ), \"Mismatch in lengths of X_test and y_test snapshots.\"\n\n            if weights is None:\n                prediction_moment_weights = None\n            else:\n                prediction_moment_weights = weights.loc[snapshots_to_include].values\n\n            # Apply category filter\n            if category_filter is None:\n                prediction_moment_category_filter = None\n            else:\n                prediction_moment_category_filter = category_filter.loc[\n                    snapshots_to_include\n                ]\n\n            # Pass the normal_approx_threshold to get_prob_dist_for_prediction_moment\n            prob_dist_dict[dt] = get_prob_dist_for_prediction_moment(\n                X_test=X_test.loc[snapshots_to_include],\n                y_test=y_test.loc[snapshots_to_include],\n                model=model,\n                weights=prediction_moment_weights,\n                category_filter=prediction_moment_category_filter,\n                normal_approx_threshold=normal_approx_threshold,\n            )\n\n        # Increment the counter and notify the user every 10 snapshot dates processed\n        count += 1\n        if verbose and count % 10 == 0 and count != len(snapshots_dict):\n            print(f\"Processed {count} snapshot dates\")\n\n    if verbose:\n        print(f\"Processed {len(snapshots_dict)} snapshot dates\")\n\n    return prob_dist_dict\n</code></pre>"},{"location":"api/#patientflow.aggregate.get_prob_dist_for_prediction_moment","title":"<code>get_prob_dist_for_prediction_moment(X_test, model, weights=None, inference_time=False, y_test=None, category_filter=None, normal_approx_threshold=30)</code>","text":"<p>Calculate both predicted distributions and observed values for a given date using test data.</p> <p>Parameters:</p> Name Type Description Default <code>X_test</code> <code>array - like</code> <p>Test features for a specific snapshot date.</p> required <code>model</code> <code>object or TrainedClassifier</code> <p>Either a predictive model which provides a <code>predict_proba</code> method, or a TrainedClassifier object containing a pipeline.</p> required <code>weights</code> <code>array - like</code> <p>Weights to apply to the predictions for aggregate calculation.</p> <code>None</code> <code>inference_time</code> <code>(bool, optional(default=False))</code> <p>If True, do not calculate or return actual aggregate.</p> <code>False</code> <code>y_test</code> <code>array - like</code> <p>Actual outcomes corresponding to the test features. Required if inference_time is False.</p> <code>None</code> <code>category_filter</code> <code>array - like</code> <p>Boolean mask indicating which samples belong to the specific outcome category being analyzed. Should be the same length as y_test.</p> <code>None</code> <code>normal_approx_threshold</code> <code>(int, optional(default=30))</code> <p>If the number of rows in X_test exceeds this threshold, use a Normal distribution approximation. Set to None or a very large number to always use the exact symbolic computation.</p> <code>30</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with keys 'agg_predicted' and, if inference_time is False, 'agg_observed'.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If y_test is not provided when inference_time is False. If model has no predict_proba method and is not a TrainedClassifier.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def get_prob_dist_for_prediction_moment(\n    X_test,\n    model,\n    weights=None,\n    inference_time=False,\n    y_test=None,\n    category_filter=None,\n    normal_approx_threshold=30,\n):\n    \"\"\"\n    Calculate both predicted distributions and observed values for a given date using test data.\n\n    Parameters\n    ----------\n    X_test : array-like\n        Test features for a specific snapshot date.\n    model : object or TrainedClassifier\n        Either a predictive model which provides a `predict_proba` method,\n        or a TrainedClassifier object containing a pipeline.\n    weights : array-like, optional\n        Weights to apply to the predictions for aggregate calculation.\n    inference_time : bool, optional (default=False)\n        If True, do not calculate or return actual aggregate.\n    y_test : array-like, optional\n        Actual outcomes corresponding to the test features. Required if inference_time is False.\n    category_filter : array-like, optional\n        Boolean mask indicating which samples belong to the specific outcome category being analyzed.\n        Should be the same length as y_test.\n    normal_approx_threshold : int, optional (default=30)\n        If the number of rows in X_test exceeds this threshold, use a Normal distribution approximation.\n        Set to None or a very large number to always use the exact symbolic computation.\n\n    Returns\n    -------\n    dict\n        A dictionary with keys 'agg_predicted' and, if inference_time is False, 'agg_observed'.\n\n    Raises\n    ------\n    ValueError\n        If y_test is not provided when inference_time is False.\n        If model has no predict_proba method and is not a TrainedClassifier.\n    \"\"\"\n    if not inference_time and y_test is None:\n        raise ValueError(\"y_test must be provided if inference_time is False.\")\n\n    # Extract pipeline if model is a TrainedClassifier\n    if hasattr(model, \"calibrated_pipeline\") and model.calibrated_pipeline is not None:\n        model = model.calibrated_pipeline\n    elif hasattr(model, \"pipeline\"):\n        model = model.pipeline\n    # Validate that model has predict_proba method\n    elif not hasattr(model, \"predict_proba\"):\n        raise ValueError(\n            \"Model must either be a TrainedClassifier or have a predict_proba method\"\n        )\n\n    prediction_moment_dict = {}\n\n    if len(X_test) &gt; 0:\n        pred_proba = model_input_to_pred_proba(X_test, model)\n        agg_predicted = pred_proba_to_agg_predicted(\n            pred_proba, weights, normal_approx_threshold\n        )\n        prediction_moment_dict[\"agg_predicted\"] = agg_predicted\n\n        if not inference_time:\n            # Apply category filter when calculating observed sum\n            if category_filter is None:\n                prediction_moment_dict[\"agg_observed\"] = sum(y_test)\n            else:\n                prediction_moment_dict[\"agg_observed\"] = sum(y_test &amp; category_filter)\n    else:\n        prediction_moment_dict[\"agg_predicted\"] = pd.DataFrame(\n            {\"agg_proba\": [1]}, index=[0]\n        )\n        if not inference_time:\n            prediction_moment_dict[\"agg_observed\"] = 0\n\n    return prediction_moment_dict\n</code></pre>"},{"location":"api/#patientflow.aggregate.get_prob_dist_using_survival_curve","title":"<code>get_prob_dist_using_survival_curve(snapshot_dates, test_visits, category, prediction_time, prediction_window, start_time_col, end_time_col, model, verbose=False)</code>","text":"<p>Calculate probability distributions for each snapshot date using an EmpiricalIncomingAdmissionPredictor.</p> <p>Parameters:</p> Name Type Description Default <code>snapshot_dates</code> <code>array - like</code> <p>Array of dates for which to calculate probability distributions.</p> required <code>test_visits</code> <code>DataFrame</code> <p>DataFrame containing test visit data. Must have either: - start_time_col as a column and end_time_col as a column, or - start_time_col as the index and end_time_col as a column</p> required <code>category</code> <code>str</code> <p>Category to use for predictions (e.g., 'medical', 'surgical')</p> required <code>prediction_time</code> <code>tuple</code> <p>Tuple of (hour, minute) representing the time of day for predictions</p> required <code>prediction_window</code> <code>timedelta</code> <p>The prediction window duration</p> required <code>start_time_col</code> <code>str</code> <p>Name of the column containing start times (or index name if using index)</p> required <code>end_time_col</code> <code>str</code> <p>Name of the column containing end times</p> required <code>model</code> <code>EmpiricalSurvivalPredictor</code> <p>A fitted instance of EmpiricalSurvivalPredictor</p> required <code>verbose</code> <code>(bool, optional(default=False))</code> <p>If True, print progress information</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary mapping snapshot dates to probability distributions.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If test_visits does not have the required columns or if model is not fitted.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def get_prob_dist_using_survival_curve(\n    snapshot_dates: List[date],\n    test_visits: pd.DataFrame,\n    category: str,\n    prediction_time: Tuple[int, int],\n    prediction_window: timedelta,\n    start_time_col: str,\n    end_time_col: str,\n    model: EmpiricalIncomingAdmissionPredictor,\n    verbose=False,\n):\n    \"\"\"\n    Calculate probability distributions for each snapshot date using an EmpiricalIncomingAdmissionPredictor.\n\n    Parameters\n    ----------\n    snapshot_dates : array-like\n        Array of dates for which to calculate probability distributions.\n    test_visits : pandas.DataFrame\n        DataFrame containing test visit data. Must have either:\n        - start_time_col as a column and end_time_col as a column, or\n        - start_time_col as the index and end_time_col as a column\n    category : str\n        Category to use for predictions (e.g., 'medical', 'surgical')\n    prediction_time : tuple\n        Tuple of (hour, minute) representing the time of day for predictions\n    prediction_window : timedelta\n        The prediction window duration\n    start_time_col : str\n        Name of the column containing start times (or index name if using index)\n    end_time_col : str\n        Name of the column containing end times\n    model : EmpiricalSurvivalPredictor\n        A fitted instance of EmpiricalSurvivalPredictor\n    verbose : bool, optional (default=False)\n        If True, print progress information\n\n    Returns\n    -------\n    dict\n        A dictionary mapping snapshot dates to probability distributions.\n\n    Raises\n    ------\n    ValueError\n        If test_visits does not have the required columns or if model is not fitted.\n    \"\"\"\n\n    # Validate test_visits has required columns\n    if start_time_col in test_visits.columns:\n        # start_time_col is a regular column\n        if end_time_col not in test_visits.columns:\n            raise ValueError(f\"Column '{end_time_col}' not found in DataFrame\")\n    else:\n        # Check if start_time_col is the index\n        if test_visits.index.name != start_time_col:\n            raise ValueError(\n                f\"'{start_time_col}' not found in DataFrame columns or index (index.name is '{test_visits.index.name}')\"\n            )\n        if end_time_col not in test_visits.columns:\n            raise ValueError(f\"Column '{end_time_col}' not found in DataFrame\")\n\n    # Validate model is fitted\n    if not hasattr(model, \"survival_df\") or model.survival_df is None:\n        raise ValueError(\"Model must be fitted before calling get_prob_dist_empirical\")\n\n    prob_dist_dict = {}\n    if verbose:\n        print(\n            f\"Calculating probability distributions for {len(snapshot_dates)} snapshot dates\"\n        )\n\n    # Create prediction context that will be the same for all dates\n    prediction_context = {category: {\"prediction_time\": prediction_time}}\n\n    for dt in snapshot_dates:\n        # Create prediction moment by combining snapshot date and prediction time\n        prediction_moment = datetime.combine(\n            dt, time(prediction_time[0], prediction_time[1])\n        )\n        # Convert to UTC if the test_visits timestamps are timezone-aware\n        if start_time_col in test_visits.columns:\n            if test_visits[start_time_col].dt.tz is not None:\n                prediction_moment = prediction_moment.replace(tzinfo=timezone.utc)\n        else:\n            if test_visits.index.tz is not None:\n                prediction_moment = prediction_moment.replace(tzinfo=timezone.utc)\n\n        # Get predictions from model\n        predictions = model.predict(prediction_context)\n        prob_dist_dict[dt] = {\"agg_predicted\": predictions[category]}\n\n        # Calculate observed values\n        if start_time_col in test_visits.columns:\n            # start_time_col is a regular column\n            mask = (test_visits[start_time_col] &gt; prediction_moment) &amp; (\n                test_visits[end_time_col] &lt;= prediction_moment + prediction_window\n            )\n        else:\n            # start_time_col is the index\n            mask = (test_visits.index &gt; prediction_moment) &amp; (\n                test_visits[end_time_col] &lt;= prediction_moment + prediction_window\n            )\n        nrow = mask.sum()\n        prob_dist_dict[dt][\"agg_observed\"] = int(nrow) if nrow &gt; 0 else 0\n\n    if verbose:\n        print(f\"Processed {len(snapshot_dates)} snapshot dates\")\n\n    return prob_dist_dict\n</code></pre>"},{"location":"api/#patientflow.aggregate.model_input_to_pred_proba","title":"<code>model_input_to_pred_proba(model_input, model)</code>","text":"<p>Use a predictive model to convert model input data into predicted probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>model_input</code> <code>array - like</code> <p>The input data to the model, typically as features used for predictions.</p> required <code>model</code> <code>object</code> <p>A model object with a <code>predict_proba</code> method that computes probability estimates.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame containing the predicted probabilities for the positive class, with one column labeled 'pred_proba'.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def model_input_to_pred_proba(model_input, model):\n    \"\"\"\n    Use a predictive model to convert model input data into predicted probabilities.\n\n    Parameters\n    ----------\n    model_input : array-like\n        The input data to the model, typically as features used for predictions.\n    model : object\n        A model object with a `predict_proba` method that computes probability estimates.\n\n    Returns\n    -------\n    DataFrame\n        A pandas DataFrame containing the predicted probabilities for the positive class,\n        with one column labeled 'pred_proba'.\n\n    \"\"\"\n    if len(model_input) == 0:\n        return pd.DataFrame(columns=[\"pred_proba\"])\n    else:\n        predictions = model.predict_proba(model_input)[:, 1]\n        return pd.DataFrame(\n            predictions, index=model_input.index, columns=[\"pred_proba\"]\n        )\n</code></pre>"},{"location":"api/#patientflow.aggregate.pred_proba_to_agg_predicted","title":"<code>pred_proba_to_agg_predicted(predictions_proba, weights=None, normal_approx_threshold=30)</code>","text":"<p>Convert individual probability predictions into aggregate predicted probability distribution using optional weights. Uses a Normal approximation for large datasets (&gt; normal_approx_threshold) for better performance.</p> <p>Parameters:</p> Name Type Description Default <code>predictions_proba</code> <code>DataFrame</code> <p>A DataFrame containing the probability predictions; must have a single column named 'pred_proba'.</p> required <code>weights</code> <code>array - like</code> <p>An array of weights, of the same length as the DataFrame rows, to apply to each prediction.</p> <code>None</code> <code>normal_approx_threshold</code> <code>(int, optional(default=30))</code> <p>If the number of rows in predictions_proba exceeds this threshold, use a Normal distribution approximation. Set to None or a very large number to always use the exact symbolic computation.</p> <code>30</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame with a single column 'agg_proba' showing the aggregated probability, indexed from 0 to n, where n is the number of predictions.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def pred_proba_to_agg_predicted(\n    predictions_proba, weights=None, normal_approx_threshold=30\n):\n    \"\"\"\n    Convert individual probability predictions into aggregate predicted probability distribution using optional weights.\n    Uses a Normal approximation for large datasets (&gt; normal_approx_threshold) for better performance.\n\n    Parameters\n    ----------\n    predictions_proba : DataFrame\n        A DataFrame containing the probability predictions; must have a single column named 'pred_proba'.\n    weights : array-like, optional\n        An array of weights, of the same length as the DataFrame rows, to apply to each prediction.\n    normal_approx_threshold : int, optional (default=30)\n        If the number of rows in predictions_proba exceeds this threshold, use a Normal distribution approximation.\n        Set to None or a very large number to always use the exact symbolic computation.\n\n    Returns\n    -------\n    DataFrame\n        A DataFrame with a single column 'agg_proba' showing the aggregated probability,\n        indexed from 0 to n, where n is the number of predictions.\n    \"\"\"\n    n = len(predictions_proba)\n\n    if n == 0:\n        agg_predicted_dict = {0: 1}\n    elif normal_approx_threshold is not None and n &gt; normal_approx_threshold:\n        # Apply a normal approximation for large datasets\n        import numpy as np\n        from scipy.stats import norm\n\n        # Apply weights if provided\n        if weights is not None:\n            probs = predictions_proba[\"pred_proba\"].values * weights\n        else:\n            probs = predictions_proba[\"pred_proba\"].values\n\n        # Calculate mean and variance for the normal approximation\n        # For a sum of Bernoulli variables, mean = sum of probabilities\n        mean = probs.sum()\n        # Variance = sum of p_i * (1-p_i)\n        variance = (probs * (1 - probs)).sum()\n\n        # Handle the case where variance is zero (all probabilities are 0 or 1)\n        if variance == 0:\n            # If variance is zero, all probabilities are the same (either all 0 or all 1)\n            # The distribution is deterministic - all probability mass is at the mean\n            agg_predicted_dict = {int(round(mean)): 1.0}\n        else:\n            # Generate probabilities for each possible count using normal approximation\n            counts = np.arange(n + 1)\n            agg_predicted_dict = {}\n\n            for i in counts:\n                # Probability that count = i is the probability that a normal RV falls between i-0.5 and i+0.5\n                if i == 0:\n                    p = norm.cdf(0.5, loc=mean, scale=np.sqrt(variance))\n                elif i == n:\n                    p = 1 - norm.cdf(n - 0.5, loc=mean, scale=np.sqrt(variance))\n                else:\n                    p = norm.cdf(i + 0.5, loc=mean, scale=np.sqrt(variance)) - norm.cdf(\n                        i - 0.5, loc=mean, scale=np.sqrt(variance)\n                    )\n                agg_predicted_dict[i] = p\n\n            # Normalize to ensure the probabilities sum to 1\n            total = sum(agg_predicted_dict.values())\n            if total &gt; 0:\n                for i in agg_predicted_dict:\n                    agg_predicted_dict[i] /= total\n            else:\n                # If all probabilities are zero, set a uniform distribution\n                n = len(agg_predicted_dict)\n                for i in agg_predicted_dict:\n                    agg_predicted_dict[i] = 1.0 / n\n    else:\n        # Use the original symbolic computation for smaller datasets\n        local_proba = predictions_proba.copy()\n        if weights is not None:\n            local_proba[\"pred_proba\"] *= weights\n\n        syms = create_symbols(n)\n        expression = build_expression(syms, n)\n        expression = expression_subs(expression, n, local_proba[\"pred_proba\"])\n        agg_predicted_dict = {i: return_coeff(expression, i) for i in range(n + 1)}\n\n    agg_predicted = pd.DataFrame.from_dict(\n        agg_predicted_dict, orient=\"index\", columns=[\"agg_proba\"]\n    )\n    return agg_predicted\n</code></pre>"},{"location":"api/#patientflow.aggregate.return_coeff","title":"<code>return_coeff(expression, i)</code>","text":"<p>Extract the coefficient of a specified power from an expanded symbolic expression.</p> <p>Parameters:</p> Name Type Description Default <code>expression</code> <code>Expr</code> <p>The expression to expand and extract from.</p> required <code>i</code> <code>int</code> <p>The power of the term whose coefficient is to be extracted.</p> required <p>Returns:</p> Type Description <code>number</code> <p>The coefficient of the specified power in the expression.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def return_coeff(expression, i):\n    \"\"\"\n    Extract the coefficient of a specified power from an expanded symbolic expression.\n\n    Parameters\n    ----------\n    expression : Expr\n        The expression to expand and extract from.\n    i : int\n        The power of the term whose coefficient is to be extracted.\n\n    Returns\n    -------\n    number\n        The coefficient of the specified power in the expression.\n\n    \"\"\"\n    s = sym.Symbol(\"s\")\n    return expand(expression).coeff(s, i)\n</code></pre>"},{"location":"api/#patientflow.calculate","title":"<code>calculate</code>","text":"<p>Calculation module for patient flow metrics.</p> <p>This module provides functions for calculating various patient flow metrics such as arrival rates and admission probabilities within prediction windows.</p>"},{"location":"api/#patientflow.calculate.admission_in_prediction_window","title":"<code>admission_in_prediction_window</code>","text":"<p>This module provides functions to model and analyze a curve consisting of an exponential growth segment followed by an exponential decay segment. It includes functions to create the curve, calculate specific points on it, and evaluate probabilities based on its shape.</p> <p>Its intended use is to derive the probability of a patient being admitted to a hospital within a certain elapsed time after their arrival in the Emergency Department (ED), given the hospital's aspirations for the time it takes patients to be admitted. For this purpose, two points on the curve are required as parameters:</p> <pre><code>* (x1,y1) : The target proportion of patients y1 (eg 76%) who have been admitted or discharged by time x1 (eg 4 hours).\n* (x2, y2) : The time x2 by which all but a small proportion y2 of patients have been admitted.\n</code></pre> <p>It is assumed that values of y where x &lt; x1 is a growth curve grow exponentially towards x1 and that (x1,y1) the curve switches to a decay curve.</p> <p>Functions:</p> Name Description <code>growth_curve : function</code> <p>Calculate exponential growth at a point where x &lt; x1.</p> <code>decay_curve : function</code> <p>Calculate exponential decay at a point where x &gt;= x1.</p> <code>create_curve : function</code> <p>Generate a full curve with both growth and decay segments.</p> <code>get_y_from_aspirational_curve : function</code> <p>Read from the curve a value for y, the probability of being admitted, for a given moment x hours after arrival</p> <code>calculate_probability : function</code> <p>Compute the probability of a patient being admitted by the end of a prediction window, given how much time has elapsed since their arrival.</p> <code>get_survival_probability : function</code> <p>Calculate the probability of a patient still being in the ED after a certain time using survival curve data.</p>"},{"location":"api/#patientflow.calculate.admission_in_prediction_window.calculate_probability","title":"<code>calculate_probability(elapsed_los, prediction_window, x1, y1, x2, y2)</code>","text":"<p>Calculates the probability of an admission occurring within a specified prediction window after the moment of prediction, based on the patient's elapsed time in the ED prior to the moment of prediction and the length of the window</p> <p>Parameters:</p> Name Type Description Default <code>elapsed_los</code> <code>timedelta</code> <p>The elapsed time since the patient arrived at the ED.</p> required <code>prediction_window</code> <code>timedelta</code> <p>The duration of the prediction window after the point of prediction, for which the probability is calculated.</p> required <code>x1</code> <code>float</code> <p>The time target for the first key point on the curve.</p> required <code>y1</code> <code>float</code> <p>The proportion target for the first key point (e.g., 76% of patients admitted by time x1).</p> required <code>x2</code> <code>float</code> <p>The time target for the second key point on the curve.</p> required <code>y2</code> <code>float</code> <p>The proportion target for the second key point (e.g., 99% of patients admitted by time x2).</p> required <p>Returns:</p> Type Description <code>float</code> <p>The probability of the event occurring within the given prediction window.</p> Edge Case Handling <p>When elapsed_los is extremely high, such as values significantly greater than x2, the admission probability prior to the current time (<code>prob_admission_prior_to_now</code>) can reach 1.0 despite the curve being asymptotic. This scenario can cause computational errors when calculating the conditional probability, as it involves a division by zero. In such cases, this function directly returns a probability of 1.0, reflecting certainty of admission.</p> Example <p>Calculate the probability that a patient, who has already been in the ED for 3 hours, will be admitted in the next 2 hours. The ED targets that 76% of patients are admitted or discharged within 4 hours, and 99% within 12 hours.</p> <p>from datetime import timedelta calculate_probability(timedelta(hours=3), timedelta(hours=2), 4, 0.76, 12, 0.99)</p> Source code in <code>src/patientflow/calculate/admission_in_prediction_window.py</code> <pre><code>def calculate_probability(\n    elapsed_los: timedelta,\n    prediction_window: timedelta,\n    x1: float,\n    y1: float,\n    x2: float,\n    y2: float,\n):\n    \"\"\"\n    Calculates the probability of an admission occurring within a specified prediction window after the moment of prediction, based on the patient's elapsed time in the ED prior to the moment of prediction and the length of the window\n\n    Parameters\n    ----------\n    elapsed_los : timedelta\n        The elapsed time since the patient arrived at the ED.\n    prediction_window : timedelta\n        The duration of the prediction window after the point of prediction, for which the probability is calculated.\n    x1 : float\n        The time target for the first key point on the curve.\n    y1 : float\n        The proportion target for the first key point (e.g., 76% of patients admitted by time x1).\n    x2 : float\n        The time target for the second key point on the curve.\n    y2 : float\n        The proportion target for the second key point (e.g., 99% of patients admitted by time x2).\n\n    Returns\n    -------\n    float\n        The probability of the event occurring within the given prediction window.\n\n    Edge Case Handling\n    ------------------\n    When elapsed_los is extremely high, such as values significantly greater than x2, the admission probability prior to the current time (`prob_admission_prior_to_now`) can reach 1.0 despite the curve being asymptotic. This scenario can cause computational errors when calculating the conditional probability, as it involves a division by zero. In such cases, this function directly returns a probability of 1.0, reflecting certainty of admission.\n\n    Example\n    -------\n    Calculate the probability that a patient, who has already been in the ED for 3 hours, will be admitted in the next 2 hours. The ED targets that 76% of patients are admitted or discharged within 4 hours, and 99% within 12 hours.\n\n    &gt;&gt;&gt; from datetime import timedelta\n    &gt;&gt;&gt; calculate_probability(timedelta(hours=3), timedelta(hours=2), 4, 0.76, 12, 0.99)\n\n    \"\"\"\n    # Validate inputs\n    if not isinstance(elapsed_los, timedelta):\n        raise TypeError(\"elapsed_los must be a timedelta object\")\n    if not isinstance(prediction_window, timedelta):\n        raise TypeError(\"prediction_window must be a timedelta object\")\n\n    # Convert timedelta to hours\n    elapsed_hours = elapsed_los.total_seconds() / 3600\n    prediction_window_hours = prediction_window.total_seconds() / 3600\n\n    # Validate elapsed time to ensure it represents a reasonable time value in hours\n    if elapsed_hours &lt; 0:\n        raise ValueError(\n            \"elapsed_los must be non-negative (cannot have negative elapsed time)\"\n        )\n\n    if elapsed_hours &gt; 168:  # 168 hours = 1 week\n        warnings.warn(\n            \"elapsed_los appears to be longer than 168 hours (1 week). \"\n            \"Check that the units of elapsed_los are correct\"\n        )\n\n    if not np.isfinite(elapsed_hours):\n        raise ValueError(\"elapsed_los must be a finite time duration\")\n\n    # Validate prediction window to ensure it represents a reasonable time value in hours\n    if prediction_window_hours &lt; 0:\n        raise ValueError(\n            \"prediction_window must be non-negative (cannot have negative prediction window)\"\n        )\n\n    if prediction_window_hours &gt; 72:  # 72 hours = 3 days\n        warnings.warn(\n            \"prediction_window appears to be longer than 72 hours (3 days). \"\n            \"Check that the units of prediction_window are correct\"\n        )\n\n    if not np.isfinite(prediction_window_hours):\n        raise ValueError(\"prediction_window must be a finite time duration\")\n\n    # probability of still being in the ED now (a function of elapsed time since arrival)\n    prob_admission_prior_to_now = get_y_from_aspirational_curve(\n        elapsed_hours, x1, y1, x2, y2\n    )\n\n    # prob admission when adding the prediction window added to elapsed time since arrival\n    prob_admission_by_end_of_window = get_y_from_aspirational_curve(\n        elapsed_hours + prediction_window_hours, x1, y1, x2, y2\n    )\n\n    # Direct return for edge cases where `prob_admission_prior_to_now` reaches 1.0\n    if prob_admission_prior_to_now == 1:\n        return 1.0\n\n    # Calculate the conditional probability of admission within the prediction window\n    # given that the patient hasn't been admitted yet\n    conditional_prob = (\n        prob_admission_by_end_of_window - prob_admission_prior_to_now\n    ) / (1 - prob_admission_prior_to_now)\n\n    return conditional_prob\n</code></pre>"},{"location":"api/#patientflow.calculate.admission_in_prediction_window.create_curve","title":"<code>create_curve(x1, y1, x2, y2, a=0.01, generate_values=False)</code>","text":"<p>Generates parameters for an exponential growth and decay curve. Optionally generates x-values and corresponding y-values across a default or specified range.</p> <p>Parameters:</p> Name Type Description Default <code>x1</code> <code>float</code> <p>The x-value where the curve transitions from growth to decay.</p> required <code>y1</code> <code>float</code> <p>The y-value at the transition point x1.</p> required <code>x2</code> <code>float</code> <p>The x-value defining the end of the decay curve for calculation purposes.</p> required <code>y2</code> <code>float</code> <p>The y-value at x2, intended to fine-tune the decay rate.</p> required <code>a</code> <code>float</code> <p>The initial value coefficient for the growth curve, defaults to 0.01.</p> <code>0.01</code> <code>generate_values</code> <code>bool</code> <p>Flag to determine whether to generate x-values and y-values for visualization purposes.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple</code> <p>If generate_values is False, returns (gamma, lamda, a). If generate_values is True, returns (gamma, lamda, a, x_values, y_values).</p> Source code in <code>src/patientflow/calculate/admission_in_prediction_window.py</code> <pre><code>def create_curve(x1, y1, x2, y2, a=0.01, generate_values=False):\n    \"\"\"\n    Generates parameters for an exponential growth and decay curve.\n    Optionally generates x-values and corresponding y-values across a default or specified range.\n\n    Parameters\n    ----------\n    x1 : float\n        The x-value where the curve transitions from growth to decay.\n    y1 : float\n        The y-value at the transition point x1.\n    x2 : float\n        The x-value defining the end of the decay curve for calculation purposes.\n    y2 : float\n        The y-value at x2, intended to fine-tune the decay rate.\n    a : float, optional\n        The initial value coefficient for the growth curve, defaults to 0.01.\n    generate_values : bool, optional\n        Flag to determine whether to generate x-values and y-values for visualization purposes.\n\n    Returns\n    -------\n    tuple\n        If generate_values is False, returns (gamma, lamda, a).\n        If generate_values is True, returns (gamma, lamda, a, x_values, y_values).\n\n    \"\"\"\n    # Validate inputs\n    if not (x1 &lt; x2):\n        raise ValueError(\"x1 must be less than x2\")\n    if not (0 &lt; y1 &lt; y2 &lt; 1):\n        raise ValueError(\"y1 must be less than y2, and both must be between 0 and 1\")\n\n    # Constants for growth and decay\n    gamma = np.log(y1 / a) / x1\n    lamda = np.log((1 - y1) / (1 - y2)) / (x2 - x1)\n\n    if generate_values:\n        x_values = np.linspace(0, 20, 200)\n        y_values = [\n            (growth_curve(x, a, gamma) if x &lt;= x1 else decay_curve(x, x1, y1, lamda))\n            for x in x_values\n        ]\n        return gamma, lamda, a, x_values, y_values\n\n    return gamma, lamda, a\n</code></pre>"},{"location":"api/#patientflow.calculate.admission_in_prediction_window.decay_curve","title":"<code>decay_curve(x, x1, y1, lamda)</code>","text":"<p>Calculate the exponential decay value at a given x using specified parameters. The function supports both scalar and array inputs for x.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float or ndarray</code> <p>The x-value(s) at which to evaluate the curve.</p> required <code>x1</code> <code>float</code> <p>The x-value where the growth curve transitions to the decay curve.</p> required <code>y1</code> <code>float</code> <p>The y-value at the transition point, where the decay curve starts.</p> required <code>lamda</code> <code>float</code> <p>The decay rate coefficient.</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The y-value(s) of the decay curve at x.</p> Source code in <code>src/patientflow/calculate/admission_in_prediction_window.py</code> <pre><code>def decay_curve(x, x1, y1, lamda):\n    \"\"\"\n    Calculate the exponential decay value at a given x using specified parameters.\n    The function supports both scalar and array inputs for x.\n\n    Parameters\n    ----------\n    x : float or np.ndarray\n        The x-value(s) at which to evaluate the curve.\n    x1 : float\n        The x-value where the growth curve transitions to the decay curve.\n    y1 : float\n        The y-value at the transition point, where the decay curve starts.\n    lamda : float\n        The decay rate coefficient.\n\n    Returns\n    -------\n    float or np.ndarray\n        The y-value(s) of the decay curve at x.\n\n    \"\"\"\n    return y1 + (1 - y1) * (1 - np.exp(-lamda * (x - x1)))\n</code></pre>"},{"location":"api/#patientflow.calculate.admission_in_prediction_window.get_survival_probability","title":"<code>get_survival_probability(survival_df, time_hours)</code>","text":"<p>Calculate the probability of a patient still being in the ED after a specified time using survival curve data.</p> <p>Parameters:</p> Name Type Description Default <code>survival_df</code> <code>DataFrame</code> <p>DataFrame containing survival curve data with columns: - time_hours: Time points in hours - survival_probability: Probability of still being in ED at each time point</p> required <code>time_hours</code> <code>float</code> <p>The time point (in hours) at which to calculate the survival probability</p> required <p>Returns:</p> Type Description <code>float</code> <p>The probability of still being in the ED at the specified time</p> Notes <ul> <li>If the exact time_hours is not in the survival curve data, the function will   interpolate between the nearest time points</li> <li>If time_hours is less than the minimum time in the data, returns 1.0</li> <li>If time_hours is greater than the maximum time in the data, returns the last   known survival probability</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; survival_df = pd.DataFrame({\n...     'time_hours': [0, 2, 4, 6],\n...     'survival_probability': [1.0, 0.8, 0.5, 0.2]\n... })\n&gt;&gt;&gt; get_survival_probability(survival_df, 3.5)\n0.65  # interpolated between 0.8 and 0.5\n</code></pre> Source code in <code>src/patientflow/calculate/admission_in_prediction_window.py</code> <pre><code>def get_survival_probability(survival_df, time_hours):\n    \"\"\"\n    Calculate the probability of a patient still being in the ED after a specified time\n    using survival curve data.\n\n    Parameters\n    ----------\n    survival_df : pandas.DataFrame\n        DataFrame containing survival curve data with columns:\n        - time_hours: Time points in hours\n        - survival_probability: Probability of still being in ED at each time point\n    time_hours : float\n        The time point (in hours) at which to calculate the survival probability\n\n    Returns\n    -------\n    float\n        The probability of still being in the ED at the specified time\n\n    Notes\n    -----\n    - If the exact time_hours is not in the survival curve data, the function will\n      interpolate between the nearest time points\n    - If time_hours is less than the minimum time in the data, returns 1.0\n    - If time_hours is greater than the maximum time in the data, returns the last\n      known survival probability\n\n    Examples\n    --------\n    &gt;&gt;&gt; survival_df = pd.DataFrame({\n    ...     'time_hours': [0, 2, 4, 6],\n    ...     'survival_probability': [1.0, 0.8, 0.5, 0.2]\n    ... })\n    &gt;&gt;&gt; get_survival_probability(survival_df, 3.5)\n    0.65  # interpolated between 0.8 and 0.5\n    \"\"\"\n    if time_hours &lt; survival_df[\"time_hours\"].min():\n        return 1.0\n\n    if time_hours &gt; survival_df[\"time_hours\"].max():\n        return survival_df[\"survival_probability\"].iloc[-1]\n\n    # Find the closest time points for interpolation\n    lower_idx = survival_df[\"time_hours\"].searchsorted(time_hours, side=\"right\") - 1\n    upper_idx = lower_idx + 1\n\n    if lower_idx &lt; 0:\n        return 1.0\n\n    if upper_idx &gt;= len(survival_df):\n        return survival_df[\"survival_probability\"].iloc[-1]\n\n    # Get the surrounding points\n    t1 = survival_df[\"time_hours\"].iloc[lower_idx]\n    t2 = survival_df[\"time_hours\"].iloc[upper_idx]\n    p1 = survival_df[\"survival_probability\"].iloc[lower_idx]\n    p2 = survival_df[\"survival_probability\"].iloc[upper_idx]\n\n    # Linear interpolation\n    return p1 + (p2 - p1) * (time_hours - t1) / (t2 - t1)\n</code></pre>"},{"location":"api/#patientflow.calculate.admission_in_prediction_window.get_y_from_aspirational_curve","title":"<code>get_y_from_aspirational_curve(x, x1, y1, x2, y2)</code>","text":"<p>Calculate the probability y that a patient will have been admitted by a specified x after their arrival, by reading from the aspirational curve that has been constrained to pass through points (x1, y1) and (x2, y2) with an exponential growth curve where x &lt; x1 and an exponential decay where x &lt; x2</p> <p>The function handles scalar or array inputs for x and determines y using either an exponential growth curve (for x &lt; x1) or an exponential decay curve (for x &gt;= x1). The curve parameters are derived to ensure the curve passes through specified points (x1, y1) and (x2, y2).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float or ndarray</code> <p>The x-coordinate(s) at which to calculate the y-value on the curve. Can be a single value or an array of values.</p> required <code>x1</code> <code>float</code> <p>The x-coordinate of the first key point on the curve, where the growth phase ends and the decay phase begins.</p> required <code>y1</code> <code>float</code> <p>The y-coordinate of the first key point (x1), representing the target proportion of patients admitted by time x1.</p> required <code>x2</code> <code>float</code> <p>The x-coordinate of the second key point on the curve, beyond which all but a few patients are expected to be admitted.</p> required <code>y2</code> <code>float</code> <p>The y-coordinate of the second key point (x2), representing the target proportion of patients admitted by time x2.</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The calculated y-value(s) (probability of admission) at the given x. The type of the return matches the input type for x (either scalar or array).</p> Source code in <code>src/patientflow/calculate/admission_in_prediction_window.py</code> <pre><code>def get_y_from_aspirational_curve(x, x1, y1, x2, y2):\n    \"\"\"\n    Calculate the probability y that a patient will have been admitted by a specified x after their arrival, by reading from the aspirational curve that has been constrained to pass through points (x1, y1) and (x2, y2) with an exponential growth curve where x &lt; x1 and an exponential decay where x &lt; x2\n\n    The function handles scalar or array inputs for x and determines y using either an exponential growth curve (for x &lt; x1)\n    or an exponential decay curve (for x &gt;= x1). The curve parameters are derived to ensure the curve passes through\n    specified points (x1, y1) and (x2, y2).\n\n    Parameters\n    ----------\n    x : float or np.ndarray\n        The x-coordinate(s) at which to calculate the y-value on the curve. Can be a single value or an array of values.\n    x1 : float\n        The x-coordinate of the first key point on the curve, where the growth phase ends and the decay phase begins.\n    y1 : float\n        The y-coordinate of the first key point (x1), representing the target proportion of patients admitted by time x1.\n    x2 : float\n        The x-coordinate of the second key point on the curve, beyond which all but a few patients are expected to be admitted.\n    y2 : float\n        The y-coordinate of the second key point (x2), representing the target proportion of patients admitted by time x2.\n\n    Returns\n    -------\n    float or np.ndarray\n        The calculated y-value(s) (probability of admission) at the given x. The type of the return matches the input type\n        for x (either scalar or array).\n\n    \"\"\"\n    gamma, lamda, a = create_curve(x1, y1, x2, y2)\n    y = np.where(x &lt; x1, growth_curve(x, a, gamma), decay_curve(x, x1, y1, lamda))\n    return y\n</code></pre>"},{"location":"api/#patientflow.calculate.admission_in_prediction_window.growth_curve","title":"<code>growth_curve(x, a, gamma)</code>","text":"<p>Calculate the exponential growth value at a given x using specified parameters. The function supports both scalar and array inputs for x.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>float or ndarray</code> <p>The x-value(s) at which to evaluate the curve.</p> required <code>a</code> <code>float</code> <p>The coefficient that defines the starting point of the growth curve when x is 0.</p> required <code>gamma</code> <code>float</code> <p>The growth rate coefficient of the curve.</p> required <p>Returns:</p> Type Description <code>float or ndarray</code> <p>The y-value(s) of the growth curve at x.</p> Source code in <code>src/patientflow/calculate/admission_in_prediction_window.py</code> <pre><code>def growth_curve(x, a, gamma):\n    \"\"\"\n    Calculate the exponential growth value at a given x using specified parameters.\n    The function supports both scalar and array inputs for x.\n\n    Parameters\n    ----------\n    x : float or np.ndarray\n        The x-value(s) at which to evaluate the curve.\n    a : float\n        The coefficient that defines the starting point of the growth curve when x is 0.\n    gamma : float\n        The growth rate coefficient of the curve.\n\n    Returns\n    -------\n    float or np.ndarray\n        The y-value(s) of the growth curve at x.\n\n    \"\"\"\n    return a * np.exp(x * gamma)\n</code></pre>"},{"location":"api/#patientflow.calculate.arrival_rates","title":"<code>arrival_rates</code>","text":"<p>Calculate and process time-varying arrival rates and admission probabilities.</p> <p>This module provides functions for calculating arrival rates, admission probabilities, and unfettered demand rates for inpatient arrivals using an aspirational approach.</p> <p>Functions:</p> Name Description <code>time_varying_arrival_rates : function</code> <p>Calculate arrival rates for each time interval across the dataset's date range.</p> <code>time_varying_arrival_rates_lagged : function</code> <p>Create lagged arrival rates based on time intervals.</p> <code>admission_probabilities : function</code> <p>Compute cumulative and hourly admission probabilities using aspirational curves.</p> <code>weighted_arrival_rates : function</code> <p>Aggregate weighted arrival rates for specific time intervals.</p> <code>unfettered_demand_by_hour : function</code> <p>Estimate inpatient demand by hour using historical data and aspirational curves.</p> <code>count_yet_to_arrive : function</code> <p>Count patients who arrived after prediction times and were admitted within prediction windows.</p> Notes <ul> <li>All times are handled in local timezone</li> <li>Arrival rates are normalized by the number of unique days in the dataset</li> <li>Demand calculations consider both historical patterns and admission probabilities</li> <li>Time intervals must divide evenly into 24 hours</li> <li>Aspirational curves use (x1,y1) and (x2,y2) coordinates to model admission probabilities</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Generate random arrival times over a week\n&gt;&gt;&gt; np.random.seed(42)  # For reproducibility\n&gt;&gt;&gt; n_arrivals = 1000\n&gt;&gt;&gt; random_times = [\n...     pd.Timestamp('2024-01-01') +\n...     pd.Timedelta(days=np.random.randint(0, 7)) +\n...     pd.Timedelta(hours=np.random.randint(0, 24)) +\n...     pd.Timedelta(minutes=np.random.randint(0, 60))\n...     for _ in range(n_arrivals)\n... ]\n&gt;&gt;&gt; df = pd.DataFrame(index=sorted(random_times))\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Calculate various rates and demand\n&gt;&gt;&gt; rates = time_varying_arrival_rates(df, yta_time_interval=60)\n&gt;&gt;&gt; lagged_rates = time_varying_arrival_rates_lagged(df, lagged_by=4)\n&gt;&gt;&gt; demand = unfettered_demand_by_hour(df, x1=4, y1=0.8, x2=8, y2=0.95)\n</code></pre>"},{"location":"api/#patientflow.calculate.arrival_rates.admission_probabilities","title":"<code>admission_probabilities(hours_since_arrival, x1, y1, x2, y2)</code>","text":"<p>Calculate probability of admission for each hour since arrival.</p> <p>Parameters:</p> Name Type Description Default <code>hours_since_arrival</code> <code>ndarray</code> <p>Array of hours since arrival.</p> required <code>x1</code> <code>float</code> <p>First x-coordinate of the aspirational curve.</p> required <code>y1</code> <code>float</code> <p>First y-coordinate of the aspirational curve.</p> required <code>x2</code> <code>float</code> <p>Second x-coordinate of the aspirational curve.</p> required <code>y2</code> <code>float</code> <p>Second y-coordinate of the aspirational curve.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>A tuple containing: - np.ndarray: Cumulative admission probabilities - np.ndarray: Hourly admission probabilities</p> Notes <p>The aspirational curve is defined by two points (x1,y1) and (x2,y2) and is used to model the probability of admission over time.</p> Source code in <code>src/patientflow/calculate/arrival_rates.py</code> <pre><code>def admission_probabilities(\n    hours_since_arrival: np.ndarray, x1: float, y1: float, x2: float, y2: float\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Calculate probability of admission for each hour since arrival.\n\n    Parameters\n    ----------\n    hours_since_arrival : np.ndarray\n        Array of hours since arrival.\n    x1 : float\n        First x-coordinate of the aspirational curve.\n    y1 : float\n        First y-coordinate of the aspirational curve.\n    x2 : float\n        Second x-coordinate of the aspirational curve.\n    y2 : float\n        Second y-coordinate of the aspirational curve.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray]\n        A tuple containing:\n        - np.ndarray: Cumulative admission probabilities\n        - np.ndarray: Hourly admission probabilities\n\n    Notes\n    -----\n    The aspirational curve is defined by two points (x1,y1) and (x2,y2) and is used\n    to model the probability of admission over time.\n    \"\"\"\n    prob_admission_by_hour = np.array(\n        [\n            get_y_from_aspirational_curve(hour, x1, y1, x2, y2)\n            for hour in hours_since_arrival\n        ]\n    )\n    prob_admission_within_hour = np.diff(prob_admission_by_hour)\n\n    return prob_admission_by_hour, prob_admission_within_hour\n</code></pre>"},{"location":"api/#patientflow.calculate.arrival_rates.count_yet_to_arrive","title":"<code>count_yet_to_arrive(df, snapshot_dates, prediction_times, prediction_window_hours)</code>","text":"<p>Count patients who arrived after prediction times and were admitted within prediction windows.</p> <p>This function counts patients who arrived after specified prediction times and were admitted to a ward within the specified prediction window for each combination of snapshot date and prediction time.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A DataFrame containing patient data with 'arrival_datetime', 'admitted_to_ward_datetime', and 'patient_id' columns.</p> required <code>snapshot_dates</code> <code>list</code> <p>List of dates (datetime.date objects) to analyze.</p> required <code>prediction_times</code> <code>list</code> <p>List of (hour, minute) tuples representing prediction times.</p> required <code>prediction_window_hours</code> <code>float</code> <p>Length of prediction window in hours after the prediction time.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns: - 'snapshot_date': The date of the snapshot - 'prediction_time': Tuple of (hour, minute) for the prediction time - 'count': Number of unique patients who arrived after prediction time           and were admitted within the prediction window</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If df is not a DataFrame or if required columns are missing.</p> <code>ValueError</code> <p>If prediction_window_hours is not positive.</p> Notes <p>This function is useful for analyzing historical patterns of patient arrivals and admissions to inform predictive models for emergency department demand. Only patients with non-null admitted_to_ward_datetime are counted.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from datetime import date, time\n&gt;&gt;&gt; prediction_times = [(12, 0), (15, 30)]\n&gt;&gt;&gt; snapshot_dates = [date(2023, 1, 1), date(2023, 1, 2)]\n&gt;&gt;&gt; results = count_yet_to_arrive(df, snapshot_dates, prediction_times, 8.0)\n</code></pre> Source code in <code>src/patientflow/calculate/arrival_rates.py</code> <pre><code>def count_yet_to_arrive(\n    df: DataFrame,\n    snapshot_dates: List,\n    prediction_times: List,\n    prediction_window_hours: float,\n) -&gt; DataFrame:\n    \"\"\"Count patients who arrived after prediction times and were admitted within prediction windows.\n\n    This function counts patients who arrived after specified prediction times and were\n    admitted to a ward within the specified prediction window for each combination of\n    snapshot date and prediction time.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A DataFrame containing patient data with 'arrival_datetime',\n        'admitted_to_ward_datetime', and 'patient_id' columns.\n    snapshot_dates : list\n        List of dates (datetime.date objects) to analyze.\n    prediction_times : list\n        List of (hour, minute) tuples representing prediction times.\n    prediction_window_hours : float\n        Length of prediction window in hours after the prediction time.\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with columns:\n        - 'snapshot_date': The date of the snapshot\n        - 'prediction_time': Tuple of (hour, minute) for the prediction time\n        - 'count': Number of unique patients who arrived after prediction time\n                  and were admitted within the prediction window\n\n    Raises\n    ------\n    TypeError\n        If df is not a DataFrame or if required columns are missing.\n    ValueError\n        If prediction_window_hours is not positive.\n\n    Notes\n    -----\n    This function is useful for analyzing historical patterns of patient arrivals\n    and admissions to inform predictive models for emergency department demand.\n    Only patients with non-null admitted_to_ward_datetime are counted.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import pandas as pd\n    &gt;&gt;&gt; from datetime import date, time\n    &gt;&gt;&gt; prediction_times = [(12, 0), (15, 30)]\n    &gt;&gt;&gt; snapshot_dates = [date(2023, 1, 1), date(2023, 1, 2)]\n    &gt;&gt;&gt; results = count_yet_to_arrive(df, snapshot_dates, prediction_times, 8.0)\n    \"\"\"\n    # Input validation\n    if not isinstance(df, DataFrame):\n        raise TypeError(\"The input 'df' must be a pandas DataFrame.\")\n\n    required_columns = [\"arrival_datetime\", \"admitted_to_ward_datetime\", \"patient_id\"]\n    missing_columns = [col for col in required_columns if col not in df.columns]\n    if missing_columns:\n        raise TypeError(f\"DataFrame missing required columns: {missing_columns}\")\n\n    if (\n        not isinstance(prediction_window_hours, (int, float))\n        or prediction_window_hours &lt;= 0\n    ):\n        raise ValueError(\"prediction_window_hours must be a positive number.\")\n\n    # Create an empty list to store results\n    results = []\n\n    # For each combination of date and time\n    for date_val in snapshot_dates:\n        for hour, minute in prediction_times:\n            # Create the prediction datetime\n            prediction_datetime = pd.Timestamp(\n                datetime.combine(date_val, time(hour=hour, minute=minute))\n            )\n\n            # Calculate the end of the prediction window\n            prediction_window_end = prediction_datetime + pd.Timedelta(\n                hours=prediction_window_hours\n            )\n\n            # Count patients who arrived after prediction time and were admitted within the window\n            admitted_within_window = len(\n                df[\n                    (df[\"arrival_datetime\"] &gt; prediction_datetime)\n                    &amp; (df[\"admitted_to_ward_datetime\"] &lt;= prediction_window_end)\n                ]\n            )\n\n            # Store the result\n            results.append(\n                {\n                    \"snapshot_date\": date_val,\n                    \"prediction_time\": (hour, minute),\n                    \"count\": admitted_within_window,\n                }\n            )\n\n    # Convert results to a DataFrame\n    results_df = pd.DataFrame(results)\n\n    return results_df\n</code></pre>"},{"location":"api/#patientflow.calculate.arrival_rates.process_arrival_rates","title":"<code>process_arrival_rates(arrival_rates_dict)</code>","text":"<p>Process arrival rates dictionary into formats needed for plotting.</p> <pre><code>Parameters\n</code></pre> <pre><code>arrival_rates_dict : Dict[datetime.time, float]\n    Mapping of times to arrival rates.\n</code></pre> <pre><code>Returns\n</code></pre> <pre><code>Tuple[List[float], List[str], List[int]]\n    A tuple containing:\n    - List[float]: Arrival rate values\n    - List[str]: Formatted hour range strings (e.g., \"09-\n</code></pre> <p>10\")         - List[int]: Integers for x-axis positioning</p> <pre><code>Notes\n</code></pre> <pre><code>The hour labels are formatted with line breaks for better plot readability.\n</code></pre> Source code in <code>src/patientflow/calculate/arrival_rates.py</code> <pre><code>def process_arrival_rates(\n    arrival_rates_dict: Dict[time, float],\n) -&gt; Tuple[List[float], List[str], List[int]]:\n    \"\"\"Process arrival rates dictionary into formats needed for plotting.\n\n    Parameters\n    ----------\n    arrival_rates_dict : Dict[datetime.time, float]\n        Mapping of times to arrival rates.\n\n    Returns\n    -------\n    Tuple[List[float], List[str], List[int]]\n        A tuple containing:\n        - List[float]: Arrival rate values\n        - List[str]: Formatted hour range strings (e.g., \"09-\\n10\")\n        - List[int]: Integers for x-axis positioning\n\n    Notes\n    -----\n    The hour labels are formatted with line breaks for better plot readability.\n    \"\"\"\n    # Extract hours and rates\n    hours = list(arrival_rates_dict.keys())\n    arrival_rates = list(arrival_rates_dict.values())\n\n    # Create formatted hour labels with line breaks for better plot readability\n    hour_labels = [\n        f'{hour.strftime(\"%H\")}-\\n{str((hour.hour + 1) % 24).zfill(2)}'\n        for hour in hours\n    ]\n\n    # Generate numerical values for x-axis positioning\n    hour_values = list(range(len(hour_labels)))\n\n    return arrival_rates, hour_labels, hour_values\n</code></pre>"},{"location":"api/#patientflow.calculate.arrival_rates.time_varying_arrival_rates","title":"<code>time_varying_arrival_rates(df, yta_time_interval, num_days=None, verbose=False)</code>","text":"<p>Calculate the time-varying arrival rates for a dataset indexed by datetime.</p> <p>This function computes the arrival rates for each time interval specified, across the entire date range present in the dataframe. The arrival rate is calculated as the number of entries in the dataframe for each time interval, divided by the number of days in the dataset's timespan.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A DataFrame indexed by datetime, representing the data for which arrival rates are to be calculated. The index of the DataFrame should be of datetime type.</p> required <code>yta_time_interval</code> <code>int or timedelta</code> <p>The time interval for which the arrival rates are to be calculated. If int, assumed to be in minutes. If timedelta, will be converted to minutes. For example, if <code>yta_time_interval=60</code>, the function will calculate hourly arrival rates.</p> required <code>num_days</code> <code>int</code> <p>The number of days that the DataFrame spans. If not provided, the number of days is calculated from the date of the min and max arrival datetimes.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, enable info-level logging. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>OrderedDict[time, float]</code> <p>A dictionary mapping times to arrival rates, where times are datetime.time objects and rates are float values.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If 'df' is not a pandas DataFrame, 'yta_time_interval' is not an integer or timedelta, or the DataFrame index is not a DatetimeIndex.</p> <code>ValueError</code> <p>If 'yta_time_interval' is less than or equal to 0 or does not divide evenly into 24 hours.</p> Notes <p>The minimum and maximum dates in the dataset are used to determine the timespan if num_days is not provided.</p> Source code in <code>src/patientflow/calculate/arrival_rates.py</code> <pre><code>def time_varying_arrival_rates(\n    df: DataFrame,\n    yta_time_interval: Union[int, timedelta],\n    num_days: Optional[int] = None,\n    verbose: bool = False,\n) -&gt; OrderedDict[time, float]:\n    \"\"\"Calculate the time-varying arrival rates for a dataset indexed by datetime.\n\n    This function computes the arrival rates for each time interval specified, across\n    the entire date range present in the dataframe. The arrival rate is calculated as\n    the number of entries in the dataframe for each time interval, divided by the\n    number of days in the dataset's timespan.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A DataFrame indexed by datetime, representing the data for which arrival rates\n        are to be calculated. The index of the DataFrame should be of datetime type.\n    yta_time_interval : int or timedelta\n        The time interval for which the arrival rates are to be calculated.\n        If int, assumed to be in minutes. If timedelta, will be converted to minutes.\n        For example, if `yta_time_interval=60`, the function will calculate hourly\n        arrival rates.\n    num_days : int, optional\n        The number of days that the DataFrame spans. If not provided, the number of\n        days is calculated from the date of the min and max arrival datetimes.\n    verbose : bool, optional\n        If True, enable info-level logging. Defaults to False.\n\n    Returns\n    -------\n    OrderedDict[datetime.time, float]\n        A dictionary mapping times to arrival rates, where times are datetime.time\n        objects and rates are float values.\n\n    Raises\n    ------\n    TypeError\n        If 'df' is not a pandas DataFrame, 'yta_time_interval' is not an integer or timedelta,\n        or the DataFrame index is not a DatetimeIndex.\n    ValueError\n        If 'yta_time_interval' is less than or equal to 0 or does not divide evenly\n        into 24 hours.\n\n    Notes\n    -----\n    The minimum and maximum dates in the dataset are used to determine the timespan\n    if num_days is not provided.\n    \"\"\"\n    import logging\n    import sys\n\n    if verbose:\n        # Create logger with a unique name\n        logger = logging.getLogger(f\"{__name__}.time_varying_arrival_rates\")\n\n        # Only set up handlers if they don't exist\n        if not logger.handlers:\n            logger.setLevel(logging.INFO if verbose else logging.WARNING)\n\n            # Create handler that writes to sys.stdout\n            handler = logging.StreamHandler(sys.stdout)\n            handler.setLevel(logging.INFO if verbose else logging.WARNING)\n\n            # Create a formatting configuration\n            formatter = logging.Formatter(\"%(message)s\")\n            handler.setFormatter(formatter)\n\n            # Add the handler to the logger\n            logger.addHandler(handler)\n\n            # Prevent propagation to root logger\n            logger.propagate = False\n\n    # Input validation\n    if not isinstance(df, DataFrame):\n        raise TypeError(\"The input 'df' must be a pandas DataFrame.\")\n    if not isinstance(yta_time_interval, (int, timedelta)):\n        raise TypeError(\n            \"The parameter 'yta_time_interval' must be an integer or timedelta.\"\n        )\n    if not isinstance(df.index, pd.DatetimeIndex):\n        raise TypeError(\"The DataFrame index must be a pandas DatetimeIndex.\")\n\n    # Handle both timedelta and numeric inputs for yta_time_interval\n    if isinstance(yta_time_interval, timedelta):\n        yta_time_interval_minutes = int(yta_time_interval.total_seconds() / 60)\n    elif isinstance(yta_time_interval, int):\n        yta_time_interval_minutes = yta_time_interval\n    else:\n        raise TypeError(\"yta_time_interval must be a timedelta object or integer\")\n\n    # Validate time interval\n    minutes_in_day = 24 * 60\n    if yta_time_interval_minutes &lt;= 0:\n        raise ValueError(\"The parameter 'yta_time_interval' must be positive.\")\n    if minutes_in_day % yta_time_interval_minutes != 0:\n        raise ValueError(\n            f\"Time interval ({yta_time_interval_minutes} minutes) must divide evenly into 24 hours.\"\n        )\n\n    if num_days is None:\n        # Calculate total days between first and last date\n        if verbose and logger:\n            logger.info(\"Inferring number of days from dataset\")\n        start_date = df.index.date.min()\n        end_date = df.index.date.max()\n        num_days = (end_date - start_date).days + 1\n\n    if num_days == 0:\n        raise ValueError(\"DataFrame contains no data.\")\n\n    if verbose and logger:\n        logger.info(\n            f\"Calculating time-varying arrival rates for data provided, which spans {num_days} unique dates\"\n        )\n\n    arrival_rates_dict = OrderedDict()\n\n    # Initialize a time object to iterate through one day in the specified intervals\n    _start_datetime = datetime(1970, 1, 1, 0, 0, 0, 0)\n    _stop_datetime = _start_datetime + timedelta(days=1)\n\n    # Iterate over each interval in a single day to calculate the arrival rate\n    while _start_datetime != _stop_datetime:\n        _start_time = _start_datetime.time()\n        _end_time = (\n            _start_datetime + timedelta(minutes=yta_time_interval_minutes)\n        ).time()\n\n        # Filter the dataframe for entries within the current time interval\n        _df = df.between_time(_start_time, _end_time, inclusive=\"left\")\n\n        # Calculate and store the arrival rate for the interval\n        arrival_rates_dict[_start_time] = _df.shape[0] / num_days\n\n        # Move to the next interval\n        _start_datetime = _start_datetime + timedelta(minutes=yta_time_interval_minutes)\n\n    return arrival_rates_dict\n</code></pre>"},{"location":"api/#patientflow.calculate.arrival_rates.time_varying_arrival_rates_lagged","title":"<code>time_varying_arrival_rates_lagged(df, lagged_by, num_days=None, yta_time_interval=60)</code>","text":"<p>Calculate lagged time-varying arrival rates for a dataset indexed by datetime.</p> <p>This function first calculates the basic arrival rates and then adjusts them by a specified lag time, returning the rates sorted by the lagged times.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A DataFrame indexed by datetime, representing the data for which arrival rates are to be calculated. The index must be a DatetimeIndex.</p> required <code>lagged_by</code> <code>int</code> <p>Number of hours to lag the arrival times.</p> required <code>num_days</code> <code>int</code> <p>The number of days that the DataFrame spans. If not provided, the number of days is calculated from the date of the min and max arrival datetimes.</p> <code>None</code> <code>yta_time_interval</code> <code>int or timedelta</code> <p>The time interval for which the arrival rates are to be calculated. If int, assumed to be in minutes. If timedelta, will be converted to minutes. Defaults to 60.</p> <code>60</code> <p>Returns:</p> Type Description <code>OrderedDict[time, float]</code> <p>A dictionary mapping lagged times (datetime.time objects) to their corresponding arrival rates.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If df is not a DataFrame, lagged_by is not an integer, yta_time_interval is not an integer or timedelta, or DataFrame index is not DatetimeIndex.</p> <code>ValueError</code> <p>If lagged_by is negative or yta_time_interval is not positive.</p> Notes <p>The lagged times are calculated by adding the specified number of hours to each time in the original arrival rates dictionary.</p> Source code in <code>src/patientflow/calculate/arrival_rates.py</code> <pre><code>def time_varying_arrival_rates_lagged(\n    df: DataFrame,\n    lagged_by: int,\n    num_days: Optional[int] = None,\n    yta_time_interval: Union[int, timedelta] = 60,\n) -&gt; OrderedDict[time, float]:\n    \"\"\"Calculate lagged time-varying arrival rates for a dataset indexed by datetime.\n\n    This function first calculates the basic arrival rates and then adjusts them by\n    a specified lag time, returning the rates sorted by the lagged times.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A DataFrame indexed by datetime, representing the data for which arrival rates\n        are to be calculated. The index must be a DatetimeIndex.\n    lagged_by : int\n        Number of hours to lag the arrival times.\n    num_days : int, optional\n        The number of days that the DataFrame spans. If not provided, the number of\n        days is calculated from the date of the min and max arrival datetimes.\n    yta_time_interval : int or timedelta, optional\n        The time interval for which the arrival rates are to be calculated.\n        If int, assumed to be in minutes. If timedelta, will be converted to minutes.\n        Defaults to 60.\n\n    Returns\n    -------\n    OrderedDict[datetime.time, float]\n        A dictionary mapping lagged times (datetime.time objects) to their\n        corresponding arrival rates.\n\n    Raises\n    ------\n    TypeError\n        If df is not a DataFrame, lagged_by is not an integer, yta_time_interval is not an integer or timedelta,\n        or DataFrame index is not DatetimeIndex.\n    ValueError\n        If lagged_by is negative or yta_time_interval is not positive.\n\n    Notes\n    -----\n    The lagged times are calculated by adding the specified number of hours to each\n    time in the original arrival rates dictionary.\n    \"\"\"\n    # Input validation\n    if not isinstance(df, DataFrame):\n        raise TypeError(\"The input 'df' must be a pandas DataFrame.\")\n\n    if not isinstance(lagged_by, int):\n        raise TypeError(\"The parameter 'lagged_by' must be an integer.\")\n\n    if not isinstance(yta_time_interval, (int, timedelta)):\n        raise TypeError(\n            \"The parameter 'yta_time_interval' must be an integer or timedelta.\"\n        )\n\n    if not isinstance(df.index, pd.DatetimeIndex):\n        raise TypeError(\"The DataFrame index must be a pandas DatetimeIndex.\")\n\n    if lagged_by &lt; 0:\n        raise ValueError(\"The parameter 'lagged_by' must be non-negative.\")\n\n    # Handle both timedelta and numeric inputs for yta_time_interval\n    if isinstance(yta_time_interval, timedelta):\n        yta_time_interval_minutes = int(yta_time_interval.total_seconds() / 60)\n    elif isinstance(yta_time_interval, int):\n        yta_time_interval_minutes = yta_time_interval\n    else:\n        raise TypeError(\"yta_time_interval must be a timedelta object or integer\")\n\n    if yta_time_interval_minutes &lt;= 0:\n        raise ValueError(\"The parameter 'yta_time_interval' must be positive.\")\n\n    # Calculate base arrival rates\n    arrival_rates_dict = time_varying_arrival_rates(\n        df, yta_time_interval, num_days=num_days\n    )\n\n    # Apply lag to the times\n    lagged_dict = OrderedDict()\n    reference_date = datetime(2000, 1, 1)  # Use arbitrary reference date\n\n    for base_time, rate in arrival_rates_dict.items():\n        # Combine with reference date and apply lag\n        lagged_datetime = datetime.combine(reference_date, base_time) + timedelta(\n            hours=lagged_by\n        )\n        lagged_dict[lagged_datetime.time()] = rate\n\n    # Sort by lagged times\n    return OrderedDict(sorted(lagged_dict.items()))\n</code></pre>"},{"location":"api/#patientflow.calculate.arrival_rates.unfettered_demand_by_hour","title":"<code>unfettered_demand_by_hour(df, x1, y1, x2, y2, yta_time_interval=60, max_hours_since_arrival=10, num_days=None)</code>","text":"<p>Calculate true inpatient demand by hour based on historical arrival data.</p> <p>This function estimates demand rates using historical arrival data and an aspirational curve for admission probabilities. It takes a DataFrame of historical arrivals and parameters defining an aspirational curve to calculate hourly demand rates.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>A DataFrame indexed by datetime, representing historical arrival data. The index must be a DatetimeIndex.</p> required <code>x1</code> <code>float</code> <p>First x-coordinate of the aspirational curve.</p> required <code>y1</code> <code>float</code> <p>First y-coordinate of the aspirational curve (0-1).</p> required <code>x2</code> <code>float</code> <p>Second x-coordinate of the aspirational curve.</p> required <code>y2</code> <code>float</code> <p>Second y-coordinate of the aspirational curve (0-1).</p> required <code>yta_time_interval</code> <code>int or timedelta</code> <p>Time interval for which the arrival rates are to be calculated. If int, assumed to be in minutes. If timedelta, will be converted to minutes. Defaults to 60.</p> <code>60</code> <code>max_hours_since_arrival</code> <code>int</code> <p>Maximum hours since arrival to consider. Defaults to 10.</p> <code>10</code> <code>num_days</code> <code>int</code> <p>The number of days that the DataFrame spans. If not provided, the number of days is calculated from the date of the min and max arrival datetimes.</p> <code>None</code> <p>Returns:</p> Type Description <code>OrderedDict[time, float]</code> <p>A dictionary mapping times (datetime.time objects) to their corresponding demand rates.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If df is not a DataFrame, coordinates are not floats, or DataFrame index is not DatetimeIndex.</p> <code>ValueError</code> <p>If coordinates are outside valid ranges, yta_time_interval is not positive, or doesn't divide evenly into 24 hours.</p> Notes <p>The function combines historical arrival patterns with admission probabilities to estimate true inpatient demand. The aspirational curve is used to model how admission probabilities change over time.</p> Source code in <code>src/patientflow/calculate/arrival_rates.py</code> <pre><code>def unfettered_demand_by_hour(\n    df: DataFrame,\n    x1: float,\n    y1: float,\n    x2: float,\n    y2: float,\n    yta_time_interval: Union[int, timedelta] = 60,\n    max_hours_since_arrival: int = 10,\n    num_days: Optional[int] = None,\n) -&gt; OrderedDict[time, float]:\n    \"\"\"Calculate true inpatient demand by hour based on historical arrival data.\n\n    This function estimates demand rates using historical arrival data and an aspirational\n    curve for admission probabilities. It takes a DataFrame of historical arrivals and\n    parameters defining an aspirational curve to calculate hourly demand rates.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A DataFrame indexed by datetime, representing historical arrival data.\n        The index must be a DatetimeIndex.\n    x1 : float\n        First x-coordinate of the aspirational curve.\n    y1 : float\n        First y-coordinate of the aspirational curve (0-1).\n    x2 : float\n        Second x-coordinate of the aspirational curve.\n    y2 : float\n        Second y-coordinate of the aspirational curve (0-1).\n    yta_time_interval : int or timedelta, optional\n        Time interval for which the arrival rates are to be calculated.\n        If int, assumed to be in minutes. If timedelta, will be converted to minutes.\n        Defaults to 60.\n    max_hours_since_arrival : int, optional\n        Maximum hours since arrival to consider. Defaults to 10.\n    num_days : int, optional\n        The number of days that the DataFrame spans. If not provided, the number of\n        days is calculated from the date of the min and max arrival datetimes.\n\n    Returns\n    -------\n    OrderedDict[datetime.time, float]\n        A dictionary mapping times (datetime.time objects) to their corresponding\n        demand rates.\n\n    Raises\n    ------\n    TypeError\n        If df is not a DataFrame, coordinates are not floats, or DataFrame index\n        is not DatetimeIndex.\n    ValueError\n        If coordinates are outside valid ranges, yta_time_interval is not positive,\n        or doesn't divide evenly into 24 hours.\n\n    Notes\n    -----\n    The function combines historical arrival patterns with admission probabilities\n    to estimate true inpatient demand. The aspirational curve is used to model\n    how admission probabilities change over time.\n    \"\"\"\n    # Input validation\n    if not isinstance(df, DataFrame):\n        raise TypeError(\"The input 'df' must be a pandas DataFrame.\")\n\n    if not isinstance(df.index, pd.DatetimeIndex):\n        raise TypeError(\"The DataFrame index must be a pandas DatetimeIndex.\")\n\n    if not all(isinstance(x, (int, float)) for x in [x1, y1, x2, y2]):\n        raise TypeError(\"Curve coordinates must be numeric values.\")\n\n    if not isinstance(yta_time_interval, (int, timedelta)):\n        raise TypeError(\n            \"The parameter 'yta_time_interval' must be an integer or timedelta.\"\n        )\n\n    if not isinstance(max_hours_since_arrival, int):\n        raise TypeError(\"The parameter 'max_hours_since_arrival' must be an integer.\")\n\n    # Handle both timedelta and numeric inputs for yta_time_interval\n    if isinstance(yta_time_interval, timedelta):\n        yta_time_interval_minutes = int(yta_time_interval.total_seconds() / 60)\n    elif isinstance(yta_time_interval, int):\n        yta_time_interval_minutes = yta_time_interval\n    else:\n        raise TypeError(\"yta_time_interval must be a timedelta object or integer\")\n\n    # Validate time interval\n    minutes_in_day = 24 * 60\n    if yta_time_interval_minutes &lt;= 0:\n        raise ValueError(\"The parameter 'yta_time_interval' must be positive.\")\n    if minutes_in_day % yta_time_interval_minutes != 0:\n        raise ValueError(\n            f\"Time interval ({yta_time_interval_minutes} minutes) must divide evenly into 24 hours.\"\n        )\n\n    if max_hours_since_arrival &lt;= 0:\n        raise ValueError(\"The parameter 'max_hours_since_arrival' must be positive.\")\n\n    if not (0 &lt;= y1 &lt;= 1 and 0 &lt;= y2 &lt;= 1):\n        raise ValueError(\"Y-coordinates must be between 0 and 1.\")\n\n    if x1 &gt;= x2:\n        raise ValueError(\"x1 must be less than x2.\")\n\n    # Calculate number of intervals in a day\n    num_intervals = minutes_in_day // yta_time_interval_minutes\n\n    # Calculate admission probabilities\n    hours_since_arrival = np.arange(max_hours_since_arrival + 1)\n    _, prob_admission_within_hour = admission_probabilities(\n        hours_since_arrival, x1, y1, x2, y2\n    )\n\n    # Calculate base arrival rates from historical data\n    arrival_rates_dict = time_varying_arrival_rates(\n        df, yta_time_interval_minutes, num_days=num_days\n    )\n\n    # Convert dict to arrays while preserving order\n    hour_keys = list(arrival_rates_dict.keys())\n    arrival_rates = np.array([arrival_rates_dict[hour] for hour in hour_keys])\n\n    # Initialize array for weighted arrival rates\n    weighted_rates = np.zeros((max_hours_since_arrival, len(arrival_rates)))\n\n    # Calculate weighted arrival rates for each hour and elapsed time\n    for hour_idx, _ in enumerate(hour_keys):\n        arrival_rate = arrival_rates[hour_idx]\n        weighted_rates[:, hour_idx] = (\n            arrival_rate * prob_admission_within_hour[:max_hours_since_arrival]\n        )\n\n    # Calculate summed demand rates for each hour\n    demand_by_hour = OrderedDict()\n    elapsed_hours = range(max_hours_since_arrival)\n\n    for hour_idx, hour_key in enumerate(hour_keys):\n        demand_by_hour[hour_key] = weighted_arrival_rates(\n            weighted_rates, elapsed_hours, hour_idx, num_intervals\n        )\n\n    return demand_by_hour\n</code></pre>"},{"location":"api/#patientflow.calculate.arrival_rates.weighted_arrival_rates","title":"<code>weighted_arrival_rates(weighted_rates, elapsed_hours, hour_idx, num_intervals)</code>","text":"<p>Calculate sum of weighted arrival rates for a specific time interval.</p> <p>Parameters:</p> Name Type Description Default <code>weighted_rates</code> <code>ndarray</code> <p>Array of weighted arrival rates.</p> required <code>elapsed_hours</code> <code>range</code> <p>Range of elapsed hours to consider.</p> required <code>hour_idx</code> <code>int</code> <p>Current interval index.</p> required <code>num_intervals</code> <code>int</code> <p>Total number of intervals in a day.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Sum of weighted arrival rates.</p> Notes <p>The function calculates the sum of weighted arrival rates by iterating through the elapsed hours and considering the appropriate interval index for each hour.</p> Source code in <code>src/patientflow/calculate/arrival_rates.py</code> <pre><code>def weighted_arrival_rates(\n    weighted_rates: np.ndarray, elapsed_hours: range, hour_idx: int, num_intervals: int\n) -&gt; float:\n    \"\"\"Calculate sum of weighted arrival rates for a specific time interval.\n\n    Parameters\n    ----------\n    weighted_rates : np.ndarray\n        Array of weighted arrival rates.\n    elapsed_hours : range\n        Range of elapsed hours to consider.\n    hour_idx : int\n        Current interval index.\n    num_intervals : int\n        Total number of intervals in a day.\n\n    Returns\n    -------\n    float\n        Sum of weighted arrival rates.\n\n    Notes\n    -----\n    The function calculates the sum of weighted arrival rates by iterating through\n    the elapsed hours and considering the appropriate interval index for each hour.\n    \"\"\"\n    total = 0\n    for elapsed_hour in elapsed_hours:\n        interval_index = (hour_idx - elapsed_hour) % num_intervals\n        total += weighted_rates[elapsed_hour][interval_index]\n    return total\n</code></pre>"},{"location":"api/#patientflow.calculate.survival_curve","title":"<code>survival_curve</code>","text":""},{"location":"api/#patientflow.calculate.survival_curve.calculate_survival_curve","title":"<code>calculate_survival_curve(df, start_time_col, end_time_col)</code>","text":"<p>Calculate survival curve data from patient visit data.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing patient visit data</p> required <code>start_time_col</code> <code>str</code> <p>Name of the column containing the start time (e.g., arrival_datetime)</p> required <code>end_time_col</code> <code>str</code> <p>Name of the column containing the end time (e.g., departure_datetime)</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns: - time_hours: Time points in hours - survival_probability: Survival probabilities at each time point - event_probability: Event probabilities (1 - survival_probability)</p> Source code in <code>src/patientflow/calculate/survival_curve.py</code> <pre><code>def calculate_survival_curve(df, start_time_col, end_time_col):\n    \"\"\"Calculate survival curve data from patient visit data.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame containing patient visit data\n    start_time_col : str\n        Name of the column containing the start time (e.g., arrival_datetime)\n    end_time_col : str\n        Name of the column containing the end time (e.g., departure_datetime)\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with columns:\n        - time_hours: Time points in hours\n        - survival_probability: Survival probabilities at each time point\n        - event_probability: Event probabilities (1 - survival_probability)\n    \"\"\"\n    # Calculate the wait time in hours\n    df = df.copy()\n    df[\"wait_time_hours\"] = (\n        df[end_time_col] - df[start_time_col]\n    ).dt.total_seconds() / 3600\n\n    # Drop any rows with missing wait times\n    df_clean = df.dropna(subset=[\"wait_time_hours\"]).copy()\n\n    # Sort the data by wait time\n    df_clean = df_clean.sort_values(\"wait_time_hours\")\n\n    # Calculate the number of patients\n    n_patients = len(df_clean)\n\n    # Calculate the survival function manually\n    # For each time point, calculate proportion of patients who are still waiting\n    unique_times = np.sort(df_clean[\"wait_time_hours\"].unique())\n    survival_prob = []\n\n    for t in unique_times:\n        # Number of patients who experienced the event after this time point\n        n_event_after = sum(df_clean[\"wait_time_hours\"] &gt; t)\n        # Proportion of patients still waiting\n        survival_prob.append(n_event_after / n_patients)\n\n    # Add zero hours wait time (everyone is waiting at time 0)\n    unique_times = np.insert(unique_times, 0, 0)\n    survival_prob = np.insert(survival_prob, 0, 1.0)\n\n    # Return structured DataFrame\n    return pd.DataFrame(\n        {\n            \"time_hours\": unique_times,\n            \"survival_probability\": survival_prob,\n            \"event_probability\": 1 - survival_prob,\n        }\n    )\n</code></pre>"},{"location":"api/#patientflow.errors","title":"<code>errors</code>","text":"<p>Custom exception classes for model loading and validation.</p> <p>This module defines specialized exceptions used during model loading</p> <p>Classes:</p> Name Description <code>ModelLoadError</code> <p>Raised when a model fails to load due to an unspecified error.</p> <code>MissingKeysError</code> <p>Raised when expected keys are missing from a dictionary of special parameters.</p>"},{"location":"api/#patientflow.errors.MissingKeysError","title":"<code>MissingKeysError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Exception raised when required keys are missing from special_params.</p> <p>Parameters:</p> Name Type Description Default <code>missing_keys</code> <code>list or set</code> <p>The keys that are required but missing from the input dictionary.</p> required <p>Attributes:</p> Name Type Description <code>missing_keys</code> <code>list or set</code> <p>Stores the missing keys that caused the exception.</p> Source code in <code>src/patientflow/errors.py</code> <pre><code>class MissingKeysError(ValueError):\n    \"\"\"\n    Exception raised when required keys are missing from special_params.\n\n    Parameters\n    ----------\n    missing_keys : list or set\n        The keys that are required but missing from the input dictionary.\n\n    Attributes\n    ----------\n    missing_keys : list or set\n        Stores the missing keys that caused the exception.\n    \"\"\"\n\n    def __init__(self, missing_keys):\n        super().__init__(f\"special_params is missing required keys: {missing_keys}\")\n        self.missing_keys = missing_keys\n</code></pre>"},{"location":"api/#patientflow.errors.ModelLoadError","title":"<code>ModelLoadError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when a model fails to load.</p> <p>This generic exception can be used to signal a failure during the model loading process due to unexpected issues such as file corruption, invalid formats, or unsupported configurations.</p> Source code in <code>src/patientflow/errors.py</code> <pre><code>class ModelLoadError(Exception):\n    \"\"\"\n    Exception raised when a model fails to load.\n\n    This generic exception can be used to signal a failure during the model\n    loading process due to unexpected issues such as file corruption,\n    invalid formats, or unsupported configurations.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/#patientflow.evaluate","title":"<code>evaluate</code>","text":"<p>Patient Flow Evaluation Module</p> <p>This module provides functions for evaluating and comparing different prediction models for non-clincal outcomes in a healthcare setting. It includes utilities for calculating metrics such as Mean Absolute Error (MAE) and Mean Percentage Error (MPE), as well as functions for predicting admissions based on historical data and combining different prediction models.</p> <p>Functions:</p> Name Description <code>calculate_results : function</code> <p>Calculate evaluation metrics based on expected and observed values</p> <code>calc_mae_mpe : function</code> <p>Calculate MAE and MPE for probability distribution predictions</p> <code>calculate_admission_probs_relative_to_prediction : function</code> <p>Calculate admission probabilities for arrivals relative to a prediction time window</p> <code>get_arrivals_with_admission_probs : function</code> <p>Get arrivals before and after prediction time with their admission probabilities</p> <code>calculate_weighted_observed : function</code> <p>Calculate actual admissions assuming ED targets are met</p> <code>create_time_mask : function</code> <p>Create a mask for times before/after a specific hour:minute</p> <code>predict_using_previous_weeks : function</code> <p>Predict admissions using average from previous weeks</p> <code>evaluate_six_week_average : function</code> <p>Evaluate the six-week average prediction model</p> <code>combine_distributions : function</code> <p>Combine two probability distributions using convolution</p> <code>evaluate_combined_model : function</code> <p>Evaluate a combined prediction model</p>"},{"location":"api/#patientflow.evaluate.calc_mae_mpe","title":"<code>calc_mae_mpe(prob_dist_dict_all, use_most_probable=False)</code>","text":"<p>Calculate MAE and MPE for all prediction times in the given probability distribution dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>prob_dist_dict_all</code> <code>Dict[Any, Dict[Any, Dict[str, Any]]]</code> <p>Nested dictionary containing probability distributions.</p> required <code>use_most_probable</code> <code>bool</code> <p>Whether to use the most probable value or mathematical expectation of the distribution. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]</code> <p>Dictionary of results sorted by prediction time, containing: - expected : List[Union[int, float]]     Expected values for each prediction - observed : List[float]     Observed values for each prediction - mae : float     Mean Absolute Error - mpe : float     Mean Percentage Error</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def calc_mae_mpe(\n    prob_dist_dict_all: Dict[Any, Dict[Any, Dict[str, Any]]],\n    use_most_probable: bool = False,\n) -&gt; Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]:\n    \"\"\"Calculate MAE and MPE for all prediction times in the given probability distribution dictionary.\n\n    Parameters\n    ----------\n    prob_dist_dict_all : Dict[Any, Dict[Any, Dict[str, Any]]]\n        Nested dictionary containing probability distributions.\n    use_most_probable : bool, optional\n        Whether to use the most probable value or mathematical expectation of the distribution.\n        Default is False.\n\n    Returns\n    -------\n    Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]\n        Dictionary of results sorted by prediction time, containing:\n        - expected : List[Union[int, float]]\n            Expected values for each prediction\n        - observed : List[float]\n            Observed values for each prediction\n        - mae : float\n            Mean Absolute Error\n        - mpe : float\n            Mean Percentage Error\n    \"\"\"\n    # Create temporary results dictionary\n    unsorted_results: Dict[Any, Dict[str, Union[List[Union[int, float]], float]]] = {}\n\n    # Process results as before\n    for _prediction_time in prob_dist_dict_all.keys():\n        expected_values: List[Union[int, float]] = []\n        observed_values: List[float] = []\n\n        for dt in prob_dist_dict_all[_prediction_time].keys():\n            preds: Dict[str, Any] = prob_dist_dict_all[_prediction_time][dt]\n\n            expected_value: Union[int, float] = (\n                int(preds[\"agg_predicted\"].idxmax().values[0])\n                if use_most_probable\n                else float(\n                    np.dot(\n                        preds[\"agg_predicted\"].index,\n                        preds[\"agg_predicted\"].values.flatten(),\n                    )\n                )\n            )\n\n            observed_value: float = float(preds[\"agg_observed\"])\n\n            expected_values.append(expected_value)\n            observed_values.append(observed_value)\n\n        unsorted_results[_prediction_time] = calculate_results(\n            expected_values, observed_values\n        )\n\n    # Sort results by prediction time\n    def get_time_value(key: str) -&gt; int:\n        # Extract time from key (e.g., 'admissions_1530' -&gt; 1530)\n        time_str = key.split(\"_\")[1]\n        return int(time_str)\n\n    # Create sorted dictionary\n    sorted_results = dict(\n        sorted(unsorted_results.items(), key=lambda x: get_time_value(x[0]))\n    )\n\n    return sorted_results\n</code></pre>"},{"location":"api/#patientflow.evaluate.calculate_admission_probs_relative_to_prediction","title":"<code>calculate_admission_probs_relative_to_prediction(df, prediction_datetime, prediction_window, x1, y1, x2, y2, is_before=True)</code>","text":"<p>Calculate admission probabilities for arrivals relative to a prediction time window.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing arrival_datetime column.</p> required <code>prediction_datetime</code> <code>datetime</code> <p>Datetime for prediction window start.</p> required <code>prediction_window</code> <code>int</code> <p>Window length in minutes.</p> required <code>x1</code> <code>float</code> <p>First x-coordinate for aspirational curve.</p> required <code>y1</code> <code>float</code> <p>First y-coordinate for aspirational curve.</p> required <code>x2</code> <code>float</code> <p>Second x-coordinate for aspirational curve.</p> required <code>y2</code> <code>float</code> <p>Second y-coordinate for aspirational curve.</p> required <code>is_before</code> <code>bool</code> <p>Boolean indicating if arrivals are before prediction time. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with added probability columns: - hours_before_pred_window : float     Hours before prediction window (if is_before=True) - hours_after_pred_window : float     Hours after prediction window (if is_before=False) - prob_admission_before_pred_window : float     Probability of admission before prediction window - prob_admission_in_pred_window : float     Probability of admission within prediction window</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def calculate_admission_probs_relative_to_prediction(\n    df, prediction_datetime, prediction_window, x1, y1, x2, y2, is_before=True\n):\n    \"\"\"Calculate admission probabilities for arrivals relative to a prediction time window.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame containing arrival_datetime column.\n    prediction_datetime : datetime\n        Datetime for prediction window start.\n    prediction_window : int\n        Window length in minutes.\n    x1 : float\n        First x-coordinate for aspirational curve.\n    y1 : float\n        First y-coordinate for aspirational curve.\n    x2 : float\n        Second x-coordinate for aspirational curve.\n    y2 : float\n        Second y-coordinate for aspirational curve.\n    is_before : bool, optional\n        Boolean indicating if arrivals are before prediction time.\n        Default is True.\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with added probability columns:\n        - hours_before_pred_window : float\n            Hours before prediction window (if is_before=True)\n        - hours_after_pred_window : float\n            Hours after prediction window (if is_before=False)\n        - prob_admission_before_pred_window : float\n            Probability of admission before prediction window\n        - prob_admission_in_pred_window : float\n            Probability of admission within prediction window\n    \"\"\"\n    result = df.copy()\n\n    if is_before:\n        result[\"hours_before_pred_window\"] = result[\"arrival_datetime\"].apply(\n            lambda x: (prediction_datetime - x).seconds / 3600\n        )\n        result[\"prob_admission_before_pred_window\"] = result[\n            \"hours_before_pred_window\"\n        ].apply(lambda x: get_y_from_aspirational_curve(x, x1, y1, x2, y2))\n        result[\"prob_admission_in_pred_window\"] = result[\n            \"hours_before_pred_window\"\n        ].apply(\n            lambda x: get_y_from_aspirational_curve(\n                x + prediction_window / 60, x1, y1, x2, y2\n            )\n            - get_y_from_aspirational_curve(x, x1, y1, x2, y2)\n        )\n    else:\n        result[\"hours_after_pred_window\"] = result[\"arrival_datetime\"].apply(\n            lambda x: (x - prediction_datetime).seconds / 3600\n        )\n        result[\"prob_admission_in_pred_window\"] = result[\n            \"hours_after_pred_window\"\n        ].apply(\n            lambda x: get_y_from_aspirational_curve(\n                (prediction_window / 60) - x, x1, y1, x2, y2\n            )\n        )\n\n    return result\n</code></pre>"},{"location":"api/#patientflow.evaluate.calculate_results","title":"<code>calculate_results(expected_values, observed_values)</code>","text":"<p>Calculate evaluation metrics based on expected and observed values.</p> <p>Parameters:</p> Name Type Description Default <code>expected_values</code> <code>List[Union[int, float]]</code> <p>List of expected values.</p> required <code>observed_values</code> <code>List[float]</code> <p>List of observed values.</p> required <p>Returns:</p> Type Description <code>Dict[str, Union[List[Union[int, float]], float]]</code> <p>Dictionary containing: - expected : List[Union[int, float]]     Original expected values - observed : List[float]     Original observed values - mae : float     Mean Absolute Error - mpe : float     Mean Percentage Error</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def calculate_results(\n    expected_values: List[Union[int, float]], observed_values: List[float]\n) -&gt; Dict[str, Union[List[Union[int, float]], float]]:\n    \"\"\"Calculate evaluation metrics based on expected and observed values.\n\n    Parameters\n    ----------\n    expected_values : List[Union[int, float]]\n        List of expected values.\n    observed_values : List[float]\n        List of observed values.\n\n    Returns\n    -------\n    Dict[str, Union[List[Union[int, float]], float]]\n        Dictionary containing:\n        - expected : List[Union[int, float]]\n            Original expected values\n        - observed : List[float]\n            Original observed values\n        - mae : float\n            Mean Absolute Error\n        - mpe : float\n            Mean Percentage Error\n    \"\"\"\n    expected_array: np.ndarray = np.array(expected_values)\n    observed_array: np.ndarray = np.array(observed_values)\n\n    if len(expected_array) == 0 or len(observed_array) == 0:\n        return {\n            \"expected\": expected_values,\n            \"observed\": observed_values,\n            \"mae\": 0.0,\n            \"mpe\": 0.0,\n        }\n\n    absolute_errors: np.ndarray = np.abs(expected_array - observed_array)\n    mae: float = float(np.mean(absolute_errors)) if len(absolute_errors) &gt; 0 else 0.0\n\n    non_zero_mask: np.ndarray = observed_array != 0\n    filtered_absolute_errors: np.ndarray = absolute_errors[non_zero_mask]\n    filtered_observed_array: np.ndarray = observed_array[non_zero_mask]\n\n    mpe: float = 0.0\n    if len(filtered_absolute_errors) &gt; 0 and len(filtered_observed_array) &gt; 0:\n        percentage_errors: np.ndarray = (\n            filtered_absolute_errors / filtered_observed_array * 100\n        )\n        mpe = float(np.mean(percentage_errors))\n\n    return {\n        \"expected\": expected_values,\n        \"observed\": observed_values,\n        \"mae\": mae,\n        \"mpe\": mpe,\n    }\n</code></pre>"},{"location":"api/#patientflow.evaluate.calculate_weighted_observed","title":"<code>calculate_weighted_observed(df, dt, prediction_window, x1, y1, x2, y2, prediction_time)</code>","text":"<p>Calculate weighted observed admissions for a specific date and prediction window.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with arrival_datetime column.</p> required <code>dt</code> <code>date</code> <p>Target date for calculation.</p> required <code>prediction_window</code> <code>int</code> <p>Window length in minutes.</p> required <code>x1</code> <code>float</code> <p>First x-coordinate for aspirational curve.</p> required <code>y1</code> <code>float</code> <p>First y-coordinate for aspirational curve.</p> required <code>x2</code> <code>float</code> <p>Second x-coordinate for aspirational curve.</p> required <code>y2</code> <code>float</code> <p>Second y-coordinate for aspirational curve.</p> required <code>prediction_time</code> <code>tuple</code> <p>Tuple of (hour, minute) for prediction time.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Weighted sum of observed admissions for the specified time period.</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def calculate_weighted_observed(\n    df, dt, prediction_window, x1, y1, x2, y2, prediction_time\n):\n    \"\"\"Calculate weighted observed admissions for a specific date and prediction window.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame with arrival_datetime column.\n    dt : datetime.date\n        Target date for calculation.\n    prediction_window : int\n        Window length in minutes.\n    x1 : float\n        First x-coordinate for aspirational curve.\n    y1 : float\n        First y-coordinate for aspirational curve.\n    x2 : float\n        Second x-coordinate for aspirational curve.\n    y2 : float\n        Second y-coordinate for aspirational curve.\n    prediction_time : tuple\n        Tuple of (hour, minute) for prediction time.\n\n    Returns\n    -------\n    float\n        Weighted sum of observed admissions for the specified time period.\n    \"\"\"\n    # Create prediction datetime\n    prediction_datetime = pd.to_datetime(dt).replace(\n        hour=prediction_time[0], minute=prediction_time[1]\n    )\n\n    # Filter for target date and get arrivals with probabilities\n    filtered_df = df[df[\"arrival_datetime\"].dt.date == dt]\n    arrived_before, arrived_after = get_arrivals_with_admission_probs(\n        filtered_df,\n        prediction_datetime,\n        prediction_window,\n        prediction_time,\n        x1,\n        y1,\n        x2,\n        y2,\n        target_date=dt,\n    )\n\n    # Calculate weighted sum\n    weighted_observed = (\n        arrived_before[\"prob_admission_in_pred_window\"].sum()\n        + arrived_after[\"prob_admission_in_pred_window\"].sum()\n    )\n\n    return weighted_observed\n</code></pre>"},{"location":"api/#patientflow.evaluate.combine_distributions","title":"<code>combine_distributions(dist1, dist2)</code>","text":"<p>Combine two probability distributions using convolution.</p> <p>Parameters:</p> Name Type Description Default <code>dist1</code> <code>DataFrame</code> <p>First probability distribution.</p> required <code>dist2</code> <code>DataFrame</code> <p>Second probability distribution.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Combined probability distribution with columns: - agg_predicted : float     Combined probability values</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def combine_distributions(dist1: pd.DataFrame, dist2: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Combine two probability distributions using convolution.\n\n    Parameters\n    ----------\n    dist1 : pandas.DataFrame\n        First probability distribution.\n    dist2 : pandas.DataFrame\n        Second probability distribution.\n\n    Returns\n    -------\n    pandas.DataFrame\n        Combined probability distribution with columns:\n        - agg_predicted : float\n            Combined probability values\n    \"\"\"\n    arr1 = dist1.values\n    arr2 = dist2.values\n\n    combined = signal.convolve(arr1, arr2)\n    new_index = range(len(combined))\n\n    combined_df = pd.DataFrame(combined, index=new_index, columns=[\"agg_predicted\"])\n    combined_df[\"agg_predicted\"] = (\n        combined_df[\"agg_predicted\"] / combined_df[\"agg_predicted\"].sum()\n    )\n\n    return combined_df\n</code></pre>"},{"location":"api/#patientflow.evaluate.create_time_mask","title":"<code>create_time_mask(df, hour, minute)</code>","text":"<p>Create a mask for times before/after a specific hour:minute.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing arrival_datetime column.</p> required <code>hour</code> <code>int</code> <p>Target hour (0-23).</p> required <code>minute</code> <code>int</code> <p>Target minute (0-59).</p> required <p>Returns:</p> Type Description <code>Series</code> <p>Boolean mask indicating times after the specified hour:minute.</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def create_time_mask(df, hour, minute):\n    \"\"\"Create a mask for times before/after a specific hour:minute.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame containing arrival_datetime column.\n    hour : int\n        Target hour (0-23).\n    minute : int\n        Target minute (0-59).\n\n    Returns\n    -------\n    pandas.Series\n        Boolean mask indicating times after the specified hour:minute.\n    \"\"\"\n    return (df[\"arrival_datetime\"].dt.hour &gt; hour) | (\n        (df[\"arrival_datetime\"].dt.hour == hour)\n        &amp; (df[\"arrival_datetime\"].dt.minute &gt; minute)\n    )\n</code></pre>"},{"location":"api/#patientflow.evaluate.evaluate_combined_model","title":"<code>evaluate_combined_model(prob_dist_dict_all, df, yta_preds, prediction_window, x1, y1, x2, y2, prediction_time, num_weeks, model_name, use_most_probable=True)</code>","text":"<p>Evaluate the combined prediction model.</p> <p>Parameters:</p> Name Type Description Default <code>prob_dist_dict_all</code> <code>Dict[Any, Dict[Any, Dict[str, Any]]]</code> <p>Nested dictionary containing probability distributions.</p> required <code>df</code> <code>DataFrame</code> <p>DataFrame containing patient data.</p> required <code>yta_preds</code> <code>DataFrame</code> <p>Yet-to-arrive predictions.</p> required <code>prediction_window</code> <code>int</code> <p>Window length in minutes.</p> required <code>x1</code> <code>float</code> <p>First x-coordinate for aspirational curve.</p> required <code>y1</code> <code>float</code> <p>First y-coordinate for aspirational curve.</p> required <code>x2</code> <code>float</code> <p>Second x-coordinate for aspirational curve.</p> required <code>y2</code> <code>float</code> <p>Second y-coordinate for aspirational curve.</p> required <code>prediction_time</code> <code>Tuple[int, int]</code> <p>Hour and minute of prediction.</p> required <code>num_weeks</code> <code>int</code> <p>Number of previous weeks to consider.</p> required <code>model_name</code> <code>str</code> <p>Name of the model.</p> required <code>use_most_probable</code> <code>bool</code> <p>Whether to use the most probable value or expected value. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]</code> <p>Dictionary containing evaluation results: - expected : List[Union[int, float]]     Expected values for each prediction - observed : List[float]     Observed values for each prediction - mae : float     Mean Absolute Error - mpe : float     Mean Percentage Error</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def evaluate_combined_model(\n    prob_dist_dict_all: Dict[Any, Dict[Any, Dict[str, Any]]],\n    df: pd.DataFrame,\n    yta_preds: pd.DataFrame,\n    prediction_window: int,\n    x1: float,\n    y1: float,\n    x2: float,\n    y2: float,\n    prediction_time: Tuple[int, int],\n    num_weeks: int,\n    model_name: str,\n    use_most_probable: bool = True,\n) -&gt; Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]:\n    \"\"\"Evaluate the combined prediction model.\n\n    Parameters\n    ----------\n    prob_dist_dict_all : Dict[Any, Dict[Any, Dict[str, Any]]]\n        Nested dictionary containing probability distributions.\n    df : pandas.DataFrame\n        DataFrame containing patient data.\n    yta_preds : pandas.DataFrame\n        Yet-to-arrive predictions.\n    prediction_window : int\n        Window length in minutes.\n    x1 : float\n        First x-coordinate for aspirational curve.\n    y1 : float\n        First y-coordinate for aspirational curve.\n    x2 : float\n        Second x-coordinate for aspirational curve.\n    y2 : float\n        Second y-coordinate for aspirational curve.\n    prediction_time : Tuple[int, int]\n        Hour and minute of prediction.\n    num_weeks : int\n        Number of previous weeks to consider.\n    model_name : str\n        Name of the model.\n    use_most_probable : bool, optional\n        Whether to use the most probable value or expected value.\n        Default is True.\n\n    Returns\n    -------\n    Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]\n        Dictionary containing evaluation results:\n        - expected : List[Union[int, float]]\n            Expected values for each prediction\n        - observed : List[float]\n            Observed values for each prediction\n        - mae : float\n            Mean Absolute Error\n        - mpe : float\n            Mean Percentage Error\n    \"\"\"\n    expected_values: List[Union[int, float]] = []\n    observed_values: List[float] = []\n\n    model_name = get_model_key(model_name, prediction_time)\n\n    for dt in prob_dist_dict_all[model_name].keys():\n        in_ed_preds: Dict[str, Any] = prob_dist_dict_all[model_name][dt]\n        combined = combine_distributions(yta_preds, in_ed_preds[\"agg_predicted\"])\n\n        expected_value: Union[int, float] = (\n            int(combined[\"agg_predicted\"].idxmax())\n            if use_most_probable\n            else float(\n                np.dot(\n                    combined[\"agg_predicted\"].index,\n                    combined[\"agg_predicted\"].values.flatten(),\n                )\n            )\n        )\n\n        observed_value: float = float(\n            calculate_weighted_observed(\n                df, dt, prediction_window, x1, y1, x2, y2, prediction_time\n            )\n        )\n\n        expected_values.append(expected_value)\n        observed_values.append(observed_value)\n\n    results = {model_name: calculate_results(expected_values, observed_values)}\n    return results\n</code></pre>"},{"location":"api/#patientflow.evaluate.evaluate_six_week_average","title":"<code>evaluate_six_week_average(prob_dist_dict_all, df, prediction_window, x1, y1, x2, y2, prediction_time, num_weeks, model_name)</code>","text":"<p>Evaluate the six-week average prediction model.</p> <p>Parameters:</p> Name Type Description Default <code>prob_dist_dict_all</code> <code>Dict[Any, Dict[Any, Dict[str, Any]]]</code> <p>Nested dictionary containing probability distributions.</p> required <code>df</code> <code>DataFrame</code> <p>DataFrame containing patient data.</p> required <code>prediction_window</code> <code>int</code> <p>Prediction window in minutes.</p> required <code>x1</code> <code>float</code> <p>First x-coordinate for aspirational curve.</p> required <code>y1</code> <code>float</code> <p>First y-coordinate for aspirational curve.</p> required <code>prediction_time</code> <code>Tuple[int, int]</code> <p>Hour and minute of prediction.</p> required <code>num_weeks</code> <code>int</code> <p>Number of previous weeks to consider.</p> required <code>model_name</code> <code>str</code> <p>Name of the model.</p> required <p>Returns:</p> Type Description <code>Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]</code> <p>Dictionary containing evaluation results: - expected : List[Union[int, float]]     Expected values for each prediction - observed : List[float]     Observed values for each prediction</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def evaluate_six_week_average(\n    prob_dist_dict_all: Dict[Any, Dict[Any, Dict[str, Any]]],\n    df: pd.DataFrame,\n    prediction_window: int,\n    x1: float,\n    y1: float,\n    x2: float,\n    y2: float,\n    prediction_time: Tuple[int, int],\n    num_weeks: int,\n    model_name: str,\n) -&gt; Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]:\n    \"\"\"\n    Evaluate the six-week average prediction model.\n\n    Parameters\n    ----------\n    prob_dist_dict_all : Dict[Any, Dict[Any, Dict[str, Any]]]\n        Nested dictionary containing probability distributions.\n    df : pandas.DataFrame\n        DataFrame containing patient data.\n    prediction_window : int\n        Prediction window in minutes.\n    x1 : float\n        First x-coordinate for aspirational curve.\n    y1 : float\n        First y-coordinate for aspirational curve.\n    prediction_time : Tuple[int, int]\n        Hour and minute of prediction.\n    num_weeks : int\n        Number of previous weeks to consider.\n    model_name : str\n        Name of the model.\n\n    Returns\n    -------\n    Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]\n        Dictionary containing evaluation results:\n        - expected : List[Union[int, float]]\n            Expected values for each prediction\n        - observed : List[float]\n            Observed values for each prediction\n    \"\"\"\n    expected_values: List[Union[int, float]] = []\n    observed_values: List[float] = []\n\n    model_name = get_model_key(model_name, prediction_time)\n\n    for dt in prob_dist_dict_all[model_name].keys():\n        expected_value: float = float(\n            predict_using_previous_weeks(\n                df, dt, prediction_window, x1, y1, x2, y2, prediction_time, num_weeks\n            )\n        )\n        observed_value: float = float(\n            calculate_weighted_observed(\n                df, dt, prediction_window, x1, y1, x2, y2, prediction_time\n            )\n        )\n\n        expected_values.append(expected_value)\n        observed_values.append(observed_value)\n\n    results = {model_name: calculate_results(expected_values, observed_values)}\n    return results\n</code></pre>"},{"location":"api/#patientflow.evaluate.get_arrivals_with_admission_probs","title":"<code>get_arrivals_with_admission_probs(df, prediction_datetime, prediction_window, prediction_time, x1, y1, x2, y2, date_range=None, target_date=None, target_weekday=None)</code>","text":"<p>Get arrivals before and after prediction time with their admission probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with arrival_datetime column.</p> required <code>prediction_datetime</code> <code>datetime</code> <p>Datetime for prediction window start.</p> required <code>prediction_window</code> <code>int</code> <p>Window length in minutes.</p> required <code>prediction_time</code> <code>tuple</code> <p>Tuple of (hour, minute) for prediction time.</p> required <code>x1</code> <code>float</code> <p>First x-coordinate for aspirational curve.</p> required <code>y1</code> <code>float</code> <p>First y-coordinate for aspirational curve.</p> required <code>x2</code> <code>float</code> <p>Second x-coordinate for aspirational curve.</p> required <code>y2</code> <code>float</code> <p>Second y-coordinate for aspirational curve.</p> required <code>date_range</code> <code>tuple</code> <p>Optional tuple of (start_date, end_date) to filter data.</p> <code>None</code> <code>target_date</code> <code>date</code> <p>Optional specific date to analyze.</p> <code>None</code> <code>target_weekday</code> <code>int</code> <p>Optional specific weekday to filter for (0-6, where 0 is Monday).</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple of (arrived_before, arrived_after) DataFrames containing: - arrived_before : pandas.DataFrame     DataFrame with arrivals before prediction time - arrived_after : pandas.DataFrame     DataFrame with arrivals after prediction time</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def get_arrivals_with_admission_probs(\n    df,\n    prediction_datetime,\n    prediction_window,\n    prediction_time,\n    x1,\n    y1,\n    x2,\n    y2,\n    date_range=None,\n    target_date=None,\n    target_weekday=None,\n):\n    \"\"\"Get arrivals before and after prediction time with their admission probabilities.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame with arrival_datetime column.\n    prediction_datetime : datetime\n        Datetime for prediction window start.\n    prediction_window : int\n        Window length in minutes.\n    prediction_time : tuple\n        Tuple of (hour, minute) for prediction time.\n    x1 : float\n        First x-coordinate for aspirational curve.\n    y1 : float\n        First y-coordinate for aspirational curve.\n    x2 : float\n        Second x-coordinate for aspirational curve.\n    y2 : float\n        Second y-coordinate for aspirational curve.\n    date_range : tuple, optional\n        Optional tuple of (start_date, end_date) to filter data.\n    target_date : datetime.date, optional\n        Optional specific date to analyze.\n    target_weekday : int, optional\n        Optional specific weekday to filter for (0-6, where 0 is Monday).\n\n    Returns\n    -------\n    tuple\n        Tuple of (arrived_before, arrived_after) DataFrames containing:\n        - arrived_before : pandas.DataFrame\n            DataFrame with arrivals before prediction time\n        - arrived_after : pandas.DataFrame\n            DataFrame with arrivals after prediction time\n    \"\"\"\n    hour, minute = prediction_time\n\n    # Create base time masks\n    after_mask = create_time_mask(df, hour, minute)\n    before_mask = ~after_mask\n\n    # Add date and weekday conditions if specified\n    if date_range:\n        start_date, end_date = date_range\n        date_mask = (df[\"arrival_datetime\"].dt.date &gt;= start_date) &amp; (\n            df[\"arrival_datetime\"].dt.date &lt; end_date\n        )\n        if target_weekday is not None:\n            date_mask &amp;= df[\"arrival_datetime\"].dt.weekday == target_weekday\n\n        after_mask &amp;= date_mask\n        before_mask &amp;= date_mask\n\n    if target_date:\n        target_mask = df[\"arrival_datetime\"].dt.date == target_date\n        after_mask &amp;= target_mask\n        before_mask &amp;= target_mask\n\n    # Calculate probabilities for filtered groups\n    arrived_before = calculate_admission_probs_relative_to_prediction(\n        df[before_mask],\n        prediction_datetime,\n        prediction_window,\n        x1,\n        y1,\n        x2,\n        y2,\n        is_before=True,\n    )\n\n    arrived_after = calculate_admission_probs_relative_to_prediction(\n        df[after_mask],\n        prediction_datetime,\n        prediction_window,\n        x1,\n        y1,\n        x2,\n        y2,\n        is_before=False,\n    )\n\n    return arrived_before, arrived_after\n</code></pre>"},{"location":"api/#patientflow.evaluate.predict_using_previous_weeks","title":"<code>predict_using_previous_weeks(df, dt, prediction_window, x1, y1, x2, y2, prediction_time, num_weeks, weighted=True)</code>","text":"<p>Calculate predicted admissions remaining until midnight.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing patient data.</p> required <code>dt</code> <code>datetime</code> <p>Date for prediction.</p> required <code>prediction_window</code> <code>int</code> <p>Window length in minutes.</p> required <code>x1</code> <code>float</code> <p>First x-coordinate for aspirational curve.</p> required <code>y1</code> <code>float</code> <p>First y-coordinate for aspirational curve.</p> required <code>x2</code> <code>float</code> <p>Second x-coordinate for aspirational curve.</p> required <code>y2</code> <code>float</code> <p>Second y-coordinate for aspirational curve.</p> required <code>prediction_time</code> <code>Tuple[int, int]</code> <p>Hour and minute of prediction.</p> required <code>num_weeks</code> <code>int</code> <p>Number of previous weeks to consider.</p> required <code>weighted</code> <code>bool</code> <p>Whether to weight the numbers according to aspirational ED targets. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>float</code> <p>Predicted number of admissions remaining until midnight.</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def predict_using_previous_weeks(\n    df: pd.DataFrame,\n    dt: datetime,\n    prediction_window: int,\n    x1: float,\n    y1: float,\n    x2: float,\n    y2: float,\n    prediction_time: Tuple[int, int],\n    num_weeks: int,\n    weighted: bool = True,\n) -&gt; float:\n    \"\"\"Calculate predicted admissions remaining until midnight.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame containing patient data.\n    dt : datetime\n        Date for prediction.\n    prediction_window : int\n        Window length in minutes.\n    x1 : float\n        First x-coordinate for aspirational curve.\n    y1 : float\n        First y-coordinate for aspirational curve.\n    x2 : float\n        Second x-coordinate for aspirational curve.\n    y2 : float\n        Second y-coordinate for aspirational curve.\n    prediction_time : Tuple[int, int]\n        Hour and minute of prediction.\n    num_weeks : int\n        Number of previous weeks to consider.\n    weighted : bool, optional\n        Whether to weight the numbers according to aspirational ED targets.\n        Default is True.\n\n    Returns\n    -------\n    float\n        Predicted number of admissions remaining until midnight.\n    \"\"\"\n    prediction_datetime = pd.to_datetime(dt).replace(\n        hour=prediction_time[0], minute=prediction_time[1]\n    )\n    target_day_of_week = dt.weekday()\n\n    end_date = dt - timedelta(days=1)\n    start_date = end_date - timedelta(weeks=num_weeks)\n\n    if weighted:\n        # Create mask for historical data\n        historical_mask = (\n            (df[\"arrival_datetime\"].dt.date &gt;= start_date)\n            &amp; (df[\"arrival_datetime\"].dt.date &lt;= end_date)\n            &amp; (df[\"arrival_datetime\"].dt.weekday == target_day_of_week)\n        )\n\n        # Create explicit copy of filtered data\n        historical_data = df[historical_mask].copy()\n\n        # Calculate minutes until midnight\n        midnight_times = (\n            historical_data[\"arrival_datetime\"].dt.normalize()\n            + pd.Timedelta(days=1)\n            - pd.Timedelta(minutes=1)\n        )\n        historical_data.loc[:, \"minutes_to_midnight\"] = (\n            midnight_times - historical_data[\"arrival_datetime\"]\n        ).dt.total_seconds() / 60\n\n        # Calculate admission probabilities\n        historical_data.loc[:, \"admission_probability\"] = historical_data[\n            \"minutes_to_midnight\"\n        ].apply(lambda x: get_y_from_aspirational_curve(x / 60, x1, y1, x2, y2))\n\n        # Group by date and calculate average\n        historical_daily_sums = historical_data.groupby(\n            historical_data[\"arrival_datetime\"].dt.date\n        )[\"admission_probability\"].sum()\n        historical_average = historical_daily_sums.mean()\n\n        # Create mask for today's data\n        today_mask = (df[\"arrival_datetime\"].dt.date == dt) &amp; (\n            df[\"arrival_datetime\"] &lt; prediction_datetime\n        )\n\n        # Create explicit copy of today's filtered data\n        today_data = df[today_mask].copy()\n\n        # Calculate minutes until midnight for today's data\n        midnight_today = (\n            pd.to_datetime(dt).normalize()\n            + pd.Timedelta(days=1)\n            - pd.Timedelta(minutes=1)\n        )\n        today_data.loc[:, \"minutes_to_midnight\"] = (\n            midnight_today - today_data[\"arrival_datetime\"]\n        ).dt.total_seconds() / 60\n\n        # Calculate admission probabilities for today\n        today_data.loc[:, \"admission_probability\"] = today_data[\n            \"minutes_to_midnight\"\n        ].apply(lambda x: get_y_from_aspirational_curve(x / 60, x1, y1, x2, y2))\n\n        today_sum = today_data[\"admission_probability\"].sum()\n\n        still_to_admit = max(historical_average - today_sum, 0)\n\n    else:\n        # Original unweighted logic with explicit copies\n        historical_mask = (\n            (df[\"arrival_datetime\"].dt.date &gt;= start_date)\n            &amp; (df[\"arrival_datetime\"].dt.date &lt; end_date)\n            &amp; (df[\"arrival_datetime\"].dt.weekday == target_day_of_week)\n        )\n        historical_df = df[historical_mask].copy()\n        average_count = len(historical_df) / num_weeks\n\n        target_mask = (df[\"arrival_datetime\"].dt.date == dt) &amp; (\n            df[\"arrival_datetime\"] &lt; prediction_datetime\n        )\n        target_date_count = len(df[target_mask])\n\n        still_to_admit = max(average_count - target_date_count, 0)\n\n    return still_to_admit\n</code></pre>"},{"location":"api/#patientflow.generate","title":"<code>generate</code>","text":"<p>Generate fake Emergency Department visit data.</p> <p>This module provides functions to generate fake datasets for patient visits to an emergency department (ED). It generates arrival and departure times, triage scores, lab orders, and patient admissions. The functions are used for illustrative purposes in some of the notebooks.</p> <p>Functions:</p> Name Description <code>create_fake_finished_visits</code> <p>Generate synthetic patient visits, triage observations, and lab orders.</p> <code>create_fake_snapshots</code> <p>Create patient-level snapshots at specific times with visit, triage, and lab features.</p>"},{"location":"api/#patientflow.generate.create_fake_finished_visits","title":"<code>create_fake_finished_visits(start_date, end_date, mean_patients_per_day, admitted_only=False)</code>","text":"<p>Generate synthetic patient visit data for an emergency department.</p> <p>This function simulates a realistic distribution of patient arrivals, triage scores, lengths of stay, admissions, and lab orders over a specified date range. Some patients may have multiple visits.</p> <p>Parameters:</p> Name Type Description Default <code>start_date</code> <code>str or datetime</code> <p>The starting date for the simulation (inclusive). Can be a datetime object or a string in 'YYYY-MM-DD' format.</p> required <code>end_date</code> <code>str or datetime</code> <p>The ending date for the simulation (exclusive). Can be a datetime object or a string in 'YYYY-MM-DD' format.</p> required <code>mean_patients_per_day</code> <code>float</code> <p>The average number of patient visits to generate per day.</p> required <code>admitted_only</code> <code>bool</code> <p>If True, only return admitted patients. The mean_patients_per_day will be adjusted to maintain the same total number of admitted patients as would be expected in the full dataset.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>visits_df</code> <code>DataFrame</code> <p>DataFrame containing visit records with the following columns: - 'visit_number' - 'patient_id' - 'arrival_datetime' - 'departure_datetime' - 'is_admitted' - 'specialty' - 'age'</p> <code>observations_df</code> <code>DataFrame</code> <p>DataFrame containing triage score observations with columns: - 'visit_number' - 'observation_datetime' - 'triage_score'</p> <code>lab_orders_df</code> <code>DataFrame</code> <p>DataFrame containing lab test orders with columns: - 'visit_number' - 'order_datetime' - 'lab_name'</p> Notes <ul> <li>Patients are more likely to arrive during daytime hours.</li> <li>20% of patients will have more than one visit during the simulation period.</li> <li>Lab test ordering likelihood depends on the severity of the triage score.</li> <li>When admitted_only=True, the mean_patients_per_day is adjusted to maintain the same number   of admitted patients as would be expected in the full dataset.</li> </ul> Source code in <code>src/patientflow/generate.py</code> <pre><code>def create_fake_finished_visits(\n    start_date, end_date, mean_patients_per_day, admitted_only=False\n):\n    \"\"\"\n    Generate synthetic patient visit data for an emergency department.\n\n    This function simulates a realistic distribution of patient arrivals, triage scores, lengths of stay,\n    admissions, and lab orders over a specified date range. Some patients may have multiple visits.\n\n    Parameters\n    ----------\n    start_date : str or datetime\n        The starting date for the simulation (inclusive). Can be a datetime object or a string in 'YYYY-MM-DD' format.\n    end_date : str or datetime\n        The ending date for the simulation (exclusive). Can be a datetime object or a string in 'YYYY-MM-DD' format.\n    mean_patients_per_day : float\n        The average number of patient visits to generate per day.\n    admitted_only : bool, optional\n        If True, only return admitted patients. The mean_patients_per_day will be adjusted to maintain\n        the same total number of admitted patients as would be expected in the full dataset.\n\n    Returns\n    -------\n    visits_df : pandas.DataFrame\n        DataFrame containing visit records with the following columns:\n        - 'visit_number'\n        - 'patient_id'\n        - 'arrival_datetime'\n        - 'departure_datetime'\n        - 'is_admitted'\n        - 'specialty'\n        - 'age'\n    observations_df : pandas.DataFrame\n        DataFrame containing triage score observations with columns:\n        - 'visit_number'\n        - 'observation_datetime'\n        - 'triage_score'\n    lab_orders_df : pandas.DataFrame\n        DataFrame containing lab test orders with columns:\n        - 'visit_number'\n        - 'order_datetime'\n        - 'lab_name'\n\n    Notes\n    -----\n    - Patients are more likely to arrive during daytime hours.\n    - 20% of patients will have more than one visit during the simulation period.\n    - Lab test ordering likelihood depends on the severity of the triage score.\n    - When admitted_only=True, the mean_patients_per_day is adjusted to maintain the same number\n      of admitted patients as would be expected in the full dataset.\n    \"\"\"\n\n    # Convert string dates to datetime if needed\n    if isinstance(start_date, str):\n        start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n    if isinstance(end_date, str):\n        end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n\n    # Set random seed for reproducibility\n    np.random.seed(42)  # You can change this seed value as needed\n\n    # Define admission probabilities based on triage score\n    # Triage 1: 80% admission, Triage 2: 60%, Triage 3: 30%, Triage 4: 10%, Triage 5: 2%\n    admission_probabilities = {\n        1: 0.80,  # Highest severity - highest admission probability\n        2: 0.60,\n        3: 0.30,\n        4: 0.10,\n        5: 0.02,  # Lowest severity - lowest admission probability\n    }\n\n    # Define triage score distribution\n    # Most common is 3-4, less common are 2 and 5, least common is 1 (most severe)\n    triage_probabilities = [0.05, 0.15, 0.35, 0.35, 0.10]  # For scores 1-5\n\n    # Calculate total days in range (changed to exclusive end date)\n    days_range = (end_date - start_date).days\n\n    # If admitted_only is True, adjust mean_patients_per_day to maintain the same number of admitted patients\n    if admitted_only:\n        # Calculate expected admission rate based on triage probabilities and admission probabilities\n        expected_admission_rate = sum(\n            triage_prob * admission_prob\n            for triage_prob, admission_prob in zip(\n                triage_probabilities, admission_probabilities.values()\n            )\n        )\n        # Adjust mean_patients_per_day to maintain the same number of admitted patients\n        mean_patients_per_day = mean_patients_per_day / expected_admission_rate\n\n    # Generate random number of patients for each day using Poisson distribution\n    daily_patients = np.random.poisson(mean_patients_per_day, days_range)\n\n    # Calculate the total number of visits\n    total_visits = sum(daily_patients)\n\n    # Calculate approximately how many unique patients we need\n    # If 20% of patients have more than one visit (let's assume they have exactly 2),\n    # then for N total visits, we need approximately N * 0.8 + (N * 0.2) / 2 unique patients\n    # Simplifying: N * (0.8 + 0.1) = N * 0.9 unique patients\n    num_unique_patients = int(total_visits * 0.9)\n\n    # Create patient ids\n    patient_ids = list(range(1, num_unique_patients + 1))\n\n    # Define common ED lab tests and their ordering probabilities based on triage score\n    lab_tests = [\"CBC\", \"BMP\", \"Troponin\", \"D-dimer\", \"Urinalysis\"]\n    lab_probabilities = {\n        # Higher severity -&gt; more likely to get labs\n        1: {\n            \"CBC\": 0.95,\n            \"BMP\": 0.95,\n            \"Troponin\": 0.90,\n            \"D-dimer\": 0.70,\n            \"Urinalysis\": 0.60,\n        },\n        2: {\n            \"CBC\": 0.90,\n            \"BMP\": 0.90,\n            \"Troponin\": 0.80,\n            \"D-dimer\": 0.60,\n            \"Urinalysis\": 0.50,\n        },\n        3: {\n            \"CBC\": 0.80,\n            \"BMP\": 0.80,\n            \"Troponin\": 0.60,\n            \"D-dimer\": 0.40,\n            \"Urinalysis\": 0.40,\n        },\n        4: {\n            \"CBC\": 0.60,\n            \"BMP\": 0.60,\n            \"Troponin\": 0.30,\n            \"D-dimer\": 0.20,\n            \"Urinalysis\": 0.30,\n        },\n        5: {\n            \"CBC\": 0.40,\n            \"BMP\": 0.40,\n            \"Troponin\": 0.15,\n            \"D-dimer\": 0.10,\n            \"Urinalysis\": 0.20,\n        },\n    }\n\n    visits = []\n    observations = []\n    lab_orders = []\n    visit_number = 1\n\n    # Create a dictionary to track number of visits per patient\n    patient_visit_count = {patient_id: 0 for patient_id in patient_ids}\n\n    # Create a pool of patients who will have multiple visits (20% of patients)\n    multi_visit_patients = set(\n        np.random.choice(\n            patient_ids, size=int(num_unique_patients * 0.2), replace=False\n        )\n    )\n\n    for day_idx, num_patients in enumerate(daily_patients):\n        current_date = start_date + timedelta(days=day_idx)\n\n        # Generate patients for this day\n        for _ in range(num_patients):\n            # Select a patient ID based on our requirements\n            # If we haven't assigned all patients yet, use a new one\n            # Otherwise, pick from multi-visit patients\n            available_new_patients = [\n                pid for pid in patient_ids if patient_visit_count[pid] == 0\n            ]\n\n            if available_new_patients:\n                # Use a new patient\n                patient_id = np.random.choice(available_new_patients)\n            else:\n                # All patients have at least one visit, now use multi-visit patients\n                patient_id = np.random.choice(list(multi_visit_patients))\n\n            # Increment the visit count for this patient\n            patient_visit_count[patient_id] += 1\n\n            # Random hour for arrival (more likely during daytime)\n            arrival_hour = np.random.normal(13, 4)  # Mean at 1 PM, std dev of 4 hours\n            arrival_hour = max(0, min(23, int(arrival_hour)))  # Clamp between 0-23\n\n            # Random minutes\n            arrival_minute = np.random.randint(0, 60)\n\n            # Create arrival datetime\n            arrival_datetime = current_date.replace(\n                hour=arrival_hour,\n                minute=arrival_minute,\n                second=np.random.randint(0, 60),\n            )\n\n            # Generate triage score (1-5)\n            triage_score = np.random.choice([1, 2, 3, 4, 5], p=triage_probabilities)\n\n            # Generate admission status based on triage score\n            admission_prob = admission_probabilities[triage_score]\n            is_admitted = np.random.choice(\n                [0, 1], p=[1 - admission_prob, admission_prob]\n            )\n\n            # Generate specialty for admitted patients\n            if is_admitted:\n                specialty = np.random.choice(\n                    [\"medical\", \"surgical\", \"haem/onc\", \"paediatric\"],\n                    p=[0.65, 0.25, 0.05, 0.05],\n                )\n            else:\n                specialty = None\n\n            # Skip this visit if admitted_only is True and patient is not admitted\n            if admitted_only and not is_admitted:\n                continue\n\n            # Generate length of stay (in minutes) - log-normal distribution\n            # Most visits are 4 to 12 hours, but some can be shorter or longer\n            length_of_stay = np.random.lognormal(mean=5.8, sigma=0.5)\n            length_of_stay = max(\n                60, min(2880, length_of_stay)\n            )  # Between 1 hour and 48 hours\n\n            # Make higher triage scores (more severe) stay longer on average\n            if triage_score &lt;= 2:\n                length_of_stay *= 1.8  # 80% longer stays for more severe cases\n\n            # Calculate departure time\n            departure_datetime = arrival_datetime + timedelta(\n                minutes=int(length_of_stay)\n            )\n\n            # For returning patients, use the same age as their first visit\n            if patient_id in [v[\"patient_id\"] for v in visits]:\n                # Find the age from a previous visit\n                age = next(v[\"age\"] for v in visits if v[\"patient_id\"] == patient_id)\n            else:\n                # Generate age with a distribution skewed towards older adults\n                age = int(\n                    np.random.lognormal(mean=3.8, sigma=0.5)\n                )  # Centers around 45 years\n                age = max(0, min(100, age))  # Clamp between 0-100 years\n\n            # Add visit record (without triage score, but with patient_id)\n            visits.append(\n                {\n                    \"patient_id\": patient_id,\n                    \"visit_number\": visit_number,\n                    \"arrival_datetime\": arrival_datetime,\n                    \"departure_datetime\": departure_datetime,\n                    \"age\": age,\n                    \"is_admitted\": is_admitted,\n                    \"specialty\": specialty,\n                }\n            )\n\n            # Generate triage observation within first 10 minutes\n            minutes_after_arrival = np.random.uniform(0, 10)\n            observation_datetime = arrival_datetime + timedelta(\n                minutes=minutes_after_arrival\n            )\n\n            observations.append(\n                {\n                    \"visit_number\": visit_number,\n                    \"observation_datetime\": observation_datetime,\n                    \"triage_score\": triage_score,\n                }\n            )\n\n            # Generate lab orders if visit is longer than 2 hours\n            if length_of_stay &gt; 120:\n                # For each lab test, decide if it should be ordered based on triage score\n                for lab_test in lab_tests:\n                    if np.random.random() &lt; lab_probabilities[triage_score][lab_test]:\n                        # Order time is after triage but within first 90 minutes\n                        minutes_after_triage = np.random.uniform(\n                            0, 90 - minutes_after_arrival\n                        )\n                        order_datetime = observation_datetime + timedelta(\n                            minutes=minutes_after_triage\n                        )\n\n                        lab_orders.append(\n                            {\n                                \"visit_number\": visit_number,\n                                \"order_datetime\": order_datetime,\n                                \"lab_name\": lab_test,\n                            }\n                        )\n\n            visit_number += 1\n\n    # Create DataFrames and sort by time\n    visits_df = pd.DataFrame(visits)\n    visits_df = visits_df.sort_values(\"arrival_datetime\").reset_index(drop=True)\n\n    observations_df = pd.DataFrame(observations)\n    observations_df = observations_df.sort_values(\"observation_datetime\").reset_index(\n        drop=True\n    )\n\n    lab_orders_df = pd.DataFrame(lab_orders)\n    if not lab_orders_df.empty:\n        lab_orders_df = lab_orders_df.sort_values(\"order_datetime\").reset_index(\n            drop=True\n        )\n\n    return visits_df, observations_df, lab_orders_df\n</code></pre>"},{"location":"api/#patientflow.generate.create_fake_snapshots","title":"<code>create_fake_snapshots(prediction_times, start_date, end_date, df=None, observations_df=None, lab_orders_df=None, mean_patients_per_day=50)</code>","text":"<p>Generate patient-level snapshots at specific times for prediction modeling.</p> <p>For each specified time on each date in the range, this function returns a snapshot of patients who are currently in the emergency department, along with their visit features, latest triage score, and number of lab tests ordered prior to that time.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_times</code> <code>list of tuple of int</code> <p>A list of (hour, minute) tuples indicating times of day to create snapshots.</p> required <code>start_date</code> <code>str or datetime</code> <p>The starting date for generating snapshots (inclusive).</p> required <code>end_date</code> <code>str or datetime</code> <p>The ending date for generating snapshots (exclusive).</p> required <code>df</code> <code>DataFrame</code> <p>Patient visit data from <code>create_fake_finished_visits</code>. If None, synthetic data is generated.</p> <code>None</code> <code>observations_df</code> <code>DataFrame</code> <p>Triage score data from <code>create_fake_finished_visits</code>. If None, synthetic data is generated.</p> <code>None</code> <code>lab_orders_df</code> <code>DataFrame</code> <p>Lab order data from <code>create_fake_finished_visits</code>. If None, synthetic data is generated.</p> <code>None</code> <code>mean_patients_per_day</code> <code>float</code> <p>Average number of patients per day (used only if synthetic data is generated).</p> <code>50</code> <p>Returns:</p> Name Type Description <code>final_df</code> <code>DataFrame</code> <p>A DataFrame with one row per patient visit present at the snapshot time. Columns include: - 'snapshot_date' - 'prediction_time' - 'patient_id' - 'visit_number' - 'is_admitted' - 'age' - 'latest_triage_score' - One column per lab test: 'num__orders' Notes <ul> <li>Only patients present in the ED at the snapshot time are included.</li> <li>Lab order columns reflect counts of tests ordered before the snapshot time.</li> <li>If no patients are present at a snapshot time, that snapshot is omitted.</li> </ul> Source code in <code>src/patientflow/generate.py</code> <pre><code>def create_fake_snapshots(\n    prediction_times,\n    start_date,\n    end_date,\n    df=None,\n    observations_df=None,\n    lab_orders_df=None,\n    mean_patients_per_day=50,\n):\n    \"\"\"\n    Generate patient-level snapshots at specific times for prediction modeling.\n\n    For each specified time on each date in the range, this function returns a snapshot of patients\n    who are currently in the emergency department, along with their visit features, latest triage score,\n    and number of lab tests ordered prior to that time.\n\n    Parameters\n    ----------\n    prediction_times : list of tuple of int\n        A list of (hour, minute) tuples indicating times of day to create snapshots.\n    start_date : str or datetime\n        The starting date for generating snapshots (inclusive).\n    end_date : str or datetime\n        The ending date for generating snapshots (exclusive).\n    df : pandas.DataFrame, optional\n        Patient visit data from `create_fake_finished_visits`. If None, synthetic data is generated.\n    observations_df : pandas.DataFrame, optional\n        Triage score data from `create_fake_finished_visits`. If None, synthetic data is generated.\n    lab_orders_df : pandas.DataFrame, optional\n        Lab order data from `create_fake_finished_visits`. If None, synthetic data is generated.\n    mean_patients_per_day : float, optional\n        Average number of patients per day (used only if synthetic data is generated).\n\n    Returns\n    -------\n    final_df : pandas.DataFrame\n        A DataFrame with one row per patient visit present at the snapshot time. Columns include:\n        - 'snapshot_date'\n        - 'prediction_time'\n        - 'patient_id'\n        - 'visit_number'\n        - 'is_admitted'\n        - 'age'\n        - 'latest_triage_score'\n        - One column per lab test: 'num_&lt;lab_name&gt;_orders'\n\n    Notes\n    -----\n    - Only patients present in the ED at the snapshot time are included.\n    - Lab order columns reflect counts of tests ordered before the snapshot time.\n    - If no patients are present at a snapshot time, that snapshot is omitted.\n    \"\"\"\n\n    # Generate fake data if not provided\n    if df is None or observations_df is None or lab_orders_df is None:\n        df, observations_df, lab_orders_df = create_fake_finished_visits(\n            start_date, end_date, mean_patients_per_day\n        )\n\n    # Add date conversion at the start\n    if isinstance(start_date, str):\n        start_date = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n    elif isinstance(start_date, datetime):\n        start_date = start_date.date()\n\n    if isinstance(end_date, str):\n        end_date = datetime.strptime(end_date, \"%Y-%m-%d\").date()\n    elif isinstance(end_date, datetime):\n        end_date = end_date.date()\n\n    # Create date range (changed to exclusive end date)\n    snapshot_dates = []\n    current_date = start_date\n    while current_date &lt; end_date:  # Changed from &lt;= to &lt;\n        snapshot_dates.append(current_date)\n        current_date += timedelta(days=1)\n\n    # Get unique lab test names\n    lab_tests = lab_orders_df[\"lab_name\"].unique() if not lab_orders_df.empty else []\n\n    # Create empty list to store all results\n    all_results = []\n\n    # For each combination of date and time\n    for date in snapshot_dates:\n        for hour, minute in prediction_times:\n            snapshot_datetime = datetime.combine(date, time(hour=hour, minute=minute))\n\n            # Filter dataframe for this snapshot\n            mask = (df[\"arrival_datetime\"] &lt;= snapshot_datetime) &amp; (\n                df[\"departure_datetime\"] &gt; snapshot_datetime\n            )\n            snapshot_df = df[mask].copy()  # Create copy to avoid SettingWithCopyWarning\n\n            # Skip if no patients at this time\n            if len(snapshot_df) == 0:\n                continue\n\n            # Get triage scores recorded before the snapshot time\n            valid_observations = observations_df[\n                (observations_df[\"visit_number\"].isin(snapshot_df[\"visit_number\"]))\n                &amp; (observations_df[\"observation_datetime\"] &lt;= snapshot_datetime)\n            ].copy()\n\n            # Keep only the most recent triage score for each visit\n            if not valid_observations.empty:\n                valid_observations = valid_observations.sort_values(\n                    \"observation_datetime\"\n                )\n                valid_observations = (\n                    valid_observations.groupby(\"visit_number\").last().reset_index()\n                )\n                valid_observations = valid_observations.rename(\n                    columns={\"triage_score\": \"latest_triage_score\"}\n                )\n\n            # Get lab orders placed before the snapshot time\n            valid_orders = lab_orders_df[\n                (lab_orders_df[\"visit_number\"].isin(snapshot_df[\"visit_number\"]))\n                &amp; (lab_orders_df[\"order_datetime\"] &lt;= snapshot_datetime)\n            ].copy()\n\n            # Initialize lab_counts with zeros for all visits in snapshot_df\n            lab_counts = pd.DataFrame(\n                0,\n                index=pd.Index(\n                    snapshot_df[\"visit_number\"].unique(), name=\"visit_number\"\n                ),\n                columns=[f\"num_{test.lower()}_orders\" for test in lab_tests],\n            )\n\n            # Update counts if there are any valid orders\n            if not valid_orders.empty:\n                order_counts = (\n                    valid_orders.groupby([\"visit_number\", \"lab_name\"])\n                    .size()\n                    .unstack(fill_value=0)\n                )\n                order_counts.columns = [\n                    f\"num_{test.lower()}_orders\" for test in order_counts.columns\n                ]\n                # Update the counts in lab_counts where we have orders\n                lab_counts.update(order_counts)\n\n            lab_counts = lab_counts.reset_index()\n\n            # Add snapshot information columns\n            snapshot_df[\"snapshot_date\"] = date\n            snapshot_df[\"prediction_time\"] = [(hour, minute)] * len(snapshot_df)\n\n            # Merge with valid observations to get triage scores, handling empty case\n            if not valid_observations.empty:\n                snapshot_df = pd.merge(\n                    snapshot_df,\n                    valid_observations[[\"visit_number\", \"latest_triage_score\"]],\n                    on=\"visit_number\",\n                    how=\"left\",\n                )\n            else:\n                snapshot_df[\"latest_triage_score\"] = pd.Series(\n                    [np.nan] * len(snapshot_df),\n                    dtype=\"float64\",\n                    index=snapshot_df.index,\n                )\n            # Merge with lab counts\n            snapshot_df = pd.merge(\n                snapshot_df, lab_counts, on=\"visit_number\", how=\"left\"\n            )\n\n            # Fill NA values in lab count columns with 0\n            for col in snapshot_df.columns:\n                if col.endswith(\"_orders\"):\n                    snapshot_df[col] = snapshot_df[col].fillna(0)\n            if not snapshot_df.empty:\n                # Optionally check for all-NA in key columns\n                snapshot_cols = [\n                    \"snapshot_date\",\n                    \"prediction_time\",\n                    \"snapshot_datetime\",\n                ]\n                # Only check columns that exist in the DataFrame\n                check_cols = [\n                    col for col in snapshot_cols if col in snapshot_df.columns\n                ]\n\n                if not check_cols or not snapshot_df[check_cols].isna().all().any():\n                    all_results.append(snapshot_df)\n                else:\n                    print(\n                        f\"Skipping DataFrame with all-NA values in key columns: {check_cols}\"\n                    )\n            else:\n                print(\"Skipping empty DataFrame\")\n\n    # Combine all results into single dataframe\n    if all_results:\n        final_df = pd.concat(all_results, ignore_index=True)\n\n        # Define column order\n        snapshot_cols = [\"snapshot_date\", \"prediction_time\"]\n        visit_cols = [\n            \"patient_id\",\n            \"visit_number\",\n            \"is_admitted\",\n            \"age\",\n            \"latest_triage_score\",\n        ]\n        lab_cols = [col for col in final_df.columns if col.endswith(\"_orders\")]\n\n        # Ensure all required columns exist\n        for col in visit_cols:\n            if col not in final_df.columns:\n                if col == \"latest_triage_score\":\n                    final_df[col] = pd.NA\n                else:\n                    final_df[col] = None\n\n        # Reorder columns\n        final_df = final_df[snapshot_cols + visit_cols + lab_cols]\n    else:\n        # Create empty dataframe with correct columns if no results found\n        lab_cols = [f\"num_{test.lower()}_orders\" for test in lab_tests]\n        columns = [\n            \"snapshot_date\",\n            \"prediction_time\",\n            \"visit_number\",\n            \"is_admitted\",\n            \"age\",\n            \"latest_triage_score\",\n        ] + lab_cols\n        final_df = pd.DataFrame(columns=columns)\n\n    # Name the index snapshot_id before returning\n    final_df.index.name = \"snapshot_id\"\n    return final_df\n</code></pre>"},{"location":"api/#patientflow.load","title":"<code>load</code>","text":"<p>This module provides functionality for loading configuration files, data from CSV files, and trained machine learning models.</p> <p>It includes the following features:</p> <ul> <li>Loading Configurations: Parse YAML configuration files and extract necessary parameters for data processing and modeling.</li> <li>Data Handling: Load and preprocess data from CSV files, including optional operations like setting an index, sorting, and applying literal evaluation on columns.</li> <li>Model Management: Load saved machine learning models, customize model filenames based on time, and categorize DataFrame columns into predefined groups for analysis.</li> </ul> <p>The module handles common file and parsing errors, returning appropriate error messages or exceptions.</p> <p>Functions:</p> Name Description <code>parse_args:</code> <p>Parses command-line arguments for training models.</p> <code>set_project_root:</code> <p>Validates project root path from specified environment variable.</p> <code>load_config_file:</code> <p>Load a YAML configuration file and extract key parameters.</p> <code>set_file_paths:</code> <p>Sets up the file paths based on UCLH-specific or default parameters.</p> <code>set_data_file_names:</code> <p>Set file locations based on UCLH-specific or default data sources.</p> <code>safe_literal_eval:</code> <p>Safely evaluate string literals into Python objects when loading from csv.</p> <code>load_data:</code> <p>Load and preprocess data from a CSV or pickle file.</p> <code>get_model_key:</code> <p>Generate a model name based on the time of day.</p> <code>load_saved_model:</code> <p>Load a machine learning model saved in a joblib file.</p> <code>get_dict_cols:</code> <p>Categorize columns from a DataFrame into predefined groups for analysis.</p>"},{"location":"api/#patientflow.load.data_from_csv","title":"<code>data_from_csv(csv_path, index_column=None, sort_columns=None, eval_columns=None)</code>","text":"<p>Loads data from a CSV file, with optional transformations. LEGACY!</p> <p>This function loads a CSV file into a pandas DataFrame and provides the following optional features: - Setting a specified column as the index. - Sorting the DataFrame by one or more specified columns. - Applying safe literal evaluation to specified columns to handle string representations of Python objects.</p> <p>Parameters:</p> Name Type Description Default <code>csv_path</code> <code>str</code> <p>The relative or absolute path to the CSV file.</p> required <code>index_column</code> <code>str</code> <p>The column to set as the index of the DataFrame. If not provided, no index column is set.</p> <code>None</code> <code>sort_columns</code> <code>list of str</code> <p>A list of columns by which to sort the DataFrame. If not provided, the DataFrame is not sorted.</p> <code>None</code> <code>eval_columns</code> <code>list of str</code> <p>A list of columns to which <code>safe_literal_eval</code> should be applied. This is useful for columns containing string representations of Python data structures (e.g., lists, dictionaries).</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame containing the loaded data with any specified transformations applied.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the file cannot be found or another error occurs during loading or processing.</p> Notes <p>The function will terminate the program with a message if the file is not found or if any errors occur while loading the data. If sorting columns or applying <code>safe_literal_eval</code> fails, a warning message is printed, but execution continues.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def data_from_csv(csv_path, index_column=None, sort_columns=None, eval_columns=None):\n    \"\"\"\n    Loads data from a CSV file, with optional transformations. LEGACY!\n\n    This function loads a CSV file into a pandas DataFrame and provides the following optional features:\n    - Setting a specified column as the index.\n    - Sorting the DataFrame by one or more specified columns.\n    - Applying safe literal evaluation to specified columns to handle string representations of Python objects.\n\n    Parameters\n    ----------\n    csv_path : str\n        The relative or absolute path to the CSV file.\n    index_column : str, optional\n        The column to set as the index of the DataFrame. If not provided, no index column is set.\n    sort_columns : list of str, optional\n        A list of columns by which to sort the DataFrame. If not provided, the DataFrame is not sorted.\n    eval_columns : list of str, optional\n        A list of columns to which `safe_literal_eval` should be applied. This is useful for columns containing\n        string representations of Python data structures (e.g., lists, dictionaries).\n\n    Returns\n    -------\n    pd.DataFrame\n        A pandas DataFrame containing the loaded data with any specified transformations applied.\n\n    Raises\n    ------\n    SystemExit\n        If the file cannot be found or another error occurs during loading or processing.\n\n    Notes\n    -----\n    The function will terminate the program with a message if the file is not found or if any errors\n    occur while loading the data. If sorting columns or applying `safe_literal_eval` fails,\n    a warning message is printed, but execution continues.\n\n    \"\"\"\n    path = os.path.join(Path().home(), csv_path)\n\n    if not os.path.exists(path):\n        print(f\"Data file not found at path: {path}\")\n        sys.exit(1)\n\n    try:\n        df = pd.read_csv(path, parse_dates=True)\n    except FileNotFoundError:\n        print(f\"Data file not found at path: {path}\")\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        sys.exit(1)\n\n    if index_column:\n        try:\n            if df.index.name != index_column:\n                df = df.set_index(index_column)\n        except KeyError:\n            print(f\"Index column '{index_column}' not found in dataframe\")\n\n    if sort_columns:\n        try:\n            df.sort_values(sort_columns, inplace=True)\n        except KeyError:\n            print(\"One or more sort columns not found in dataframe\")\n\n    if eval_columns:\n        for column in eval_columns:\n            if column in df.columns:\n                try:\n                    df[column] = df[column].apply(safe_literal_eval)\n                except Exception as e:\n                    print(f\"Error applying safe_literal_eval to column '{column}': {e}\")\n\n    return df\n</code></pre>"},{"location":"api/#patientflow.load.get_dict_cols","title":"<code>get_dict_cols(df)</code>","text":"<p>Categorize DataFrame columns into predefined groups.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to categorize.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary where keys are column group names and values are lists of column names in each group.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def get_dict_cols(df):\n    \"\"\"\n    Categorize DataFrame columns into predefined groups.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame to categorize.\n\n    Returns\n    -------\n    dict\n        A dictionary where keys are column group names and values are lists of column names in each group.\n    \"\"\"\n    not_used_in_training_vars = [\n        \"snapshot_id\",\n        \"snapshot_date\",\n        \"prediction_time\",\n        \"visit_number\",\n        \"training_validation_test\",\n        \"random_number\",\n    ]\n    arrival_and_demographic_vars = [\n        \"elapsed_los\",\n        \"sex\",\n        \"age_group\",\n        \"age_on_arrival\",\n        \"arrival_method\",\n    ]\n    summary_vars = [\n        \"num_obs\",\n        \"num_obs_events\",\n        \"num_obs_types\",\n        \"num_lab_batteries_ordered\",\n    ]\n\n    location_vars = []\n    observations_vars = []\n    labs_vars = []\n    consults_vars = [\n        \"has_consultation\",\n        \"consultation_sequence\",\n        \"final_sequence\",\n        \"specialty\",\n    ]\n    outcome_vars = [\"is_admitted\"]\n\n    for col in df.columns:\n        if (\n            col in not_used_in_training_vars\n            or col in arrival_and_demographic_vars\n            or col in summary_vars\n        ):\n            continue\n        elif \"visited\" in col or \"location\" in col:\n            location_vars.append(col)\n        elif \"num_obs\" in col or \"latest_obs\" in col:\n            observations_vars.append(col)\n        elif \"lab_orders\" in col or \"latest_lab_results\" in col:\n            labs_vars.append(col)\n        elif col in consults_vars or col in outcome_vars:\n            continue  # Already categorized\n        else:\n            print(f\"Column '{col}' did not match any predefined group\")\n\n    # Create a list of column groups\n    col_group_names = [\n        \"not used in training\",\n        \"arrival and demographic\",\n        \"summary\",\n        \"location\",\n        \"observations\",\n        \"lab orders and results\",\n        \"consults\",\n        \"outcome\",\n    ]\n\n    # Create a list of the column names within those groups\n    col_groups = [\n        not_used_in_training_vars,\n        arrival_and_demographic_vars,\n        summary_vars,\n        location_vars,\n        observations_vars,\n        labs_vars,\n        consults_vars,\n        outcome_vars,\n    ]\n\n    # Use dictionary to combine them\n    dict_col_groups = {\n        category: var_list for category, var_list in zip(col_group_names, col_groups)\n    }\n\n    return dict_col_groups\n</code></pre>"},{"location":"api/#patientflow.load.get_model_key","title":"<code>get_model_key(model_name, prediction_time)</code>","text":"<p>Create a model name based on the time of day.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The base name of the model.</p> required <code>prediction_time</code> <code>tuple of int</code> <p>A tuple representing the time of day (hour, minute).</p> required <p>Returns:</p> Type Description <code>str</code> <p>A string representing the model name based on the time of day.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def get_model_key(model_name, prediction_time):\n    \"\"\"\n    Create a model name based on the time of day.\n\n    Parameters\n    ----------\n    model_name : str\n        The base name of the model.\n    prediction_time : tuple of int\n        A tuple representing the time of day (hour, minute).\n\n    Returns\n    -------\n    str\n        A string representing the model name based on the time of day.\n    \"\"\"\n\n    hour_, min_ = prediction_time\n    min_ = f\"{min_}0\" if min_ % 60 == 0 else str(min_)\n    model_name = model_name + \"_\" + f\"{hour_:02}\" + min_\n    return model_name\n</code></pre>"},{"location":"api/#patientflow.load.load_config_file","title":"<code>load_config_file(config_file_path, return_start_end_dates=False)</code>","text":"<p>Load configuration from a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>config_file_path</code> <code>str</code> <p>The path to the configuration file.</p> required <code>return_start_end_dates</code> <code>bool</code> <p>If True, return only the start and end dates from the file (default is False).</p> <code>False</code> <p>Returns:</p> Type Description <code>dict or tuple or None</code> <p>If <code>return_start_end_dates</code> is True, returns a tuple of start and end dates (str). Otherwise, returns a dictionary containing the configuration parameters. Returns None if an error occurs during file reading or parsing.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def load_config_file(\n    config_file_path: str, return_start_end_dates: bool = False\n) -&gt; Optional[Union[Dict[str, Any], Tuple[str, str]]]:\n    \"\"\"\n    Load configuration from a YAML file.\n\n    Parameters\n    ----------\n    config_file_path : str\n        The path to the configuration file.\n    return_start_end_dates : bool, optional\n        If True, return only the start and end dates from the file (default is False).\n\n    Returns\n    -------\n    dict or tuple or None\n        If `return_start_end_dates` is True, returns a tuple of start and end dates (str).\n        Otherwise, returns a dictionary containing the configuration parameters.\n        Returns None if an error occurs during file reading or parsing.\n    \"\"\"\n    try:\n        with open(config_file_path, \"r\") as file:\n            config = yaml.safe_load(file)\n    except FileNotFoundError:\n        print(f\"Error: The file '{config_file_path}' was not found.\")\n        return None\n    except yaml.YAMLError as e:\n        print(f\"Error parsing YAML file: {e}\")\n        return None\n\n    try:\n        if return_start_end_dates:\n            # load the dates used in saved data for uclh versions\n            if \"file_dates\" in config and config[\"file_dates\"]:\n                start_date, end_date = [str(item) for item in config[\"file_dates\"]]\n                return (start_date, end_date)\n            else:\n                print(\n                    \"Error: 'file_dates' key not found or empty in the configuration file.\"\n                )\n                return None\n\n        params: Dict[str, Any] = {}\n\n        if \"prediction_times\" in config:\n            params[\"prediction_times\"] = [\n                tuple(item) for item in config[\"prediction_times\"]\n            ]\n        else:\n            print(\"Error: 'prediction_times' key not found in the configuration file.\")\n            sys.exit(1)\n\n        if \"modelling_dates\" in config and len(config[\"modelling_dates\"]) == 4:\n            (\n                params[\"start_training_set\"],\n                params[\"start_validation_set\"],\n                params[\"start_test_set\"],\n                params[\"end_test_set\"],\n            ) = [item for item in config[\"modelling_dates\"]]\n        else:\n            print(\n                f\"Error: expecting 4 modelling dates and only got {len(config.get('modelling_dates', []))}\"\n            )\n            return None\n\n        params[\"x1\"] = float(config.get(\"x1\", 4))\n        params[\"y1\"] = float(config.get(\"y1\", 0.76))\n        params[\"x2\"] = float(config.get(\"x2\", 12))\n        params[\"y2\"] = float(config.get(\"y2\", 0.99))\n        params[\"prediction_window\"] = config.get(\"prediction_window\", 480)\n        params[\"epsilon\"] = config.get(\"epsilon\", 10**-7)\n        params[\"yta_time_interval\"] = config.get(\"yta_time_interval\", 15)\n\n        return params\n\n    except KeyError as e:\n        print(f\"Error: Missing key in the configuration file: {e}\")\n        return None\n    except ValueError as e:\n        print(f\"Error: Invalid value found in the configuration file: {e}\")\n        return None\n</code></pre>"},{"location":"api/#patientflow.load.load_data","title":"<code>load_data(data_file_path, file_name, index_column=None, sort_columns=None, eval_columns=None, home_path=None, encoding=None)</code>","text":"<p>Loads data from CSV or pickle file with optional transformations.</p> <p>Parameters:</p> Name Type Description Default <code>data_file_path</code> <code>str</code> <p>Directory path containing the data file</p> required <code>file_name</code> <code>str</code> <p>Name of the CSV or pickle file to load</p> required <code>index_column</code> <code>str</code> <p>Column to set as DataFrame index</p> <code>None</code> <code>sort_columns</code> <code>list of str</code> <p>Columns to sort DataFrame by</p> <code>None</code> <code>eval_columns</code> <code>list of str</code> <p>Columns to apply safe_literal_eval to</p> <code>None</code> <code>home_path</code> <code>str or Path</code> <p>Base path to use instead of user's home directory</p> <code>None</code> <code>encoding</code> <code>str</code> <p>The encoding to use when reading CSV files (e.g., 'utf-8', 'latin1')</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Loaded and transformed DataFrame</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified file does not exist</p> <code>ValueError</code> <p>If the file format is not supported or other processing errors occur</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def load_data(\n    data_file_path,\n    file_name,\n    index_column=None,\n    sort_columns=None,\n    eval_columns=None,\n    home_path=None,\n    encoding=None,\n):\n    \"\"\"\n    Loads data from CSV or pickle file with optional transformations.\n\n    Parameters\n    ----------\n    data_file_path : str\n        Directory path containing the data file\n    file_name : str\n        Name of the CSV or pickle file to load\n    index_column : str, optional\n        Column to set as DataFrame index\n    sort_columns : list of str, optional\n        Columns to sort DataFrame by\n    eval_columns : list of str, optional\n        Columns to apply safe_literal_eval to\n    home_path : str or Path, optional\n        Base path to use instead of user's home directory\n    encoding : str, optional\n        The encoding to use when reading CSV files (e.g., 'utf-8', 'latin1')\n\n    Returns\n    -------\n    pd.DataFrame\n        Loaded and transformed DataFrame\n\n    Raises\n    ------\n    FileNotFoundError\n        If the specified file does not exist\n    ValueError\n        If the file format is not supported or other processing errors occur\n    \"\"\"\n    from pathlib import Path\n\n    # Use provided home_path if available, otherwise default to user's home directory\n    base_path = Path(home_path) if home_path else Path.home()\n    path = base_path / data_file_path / file_name\n\n    if not path.exists():\n        raise FileNotFoundError(f\"Data file not found at path: {path}\")\n\n    try:\n        if path.suffix.lower() == \".csv\":\n            df = pd.read_csv(path, parse_dates=True, encoding=encoding)\n        elif path.suffix.lower() == \".pkl\":\n            df = pd.read_pickle(path)\n        else:\n            raise ValueError(\n                f\"Unsupported file format: {path.suffix}. Must be .csv or .pkl\"\n            )\n    except Exception as e:\n        raise ValueError(f\"Error loading data: {str(e)}\")\n\n    if index_column and df.index.name != index_column:\n        try:\n            df = df.set_index(index_column)\n        except KeyError:\n            print(f\"Warning: Index column '{index_column}' not found in dataframe\")\n\n    if sort_columns:\n        try:\n            df.sort_values(sort_columns, inplace=True)\n        except KeyError:\n            print(\"Warning: One or more sort columns not found in dataframe\")\n\n    if eval_columns:\n        for column in eval_columns:\n            if column in df.columns:\n                try:\n                    df[column] = df[column].apply(safe_literal_eval)\n                except Exception as e:\n                    print(\n                        f\"Warning: Error applying safe_literal_eval to column '{column}': {str(e)}\"\n                    )\n\n    return df\n</code></pre>"},{"location":"api/#patientflow.load.parse_args","title":"<code>parse_args()</code>","text":"<p>Parse command-line arguments for the training script.</p> <p>Returns:     argparse.Namespace: The parsed arguments containing 'data_folder_name' and 'uclh' keys.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def parse_args() -&gt; argparse.Namespace:\n    \"\"\"\n    Parse command-line arguments for the training script.\n\n    Returns:\n        argparse.Namespace: The parsed arguments containing 'data_folder_name' and 'uclh' keys.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Train emergency demand models\")\n    parser.add_argument(\n        \"--data_folder_name\",\n        type=str,\n        default=\"data-synthetic\",\n        help=\"Location of data for training\",\n    )\n    parser.add_argument(\n        \"--uclh\",\n        type=lambda x: x.lower() in [\"true\", \"1\", \"yes\", \"y\"],\n        default=False,\n        help=\"Train using UCLH data (True) or Public data (False)\",\n    )\n    args = parser.parse_args()\n    return args\n</code></pre>"},{"location":"api/#patientflow.load.safe_literal_eval","title":"<code>safe_literal_eval(s)</code>","text":"<p>Safely evaluate a string literal into a Python object. Handles list-like strings by converting them to lists.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>The string to evaluate.</p> required <p>Returns:</p> Type Description <code>Any, list, or None</code> <p>The evaluated Python object if successful, a list if the input is list-like, or None for empty/null values.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def safe_literal_eval(s):\n    \"\"\"\n    Safely evaluate a string literal into a Python object.\n    Handles list-like strings by converting them to lists.\n\n    Parameters\n    ----------\n    s : str\n        The string to evaluate.\n\n    Returns\n    -------\n    Any, list, or None\n        The evaluated Python object if successful, a list if the input is list-like,\n        or None for empty/null values.\n    \"\"\"\n    if pd.isna(s) or str(s).strip().lower() in [\"nan\", \"none\", \"\"]:\n        return None\n\n    if isinstance(s, str):\n        s = s.strip()\n        if s.startswith(\"[\") and s.endswith(\"]\"):\n            try:\n                # Remove square brackets and split by comma\n                items = s[1:-1].split(\",\")\n                # Strip whitespace from each item and remove empty strings\n                return [item.strip() for item in items if item.strip()]\n            except Exception:\n                # If the above fails, fall back to ast.literal_eval\n                pass\n\n    try:\n        return ast.literal_eval(s)\n    except (ValueError, SyntaxError):\n        # If ast.literal_eval fails, return the original string\n        return s\n</code></pre>"},{"location":"api/#patientflow.load.set_data_file_names","title":"<code>set_data_file_names(uclh, data_file_path, config_file_path=None)</code>","text":"<p>Set file locations based on UCLH or default data source.</p> <p>Parameters:</p> Name Type Description Default <code>uclh</code> <code>bool</code> <p>If True, use UCLH-specific file locations. If False, use default file locations.</p> required <code>data_file_path</code> <code>Path</code> <p>The base path to the data directory.</p> required <code>config_file_path</code> <code>str</code> <p>The path to the configuration file, required if <code>uclh</code> is True.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>Paths to the required files (visits, arrivals) based on the configuration.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def set_data_file_names(uclh, data_file_path, config_file_path=None):\n    \"\"\"\n    Set file locations based on UCLH or default data source.\n\n    Parameters\n    ----------\n    uclh : bool\n        If True, use UCLH-specific file locations. If False, use default file locations.\n    data_file_path : Path\n        The base path to the data directory.\n    config_file_path : str, optional\n        The path to the configuration file, required if `uclh` is True.\n\n    Returns\n    -------\n    tuple\n        Paths to the required files (visits, arrivals) based on the configuration.\n    \"\"\"\n    if not isinstance(data_file_path, Path):\n        data_file_path = Path(data_file_path)\n\n    if not uclh:\n        csv_filename = \"ed_visits.csv\"\n        yta_csv_filename = \"inpatient_arrivals.csv\"\n\n        visits_csv_path = data_file_path / csv_filename\n        yta_csv_path = data_file_path / yta_csv_filename\n\n        return visits_csv_path, yta_csv_path\n\n    else:\n        start_date, end_date = load_config_file(\n            config_file_path, return_start_end_dates=True\n        )\n        data_filename = (\n            \"uclh_visits_exc_beds_inc_minority_\"\n            + str(start_date)\n            + \"_\"\n            + str(end_date)\n            + \".pickle\"\n        )\n        csv_filename = \"uclh_ed_visits.csv\"\n        yta_filename = (\n            \"uclh_yet_to_arrive_\" + str(start_date) + \"_\" + str(end_date) + \".pickle\"\n        )\n        yta_csv_filename = \"uclh_inpatient_arrivals.csv\"\n\n        visits_path = data_file_path / data_filename\n        yta_path = data_file_path / yta_filename\n\n        visits_csv_path = data_file_path / csv_filename\n        yta_csv_path = data_file_path / yta_csv_filename\n\n    return visits_path, visits_csv_path, yta_path, yta_csv_path\n</code></pre>"},{"location":"api/#patientflow.load.set_file_paths","title":"<code>set_file_paths(project_root, data_folder_name, train_dttm=None, inference_time=False, config_file='config.yaml', prefix=None, verbose=True)</code>","text":"<p>Sets up the file paths</p> <p>Args:     project_root (Path): Root path of the project     data_folder_name (str): Name of the folder where data files are located     train_dttm (Optional[str], optional): A string representation of the datetime at which training commenced. Defaults to None     inference_time (bool, optional): A flag indicating whether it is inference time or not. Defaults to False     config_file (str, optional): Name of config file. Defaults to \"config.yaml\"     prefix (Optional[str], optional): String to prefix model folder names. Defaults to None     verbose (bool, optional): Whether to print path information. Defaults to True</p> <p>Returns:     tuple: Contains (data_file_path, media_file_path, model_file_path, config_path)</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def set_file_paths(\n    project_root: Path,\n    data_folder_name: str,\n    train_dttm: Optional[str] = None,\n    inference_time: bool = False,\n    config_file: str = \"config.yaml\",\n    prefix: Optional[str] = None,\n    verbose: bool = True,\n) -&gt; Tuple[Path, Path, Path, Path]:\n    \"\"\"\n    Sets up the file paths\n\n    Args:\n        project_root (Path): Root path of the project\n        data_folder_name (str): Name of the folder where data files are located\n        train_dttm (Optional[str], optional): A string representation of the datetime at which training commenced. Defaults to None\n        inference_time (bool, optional): A flag indicating whether it is inference time or not. Defaults to False\n        config_file (str, optional): Name of config file. Defaults to \"config.yaml\"\n        prefix (Optional[str], optional): String to prefix model folder names. Defaults to None\n        verbose (bool, optional): Whether to print path information. Defaults to True\n\n    Returns:\n        tuple: Contains (data_file_path, media_file_path, model_file_path, config_path)\n    \"\"\"\n\n    config_path = Path(project_root) / config_file\n    if verbose:\n        print(f\"Configuration will be loaded from: {config_path}\")\n\n    data_file_path = Path(project_root) / data_folder_name\n    if verbose:\n        print(f\"Data files will be loaded from: {data_file_path}\")\n\n    model_id = data_folder_name.lstrip(\"data-\")\n    if prefix:\n        model_id = f\"{prefix}_{model_id}\"\n    if train_dttm:\n        model_id = f\"{model_id}_{train_dttm}\"\n\n    model_file_path = Path(project_root) / \"trained-models\" / model_id\n    media_file_path = model_file_path / \"media\"\n\n    if not inference_time:\n        if verbose:\n            print(f\"Trained models will be saved to: {model_file_path}\")\n        model_file_path.mkdir(parents=True, exist_ok=True)\n        (model_file_path / \"model-output\").mkdir(parents=False, exist_ok=True)\n        media_file_path.mkdir(parents=False, exist_ok=True)\n        if verbose:\n            print(f\"Images will be saved to: {media_file_path}\")\n\n    return data_file_path, media_file_path, model_file_path, config_path\n</code></pre>"},{"location":"api/#patientflow.load.set_project_root","title":"<code>set_project_root(env_var=None)</code>","text":"<p>Sets project root path from environment variable or infers it from current path.</p> <p>First checks specified environment variable for project root path. If not found, searches current path hierarchy for highest-level 'patientflow' directory.</p> <p>Args:     env_var (Optional[str]): Name of environment variable containing project root path</p> <p>Returns:     Path: Validated project root path</p> <p>Raises:     ValueError: If environment variable not set and 'patientflow' not found in path     NotADirectoryError: If path doesn't exist     TypeError: If env_var is not None and not a string</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def set_project_root(env_var: Optional[str] = None) -&gt; Path:\n    \"\"\"\n    Sets project root path from environment variable or infers it from current path.\n\n    First checks specified environment variable for project root path.\n    If not found, searches current path hierarchy for highest-level 'patientflow' directory.\n\n    Args:\n        env_var (Optional[str]): Name of environment variable containing project root path\n\n    Returns:\n        Path: Validated project root path\n\n    Raises:\n        ValueError: If environment variable not set and 'patientflow' not found in path\n        NotADirectoryError: If path doesn't exist\n        TypeError: If env_var is not None and not a string\n    \"\"\"\n    # Only try to get env path if env_var is provided\n    env_path: Optional[str] = os.getenv(env_var) if env_var is not None else None\n    project_root: Optional[Path] = None\n\n    # Try getting from environment variable first\n    if env_path is not None:\n        try:\n            project_root = Path(env_path)\n            if not project_root.is_dir():\n                raise NotADirectoryError(f\"Path does not exist: {project_root}\")\n            print(f\"Project root from environment: {project_root}\")\n            return project_root\n        except (TypeError, ValueError) as e:\n            print(f\"Error converting {env_path} to Path: {e}\")\n            raise\n    else:\n        # If not in env var, try to infer from current path\n        current: Path = Path().absolute()\n\n        # Search through parents to find highest-level 'patientflow' directory\n        for parent in [current, *current.parents]:\n            if parent.name == \"patientflow\" and parent.is_dir():\n                project_root = parent\n                # Continue searching to find highest level\n\n        if project_root:\n            print(f\"Inferred project root: {project_root}\")\n            return project_root\n\n        print(\n            f\"Could not find project root - {env_var} not set and 'patientflow' not found in path\"\n        )\n        print(f\"\\nCurrent directory: {Path().absolute()}\")\n        if env_var:\n            print(f\"\\nRun one of these commands in a new cell to set {env_var}:\")\n            print(\"# Linux/Mac:\")\n            print(f\"%env {env_var}=/path/to/project\")\n            print(\"\\n# Windows:\")\n            print(f\"%env {env_var}=C:\\\\path\\\\to\\\\project\")\n        raise ValueError(\"Project root not found\")\n</code></pre>"},{"location":"api/#patientflow.model_artifacts","title":"<code>model_artifacts</code>","text":"<p>Model training results containers.</p> <p>This module defines a set of data classes to organise results from model training, including hyperparameter tuning, cross-validation fold metrics, and final trained classifier artifacts. These classes serve as structured containers for various types of model evaluation outputs and metadata.</p> <p>Classes:</p> Name Description <code>HyperParameterTrial</code> <p>Container for storing hyperparameter tuning trial results.</p> <code>FoldResults</code> <p>Stores evaluation metrics from a single cross-validation fold.</p> <code>TrainingResults</code> <p>Encapsulates comprehensive evaluation metrics and metadata from model training.</p> <code>TrainedClassifier</code> <p>Container for a trained model and associated training results.</p>"},{"location":"api/#patientflow.model_artifacts.FoldResults","title":"<code>FoldResults</code>  <code>dataclass</code>","text":"<p>Store evaluation metrics for a single fold.</p> <p>Attributes:</p> Name Type Description <code>auc</code> <code>float</code> <p>Area Under the ROC Curve (AUC) for this fold.</p> <code>logloss</code> <code>float</code> <p>Logarithmic loss (cross-entropy loss) for this fold.</p> <code>auprc</code> <code>float</code> <p>Area Under the Precision-Recall Curve (AUPRC) for this fold.</p> Source code in <code>src/patientflow/model_artifacts.py</code> <pre><code>@dataclass\nclass FoldResults:\n    \"\"\"\n    Store evaluation metrics for a single fold.\n\n    Attributes\n    ----------\n    auc : float\n        Area Under the ROC Curve (AUC) for this fold.\n    logloss : float\n        Logarithmic loss (cross-entropy loss) for this fold.\n    auprc : float\n        Area Under the Precision-Recall Curve (AUPRC) for this fold.\n    \"\"\"\n\n    auc: float\n    logloss: float\n    auprc: float\n</code></pre>"},{"location":"api/#patientflow.model_artifacts.HyperParameterTrial","title":"<code>HyperParameterTrial</code>  <code>dataclass</code>","text":"<p>Container for a single hyperparameter tuning trial.</p> <p>Attributes:</p> Name Type Description <code>parameters</code> <code>dict of str to Any</code> <p>Dictionary of hyperparameters used in the trial.</p> <code>cv_results</code> <code>dict of str to float</code> <p>Cross-validation metrics obtained using the specified parameters.</p> Source code in <code>src/patientflow/model_artifacts.py</code> <pre><code>@dataclass\nclass HyperParameterTrial:\n    \"\"\"\n    Container for a single hyperparameter tuning trial.\n\n    Attributes\n    ----------\n    parameters : dict of str to Any\n        Dictionary of hyperparameters used in the trial.\n    cv_results : dict of str to float\n        Cross-validation metrics obtained using the specified parameters.\n    \"\"\"\n\n    parameters: Dict[str, Any]\n    cv_results: Dict[str, float]\n</code></pre>"},{"location":"api/#patientflow.model_artifacts.TrainedClassifier","title":"<code>TrainedClassifier</code>  <code>dataclass</code>","text":"<p>Container for trained model artifacts and their associated information.</p> <p>Attributes:</p> Name Type Description <code>training_results</code> <code>TrainingResults</code> <p>Evaluation metrics and training metadata for the classifier.</p> <code>pipeline</code> <code>(Pipeline or None, optional)</code> <p>The scikit-learn pipeline representing the trained classifier.</p> <code>calibrated_pipeline</code> <code>(Pipeline or None, optional)</code> <p>The calibrated version of the pipeline, if model calibration was performed.</p> Source code in <code>src/patientflow/model_artifacts.py</code> <pre><code>@dataclass\nclass TrainedClassifier:\n    \"\"\"\n    Container for trained model artifacts and their associated information.\n\n    Attributes\n    ----------\n    training_results : TrainingResults\n        Evaluation metrics and training metadata for the classifier.\n    pipeline : sklearn.pipeline.Pipeline or None, optional\n        The scikit-learn pipeline representing the trained classifier.\n    calibrated_pipeline : sklearn.pipeline.Pipeline or None, optional\n        The calibrated version of the pipeline, if model calibration was performed.\n    \"\"\"\n\n    training_results: TrainingResults\n    pipeline: Optional[Pipeline] = None\n    calibrated_pipeline: Optional[Pipeline] = None\n</code></pre>"},{"location":"api/#patientflow.model_artifacts.TrainingResults","title":"<code>TrainingResults</code>  <code>dataclass</code>","text":"<p>Store comprehensive evaluation metrics and metadata from model training.</p> <p>Attributes:</p> Name Type Description <code>prediction_time</code> <code>tuple of int</code> <p>Start and end time of prediction, represented as UNIX timestamps.</p> <code>training_info</code> <code>dict of str to Any, optional</code> <p>Metadata or logs collected during training.</p> <code>calibration_info</code> <code>dict of str to Any, optional</code> <p>Information about model calibration, if applicable.</p> <code>test_results</code> <code>dict of str to float, optional</code> <p>Evaluation metrics computed on the test dataset. None if test evaluation was not performed.</p> <code>balance_info</code> <code>dict of str to bool or int or float, optional</code> <p>Information related to class balance (e.g., whether data was balanced, class ratios).</p> Source code in <code>src/patientflow/model_artifacts.py</code> <pre><code>@dataclass\nclass TrainingResults:\n    \"\"\"\n    Store comprehensive evaluation metrics and metadata from model training.\n\n    Attributes\n    ----------\n    prediction_time : tuple of int\n        Start and end time of prediction, represented as UNIX timestamps.\n    training_info : dict of str to Any, optional\n        Metadata or logs collected during training.\n    calibration_info : dict of str to Any, optional\n        Information about model calibration, if applicable.\n    test_results : dict of str to float, optional\n        Evaluation metrics computed on the test dataset. None if test evaluation was not performed.\n    balance_info : dict of str to bool or int or float, optional\n        Information related to class balance (e.g., whether data was balanced, class ratios).\n    \"\"\"\n\n    prediction_time: Tuple[int, int]\n    training_info: Dict[str, Any] = field(default_factory=dict)\n    calibration_info: Dict[str, Any] = field(default_factory=dict)\n    test_results: Optional[Dict[str, float]] = None\n    balance_info: Dict[str, Union[bool, int, float]] = field(default_factory=dict)\n</code></pre>"},{"location":"api/#patientflow.predict","title":"<code>predict</code>","text":"<p>Prediction module for patient flow forecasting.</p> <p>This module provides functions for making predictions about future patient flow, including emergency demand forecasting and other predictive analytics.</p>"},{"location":"api/#patientflow.predict.emergency_demand","title":"<code>emergency_demand</code>","text":"<p>Emergency demand prediction module.</p> <p>This module provides functionality for predicting emergency department demand, including specialty-specific predictions for both current patients and yet-to-arrive patients. It handles probability calculations, model predictions, and threshold-based resource estimation.</p> <p>The module integrates multiple prediction models: - Admission prediction classifier - Specialty sequence predictor - Yet-to-arrive weighted Poisson predictor</p> <p>Functions:</p> Name Description <code>add_missing_columns : function</code> <p>Add missing columns required by the prediction pipeline</p> <code>find_probability_threshold_index : function</code> <p>Find index where cumulative probability exceeds threshold</p> <code>get_specialty_probs : function</code> <p>Calculate specialty probability distributions</p> <code>create_predictions : function</code> <p>Create predictions for emergency demand</p>"},{"location":"api/#patientflow.predict.emergency_demand.add_missing_columns","title":"<code>add_missing_columns(pipeline, df)</code>","text":"<p>Add missing columns required by the prediction pipeline from the training data.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>Pipeline</code> <p>The trained pipeline containing the feature transformer</p> required <code>df</code> <code>DataFrame</code> <p>Input dataframe that may be missing required columns</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with missing columns added and filled with appropriate default values</p> Notes <p>Adds columns with default values based on column name patterns: - lab_orders_, visited_, has_ : False - num_, total_ : 0 - latest_ : pd.NA - arrival_method : \"None\" - others : pd.NA</p> Source code in <code>src/patientflow/predict/emergency_demand.py</code> <pre><code>def add_missing_columns(pipeline, df):\n    \"\"\"Add missing columns required by the prediction pipeline from the training data.\n\n    Parameters\n    ----------\n    pipeline : sklearn.pipeline.Pipeline\n        The trained pipeline containing the feature transformer\n    df : pandas.DataFrame\n        Input dataframe that may be missing required columns\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with missing columns added and filled with appropriate default values\n\n    Notes\n    -----\n    Adds columns with default values based on column name patterns:\n    - lab_orders_, visited_, has_ : False\n    - num_, total_ : 0\n    - latest_ : pd.NA\n    - arrival_method : \"None\"\n    - others : pd.NA\n    \"\"\"\n    # check input data for missing columns\n    column_transformer = pipeline.named_steps[\"feature_transformer\"]\n\n    # Function to get feature names before one-hot encoding\n    def get_feature_names_before_encoding(column_transformer):\n        feature_names = []\n        for name, transformer, columns in column_transformer.transformers:\n            if isinstance(transformer, OneHotEncoder):\n                feature_names.extend(columns)\n            elif isinstance(transformer, OrdinalEncoder):\n                feature_names.extend(columns)\n            elif isinstance(transformer, StandardScaler):\n                feature_names.extend(columns)\n            else:\n                feature_names.extend(columns)\n        return feature_names\n\n    feature_names_before_encoding = get_feature_names_before_encoding(\n        column_transformer\n    )\n\n    added_columns = []\n    for missing_col in set(feature_names_before_encoding).difference(set(df.columns)):\n        if missing_col.startswith((\"lab_orders_\", \"visited_\", \"has_\")):\n            df[missing_col] = False\n        elif missing_col.startswith((\"num_\", \"total_\")):\n            df[missing_col] = 0\n        elif missing_col.startswith(\"latest_\"):\n            df[missing_col] = pd.NA\n        elif missing_col == \"arrival_method\":\n            df[missing_col] = \"None\"\n        else:\n            df[missing_col] = pd.NA\n        added_columns.append(missing_col)\n\n    if added_columns:\n        print(\n            f\"Warning: The following columns were used in training, but not found in the real-time data. These have been added to the dataframe: {', '.join(added_columns)}\"\n        )\n\n    return df\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.create_predictions","title":"<code>create_predictions(models, prediction_time, prediction_snapshots, specialties, prediction_window, x1, y1, x2, y2, cdf_cut_points, use_admission_in_window_prob=True)</code>","text":"<p>Create predictions for emergency demand for a single prediction moment.</p> <p>Parameters:</p> Name Type Description Default <code>models</code> <code>Tuple[TrainedClassifier, Union[SequenceToOutcomePredictor, ValueToOutcomePredictor], ParametricIncomingAdmissionPredictor]</code> <p>Tuple containing: - classifier: TrainedClassifier containing admission predictions - spec_model: SequenceToOutcomePredictor or ValueToOutcomePredictor for specialty predictions - yet_to_arrive_model: ParametricIncomingAdmissionPredictor for yet-to-arrive predictions</p> required <code>prediction_time</code> <code>Tuple</code> <p>Hour and minute of time for model inference</p> required <code>prediction_snapshots</code> <code>DataFrame</code> <p>DataFrame containing prediction snapshots. Must have an 'elapsed_los' column of type timedelta.</p> required <code>specialties</code> <code>List[str]</code> <p>List of specialty names for predictions (e.g., ['surgical', 'medical'])</p> required <code>prediction_window</code> <code>timedelta</code> <p>Prediction window as a timedelta object</p> required <code>x1</code> <code>float</code> <p>X-coordinate of first point for probability curve</p> required <code>y1</code> <code>float</code> <p>Y-coordinate of first point for probability curve</p> required <code>x2</code> <code>float</code> <p>X-coordinate of second point for probability curve</p> required <code>y2</code> <code>float</code> <p>Y-coordinate of second point for probability curve</p> required <code>cdf_cut_points</code> <code>List[float]</code> <p>List of cumulative distribution function cut points (e.g., [0.9, 0.7])</p> required <code>use_admission_in_window_prob</code> <code>bool</code> <p>Whether to use probability calculation for admission within prediction window for patients already in the ED. If False, probability is set to 1.0 for all current ED patients. This parameter does not affect the yet-to-arrive predictions. By default True</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, List[int]]]</code> <p>Nested dictionary containing predictions for each specialty: {     'specialty_name': {         'in_ed': [pred1, pred2, ...],         'yet_to_arrive': [pred1, pred2, ...]     } }</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If any of the models are not of the expected type or if prediction_window is not a timedelta</p> <code>ValueError</code> <p>If models have not been fit or if prediction parameters don't match training parameters If 'elapsed_los' column is missing or not of type timedelta</p> Notes <p>The models in the models dictionary must be ModelResults objects that contain either a 'pipeline' or 'calibrated_pipeline' attribute. The pipeline will be used for making predictions, with calibrated_pipeline taking precedence if both exist.</p> Source code in <code>src/patientflow/predict/emergency_demand.py</code> <pre><code>def create_predictions(\n    models: Tuple[\n        TrainedClassifier,\n        Union[SequenceToOutcomePredictor, ValueToOutcomePredictor],\n        ParametricIncomingAdmissionPredictor,\n    ],\n    prediction_time: Tuple,\n    prediction_snapshots: pd.DataFrame,\n    specialties: List[str],\n    prediction_window: timedelta,\n    x1: float,\n    y1: float,\n    x2: float,\n    y2: float,\n    cdf_cut_points: List[float],\n    use_admission_in_window_prob: bool = True,\n) -&gt; Dict[str, Dict[str, List[int]]]:\n    \"\"\"Create predictions for emergency demand for a single prediction moment.\n\n    Parameters\n    ----------\n    models : Tuple[TrainedClassifier, Union[SequenceToOutcomePredictor, ValueToOutcomePredictor], ParametricIncomingAdmissionPredictor]\n        Tuple containing:\n        - classifier: TrainedClassifier containing admission predictions\n        - spec_model: SequenceToOutcomePredictor or ValueToOutcomePredictor for specialty predictions\n        - yet_to_arrive_model: ParametricIncomingAdmissionPredictor for yet-to-arrive predictions\n    prediction_time : Tuple\n        Hour and minute of time for model inference\n    prediction_snapshots : pandas.DataFrame\n        DataFrame containing prediction snapshots. Must have an 'elapsed_los' column of type timedelta.\n    specialties : List[str]\n        List of specialty names for predictions (e.g., ['surgical', 'medical'])\n    prediction_window : timedelta\n        Prediction window as a timedelta object\n    x1 : float\n        X-coordinate of first point for probability curve\n    y1 : float\n        Y-coordinate of first point for probability curve\n    x2 : float\n        X-coordinate of second point for probability curve\n    y2 : float\n        Y-coordinate of second point for probability curve\n    cdf_cut_points : List[float]\n        List of cumulative distribution function cut points (e.g., [0.9, 0.7])\n    use_admission_in_window_prob : bool, optional\n        Whether to use probability calculation for admission within prediction window for patients\n        already in the ED. If False, probability is set to 1.0 for all current ED patients.\n        This parameter does not affect the yet-to-arrive predictions. By default True\n\n    Returns\n    -------\n    Dict[str, Dict[str, List[int]]]\n        Nested dictionary containing predictions for each specialty:\n        {\n            'specialty_name': {\n                'in_ed': [pred1, pred2, ...],\n                'yet_to_arrive': [pred1, pred2, ...]\n            }\n        }\n\n    Raises\n    ------\n    TypeError\n        If any of the models are not of the expected type or if prediction_window is not a timedelta\n    ValueError\n        If models have not been fit or if prediction parameters don't match training parameters\n        If 'elapsed_los' column is missing or not of type timedelta\n\n    Notes\n    -----\n    The models in the models dictionary must be ModelResults objects\n    that contain either a 'pipeline' or 'calibrated_pipeline' attribute. The pipeline\n    will be used for making predictions, with calibrated_pipeline taking precedence\n    if both exist.\n    \"\"\"\n    # Validate model types\n    classifier, spec_model, yet_to_arrive_model = models\n\n    if not isinstance(classifier, TrainedClassifier):\n        raise TypeError(\"First model must be of type TrainedClassifier\")\n    if not isinstance(\n        spec_model, (SequenceToOutcomePredictor, ValueToOutcomePredictor)\n    ):\n        raise TypeError(\n            \"Second model must be of type SequenceToOutcomePredictor or ValueToOutcomePredictor\"\n        )\n    if not isinstance(yet_to_arrive_model, ParametricIncomingAdmissionPredictor):\n        raise TypeError(\n            \"Third model must be of type ParametricIncomingAdmissionPredictor\"\n        )\n    if \"elapsed_los\" not in prediction_snapshots.columns:\n        raise ValueError(\"Column 'elapsed_los' not found in prediction_snapshots\")\n    if not pd.api.types.is_timedelta64_dtype(prediction_snapshots[\"elapsed_los\"]):\n        actual_type = prediction_snapshots[\"elapsed_los\"].dtype\n        raise ValueError(\n            f\"Column 'elapsed_los' must be a timedelta column, but found type: {actual_type}\"\n        )\n\n    # Check that all models have been fit\n    if not hasattr(classifier, \"pipeline\") or classifier.pipeline is None:\n        raise ValueError(\"Classifier model has not been fit\")\n    if not hasattr(spec_model, \"weights\") or spec_model.weights is None:\n        raise ValueError(\"Specialty model has not been fit\")\n    if (\n        not hasattr(yet_to_arrive_model, \"prediction_window\")\n        or yet_to_arrive_model.prediction_window is None\n    ):\n        raise ValueError(\"Yet-to-arrive model has not been fit\")\n\n    # Validate that the correct models have been passed for the requested prediction time and prediction window\n    if not classifier.training_results.prediction_time == prediction_time:\n        raise ValueError(\n            f\"Requested prediction time {prediction_time} does not match the prediction time of the trained classifier {classifier.training_results.prediction_time}\"\n        )\n\n    # Compare prediction windows directly\n    if prediction_window != yet_to_arrive_model.prediction_window:\n        raise ValueError(\n            f\"Requested prediction window {prediction_window} does not match the prediction window of the trained yet-to-arrive model {yet_to_arrive_model.prediction_window}\"\n        )\n\n    if not set(yet_to_arrive_model.filters.keys()) == set(specialties):\n        raise ValueError(\n            f\"Requested specialties {set(specialties)} do not match the specialties of the trained yet-to-arrive model {set(yet_to_arrive_model.filters.keys())}\"\n        )\n\n    special_params = spec_model.special_params\n\n    if special_params:\n        special_category_func = special_params[\"special_category_func\"]\n        special_category_dict = special_params[\"special_category_dict\"]\n        special_func_map = special_params[\"special_func_map\"]\n    else:\n        special_category_func = special_category_dict = special_func_map = None\n\n    if special_category_dict is not None and not set(specialties) == set(\n        special_category_dict.keys()\n    ):\n        raise ValueError(\n            \"Requested specialties do not match the specialty dictionary defined in special_params\"\n        )\n\n    predictions: Dict[str, Dict[str, List[int]]] = {\n        specialty: {\"in_ed\": [], \"yet_to_arrive\": []} for specialty in specialties\n    }\n\n    # Use calibrated pipeline if available, otherwise use regular pipeline\n    if (\n        hasattr(classifier, \"calibrated_pipeline\")\n        and classifier.calibrated_pipeline is not None\n    ):\n        pipeline = classifier.calibrated_pipeline\n    else:\n        pipeline = classifier.pipeline\n\n    # Add missing columns expected by the model\n    prediction_snapshots = add_missing_columns(pipeline, prediction_snapshots)\n\n    # Before we get predictions, we need to create a temp copy with the elapsed_los column in seconds\n    prediction_snapshots_temp = prediction_snapshots.copy()\n    prediction_snapshots_temp[\"elapsed_los\"] = prediction_snapshots_temp[\n        \"elapsed_los\"\n    ].dt.total_seconds()\n\n    # Get predictions of admissions for ED patients\n    prob_admission_after_ed = model_input_to_pred_proba(\n        prediction_snapshots_temp, pipeline\n    )\n\n    # Get predictions of admission to specialty\n    prediction_snapshots.loc[:, \"specialty_prob\"] = get_specialty_probs(\n        specialties,\n        spec_model,\n        prediction_snapshots,\n        special_category_func=special_category_func,\n        special_category_dict=special_category_dict,\n    )\n\n    # Get probability of admission within prediction window for current ED patients\n    if use_admission_in_window_prob:\n        prob_admission_in_window = prediction_snapshots.apply(\n            lambda row: calculate_probability(\n                row[\"elapsed_los\"], prediction_window, x1, y1, x2, y2\n            ),\n            axis=1,\n        )\n    else:\n        prob_admission_in_window = pd.Series(1.0, index=prediction_snapshots.index)\n\n    if special_func_map is None:\n        special_func_map = {\"default\": lambda row: True}\n\n    for specialty in specialties:\n        func = special_func_map.get(specialty, special_func_map[\"default\"])\n        non_zero_indices = prediction_snapshots[\n            prediction_snapshots.apply(func, axis=1)\n        ].index\n\n        filtered_prob_admission_after_ed = prob_admission_after_ed.loc[non_zero_indices]\n        prob_admission_to_specialty = prediction_snapshots[\"specialty_prob\"].apply(\n            lambda x: x[specialty]\n        )\n\n        filtered_prob_admission_to_specialty = prob_admission_to_specialty.loc[\n            non_zero_indices\n        ]\n        filtered_prob_admission_in_window = prob_admission_in_window.loc[\n            non_zero_indices\n        ]\n\n        filtered_weights = (\n            filtered_prob_admission_to_specialty * filtered_prob_admission_in_window\n        )\n\n        agg_predicted_in_ed = pred_proba_to_agg_predicted(\n            filtered_prob_admission_after_ed, weights=filtered_weights\n        )\n\n        prediction_context = {specialty: {\"prediction_time\": prediction_time}}\n        agg_predicted_yta = yet_to_arrive_model.predict(\n            prediction_context, x1=x1, y1=y1, x2=x2, y2=y2\n        )\n\n        predictions[specialty][\"in_ed\"] = [\n            find_probability_threshold_index(\n                agg_predicted_in_ed[\"agg_proba\"].values.cumsum(), cut_point\n            )\n            for cut_point in cdf_cut_points\n        ]\n        predictions[specialty][\"yet_to_arrive\"] = [\n            find_probability_threshold_index(\n                agg_predicted_yta[specialty][\"agg_proba\"].values.cumsum(), cut_point\n            )\n            for cut_point in cdf_cut_points\n        ]\n\n    return predictions\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.find_probability_threshold_index","title":"<code>find_probability_threshold_index(sequence, threshold)</code>","text":"<p>Find index where cumulative probability exceeds threshold.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>List[float]</code> <p>The probability mass function (PMF) of resource needs</p> required <code>threshold</code> <code>float</code> <p>The probability threshold (e.g., 0.9 for 90%)</p> required <p>Returns:</p> Type Description <code>int</code> <p>The index where the cumulative probability exceeds 1 - threshold, indicating the number of resources needed with the specified probability</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pmf = [0.05, 0.1, 0.2, 0.3, 0.2, 0.1, 0.05]\n&gt;&gt;&gt; find_probability_threshold_index(pmf, 0.9)\n5\n# This means there is a 90% probability of needing at least 5 beds\n</code></pre> Source code in <code>src/patientflow/predict/emergency_demand.py</code> <pre><code>def find_probability_threshold_index(sequence: List[float], threshold: float) -&gt; int:\n    \"\"\"Find index where cumulative probability exceeds threshold.\n\n    Parameters\n    ----------\n    sequence : List[float]\n        The probability mass function (PMF) of resource needs\n    threshold : float\n        The probability threshold (e.g., 0.9 for 90%)\n\n    Returns\n    -------\n    int\n        The index where the cumulative probability exceeds 1 - threshold,\n        indicating the number of resources needed with the specified probability\n\n    Examples\n    --------\n    &gt;&gt;&gt; pmf = [0.05, 0.1, 0.2, 0.3, 0.2, 0.1, 0.05]\n    &gt;&gt;&gt; find_probability_threshold_index(pmf, 0.9)\n    5\n    # This means there is a 90% probability of needing at least 5 beds\n    \"\"\"\n    cumulative_sum = 0.0\n    for i, value in enumerate(sequence):\n        cumulative_sum += value\n        if cumulative_sum &gt;= 1 - threshold:\n            return i\n    return len(sequence) - 1  # Return the last index if the threshold isn't reached\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.get_specialty_probs","title":"<code>get_specialty_probs(specialties, specialty_model, snapshots_df, special_category_func=None, special_category_dict=None)</code>","text":"<p>Calculate specialty probability distributions for patient visits.</p> <p>Parameters:</p> Name Type Description Default <code>specialties</code> <code>str</code> <p>List of specialty names for which predictions are required</p> required <code>specialty_model</code> <code>object</code> <p>Trained model for making specialty predictions</p> required <code>snapshots_df</code> <code>DataFrame</code> <p>DataFrame containing the data on which predictions are to be made. Must include the input_var column if no special_category_func is applied</p> required <code>special_category_func</code> <code>callable</code> <p>A function that takes a DataFrame row (Series) as input and returns True if the row belongs to a special category that requires a fixed probability distribution</p> <code>None</code> <code>special_category_dict</code> <code>dict</code> <p>A dictionary containing the fixed probability distribution for special category cases. Required if special_category_func is provided</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>A Series containing dictionaries as values. Each dictionary represents the probability distribution of specialties for each patient visit</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If special_category_func is provided but special_category_dict is None</p> Source code in <code>src/patientflow/predict/emergency_demand.py</code> <pre><code>def get_specialty_probs(\n    specialties,\n    specialty_model,\n    snapshots_df,\n    special_category_func=None,\n    special_category_dict=None,\n):\n    \"\"\"Calculate specialty probability distributions for patient visits.\n\n    Parameters\n    ----------\n    specialties : str\n        List of specialty names for which predictions are required\n    specialty_model : object\n        Trained model for making specialty predictions\n    snapshots_df : pandas.DataFrame\n        DataFrame containing the data on which predictions are to be made. Must include\n        the input_var column if no special_category_func is applied\n    special_category_func : callable, optional\n        A function that takes a DataFrame row (Series) as input and returns True if the row\n        belongs to a special category that requires a fixed probability distribution\n    special_category_dict : dict, optional\n        A dictionary containing the fixed probability distribution for special category cases.\n        Required if special_category_func is provided\n\n    Returns\n    -------\n    pandas.Series\n        A Series containing dictionaries as values. Each dictionary represents the probability\n        distribution of specialties for each patient visit\n\n    Raises\n    ------\n    ValueError\n        If special_category_func is provided but special_category_dict is None\n\n    \"\"\"\n\n    # Convert input_var to tuple if not already a tuple\n    if len(snapshots_df[specialty_model.input_var]) &gt; 0 and not isinstance(\n        snapshots_df[specialty_model.input_var].iloc[0], tuple\n    ):\n        snapshots_df.loc[:, specialty_model.input_var] = snapshots_df[\n            specialty_model.input_var\n        ].apply(lambda x: tuple(x) if x else ())\n\n    if special_category_func and not special_category_dict:\n        raise ValueError(\n            \"special_category_dict must be provided if special_category_func is specified.\"\n        )\n\n    # Function to determine the specialty probabilities\n    def determine_specialty(row):\n        if special_category_func and special_category_func(row):\n            return special_category_dict\n        else:\n            return specialty_model.predict(row[specialty_model.input_var])\n\n    # Apply the determine_specialty function to each row\n    specialty_prob_series = snapshots_df.apply(determine_specialty, axis=1)\n\n    # Find all unique keys used in any dictionary within the series\n    all_keys = set().union(\n        *(d.keys() for d in specialty_prob_series if isinstance(d, dict))\n    )\n\n    # Combine all_keys with the specialties requested\n    all_keys = set(all_keys).union(set(specialties))\n\n    # Ensure each dictionary contains all keys found, with default values of 0 for missing keys\n    specialty_prob_series = specialty_prob_series.apply(\n        lambda d: (\n            {key: d.get(key, 0) for key in all_keys} if isinstance(d, dict) else d\n        )\n    )\n\n    return specialty_prob_series\n</code></pre>"},{"location":"api/#patientflow.predictors","title":"<code>predictors</code>","text":"<p>Predictor models for patient flow analysis.</p> <p>This module contains various predictor model implementations, including sequence-based predictors and weighted Poisson predictors for modeling patient flow patterns.</p>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors","title":"<code>incoming_admission_predictors</code>","text":"<p>Hospital Admissions Forecasting Predictors.</p> <p>This module implements custom predictors to estimate the number of hospital admissions within a specified prediction window using historical admission data. It provides two approaches: parametric curves with Poisson-binomial distributions and empirical survival curves with convolution of Poisson distributions. Both predictors accommodate different data filters for tailored predictions across various hospital settings.</p> <p>Classes:</p> Name Description <code>IncomingAdmissionPredictor : BaseEstimator, TransformerMixin</code> <p>Base class for admission predictors that handles filtering and arrival rate calculation.</p> <code>ParametricIncomingAdmissionPredictor : IncomingAdmissionPredictor</code> <p>Predicts the number of admissions within a given prediction window based on historical data and Poisson-binomial distribution using parametric aspirational curves.</p> <code>EmpiricalIncomingAdmissionPredictor : IncomingAdmissionPredictor</code> <p>Predicts the number of admissions using empirical survival curves and convolution of Poisson distributions instead of parametric curves.</p> Notes <p>The ParametricIncomingAdmissionPredictor uses a combination of Poisson and binomial distributions to model the probability of admissions within a prediction window using parametric curves defined by transition points (x1, y1, x2, y2).</p> <p>The EmpiricalIncomingAdmissionPredictor inherits the arrival rate calculation and filtering logic but replaces the parametric approach with empirical survival probabilities and convolution of individual Poisson distributions for each time interval.</p> <p>Both predictors take into account historical data patterns and can be filtered for specific hospital settings or specialties.</p>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.EmpiricalIncomingAdmissionPredictor","title":"<code>EmpiricalIncomingAdmissionPredictor</code>","text":"<p>               Bases: <code>IncomingAdmissionPredictor</code></p> <p>A predictor that uses empirical survival curves instead of parameterised curves.</p> <p>This predictor inherits all the arrival rate calculation and filtering logic from IncomingAdmissionPredictor but uses empirical survival probabilities and convolution of Poisson distributions for prediction instead of the Poisson-binomial approach.</p> <p>The survival curve is automatically calculated from the training data during the fit process by analysing time-to-admission patterns.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict</code> <p>Optional filters for data categorization. If None, no filtering is applied.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to enable verbose logging.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>survival_df</code> <code>DataFrame</code> <p>The survival data calculated from training data, containing time-to-event information for empirical probability calculations.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>class EmpiricalIncomingAdmissionPredictor(IncomingAdmissionPredictor):\n    \"\"\"A predictor that uses empirical survival curves instead of parameterised curves.\n\n    This predictor inherits all the arrival rate calculation and filtering logic from\n    IncomingAdmissionPredictor but uses empirical survival probabilities and convolution\n    of Poisson distributions for prediction instead of the Poisson-binomial approach.\n\n    The survival curve is automatically calculated from the training data during the\n    fit process by analysing time-to-admission patterns.\n\n    Parameters\n    ----------\n    filters : dict, optional\n        Optional filters for data categorization. If None, no filtering is applied.\n    verbose : bool, default=False\n        Whether to enable verbose logging.\n\n    Attributes\n    ----------\n    survival_df : pandas.DataFrame\n        The survival data calculated from training data, containing time-to-event\n        information for empirical probability calculations.\n    \"\"\"\n\n    def __init__(self, filters=None, verbose=False):\n        \"\"\"Initialize the EmpiricalIncomingAdmissionPredictor.\"\"\"\n        super().__init__(filters, verbose)\n        self.survival_df = None\n\n    def fit(\n        self,\n        train_df: pd.DataFrame,\n        prediction_window,\n        yta_time_interval,\n        prediction_times: List[float],\n        num_days: int,\n        epsilon=10**-7,\n        y=None,\n        start_time_col=\"arrival_datetime\",\n        end_time_col=\"departure_datetime\",\n    ) -&gt; \"EmpiricalIncomingAdmissionPredictor\":\n        \"\"\"Fit the model to the training data and calculate empirical survival curve.\n\n        Parameters\n        ----------\n        train_df : pandas.DataFrame\n            The training dataset with historical admission data.\n            Expected to have start_time_col as the index and end_time_col as a column.\n            Alternatively, both can be regular columns.\n        prediction_window : int or timedelta\n            The prediction window in minutes. If timedelta, will be converted to minutes.\n            If int, assumed to be in minutes.\n        yta_time_interval : int or timedelta\n            The interval in minutes for splitting the prediction window. If timedelta, will be converted to minutes.\n            If int, assumed to be in minutes.\n        prediction_times : list\n            Times of day at which predictions are made, in hours.\n        num_days : int\n            The number of days that the train_df spans.\n        epsilon : float, default=1e-7\n            A small value representing acceptable error rate to enable calculation\n            of the maximum value of the random variable representing number of beds.\n        y : None, optional\n            Ignored, present for compatibility with scikit-learn's fit method.\n        start_time_col : str, default='arrival_datetime'\n            Name of the column containing the start time (e.g., arrival time).\n            Expected to be the DataFrame index, but can also be a regular column.\n        end_time_col : str, default='departure_datetime'\n            Name of the column containing the end time (e.g., departure time).\n\n        Returns\n        -------\n        EmpiricalIncomingAdmissionPredictor\n            The instance itself, fitted with the training data.\n        \"\"\"\n        # Calculate survival curve from training data using existing function\n        # Handle case where start_time_col is in the index\n        if start_time_col in train_df.columns:\n            # start_time_col is a regular column\n            df_for_survival = train_df\n        else:\n            # start_time_col is likely the index, reset it to make it a column\n            df_for_survival = train_df.reset_index()\n            # Verify that start_time_col is now available\n            if start_time_col not in df_for_survival.columns:\n                raise ValueError(\n                    f\"Column '{start_time_col}' not found in DataFrame columns or index\"\n                )\n\n        self.survival_df = calculate_survival_curve(\n            df_for_survival, start_time_col=start_time_col, end_time_col=end_time_col\n        )\n\n        # Verify survival curve was calculated and saved successfully\n        if self.survival_df is None or len(self.survival_df) == 0:\n            raise RuntimeError(\"Failed to calculate survival curve from training data\")\n\n        # Ensure train_df has start_time_col as index for parent fit method\n        if start_time_col in train_df.columns:\n            train_df = train_df.set_index(start_time_col)\n\n        # Call parent fit method to handle arrival rate calculation and validation\n        super().fit(\n            train_df,\n            prediction_window,\n            yta_time_interval,\n            prediction_times,\n            num_days,\n            epsilon=epsilon,\n            y=y,\n        )\n\n        if self.verbose:\n            self.logger.info(\n                f\"EmpiricalIncomingAdmissionPredictor has been fitted with survival curve containing {len(self.survival_df)} time points\"\n            )\n\n        return self\n\n    def get_survival_curve(self):\n        \"\"\"Get the survival curve calculated during fitting.\n\n        Returns\n        -------\n        pandas.DataFrame\n            DataFrame containing the survival curve with columns:\n            - time_hours: Time points in hours\n            - survival_probability: Survival probabilities at each time point\n            - event_probability: Event probabilities (1 - survival_probability)\n\n        Raises\n        ------\n        RuntimeError\n            If the model has not been fitted yet.\n        \"\"\"\n        if self.survival_df is None:\n            raise RuntimeError(\"Model has not been fitted yet. Call fit() first.\")\n        return self.survival_df.copy()\n\n    def _calculate_survival_probabilities(self, prediction_window, yta_time_interval):\n        \"\"\"Calculate survival probabilities for each time interval.\n\n        Parameters\n        ----------\n        prediction_window : int or timedelta\n            The prediction window.\n        yta_time_interval : int or timedelta\n            The time interval for splitting the prediction window.\n\n        Returns\n        -------\n        numpy.ndarray\n            Array of admission probabilities for each time interval.\n        \"\"\"\n        # Calculate number of time intervals\n        if isinstance(prediction_window, timedelta) and isinstance(\n            yta_time_interval, timedelta\n        ):\n            NTimes = int(prediction_window / yta_time_interval)\n        elif isinstance(prediction_window, timedelta):\n            NTimes = int(prediction_window.total_seconds() / 60 / yta_time_interval)\n        elif isinstance(yta_time_interval, timedelta):\n            NTimes = int(prediction_window / (yta_time_interval.total_seconds() / 60))\n        else:\n            NTimes = int(prediction_window / yta_time_interval)\n\n        # Convert to hours for survival probability calculation\n        if isinstance(prediction_window, timedelta):\n            prediction_window_hours = prediction_window.total_seconds() / 3600\n        else:\n            prediction_window_hours = prediction_window / 60\n\n        if isinstance(yta_time_interval, timedelta):\n            yta_time_interval_hours = yta_time_interval.total_seconds() / 3600\n        else:\n            yta_time_interval_hours = yta_time_interval / 60\n\n        # Calculate admission probabilities for each time interval\n        probabilities = []\n        for i in range(NTimes):\n            # Time remaining until end of prediction window\n            time_remaining = prediction_window_hours - (i * yta_time_interval_hours)\n\n            # Interpolate survival probability from survival curve\n            if time_remaining &lt;= 0:\n                prob_admission = (\n                    1.0  # If time remaining is 0 or negative, probability is 1\n                )\n            else:\n                # Find the survival probability at this time point\n                # Linear interpolation between points in survival curve\n                survival_curve = self.survival_df\n                if time_remaining &gt;= survival_curve[\"time_hours\"].max():\n                    # If time is beyond our data, use the last survival probability\n                    survival_prob = survival_curve[\"survival_probability\"].iloc[-1]\n                elif time_remaining &lt;= survival_curve[\"time_hours\"].min():\n                    # If time is before our data, use the first survival probability\n                    survival_prob = survival_curve[\"survival_probability\"].iloc[0]\n                else:\n                    # Interpolate between points\n                    survival_prob = np.interp(\n                        time_remaining,\n                        survival_curve[\"time_hours\"],\n                        survival_curve[\"survival_probability\"],\n                    )\n\n                # Probability of admission = 1 - survival probability\n                prob_admission = 1 - survival_prob\n\n            probabilities.append(prob_admission)\n\n        return np.array(probabilities)\n\n    def _convolve_poisson_distributions(\n        self, arrival_rates, probabilities, max_value=20\n    ):\n        \"\"\"Convolve Poisson distributions for each time interval.\n\n        Parameters\n        ----------\n        arrival_rates : numpy.ndarray\n            Array of arrival rates for each time interval.\n        probabilities : numpy.ndarray\n            Array of admission probabilities for each time interval.\n        max_value : int, default=20\n            Maximum value for the discrete distribution support.\n\n        Returns\n        -------\n        pandas.DataFrame\n            DataFrame with 'sum' and 'agg_proba' columns representing the final distribution.\n        \"\"\"\n        from scipy import stats\n\n        # Create weighted Poisson distributions for each time interval\n        weighted_rates = arrival_rates * probabilities\n        poisson_dists = [stats.poisson(rate) for rate in weighted_rates]\n\n        # Get PMF for each distribution\n        x = np.arange(max_value)\n        pmfs = [dist.pmf(x) for dist in poisson_dists]\n\n        # Convolve all distributions together\n        if len(pmfs) == 0:\n            # Handle edge case of no distributions\n            combined_pmf = np.zeros(max_value)\n            combined_pmf[0] = 1.0  # All probability at 0\n        else:\n            combined_pmf = pmfs[0]\n            for pmf in pmfs[1:]:\n                combined_pmf = np.convolve(combined_pmf, pmf)\n\n        # Create result DataFrame\n        result_df = pd.DataFrame(\n            {\"sum\": range(len(combined_pmf)), \"agg_proba\": combined_pmf}\n        )\n\n        # Filter out near-zero probabilities and normalize\n        result_df = result_df[result_df[\"agg_proba\"] &gt; 1e-10]\n        result_df[\"agg_proba\"] = result_df[\"agg_proba\"] / result_df[\"agg_proba\"].sum()\n\n        return result_df.set_index(\"sum\")\n\n    def predict(self, prediction_context: Dict, **kwargs) -&gt; Dict:\n        \"\"\"Predict the number of admissions using empirical survival curves.\n\n        Parameters\n        ----------\n        prediction_context : dict\n            A dictionary defining the context for which predictions are to be made.\n            It should specify either a general context or one based on the applied filters.\n        **kwargs\n            Additional keyword arguments for prediction configuration:\n\n            max_value : int, default=20\n                Maximum value for the discrete distribution support.\n\n        Returns\n        -------\n        dict\n            A dictionary with predictions for each specified context.\n\n        Raises\n        ------\n        ValueError\n            If filter key is not recognized or prediction_time is not provided.\n        KeyError\n            If required keys are missing from the prediction context.\n        RuntimeError\n            If survival_df was not provided during fitting.\n        \"\"\"\n        if self.survival_df is None:\n            raise RuntimeError(\n                \"No survival data available. Please call fit() method first to calculate survival curve from training data.\"\n            )\n\n        # Extract parameters from kwargs with defaults\n        max_value = kwargs.get(\"max_value\", 20)\n\n        predictions = {}\n\n        # Calculate survival probabilities once (they're the same for all contexts)\n        survival_probabilities = self._calculate_survival_probabilities(\n            self.prediction_window, self.yta_time_interval\n        )\n\n        for filter_key, filter_values in prediction_context.items():\n            try:\n                if filter_key not in self.weights:\n                    raise ValueError(\n                        f\"Filter key '{filter_key}' is not recognized in the model weights.\"\n                    )\n\n                prediction_time = filter_values.get(\"prediction_time\")\n                if prediction_time is None:\n                    raise ValueError(\n                        f\"No 'prediction_time' provided for filter '{filter_key}'.\"\n                    )\n\n                if prediction_time not in self.prediction_times:\n                    prediction_time = find_nearest_previous_prediction_time(\n                        prediction_time, self.prediction_times\n                    )\n\n                arrival_rates = self.weights[filter_key][prediction_time].get(\n                    \"arrival_rates\"\n                )\n                if arrival_rates is None:\n                    raise ValueError(\n                        f\"No arrival_rates found for the time of day '{prediction_time}' under filter '{filter_key}'.\"\n                    )\n\n                # Convert arrival rates to numpy array\n                arrival_rates = np.array(arrival_rates)\n\n                # Generate prediction using convolution approach\n                predictions[filter_key] = self._convolve_poisson_distributions(\n                    arrival_rates, survival_probabilities, max_value=max_value\n                )\n\n                # if self.verbose:\n                #     total_expected = (arrival_rates * survival_probabilities).sum()\n                #     self.logger.info(\n                #         f\"Prediction for {filter_key} at {prediction_time}: \"\n                #         f\"Expected value \u2248 {total_expected:.2f}\"\n                #     )\n\n            except KeyError as e:\n                raise KeyError(f\"Key error occurred: {e!s}\")\n\n        return predictions\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.EmpiricalIncomingAdmissionPredictor.__init__","title":"<code>__init__(filters=None, verbose=False)</code>","text":"<p>Initialize the EmpiricalIncomingAdmissionPredictor.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def __init__(self, filters=None, verbose=False):\n    \"\"\"Initialize the EmpiricalIncomingAdmissionPredictor.\"\"\"\n    super().__init__(filters, verbose)\n    self.survival_df = None\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.EmpiricalIncomingAdmissionPredictor.fit","title":"<code>fit(train_df, prediction_window, yta_time_interval, prediction_times, num_days, epsilon=10 ** -7, y=None, start_time_col='arrival_datetime', end_time_col='departure_datetime')</code>","text":"<p>Fit the model to the training data and calculate empirical survival curve.</p> <p>Parameters:</p> Name Type Description Default <code>train_df</code> <code>DataFrame</code> <p>The training dataset with historical admission data. Expected to have start_time_col as the index and end_time_col as a column. Alternatively, both can be regular columns.</p> required <code>prediction_window</code> <code>int or timedelta</code> <p>The prediction window in minutes. If timedelta, will be converted to minutes. If int, assumed to be in minutes.</p> required <code>yta_time_interval</code> <code>int or timedelta</code> <p>The interval in minutes for splitting the prediction window. If timedelta, will be converted to minutes. If int, assumed to be in minutes.</p> required <code>prediction_times</code> <code>list</code> <p>Times of day at which predictions are made, in hours.</p> required <code>num_days</code> <code>int</code> <p>The number of days that the train_df spans.</p> required <code>epsilon</code> <code>float</code> <p>A small value representing acceptable error rate to enable calculation of the maximum value of the random variable representing number of beds.</p> <code>1e-7</code> <code>y</code> <code>None</code> <p>Ignored, present for compatibility with scikit-learn's fit method.</p> <code>None</code> <code>start_time_col</code> <code>str</code> <p>Name of the column containing the start time (e.g., arrival time). Expected to be the DataFrame index, but can also be a regular column.</p> <code>'arrival_datetime'</code> <code>end_time_col</code> <code>str</code> <p>Name of the column containing the end time (e.g., departure time).</p> <code>'departure_datetime'</code> <p>Returns:</p> Type Description <code>EmpiricalIncomingAdmissionPredictor</code> <p>The instance itself, fitted with the training data.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def fit(\n    self,\n    train_df: pd.DataFrame,\n    prediction_window,\n    yta_time_interval,\n    prediction_times: List[float],\n    num_days: int,\n    epsilon=10**-7,\n    y=None,\n    start_time_col=\"arrival_datetime\",\n    end_time_col=\"departure_datetime\",\n) -&gt; \"EmpiricalIncomingAdmissionPredictor\":\n    \"\"\"Fit the model to the training data and calculate empirical survival curve.\n\n    Parameters\n    ----------\n    train_df : pandas.DataFrame\n        The training dataset with historical admission data.\n        Expected to have start_time_col as the index and end_time_col as a column.\n        Alternatively, both can be regular columns.\n    prediction_window : int or timedelta\n        The prediction window in minutes. If timedelta, will be converted to minutes.\n        If int, assumed to be in minutes.\n    yta_time_interval : int or timedelta\n        The interval in minutes for splitting the prediction window. If timedelta, will be converted to minutes.\n        If int, assumed to be in minutes.\n    prediction_times : list\n        Times of day at which predictions are made, in hours.\n    num_days : int\n        The number of days that the train_df spans.\n    epsilon : float, default=1e-7\n        A small value representing acceptable error rate to enable calculation\n        of the maximum value of the random variable representing number of beds.\n    y : None, optional\n        Ignored, present for compatibility with scikit-learn's fit method.\n    start_time_col : str, default='arrival_datetime'\n        Name of the column containing the start time (e.g., arrival time).\n        Expected to be the DataFrame index, but can also be a regular column.\n    end_time_col : str, default='departure_datetime'\n        Name of the column containing the end time (e.g., departure time).\n\n    Returns\n    -------\n    EmpiricalIncomingAdmissionPredictor\n        The instance itself, fitted with the training data.\n    \"\"\"\n    # Calculate survival curve from training data using existing function\n    # Handle case where start_time_col is in the index\n    if start_time_col in train_df.columns:\n        # start_time_col is a regular column\n        df_for_survival = train_df\n    else:\n        # start_time_col is likely the index, reset it to make it a column\n        df_for_survival = train_df.reset_index()\n        # Verify that start_time_col is now available\n        if start_time_col not in df_for_survival.columns:\n            raise ValueError(\n                f\"Column '{start_time_col}' not found in DataFrame columns or index\"\n            )\n\n    self.survival_df = calculate_survival_curve(\n        df_for_survival, start_time_col=start_time_col, end_time_col=end_time_col\n    )\n\n    # Verify survival curve was calculated and saved successfully\n    if self.survival_df is None or len(self.survival_df) == 0:\n        raise RuntimeError(\"Failed to calculate survival curve from training data\")\n\n    # Ensure train_df has start_time_col as index for parent fit method\n    if start_time_col in train_df.columns:\n        train_df = train_df.set_index(start_time_col)\n\n    # Call parent fit method to handle arrival rate calculation and validation\n    super().fit(\n        train_df,\n        prediction_window,\n        yta_time_interval,\n        prediction_times,\n        num_days,\n        epsilon=epsilon,\n        y=y,\n    )\n\n    if self.verbose:\n        self.logger.info(\n            f\"EmpiricalIncomingAdmissionPredictor has been fitted with survival curve containing {len(self.survival_df)} time points\"\n        )\n\n    return self\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.EmpiricalIncomingAdmissionPredictor.get_survival_curve","title":"<code>get_survival_curve()</code>","text":"<p>Get the survival curve calculated during fitting.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the survival curve with columns: - time_hours: Time points in hours - survival_probability: Survival probabilities at each time point - event_probability: Event probabilities (1 - survival_probability)</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the model has not been fitted yet.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def get_survival_curve(self):\n    \"\"\"Get the survival curve calculated during fitting.\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame containing the survival curve with columns:\n        - time_hours: Time points in hours\n        - survival_probability: Survival probabilities at each time point\n        - event_probability: Event probabilities (1 - survival_probability)\n\n    Raises\n    ------\n    RuntimeError\n        If the model has not been fitted yet.\n    \"\"\"\n    if self.survival_df is None:\n        raise RuntimeError(\"Model has not been fitted yet. Call fit() first.\")\n    return self.survival_df.copy()\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.EmpiricalIncomingAdmissionPredictor.predict","title":"<code>predict(prediction_context, **kwargs)</code>","text":"<p>Predict the number of admissions using empirical survival curves.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_context</code> <code>dict</code> <p>A dictionary defining the context for which predictions are to be made. It should specify either a general context or one based on the applied filters.</p> required <code>**kwargs</code> <p>Additional keyword arguments for prediction configuration:</p> <p>max_value : int, default=20     Maximum value for the discrete distribution support.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with predictions for each specified context.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If filter key is not recognized or prediction_time is not provided.</p> <code>KeyError</code> <p>If required keys are missing from the prediction context.</p> <code>RuntimeError</code> <p>If survival_df was not provided during fitting.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def predict(self, prediction_context: Dict, **kwargs) -&gt; Dict:\n    \"\"\"Predict the number of admissions using empirical survival curves.\n\n    Parameters\n    ----------\n    prediction_context : dict\n        A dictionary defining the context for which predictions are to be made.\n        It should specify either a general context or one based on the applied filters.\n    **kwargs\n        Additional keyword arguments for prediction configuration:\n\n        max_value : int, default=20\n            Maximum value for the discrete distribution support.\n\n    Returns\n    -------\n    dict\n        A dictionary with predictions for each specified context.\n\n    Raises\n    ------\n    ValueError\n        If filter key is not recognized or prediction_time is not provided.\n    KeyError\n        If required keys are missing from the prediction context.\n    RuntimeError\n        If survival_df was not provided during fitting.\n    \"\"\"\n    if self.survival_df is None:\n        raise RuntimeError(\n            \"No survival data available. Please call fit() method first to calculate survival curve from training data.\"\n        )\n\n    # Extract parameters from kwargs with defaults\n    max_value = kwargs.get(\"max_value\", 20)\n\n    predictions = {}\n\n    # Calculate survival probabilities once (they're the same for all contexts)\n    survival_probabilities = self._calculate_survival_probabilities(\n        self.prediction_window, self.yta_time_interval\n    )\n\n    for filter_key, filter_values in prediction_context.items():\n        try:\n            if filter_key not in self.weights:\n                raise ValueError(\n                    f\"Filter key '{filter_key}' is not recognized in the model weights.\"\n                )\n\n            prediction_time = filter_values.get(\"prediction_time\")\n            if prediction_time is None:\n                raise ValueError(\n                    f\"No 'prediction_time' provided for filter '{filter_key}'.\"\n                )\n\n            if prediction_time not in self.prediction_times:\n                prediction_time = find_nearest_previous_prediction_time(\n                    prediction_time, self.prediction_times\n                )\n\n            arrival_rates = self.weights[filter_key][prediction_time].get(\n                \"arrival_rates\"\n            )\n            if arrival_rates is None:\n                raise ValueError(\n                    f\"No arrival_rates found for the time of day '{prediction_time}' under filter '{filter_key}'.\"\n                )\n\n            # Convert arrival rates to numpy array\n            arrival_rates = np.array(arrival_rates)\n\n            # Generate prediction using convolution approach\n            predictions[filter_key] = self._convolve_poisson_distributions(\n                arrival_rates, survival_probabilities, max_value=max_value\n            )\n\n            # if self.verbose:\n            #     total_expected = (arrival_rates * survival_probabilities).sum()\n            #     self.logger.info(\n            #         f\"Prediction for {filter_key} at {prediction_time}: \"\n            #         f\"Expected value \u2248 {total_expected:.2f}\"\n            #     )\n\n        except KeyError as e:\n            raise KeyError(f\"Key error occurred: {e!s}\")\n\n    return predictions\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.IncomingAdmissionPredictor","title":"<code>IncomingAdmissionPredictor</code>","text":"<p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code>, <code>ABC</code></p> <p>Base class for admission predictors that handles filtering and arrival rate calculation.</p> <p>This abstract base class provides the common functionality for predicting hospital admissions, including data filtering, arrival rate calculation, and basic prediction infrastructure. Subclasses implement specific prediction strategies.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict</code> <p>Optional filters for data categorization. If None, no filtering is applied.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to enable verbose logging.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>filters</code> <code>dict</code> <p>Filters for data categorization.</p> <code>verbose</code> <code>bool</code> <p>Verbose logging flag.</p> <code>metrics</code> <code>dict</code> <p>Stores metadata about the model and training data.</p> <code>weights</code> <code>dict</code> <p>Model parameters computed during fitting.</p> Notes <p>The predictor implements scikit-learn's BaseEstimator and TransformerMixin interfaces for compatibility with scikit-learn pipelines.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>class IncomingAdmissionPredictor(BaseEstimator, TransformerMixin, ABC):\n    \"\"\"Base class for admission predictors that handles filtering and arrival rate calculation.\n\n    This abstract base class provides the common functionality for predicting hospital\n    admissions, including data filtering, arrival rate calculation, and basic prediction\n    infrastructure. Subclasses implement specific prediction strategies.\n\n    Parameters\n    ----------\n    filters : dict, optional\n        Optional filters for data categorization. If None, no filtering is applied.\n    verbose : bool, default=False\n        Whether to enable verbose logging.\n\n    Attributes\n    ----------\n    filters : dict\n        Filters for data categorization.\n    verbose : bool\n        Verbose logging flag.\n    metrics : dict\n        Stores metadata about the model and training data.\n    weights : dict\n        Model parameters computed during fitting.\n\n    Notes\n    -----\n    The predictor implements scikit-learn's BaseEstimator and TransformerMixin\n    interfaces for compatibility with scikit-learn pipelines.\n    \"\"\"\n\n    def __init__(self, filters=None, verbose=False):\n        \"\"\"\n        Initialize the IncomingAdmissionPredictor with optional filters.\n\n        Args:\n            filters (dict, optional): A dictionary defining filters for different categories or specialties.\n                                    If None or empty, no filtering will be applied.\n            verbose (bool, optional): If True, enable info-level logging. Defaults to False.\n        \"\"\"\n        self.filters = filters if filters else {}\n        self.verbose = verbose\n        self.metrics = {}  # Add metrics dictionary to store metadata\n\n        if verbose:\n            # Configure logging for Jupyter notebook compatibility\n            import logging\n            import sys\n\n            # Create logger\n            self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n\n            # Only set up handlers if they don't exist\n            if not self.logger.handlers:\n                self.logger.setLevel(logging.INFO if verbose else logging.WARNING)\n\n                # Create handler that writes to sys.stdout\n                handler = logging.StreamHandler(sys.stdout)\n                handler.setLevel(logging.INFO if verbose else logging.WARNING)\n\n                # Create a formatting configuration\n                formatter = logging.Formatter(\"%(message)s\")\n                handler.setFormatter(formatter)\n\n                # Add the handler to the logger\n                self.logger.addHandler(handler)\n\n                # Prevent propagation to root logger\n                self.logger.propagate = False\n\n        # Apply filters\n        self.filters = filters if filters else {}\n\n    def filter_dataframe(self, df: pd.DataFrame, filters: Dict) -&gt; pd.DataFrame:\n        \"\"\"Apply a set of filters to a dataframe.\n\n        Parameters\n        ----------\n        df : pandas.DataFrame\n            The DataFrame to filter.\n        filters : dict\n            A dictionary where keys are column names and values are the criteria\n            or function to filter by.\n\n        Returns\n        -------\n        pandas.DataFrame\n            A filtered DataFrame.\n        \"\"\"\n        filtered_df = df\n        for column, criteria in filters.items():\n            if callable(criteria):  # If the criteria is a function, apply it directly\n                filtered_df = filtered_df[filtered_df[column].apply(criteria)]\n            else:  # Otherwise, assume the criteria is a value or list of values for equality check\n                filtered_df = filtered_df[filtered_df[column] == criteria]\n        return filtered_df\n\n    def _calculate_parameters(\n        self,\n        df,\n        prediction_window: timedelta,\n        yta_time_interval: timedelta,\n        prediction_times,\n        num_days,\n    ):\n        \"\"\"Calculate parameters required for the model.\n\n        Parameters\n        ----------\n        df : pandas.DataFrame\n            The data frame to process.\n        prediction_window : timedelta\n            The total prediction window for prediction.\n        yta_time_interval : timedelta\n            The interval for splitting the prediction window.\n        prediction_times : list\n            Times of day at which predictions are made.\n        num_days : int\n            Number of days over which to calculate time-varying arrival rates.\n\n        Returns\n        -------\n        dict\n            Calculated arrival_rates parameters organized by time of day.\n        \"\"\"\n\n        # Calculate Ntimes - Python handles the division naturally\n        Ntimes = int(prediction_window / yta_time_interval)\n\n        # Pass original type to time_varying_arrival_rates\n        arrival_rates_dict = time_varying_arrival_rates(\n            df, yta_time_interval, num_days, verbose=self.verbose\n        )\n        prediction_time_dict = {}\n\n        for prediction_time_ in prediction_times:\n            prediction_time_hr, prediction_time_min = (\n                (prediction_time_, 0)\n                if isinstance(prediction_time_, int)\n                else prediction_time_\n            )\n            arrival_rates = [\n                arrival_rates_dict[\n                    (\n                        datetime(1970, 1, 1, prediction_time_hr, prediction_time_min)\n                        + i * yta_time_interval\n                    ).time()\n                ]\n                for i in range(Ntimes)\n            ]\n            prediction_time_dict[(prediction_time_hr, prediction_time_min)] = {\n                \"arrival_rates\": arrival_rates\n            }\n\n        return prediction_time_dict\n\n    def fit(\n        self,\n        train_df: pd.DataFrame,\n        prediction_window: timedelta,\n        yta_time_interval: timedelta,\n        prediction_times: List[float],\n        num_days: int,\n        epsilon: float = 10**-7,\n        y: Optional[None] = None,\n    ) -&gt; \"IncomingAdmissionPredictor\":\n        \"\"\"Fit the model to the training data.\n\n        Parameters\n        ----------\n        train_df : pandas.DataFrame\n            The training dataset with historical admission data.\n        prediction_window : timedelta\n            The prediction window as a timedelta object.\n        yta_time_interval : timedelta\n            The interval for splitting the prediction window as a timedelta object.\n        prediction_times : list\n            Times of day at which predictions are made, in hours.\n        num_days : int\n            The number of days that the train_df spans.\n        epsilon : float, default=1e-7\n            A small value representing acceptable error rate to enable calculation\n            of the maximum value of the random variable representing number of beds.\n        y : None, optional\n            Ignored, present for compatibility with scikit-learn's fit method.\n\n        Returns\n        -------\n        IncomingAdmissionPredictor\n            The instance itself, fitted with the training data.\n\n        Raises\n        ------\n        TypeError\n            If prediction_window or yta_time_interval are not timedelta objects.\n        ValueError\n            If prediction_window/yta_time_interval is not greater than 1.\n        \"\"\"\n\n        # Validate inputs\n        if not isinstance(prediction_window, timedelta):\n            raise TypeError(\"prediction_window must be a timedelta object\")\n        if not isinstance(yta_time_interval, timedelta):\n            raise TypeError(\"yta_time_interval must be a timedelta object\")\n\n        if prediction_window.total_seconds() &lt;= 0:\n            raise ValueError(\"prediction_window must be positive\")\n        if yta_time_interval.total_seconds() &lt;= 0:\n            raise ValueError(\"yta_time_interval must be positive\")\n        if yta_time_interval.total_seconds() &gt; 4 * 3600:  # 4 hours in seconds\n            warnings.warn(\"yta_time_interval appears to be longer than 4 hours\")\n\n        # Validate the ratio makes sense\n        ratio = prediction_window / yta_time_interval\n        if int(ratio) == 0:\n            raise ValueError(\n                \"prediction_window must be significantly larger than yta_time_interval\"\n            )\n\n        # Store original types\n        self.prediction_window = prediction_window\n        self.yta_time_interval = yta_time_interval\n        self.epsilon = epsilon\n        self.prediction_times = [\n            tuple(x)\n            if isinstance(x, (list, np.ndarray))\n            else (x, 0)\n            if isinstance(x, (int, float))\n            else x\n            for x in prediction_times\n        ]\n\n        # Initialize yet_to_arrive_dict\n        self.weights = {}\n\n        # If there are filters specified, calculate and store the parameters directly with the respective spec keys\n        if self.filters:\n            for spec, filters in self.filters.items():\n                self.weights[spec] = self._calculate_parameters(\n                    self.filter_dataframe(train_df, filters),\n                    prediction_window,\n                    yta_time_interval,\n                    prediction_times,\n                    num_days,\n                )\n        else:\n            # If there are no filters, store the parameters with a generic key of 'unfiltered'\n            self.weights[\"unfiltered\"] = self._calculate_parameters(\n                train_df,\n                prediction_window,\n                yta_time_interval,\n                prediction_times,\n                num_days,\n            )\n\n        if self.verbose:\n            self.logger.info(\n                f\"{self.__class__.__name__} trained for these times: {prediction_times}\"\n            )\n            self.logger.info(\n                f\"using prediction window of {prediction_window} after the time of prediction\"\n            )\n            self.logger.info(\n                f\"and time interval of {yta_time_interval} within the prediction window.\"\n            )\n            self.logger.info(f\"The error value for prediction will be {epsilon}\")\n            self.logger.info(\n                \"To see the weights saved by this model, used the get_weights() method\"\n            )\n\n        # Store metrics about the training data\n        self.metrics[\"train_dttm\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n        self.metrics[\"train_set_no\"] = len(train_df)\n        self.metrics[\"start_date\"] = train_df.index.min().date()\n        self.metrics[\"end_date\"] = train_df.index.max().date()\n        self.metrics[\"num_days\"] = num_days\n\n        return self\n\n    def get_weights(self):\n        \"\"\"Get the weights computed by the fit method.\n\n        Returns\n        -------\n        dict\n            The weights computed during model fitting.\n        \"\"\"\n        return self.weights\n\n    @abstractmethod\n    def predict(self, prediction_context: Dict, **kwargs) -&gt; Dict:\n        \"\"\"Predict the number of admissions for the given context.\n\n        This is an abstract method that must be implemented by subclasses.\n\n        Parameters\n        ----------\n        prediction_context : dict\n            A dictionary defining the context for which predictions are to be made.\n            It should specify either a general context or one based on the applied filters.\n        **kwargs\n            Additional keyword arguments specific to the prediction method.\n\n        Returns\n        -------\n        dict\n            A dictionary with predictions for each specified context.\n\n        Raises\n        ------\n        ValueError\n            If filter key is not recognized or prediction_time is not provided.\n        KeyError\n            If required keys are missing from the prediction context.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.IncomingAdmissionPredictor.__init__","title":"<code>__init__(filters=None, verbose=False)</code>","text":"<p>Initialize the IncomingAdmissionPredictor with optional filters.</p> <p>Args:     filters (dict, optional): A dictionary defining filters for different categories or specialties.                             If None or empty, no filtering will be applied.     verbose (bool, optional): If True, enable info-level logging. Defaults to False.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def __init__(self, filters=None, verbose=False):\n    \"\"\"\n    Initialize the IncomingAdmissionPredictor with optional filters.\n\n    Args:\n        filters (dict, optional): A dictionary defining filters for different categories or specialties.\n                                If None or empty, no filtering will be applied.\n        verbose (bool, optional): If True, enable info-level logging. Defaults to False.\n    \"\"\"\n    self.filters = filters if filters else {}\n    self.verbose = verbose\n    self.metrics = {}  # Add metrics dictionary to store metadata\n\n    if verbose:\n        # Configure logging for Jupyter notebook compatibility\n        import logging\n        import sys\n\n        # Create logger\n        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n\n        # Only set up handlers if they don't exist\n        if not self.logger.handlers:\n            self.logger.setLevel(logging.INFO if verbose else logging.WARNING)\n\n            # Create handler that writes to sys.stdout\n            handler = logging.StreamHandler(sys.stdout)\n            handler.setLevel(logging.INFO if verbose else logging.WARNING)\n\n            # Create a formatting configuration\n            formatter = logging.Formatter(\"%(message)s\")\n            handler.setFormatter(formatter)\n\n            # Add the handler to the logger\n            self.logger.addHandler(handler)\n\n            # Prevent propagation to root logger\n            self.logger.propagate = False\n\n    # Apply filters\n    self.filters = filters if filters else {}\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.IncomingAdmissionPredictor.filter_dataframe","title":"<code>filter_dataframe(df, filters)</code>","text":"<p>Apply a set of filters to a dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to filter.</p> required <code>filters</code> <code>dict</code> <p>A dictionary where keys are column names and values are the criteria or function to filter by.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A filtered DataFrame.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def filter_dataframe(self, df: pd.DataFrame, filters: Dict) -&gt; pd.DataFrame:\n    \"\"\"Apply a set of filters to a dataframe.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        The DataFrame to filter.\n    filters : dict\n        A dictionary where keys are column names and values are the criteria\n        or function to filter by.\n\n    Returns\n    -------\n    pandas.DataFrame\n        A filtered DataFrame.\n    \"\"\"\n    filtered_df = df\n    for column, criteria in filters.items():\n        if callable(criteria):  # If the criteria is a function, apply it directly\n            filtered_df = filtered_df[filtered_df[column].apply(criteria)]\n        else:  # Otherwise, assume the criteria is a value or list of values for equality check\n            filtered_df = filtered_df[filtered_df[column] == criteria]\n    return filtered_df\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.IncomingAdmissionPredictor.fit","title":"<code>fit(train_df, prediction_window, yta_time_interval, prediction_times, num_days, epsilon=10 ** -7, y=None)</code>","text":"<p>Fit the model to the training data.</p> <p>Parameters:</p> Name Type Description Default <code>train_df</code> <code>DataFrame</code> <p>The training dataset with historical admission data.</p> required <code>prediction_window</code> <code>timedelta</code> <p>The prediction window as a timedelta object.</p> required <code>yta_time_interval</code> <code>timedelta</code> <p>The interval for splitting the prediction window as a timedelta object.</p> required <code>prediction_times</code> <code>list</code> <p>Times of day at which predictions are made, in hours.</p> required <code>num_days</code> <code>int</code> <p>The number of days that the train_df spans.</p> required <code>epsilon</code> <code>float</code> <p>A small value representing acceptable error rate to enable calculation of the maximum value of the random variable representing number of beds.</p> <code>1e-7</code> <code>y</code> <code>None</code> <p>Ignored, present for compatibility with scikit-learn's fit method.</p> <code>None</code> <p>Returns:</p> Type Description <code>IncomingAdmissionPredictor</code> <p>The instance itself, fitted with the training data.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If prediction_window or yta_time_interval are not timedelta objects.</p> <code>ValueError</code> <p>If prediction_window/yta_time_interval is not greater than 1.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def fit(\n    self,\n    train_df: pd.DataFrame,\n    prediction_window: timedelta,\n    yta_time_interval: timedelta,\n    prediction_times: List[float],\n    num_days: int,\n    epsilon: float = 10**-7,\n    y: Optional[None] = None,\n) -&gt; \"IncomingAdmissionPredictor\":\n    \"\"\"Fit the model to the training data.\n\n    Parameters\n    ----------\n    train_df : pandas.DataFrame\n        The training dataset with historical admission data.\n    prediction_window : timedelta\n        The prediction window as a timedelta object.\n    yta_time_interval : timedelta\n        The interval for splitting the prediction window as a timedelta object.\n    prediction_times : list\n        Times of day at which predictions are made, in hours.\n    num_days : int\n        The number of days that the train_df spans.\n    epsilon : float, default=1e-7\n        A small value representing acceptable error rate to enable calculation\n        of the maximum value of the random variable representing number of beds.\n    y : None, optional\n        Ignored, present for compatibility with scikit-learn's fit method.\n\n    Returns\n    -------\n    IncomingAdmissionPredictor\n        The instance itself, fitted with the training data.\n\n    Raises\n    ------\n    TypeError\n        If prediction_window or yta_time_interval are not timedelta objects.\n    ValueError\n        If prediction_window/yta_time_interval is not greater than 1.\n    \"\"\"\n\n    # Validate inputs\n    if not isinstance(prediction_window, timedelta):\n        raise TypeError(\"prediction_window must be a timedelta object\")\n    if not isinstance(yta_time_interval, timedelta):\n        raise TypeError(\"yta_time_interval must be a timedelta object\")\n\n    if prediction_window.total_seconds() &lt;= 0:\n        raise ValueError(\"prediction_window must be positive\")\n    if yta_time_interval.total_seconds() &lt;= 0:\n        raise ValueError(\"yta_time_interval must be positive\")\n    if yta_time_interval.total_seconds() &gt; 4 * 3600:  # 4 hours in seconds\n        warnings.warn(\"yta_time_interval appears to be longer than 4 hours\")\n\n    # Validate the ratio makes sense\n    ratio = prediction_window / yta_time_interval\n    if int(ratio) == 0:\n        raise ValueError(\n            \"prediction_window must be significantly larger than yta_time_interval\"\n        )\n\n    # Store original types\n    self.prediction_window = prediction_window\n    self.yta_time_interval = yta_time_interval\n    self.epsilon = epsilon\n    self.prediction_times = [\n        tuple(x)\n        if isinstance(x, (list, np.ndarray))\n        else (x, 0)\n        if isinstance(x, (int, float))\n        else x\n        for x in prediction_times\n    ]\n\n    # Initialize yet_to_arrive_dict\n    self.weights = {}\n\n    # If there are filters specified, calculate and store the parameters directly with the respective spec keys\n    if self.filters:\n        for spec, filters in self.filters.items():\n            self.weights[spec] = self._calculate_parameters(\n                self.filter_dataframe(train_df, filters),\n                prediction_window,\n                yta_time_interval,\n                prediction_times,\n                num_days,\n            )\n    else:\n        # If there are no filters, store the parameters with a generic key of 'unfiltered'\n        self.weights[\"unfiltered\"] = self._calculate_parameters(\n            train_df,\n            prediction_window,\n            yta_time_interval,\n            prediction_times,\n            num_days,\n        )\n\n    if self.verbose:\n        self.logger.info(\n            f\"{self.__class__.__name__} trained for these times: {prediction_times}\"\n        )\n        self.logger.info(\n            f\"using prediction window of {prediction_window} after the time of prediction\"\n        )\n        self.logger.info(\n            f\"and time interval of {yta_time_interval} within the prediction window.\"\n        )\n        self.logger.info(f\"The error value for prediction will be {epsilon}\")\n        self.logger.info(\n            \"To see the weights saved by this model, used the get_weights() method\"\n        )\n\n    # Store metrics about the training data\n    self.metrics[\"train_dttm\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n    self.metrics[\"train_set_no\"] = len(train_df)\n    self.metrics[\"start_date\"] = train_df.index.min().date()\n    self.metrics[\"end_date\"] = train_df.index.max().date()\n    self.metrics[\"num_days\"] = num_days\n\n    return self\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.IncomingAdmissionPredictor.get_weights","title":"<code>get_weights()</code>","text":"<p>Get the weights computed by the fit method.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The weights computed during model fitting.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def get_weights(self):\n    \"\"\"Get the weights computed by the fit method.\n\n    Returns\n    -------\n    dict\n        The weights computed during model fitting.\n    \"\"\"\n    return self.weights\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.IncomingAdmissionPredictor.predict","title":"<code>predict(prediction_context, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Predict the number of admissions for the given context.</p> <p>This is an abstract method that must be implemented by subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_context</code> <code>dict</code> <p>A dictionary defining the context for which predictions are to be made. It should specify either a general context or one based on the applied filters.</p> required <code>**kwargs</code> <p>Additional keyword arguments specific to the prediction method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with predictions for each specified context.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If filter key is not recognized or prediction_time is not provided.</p> <code>KeyError</code> <p>If required keys are missing from the prediction context.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>@abstractmethod\ndef predict(self, prediction_context: Dict, **kwargs) -&gt; Dict:\n    \"\"\"Predict the number of admissions for the given context.\n\n    This is an abstract method that must be implemented by subclasses.\n\n    Parameters\n    ----------\n    prediction_context : dict\n        A dictionary defining the context for which predictions are to be made.\n        It should specify either a general context or one based on the applied filters.\n    **kwargs\n        Additional keyword arguments specific to the prediction method.\n\n    Returns\n    -------\n    dict\n        A dictionary with predictions for each specified context.\n\n    Raises\n    ------\n    ValueError\n        If filter key is not recognized or prediction_time is not provided.\n    KeyError\n        If required keys are missing from the prediction context.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.ParametricIncomingAdmissionPredictor","title":"<code>ParametricIncomingAdmissionPredictor</code>","text":"<p>               Bases: <code>IncomingAdmissionPredictor</code></p> <p>A predictor for estimating hospital admissions using parametric curves.</p> <p>This predictor uses a combination of Poisson and binomial distributions to forecast future admissions, excluding patients who have already arrived. The prediction is based on historical data and can be filtered for specific hospital settings.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict</code> <p>Optional filters for data categorization. If None, no filtering is applied.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to enable verbose logging.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>filters</code> <code>dict</code> <p>Filters for data categorization.</p> <code>verbose</code> <code>bool</code> <p>Verbose logging flag.</p> <code>metrics</code> <code>dict</code> <p>Stores metadata about the model and training data.</p> <code>weights</code> <code>dict</code> <p>Model parameters computed during fitting.</p> Notes <p>The predictor implements scikit-learn's BaseEstimator and TransformerMixin interfaces for compatibility with scikit-learn pipelines.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>class ParametricIncomingAdmissionPredictor(IncomingAdmissionPredictor):\n    \"\"\"A predictor for estimating hospital admissions using parametric curves.\n\n    This predictor uses a combination of Poisson and binomial distributions to forecast\n    future admissions, excluding patients who have already arrived. The prediction is\n    based on historical data and can be filtered for specific hospital settings.\n\n    Parameters\n    ----------\n    filters : dict, optional\n        Optional filters for data categorization. If None, no filtering is applied.\n    verbose : bool, default=False\n        Whether to enable verbose logging.\n\n    Attributes\n    ----------\n    filters : dict\n        Filters for data categorization.\n    verbose : bool\n        Verbose logging flag.\n    metrics : dict\n        Stores metadata about the model and training data.\n    weights : dict\n        Model parameters computed during fitting.\n\n    Notes\n    -----\n    The predictor implements scikit-learn's BaseEstimator and TransformerMixin\n    interfaces for compatibility with scikit-learn pipelines.\n    \"\"\"\n\n    def predict(self, prediction_context: Dict, **kwargs) -&gt; Dict:\n        \"\"\"Predict the number of admissions for the given context using parametric curves.\n\n        Parameters\n        ----------\n        prediction_context : dict\n            A dictionary defining the context for which predictions are to be made.\n            It should specify either a general context or one based on the applied filters.\n        **kwargs\n            Additional keyword arguments for parametric curve configuration:\n\n            x1 : float\n                The x-coordinate of the first transition point on the aspirational curve,\n                where the growth phase ends and the decay phase begins.\n            y1 : float\n                The y-coordinate of the first transition point (x1), representing the target\n                proportion of patients admitted by time x1.\n            x2 : float\n                The x-coordinate of the second transition point on the curve, beyond which\n                all but a few patients are expected to be admitted.\n            y2 : float\n                The y-coordinate of the second transition point (x2), representing the target\n                proportion of patients admitted by time x2.\n\n        Returns\n        -------\n        dict\n            A dictionary with predictions for each specified context.\n\n        Raises\n        ------\n        ValueError\n            If filter key is not recognized or prediction_time is not provided.\n        KeyError\n            If required keys are missing from the prediction context.\n        \"\"\"\n        # Extract required parameters from kwargs\n        x1 = kwargs.get(\"x1\")\n        y1 = kwargs.get(\"y1\")\n        x2 = kwargs.get(\"x2\")\n        y2 = kwargs.get(\"y2\")\n\n        # Validate that required parameters are provided\n        if x1 is None or y1 is None or x2 is None or y2 is None:\n            raise ValueError(\n                \"x1, y1, x2, and y2 parameters are required for parametric prediction\"\n            )\n\n        predictions = {}\n\n        # Calculate Ntimes\n        if isinstance(self.prediction_window, timedelta) and isinstance(\n            self.yta_time_interval, timedelta\n        ):\n            NTimes = int(self.prediction_window / self.yta_time_interval)\n        elif isinstance(self.prediction_window, timedelta):\n            NTimes = int(\n                self.prediction_window.total_seconds() / 60 / self.yta_time_interval\n            )\n        elif isinstance(self.yta_time_interval, timedelta):\n            NTimes = int(\n                self.prediction_window / (self.yta_time_interval.total_seconds() / 60)\n            )\n        else:\n            NTimes = int(self.prediction_window / self.yta_time_interval)\n\n        # Convert to hours only for numpy operations (which require numeric types)\n        prediction_window_hours = (\n            self.prediction_window.total_seconds() / 3600\n            if isinstance(self.prediction_window, timedelta)\n            else self.prediction_window / 60\n        )\n        yta_time_interval_hours = (\n            self.yta_time_interval.total_seconds() / 3600\n            if isinstance(self.yta_time_interval, timedelta)\n            else self.yta_time_interval / 60\n        )\n\n        # Calculate theta, probability of admission in prediction window\n        # for each time interval, calculate time remaining before end of window\n        time_remaining_before_end_of_window = prediction_window_hours - np.arange(\n            0, prediction_window_hours, yta_time_interval_hours\n        )\n\n        theta = get_y_from_aspirational_curve(\n            time_remaining_before_end_of_window, x1, y1, x2, y2\n        )\n\n        for filter_key, filter_values in prediction_context.items():\n            try:\n                if filter_key not in self.weights:\n                    raise ValueError(\n                        f\"Filter key '{filter_key}' is not recognized in the model weights.\"\n                    )\n\n                prediction_time = filter_values.get(\"prediction_time\")\n                if prediction_time is None:\n                    raise ValueError(\n                        f\"No 'prediction_time' provided for filter '{filter_key}'.\"\n                    )\n\n                if prediction_time not in self.prediction_times:\n                    prediction_time = find_nearest_previous_prediction_time(\n                        prediction_time, self.prediction_times\n                    )\n\n                arrival_rates = self.weights[filter_key][prediction_time].get(\n                    \"arrival_rates\"\n                )\n                if arrival_rates is None:\n                    raise ValueError(\n                        f\"No arrival_rates found for the time of day '{prediction_time}' under filter '{filter_key}'.\"\n                    )\n\n                predictions[filter_key] = poisson_binom_generating_function(\n                    NTimes, arrival_rates, theta, self.epsilon\n                )\n\n            except KeyError as e:\n                raise KeyError(f\"Key error occurred: {e!s}\")\n\n        return predictions\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.ParametricIncomingAdmissionPredictor.predict","title":"<code>predict(prediction_context, **kwargs)</code>","text":"<p>Predict the number of admissions for the given context using parametric curves.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_context</code> <code>dict</code> <p>A dictionary defining the context for which predictions are to be made. It should specify either a general context or one based on the applied filters.</p> required <code>**kwargs</code> <p>Additional keyword arguments for parametric curve configuration:</p> <p>x1 : float     The x-coordinate of the first transition point on the aspirational curve,     where the growth phase ends and the decay phase begins. y1 : float     The y-coordinate of the first transition point (x1), representing the target     proportion of patients admitted by time x1. x2 : float     The x-coordinate of the second transition point on the curve, beyond which     all but a few patients are expected to be admitted. y2 : float     The y-coordinate of the second transition point (x2), representing the target     proportion of patients admitted by time x2.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with predictions for each specified context.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If filter key is not recognized or prediction_time is not provided.</p> <code>KeyError</code> <p>If required keys are missing from the prediction context.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def predict(self, prediction_context: Dict, **kwargs) -&gt; Dict:\n    \"\"\"Predict the number of admissions for the given context using parametric curves.\n\n    Parameters\n    ----------\n    prediction_context : dict\n        A dictionary defining the context for which predictions are to be made.\n        It should specify either a general context or one based on the applied filters.\n    **kwargs\n        Additional keyword arguments for parametric curve configuration:\n\n        x1 : float\n            The x-coordinate of the first transition point on the aspirational curve,\n            where the growth phase ends and the decay phase begins.\n        y1 : float\n            The y-coordinate of the first transition point (x1), representing the target\n            proportion of patients admitted by time x1.\n        x2 : float\n            The x-coordinate of the second transition point on the curve, beyond which\n            all but a few patients are expected to be admitted.\n        y2 : float\n            The y-coordinate of the second transition point (x2), representing the target\n            proportion of patients admitted by time x2.\n\n    Returns\n    -------\n    dict\n        A dictionary with predictions for each specified context.\n\n    Raises\n    ------\n    ValueError\n        If filter key is not recognized or prediction_time is not provided.\n    KeyError\n        If required keys are missing from the prediction context.\n    \"\"\"\n    # Extract required parameters from kwargs\n    x1 = kwargs.get(\"x1\")\n    y1 = kwargs.get(\"y1\")\n    x2 = kwargs.get(\"x2\")\n    y2 = kwargs.get(\"y2\")\n\n    # Validate that required parameters are provided\n    if x1 is None or y1 is None or x2 is None or y2 is None:\n        raise ValueError(\n            \"x1, y1, x2, and y2 parameters are required for parametric prediction\"\n        )\n\n    predictions = {}\n\n    # Calculate Ntimes\n    if isinstance(self.prediction_window, timedelta) and isinstance(\n        self.yta_time_interval, timedelta\n    ):\n        NTimes = int(self.prediction_window / self.yta_time_interval)\n    elif isinstance(self.prediction_window, timedelta):\n        NTimes = int(\n            self.prediction_window.total_seconds() / 60 / self.yta_time_interval\n        )\n    elif isinstance(self.yta_time_interval, timedelta):\n        NTimes = int(\n            self.prediction_window / (self.yta_time_interval.total_seconds() / 60)\n        )\n    else:\n        NTimes = int(self.prediction_window / self.yta_time_interval)\n\n    # Convert to hours only for numpy operations (which require numeric types)\n    prediction_window_hours = (\n        self.prediction_window.total_seconds() / 3600\n        if isinstance(self.prediction_window, timedelta)\n        else self.prediction_window / 60\n    )\n    yta_time_interval_hours = (\n        self.yta_time_interval.total_seconds() / 3600\n        if isinstance(self.yta_time_interval, timedelta)\n        else self.yta_time_interval / 60\n    )\n\n    # Calculate theta, probability of admission in prediction window\n    # for each time interval, calculate time remaining before end of window\n    time_remaining_before_end_of_window = prediction_window_hours - np.arange(\n        0, prediction_window_hours, yta_time_interval_hours\n    )\n\n    theta = get_y_from_aspirational_curve(\n        time_remaining_before_end_of_window, x1, y1, x2, y2\n    )\n\n    for filter_key, filter_values in prediction_context.items():\n        try:\n            if filter_key not in self.weights:\n                raise ValueError(\n                    f\"Filter key '{filter_key}' is not recognized in the model weights.\"\n                )\n\n            prediction_time = filter_values.get(\"prediction_time\")\n            if prediction_time is None:\n                raise ValueError(\n                    f\"No 'prediction_time' provided for filter '{filter_key}'.\"\n                )\n\n            if prediction_time not in self.prediction_times:\n                prediction_time = find_nearest_previous_prediction_time(\n                    prediction_time, self.prediction_times\n                )\n\n            arrival_rates = self.weights[filter_key][prediction_time].get(\n                \"arrival_rates\"\n            )\n            if arrival_rates is None:\n                raise ValueError(\n                    f\"No arrival_rates found for the time of day '{prediction_time}' under filter '{filter_key}'.\"\n                )\n\n            predictions[filter_key] = poisson_binom_generating_function(\n                NTimes, arrival_rates, theta, self.epsilon\n            )\n\n        except KeyError as e:\n            raise KeyError(f\"Key error occurred: {e!s}\")\n\n    return predictions\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.aggregate_probabilities","title":"<code>aggregate_probabilities(lam, kmax, theta, time_index)</code>","text":"<p>Aggregate probabilities for a range of values using the weighted Poisson-Binomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>lam</code> <code>ndarray</code> <p>An array of lambda values for each time interval.</p> required <code>kmax</code> <code>int</code> <p>The maximum number of events to consider.</p> required <code>theta</code> <code>ndarray</code> <p>An array of theta values for each time interval.</p> required <code>time_index</code> <code>int</code> <p>The current time index for which to calculate probabilities.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Aggregated probabilities for the given time index.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If kmax &lt; 0, time_index &lt; 0, or array lengths are invalid.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def aggregate_probabilities(lam, kmax, theta, time_index):\n    \"\"\"Aggregate probabilities for a range of values using the weighted Poisson-Binomial distribution.\n\n    Parameters\n    ----------\n    lam : numpy.ndarray\n        An array of lambda values for each time interval.\n    kmax : int\n        The maximum number of events to consider.\n    theta : numpy.ndarray\n        An array of theta values for each time interval.\n    time_index : int\n        The current time index for which to calculate probabilities.\n\n    Returns\n    -------\n    numpy.ndarray\n        Aggregated probabilities for the given time index.\n\n    Raises\n    ------\n    ValueError\n        If kmax &lt; 0, time_index &lt; 0, or array lengths are invalid.\n    \"\"\"\n    if kmax &lt; 0 or time_index &lt; 0 or len(lam) &lt;= time_index or len(theta) &lt;= time_index:\n        raise ValueError(\"Invalid kmax, time_index, or array lengths.\")\n\n    probabilities_matrix = np.zeros((kmax + 1, kmax + 1))\n    for i in range(kmax + 1):\n        probabilities_matrix[: i + 1, i] = weighted_poisson_binomial(\n            i, lam[time_index], theta[time_index]\n        )\n    return probabilities_matrix.sum(axis=1)\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.convolute_distributions","title":"<code>convolute_distributions(dist_a, dist_b)</code>","text":"<p>Convolutes two probability distributions represented as dataframes.</p> <p>Parameters:</p> Name Type Description Default <code>dist_a</code> <code>DataFrame</code> <p>The first distribution with columns ['sum', 'prob'].</p> required <code>dist_b</code> <code>DataFrame</code> <p>The second distribution with columns ['sum', 'prob'].</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The convoluted distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If DataFrames do not contain required 'sum' and 'prob' columns.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def convolute_distributions(dist_a, dist_b):\n    \"\"\"Convolutes two probability distributions represented as dataframes.\n\n    Parameters\n    ----------\n    dist_a : pd.DataFrame\n        The first distribution with columns ['sum', 'prob'].\n    dist_b : pd.DataFrame\n        The second distribution with columns ['sum', 'prob'].\n\n    Returns\n    -------\n    pd.DataFrame\n        The convoluted distribution.\n\n    Raises\n    ------\n    ValueError\n        If DataFrames do not contain required 'sum' and 'prob' columns.\n    \"\"\"\n    if not {\"sum\", \"prob\"}.issubset(dist_a.columns) or not {\n        \"sum\",\n        \"prob\",\n    }.issubset(dist_b.columns):\n        raise ValueError(\"DataFrames must contain 'sum' and 'prob' columns.\")\n\n    sums = [x + y for x in dist_a[\"sum\"] for y in dist_b[\"sum\"]]\n    probs = [x * y for x in dist_a[\"prob\"] for y in dist_b[\"prob\"]]\n    result = pd.DataFrame(zip(sums, probs), columns=[\"sum\", \"prob\"])\n    return result.groupby(\"sum\")[\"prob\"].sum().reset_index()\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.find_nearest_previous_prediction_time","title":"<code>find_nearest_previous_prediction_time(requested_time, prediction_times)</code>","text":"<p>Find the nearest previous time of day in prediction_times relative to requested time.</p> <p>Parameters:</p> Name Type Description Default <code>requested_time</code> <code>tuple</code> <p>The requested time as (hour, minute).</p> required <code>prediction_times</code> <code>list</code> <p>List of available prediction times.</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>The closest previous time of day from prediction_times.</p> Notes <p>If the requested time is earlier than all times in prediction_times, returns the latest time in prediction_times.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def find_nearest_previous_prediction_time(requested_time, prediction_times):\n    \"\"\"Find the nearest previous time of day in prediction_times relative to requested time.\n\n    Parameters\n    ----------\n    requested_time : tuple\n        The requested time as (hour, minute).\n    prediction_times : list\n        List of available prediction times.\n\n    Returns\n    -------\n    tuple\n        The closest previous time of day from prediction_times.\n\n    Notes\n    -----\n    If the requested time is earlier than all times in prediction_times,\n    returns the latest time in prediction_times.\n    \"\"\"\n    if requested_time in prediction_times:\n        return requested_time\n\n    original_prediction_time = requested_time\n    requested_datetime = datetime.strptime(\n        f\"{requested_time[0]:02d}:{requested_time[1]:02d}\", \"%H:%M\"\n    )\n    closest_prediction_time = max(\n        prediction_times,\n        key=lambda prediction_time_time: datetime.strptime(\n            f\"{prediction_time_time[0]:02d}:{prediction_time_time[1]:02d}\",\n            \"%H:%M\",\n        ),\n    )\n    min_diff = float(\"inf\")\n\n    for prediction_time_time in prediction_times:\n        prediction_time_datetime = datetime.strptime(\n            f\"{prediction_time_time[0]:02d}:{prediction_time_time[1]:02d}\",\n            \"%H:%M\",\n        )\n        diff = (requested_datetime - prediction_time_datetime).total_seconds()\n\n        # If the difference is negative, it means the prediction_time_time is ahead of the requested_time,\n        # hence we calculate the difference by considering a day's wrap around.\n        if diff &lt; 0:\n            diff += 24 * 60 * 60  # Add 24 hours in seconds\n\n        if 0 &lt;= diff &lt; min_diff:\n            closest_prediction_time = prediction_time_time\n            min_diff = diff\n\n    warnings.warn(\n        f\"Time of day requested of {original_prediction_time} was not in model training. \"\n        f\"Reverting to predictions for {closest_prediction_time}.\"\n    )\n\n    return closest_prediction_time\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.poisson_binom_generating_function","title":"<code>poisson_binom_generating_function(NTimes, arrival_rates, theta, epsilon)</code>","text":"<p>Generate a distribution based on the aggregate of Poisson and Binomial distributions.</p> <p>Parameters:</p> Name Type Description Default <code>NTimes</code> <code>int</code> <p>The number of time intervals.</p> required <code>arrival_rates</code> <code>ndarray</code> <p>An array of lambda values for each time interval.</p> required <code>theta</code> <code>ndarray</code> <p>An array of theta values for each time interval.</p> required <code>epsilon</code> <code>float</code> <p>The desired error threshold.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The generated distribution.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If NTimes &lt;= 0 or epsilon is not between 0 and 1.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def poisson_binom_generating_function(NTimes, arrival_rates, theta, epsilon):\n    \"\"\"Generate a distribution based on the aggregate of Poisson and Binomial distributions.\n\n    Parameters\n    ----------\n    NTimes : int\n        The number of time intervals.\n    arrival_rates : numpy.ndarray\n        An array of lambda values for each time interval.\n    theta : numpy.ndarray\n        An array of theta values for each time interval.\n    epsilon : float\n        The desired error threshold.\n\n    Returns\n    -------\n    pd.DataFrame\n        The generated distribution.\n\n    Raises\n    ------\n    ValueError\n        If NTimes &lt;= 0 or epsilon is not between 0 and 1.\n    \"\"\"\n\n    if NTimes &lt;= 0 or epsilon &lt;= 0 or epsilon &gt;= 1:\n        raise ValueError(\"Ensure NTimes &gt; 0 and 0 &lt; epsilon &lt; 1.\")\n\n    maxlam = max(arrival_rates)\n    kmax = int(poisson.ppf(1 - epsilon, maxlam))\n    distribution = np.zeros((kmax + 1, NTimes))\n\n    for j in range(NTimes):\n        distribution[:, j] = aggregate_probabilities(arrival_rates, kmax, theta, j)\n\n    df_list = [\n        pd.DataFrame({\"sum\": range(kmax + 1), \"prob\": distribution[:, j]})\n        for j in range(NTimes)\n    ]\n    total_distribution = df_list[0]\n\n    for df in df_list[1:]:\n        total_distribution = convolute_distributions(total_distribution, df)\n\n    total_distribution = total_distribution.rename(\n        columns={\"prob\": \"agg_proba\"}\n    ).set_index(\"sum\")\n\n    return total_distribution\n</code></pre>"},{"location":"api/#patientflow.predictors.incoming_admission_predictors.weighted_poisson_binomial","title":"<code>weighted_poisson_binomial(i, lam, theta)</code>","text":"<p>Calculate weighted probabilities using Poisson and Binomial distributions.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>int</code> <p>The upper bound of the range for the binomial distribution.</p> required <code>lam</code> <code>float</code> <p>The lambda parameter for the Poisson distribution.</p> required <code>theta</code> <code>float</code> <p>The probability of success for the binomial distribution.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of weighted probabilities.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If i &lt; 0, lam &lt; 0, or theta is not between 0 and 1.</p> Source code in <code>src/patientflow/predictors/incoming_admission_predictors.py</code> <pre><code>def weighted_poisson_binomial(i, lam, theta):\n    \"\"\"Calculate weighted probabilities using Poisson and Binomial distributions.\n\n    Parameters\n    ----------\n    i : int\n        The upper bound of the range for the binomial distribution.\n    lam : float\n        The lambda parameter for the Poisson distribution.\n    theta : float\n        The probability of success for the binomial distribution.\n\n    Returns\n    -------\n    numpy.ndarray\n        An array of weighted probabilities.\n\n    Raises\n    ------\n    ValueError\n        If i &lt; 0, lam &lt; 0, or theta is not between 0 and 1.\n    \"\"\"\n    if i &lt; 0 or lam &lt; 0 or not 0 &lt;= theta &lt;= 1:\n        raise ValueError(\"Ensure i &gt;= 0, lam &gt;= 0, and 0 &lt;= theta &lt;= 1.\")\n\n    arr_seq = np.arange(i + 1)\n    probabilities = binom.pmf(arr_seq, i, theta)\n    return poisson.pmf(i, lam) * probabilities\n</code></pre>"},{"location":"api/#patientflow.predictors.sequence_to_outcome_predictor","title":"<code>sequence_to_outcome_predictor</code>","text":"<p>This module implements a <code>SequenceToOutcomePredictor</code> class that models and predicts the probability distribution of sequences in categorical data. The class builds a model based on training data, where input sequences are mapped to specific outcome categories. It provides methods to fit the model, compute sequence-based probabilities, and make predictions on an unseen datatset of input sequences.</p> <p>Classes:</p> Name Description <code>SequenceToOutcomePredictor : sklearn.base.BaseEstimator, sklearn.base.TransformerMixin</code> <p>A model that predicts the probability of ending in different outcome categories based on input sequences. Note: All sequence inputs are expected to be tuples. Lists will be automatically converted to tuples, and None values will be converted to empty tuples.</p>"},{"location":"api/#patientflow.predictors.sequence_to_outcome_predictor.SequenceToOutcomePredictor","title":"<code>SequenceToOutcomePredictor</code>","text":"<p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>A class to model sequence-based predictions for categorical data using input and grouping sequences. This class implements both the <code>fit</code> and <code>predict</code> methods from the parent sklearn classes.</p> <p>Parameters:</p> Name Type Description Default <code>input_var</code> <code>str</code> <p>Name of the column representing the input sequence in the DataFrame.</p> required <code>grouping_var</code> <code>str</code> <p>Name of the column representing the grouping sequence in the DataFrame.</p> required <code>outcome_var</code> <code>str</code> <p>Name of the column representing the outcome category in the DataFrame.</p> required <code>apply_special_category_filtering</code> <code>bool</code> <p>Whether to filter out special categories of patients before fitting the model.</p> <code>True</code> <code>admit_col</code> <code>str</code> <p>Name of the column indicating whether a patient was admitted.</p> <code>'is_admitted'</code> <p>Attributes:</p> Name Type Description <code>weights</code> <code>dict</code> <p>A dictionary storing the probabilities of different input sequences leading to specific outcome categories.</p> <code>input_to_grouping_probs</code> <code>DataFrame</code> <p>A DataFrame that stores the computed probabilities of input sequences being associated with different grouping sequences.</p> <code>special_params</code> <code>(dict, optional)</code> <p>The special category parameters used for filtering, only populated if apply_special_category_filtering=True.</p> <code>metrics</code> <code>dict</code> <p>A dictionary to store metrics related to the training process.</p> Source code in <code>src/patientflow/predictors/sequence_to_outcome_predictor.py</code> <pre><code>class SequenceToOutcomePredictor(BaseEstimator, TransformerMixin):\n    \"\"\"\n    A class to model sequence-based predictions for categorical data using input and grouping sequences.\n    This class implements both the `fit` and `predict` methods from the parent sklearn classes.\n\n    Parameters\n    ----------\n    input_var : str\n        Name of the column representing the input sequence in the DataFrame.\n    grouping_var : str\n        Name of the column representing the grouping sequence in the DataFrame.\n    outcome_var : str\n        Name of the column representing the outcome category in the DataFrame.\n    apply_special_category_filtering : bool, default=True\n        Whether to filter out special categories of patients before fitting the model.\n    admit_col : str, default='is_admitted'\n        Name of the column indicating whether a patient was admitted.\n\n    Attributes\n    ----------\n    weights : dict\n        A dictionary storing the probabilities of different input sequences leading to specific outcome categories.\n    input_to_grouping_probs : pd.DataFrame\n        A DataFrame that stores the computed probabilities of input sequences being associated with different grouping sequences.\n    special_params : dict, optional\n        The special category parameters used for filtering, only populated if apply_special_category_filtering=True.\n    metrics : dict\n        A dictionary to store metrics related to the training process.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_var,\n        grouping_var,\n        outcome_var,\n        apply_special_category_filtering=True,\n        admit_col=\"is_admitted\",\n    ):\n        self.input_var = input_var\n        self.grouping_var = grouping_var\n        self.outcome_var = outcome_var\n        self.apply_special_category_filtering = apply_special_category_filtering\n        self.admit_col = admit_col\n        self.weights = None\n        self.special_params = None\n        self.metrics = {}\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the estimator.\"\"\"\n        class_name = self.__class__.__name__\n        return (\n            f\"{class_name}(\\n\"\n            f\"    input_var='{self.input_var}',\\n\"\n            f\"    grouping_var='{self.grouping_var}',\\n\"\n            f\"    outcome_var='{self.outcome_var}',\\n\"\n            f\"    apply_special_category_filtering={self.apply_special_category_filtering},\\n\"\n            f\"    admit_col='{self.admit_col}'\\n\"\n            f\")\"\n        )\n\n    def _ensure_tuple(self, sequence):\n        \"\"\"\n        Convert a sequence to tuple if it's not already a tuple.\n        Handles string cleaning to avoid double-quoting issues.\n\n        Parameters\n        ----------\n        sequence : tuple, list, or None\n            The sequence to convert\n\n        Returns\n        -------\n        tuple\n            The input sequence as a tuple, or an empty tuple if input was None\n        \"\"\"\n        if sequence is None:\n            return ()\n        if isinstance(sequence, (list, pd.Series)):\n            # Clean any quoted strings in the sequence\n            cleaned_sequence = [\n                ast.literal_eval(item)\n                if isinstance(item, str) and item.startswith(\"'\") and item.endswith(\"'\")\n                else item\n                for item in sequence\n            ]\n            return tuple(cleaned_sequence) if cleaned_sequence else ()\n        if isinstance(sequence, tuple):\n            # Clean any quoted strings in the tuple\n            return tuple(\n                ast.literal_eval(item)\n                if isinstance(item, str) and item.startswith(\"'\") and item.endswith(\"'\")\n                else item\n                for item in sequence\n            )\n        return sequence\n\n    def _preprocess_data(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Preprocesses the input data before fitting the model.\n\n        Steps include:\n        1. Selecting only admitted patients with a non-null specialty\n        2. Optionally filtering out special categories\n        3. Converting sequence columns to tuple format if they aren't already\n\n        Parameters\n        ----------\n        X : pd.DataFrame\n            DataFrame containing patient data.\n\n        Returns\n        -------\n        pd.DataFrame\n            Preprocessed DataFrame ready for model fitting.\n        \"\"\"\n        # Make a copy to avoid modifying the original\n        df = X.copy()\n\n        # Step 1: Select only admitted patients with a non-null specialty\n        if self.admit_col in df.columns:\n            df = df[df[self.admit_col] &amp; ~df[self.outcome_var].isnull()]\n\n        # Step 2: Optionally apply filtering for special categories\n        if self.apply_special_category_filtering:\n            # Get configuration for categorizing patients based on columns\n            self.special_params = create_special_category_objects(df.columns)\n\n            # Extract function that identifies non-special category patients\n            opposite_special_category_func = self.special_params[\"special_func_map\"][\n                \"default\"\n            ]\n\n            # Determine which category is the special category\n            special_category_key = next(\n                key\n                for key, value in self.special_params[\"special_category_dict\"].items()\n                if value == 1.0\n            )\n\n            # Filter out special category patients\n            df = df[\n                df.apply(opposite_special_category_func, axis=1)\n                &amp; (df[self.outcome_var] != special_category_key)\n            ]\n\n        # Step 3: Convert sequence columns to tuple format\n        if self.input_var in df.columns:\n            df[self.input_var] = df[self.input_var].apply(self._ensure_tuple)\n\n        if self.grouping_var in df.columns:\n            df[self.grouping_var] = df[self.grouping_var].apply(self._ensure_tuple)\n\n        return df\n\n    def fit(self, X: pd.DataFrame) -&gt; \"SequenceToOutcomePredictor\":\n        \"\"\"\n        Fits the predictor based on training data by computing the proportion of each input variable sequence\n        ending in specific outcome variable categories.\n\n        Automatically preprocesses the data before fitting.\n\n        Parameters\n        ----------\n        X : pd.DataFrame\n            A pandas DataFrame containing at least the columns specified by `input_var`, `grouping_var`, and `outcome_var`.\n\n        Returns\n        -------\n        self : SequenceToOutcomePredictor\n            The fitted SequenceToOutcomePredictor model with calculated probabilities for each sequence.\n        \"\"\"\n        # Store metrics about the training data\n        self.metrics[\"train_dttm\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n        self.metrics[\"train_set_no\"] = len(X)\n        if not X.empty:\n            self.metrics[\"start_date\"] = X[\"snapshot_date\"].min()\n            self.metrics[\"end_date\"] = X[\"snapshot_date\"].max()\n\n        # Preprocess the data\n        X = self._preprocess_data(X)\n\n        # derive the names of the observed outcome variables from the data\n        prop_keys = X[self.outcome_var].unique()\n\n        # For each sequence count the number of observed categories\n        X_grouped = (\n            X.groupby(self.grouping_var)[self.outcome_var]\n            .value_counts()\n            .unstack(fill_value=0)\n        )\n\n        # Calculate the total number of times each grouping sequence occurred\n        row_totals = X_grouped.sum(axis=1)\n\n        # Calculate for each grouping sequence, the proportion of ending with each observed specialty\n        proportions = X_grouped.div(row_totals, axis=0)\n\n        # Calculate the probability of each grouping sequence occurring in the original data\n        proportions[\"probability_of_grouping_sequence\"] = row_totals / row_totals.sum()\n\n        # Reweight probabilities of ending with each observed specialty\n        # by the likelihood of each grouping sequence occurring\n        for col in proportions.columns[\n            :-1\n        ]:  # Avoid the last column which is the 'probability_of_grouping_sequence'\n            proportions[col] *= proportions[\"probability_of_grouping_sequence\"]\n\n        # Convert final sequence to a string in order to conduct string searches on it\n        proportions[\"grouping_sequence_to_string\"] = proportions.index.map(\n            lambda x: \"-\".join(map(str, x))\n        )\n\n        # Row-wise function to return, for each input sequence,\n        # the proportion that end up in each final sequence and thereby\n        # the probability of it ending in any observed category\n        proportions[\"prob_input_var_ends_in_observed_specialty\"] = proportions[\n            \"grouping_sequence_to_string\"\n        ].apply(lambda x: self._string_match_input_var(x, proportions, prop_keys))\n\n        # Convert the prob_input_var_ends_in_observed_specialty column to a dictionary\n        result_dict = proportions[\"prob_input_var_ends_in_observed_specialty\"].to_dict()\n\n        # Clean the key to remove excess strint quotes\n        def clean_tuple_key(key):\n            if isinstance(key, tuple):\n                return tuple(\n                    ast.literal_eval(item)\n                    if item.startswith(\"'\") and item.endswith(\"'\")\n                    else item\n                    for item in key\n                )\n            return key\n\n        cleaned_dict = {clean_tuple_key(k): v for k, v in result_dict.items()}\n\n        # save prob_input_var_ends_in_observed_specialty as weights within the model\n        self.weights = cleaned_dict\n\n        # save the input to grouping probabilities for use as a reference\n        self.input_to_grouping_probs = self._probability_of_input_to_grouping_sequence(\n            X\n        )\n\n        return self\n\n    def _string_match_input_var(self, input_var_string, proportions, prop_keys):\n        \"\"\"\n        Matches a given input sequence string with grouped sequences (expressed as strings) in the dataset and aggregates\n        their probabilities for each outcome category. This function filters the data to\n        match only those rows where the *beginning* of the grouped sequence string\n        matches the given input sequence string, allowing for partial matches.\n        For instance, the sequence 'medical' will match 'medical, elderly' and 'medical, surgical'\n        as well as 'medical' on its own. It computes the total probabilities of any input sequence ending\n        in each outcome category, and normalizes these totals if possible.\n\n        Parameters\n        ----------\n        input_var_string : str\n            The sequence of inputs represented as a string, used to match against sequences in the proportions DataFrame.\n        proportions : pd.DataFrame\n            DataFrame containing proportions data with an additional column 'grouping_sequence_to_string'\n            which includes string representations of sequences.\n        prop_keys : np.array\n            Array of unique outcomes to consider in calculations.\n\n        Returns\n        -------\n        dict\n            A dictionary where keys are outcome names and values are the aggregated and normalized probabilities\n            of an input sequence ending in those outcomes.\n\n        \"\"\"\n        # Filter rows where the grouped sequence string starts with the input sequence string\n        props = proportions[\n            proportions[\"grouping_sequence_to_string\"].str.match(\"^\" + input_var_string)\n        ][prop_keys].sum()\n\n        # Sum of all probabilities to normalize them\n        props_total = props.sum()\n\n        # Handle cases where the total probability is zero to avoid division by zero\n        if props_total &gt; 0:\n            normalized_props = props / props_total\n        else:\n            normalized_props = (\n                props * 0\n            )  # Returns zero probabilities if no matches found\n\n        return dict(zip(prop_keys, normalized_props))\n\n    def _probability_of_input_to_grouping_sequence(self, X):\n        \"\"\"\n        Computes the probabilities of different input sequences leading to specific grouping sequences.\n\n        Parameters\n        ----------\n        X : pd.DataFrame\n            A pandas DataFrame containing at least the columns specified by `input_var` and `grouping_var`.\n\n        Returns\n        -------\n        pd.DataFrame\n            A DataFrame containing the probabilities of input sequences leading to grouping sequences.\n        \"\"\"\n        # For each input sequence count the number of grouping sequences\n        X_grouped = (\n            X.groupby(self.input_var)[self.grouping_var]\n            .value_counts()\n            .unstack(fill_value=0)\n        )\n\n        # # Calculate the total number of times each input sequence occurred\n        row_totals = X_grouped.sum(axis=1)\n\n        # # Calculate for each grouping sequence, the proportion of ending with each grouping sequence\n        proportions = X_grouped.div(row_totals, axis=0)\n\n        # # Calculate the probability of each input sequence occurring in the original data\n        proportions[\"probability_of_grouping_sequence\"] = row_totals / row_totals.sum()\n\n        return proportions\n\n    def predict(self, input_sequence: tuple[str, ...]) -&gt; Dict[str, float]:\n        \"\"\"\n        Predicts the probabilities of ending in various outcome categories for a given input sequence.\n\n        Parameters\n        ----------\n        input_sequence : tuple[str, ...]\n            A tuple containing the categories that have been observed for an entity in the order they\n            have been encountered. An empty tuple represents an entity with no observed categories.\n\n        Returns\n        -------\n        dict\n            A dictionary of categories and the probabilities that the input sequence will end in them.\n        \"\"\"\n        input_sequence = self._ensure_tuple(input_sequence)\n\n        if input_sequence is None or pd.isna(input_sequence):\n            return self.weights.get(tuple(), {})\n\n        # Return a direct lookup of probabilities if possible.\n        if input_sequence in self.weights:\n            return self.weights[input_sequence]\n\n        # Otherwise, if the sequence has multiple elements, work back looking for a match\n        while len(input_sequence) &gt; 1:\n            input_sequence_list = list(input_sequence)\n            input_sequence = tuple(input_sequence_list[:-1])  # remove last element\n\n            if input_sequence in self.weights:\n                return self.weights[input_sequence]\n\n        # If no relevant data is found:\n        return self.weights.get(tuple(), {})\n</code></pre>"},{"location":"api/#patientflow.predictors.sequence_to_outcome_predictor.SequenceToOutcomePredictor.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the estimator.</p> Source code in <code>src/patientflow/predictors/sequence_to_outcome_predictor.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a string representation of the estimator.\"\"\"\n    class_name = self.__class__.__name__\n    return (\n        f\"{class_name}(\\n\"\n        f\"    input_var='{self.input_var}',\\n\"\n        f\"    grouping_var='{self.grouping_var}',\\n\"\n        f\"    outcome_var='{self.outcome_var}',\\n\"\n        f\"    apply_special_category_filtering={self.apply_special_category_filtering},\\n\"\n        f\"    admit_col='{self.admit_col}'\\n\"\n        f\")\"\n    )\n</code></pre>"},{"location":"api/#patientflow.predictors.sequence_to_outcome_predictor.SequenceToOutcomePredictor.fit","title":"<code>fit(X)</code>","text":"<p>Fits the predictor based on training data by computing the proportion of each input variable sequence ending in specific outcome variable categories.</p> <p>Automatically preprocesses the data before fitting.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame</code> <p>A pandas DataFrame containing at least the columns specified by <code>input_var</code>, <code>grouping_var</code>, and <code>outcome_var</code>.</p> required <p>Returns:</p> Name Type Description <code>self</code> <code>SequenceToOutcomePredictor</code> <p>The fitted SequenceToOutcomePredictor model with calculated probabilities for each sequence.</p> Source code in <code>src/patientflow/predictors/sequence_to_outcome_predictor.py</code> <pre><code>def fit(self, X: pd.DataFrame) -&gt; \"SequenceToOutcomePredictor\":\n    \"\"\"\n    Fits the predictor based on training data by computing the proportion of each input variable sequence\n    ending in specific outcome variable categories.\n\n    Automatically preprocesses the data before fitting.\n\n    Parameters\n    ----------\n    X : pd.DataFrame\n        A pandas DataFrame containing at least the columns specified by `input_var`, `grouping_var`, and `outcome_var`.\n\n    Returns\n    -------\n    self : SequenceToOutcomePredictor\n        The fitted SequenceToOutcomePredictor model with calculated probabilities for each sequence.\n    \"\"\"\n    # Store metrics about the training data\n    self.metrics[\"train_dttm\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n    self.metrics[\"train_set_no\"] = len(X)\n    if not X.empty:\n        self.metrics[\"start_date\"] = X[\"snapshot_date\"].min()\n        self.metrics[\"end_date\"] = X[\"snapshot_date\"].max()\n\n    # Preprocess the data\n    X = self._preprocess_data(X)\n\n    # derive the names of the observed outcome variables from the data\n    prop_keys = X[self.outcome_var].unique()\n\n    # For each sequence count the number of observed categories\n    X_grouped = (\n        X.groupby(self.grouping_var)[self.outcome_var]\n        .value_counts()\n        .unstack(fill_value=0)\n    )\n\n    # Calculate the total number of times each grouping sequence occurred\n    row_totals = X_grouped.sum(axis=1)\n\n    # Calculate for each grouping sequence, the proportion of ending with each observed specialty\n    proportions = X_grouped.div(row_totals, axis=0)\n\n    # Calculate the probability of each grouping sequence occurring in the original data\n    proportions[\"probability_of_grouping_sequence\"] = row_totals / row_totals.sum()\n\n    # Reweight probabilities of ending with each observed specialty\n    # by the likelihood of each grouping sequence occurring\n    for col in proportions.columns[\n        :-1\n    ]:  # Avoid the last column which is the 'probability_of_grouping_sequence'\n        proportions[col] *= proportions[\"probability_of_grouping_sequence\"]\n\n    # Convert final sequence to a string in order to conduct string searches on it\n    proportions[\"grouping_sequence_to_string\"] = proportions.index.map(\n        lambda x: \"-\".join(map(str, x))\n    )\n\n    # Row-wise function to return, for each input sequence,\n    # the proportion that end up in each final sequence and thereby\n    # the probability of it ending in any observed category\n    proportions[\"prob_input_var_ends_in_observed_specialty\"] = proportions[\n        \"grouping_sequence_to_string\"\n    ].apply(lambda x: self._string_match_input_var(x, proportions, prop_keys))\n\n    # Convert the prob_input_var_ends_in_observed_specialty column to a dictionary\n    result_dict = proportions[\"prob_input_var_ends_in_observed_specialty\"].to_dict()\n\n    # Clean the key to remove excess strint quotes\n    def clean_tuple_key(key):\n        if isinstance(key, tuple):\n            return tuple(\n                ast.literal_eval(item)\n                if item.startswith(\"'\") and item.endswith(\"'\")\n                else item\n                for item in key\n            )\n        return key\n\n    cleaned_dict = {clean_tuple_key(k): v for k, v in result_dict.items()}\n\n    # save prob_input_var_ends_in_observed_specialty as weights within the model\n    self.weights = cleaned_dict\n\n    # save the input to grouping probabilities for use as a reference\n    self.input_to_grouping_probs = self._probability_of_input_to_grouping_sequence(\n        X\n    )\n\n    return self\n</code></pre>"},{"location":"api/#patientflow.predictors.sequence_to_outcome_predictor.SequenceToOutcomePredictor.predict","title":"<code>predict(input_sequence)</code>","text":"<p>Predicts the probabilities of ending in various outcome categories for a given input sequence.</p> <p>Parameters:</p> Name Type Description Default <code>input_sequence</code> <code>tuple[str, ...]</code> <p>A tuple containing the categories that have been observed for an entity in the order they have been encountered. An empty tuple represents an entity with no observed categories.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of categories and the probabilities that the input sequence will end in them.</p> Source code in <code>src/patientflow/predictors/sequence_to_outcome_predictor.py</code> <pre><code>def predict(self, input_sequence: tuple[str, ...]) -&gt; Dict[str, float]:\n    \"\"\"\n    Predicts the probabilities of ending in various outcome categories for a given input sequence.\n\n    Parameters\n    ----------\n    input_sequence : tuple[str, ...]\n        A tuple containing the categories that have been observed for an entity in the order they\n        have been encountered. An empty tuple represents an entity with no observed categories.\n\n    Returns\n    -------\n    dict\n        A dictionary of categories and the probabilities that the input sequence will end in them.\n    \"\"\"\n    input_sequence = self._ensure_tuple(input_sequence)\n\n    if input_sequence is None or pd.isna(input_sequence):\n        return self.weights.get(tuple(), {})\n\n    # Return a direct lookup of probabilities if possible.\n    if input_sequence in self.weights:\n        return self.weights[input_sequence]\n\n    # Otherwise, if the sequence has multiple elements, work back looking for a match\n    while len(input_sequence) &gt; 1:\n        input_sequence_list = list(input_sequence)\n        input_sequence = tuple(input_sequence_list[:-1])  # remove last element\n\n        if input_sequence in self.weights:\n            return self.weights[input_sequence]\n\n    # If no relevant data is found:\n    return self.weights.get(tuple(), {})\n</code></pre>"},{"location":"api/#patientflow.predictors.value_to_outcome_predictor","title":"<code>value_to_outcome_predictor</code>","text":"<p>This module implements a <code>ValueToOutcomePredictor</code> class that models and predicts the probability distribution of outcomes based on a single categorical input. The class builds a model based on training data, where input values are mapped to specific outcome categories through an intermediate grouping variable. It provides methods to fit the model, compute probabilities, and make predictions on unseen data.</p> <p>Classes:</p> Name Description <code>ValueToOutcomePredictor : sklearn.base.BaseEstimator, sklearn.base.TransformerMixin</code> <p>A model that predicts the probability of ending in different outcome categories based on a single input value. Note: All inputs are expected to be strings. None values will be converted to empty strings during preprocessing.</p>"},{"location":"api/#patientflow.predictors.value_to_outcome_predictor.ValueToOutcomePredictor","title":"<code>ValueToOutcomePredictor</code>","text":"<p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>A class to model predictions for categorical data using a single input value and grouping variable. This class implements both the <code>fit</code> and <code>predict</code> methods from the parent sklearn classes.</p> <p>Parameters:</p> Name Type Description Default <code>input_var</code> <code>str</code> <p>Name of the column representing the input value in the DataFrame.</p> required <code>grouping_var</code> <code>str</code> <p>Name of the column representing the grouping value in the DataFrame.</p> required <code>outcome_var</code> <code>str</code> <p>Name of the column representing the outcome category in the DataFrame.</p> required <code>apply_special_category_filtering</code> <code>bool</code> <p>Whether to filter out special categories of patients before fitting the model.</p> <code>True</code> <code>admit_col</code> <code>str</code> <p>Name of the column indicating whether a patient was admitted.</p> <code>'is_admitted'</code> <p>Attributes:</p> Name Type Description <code>weights</code> <code>dict</code> <p>A dictionary storing the probabilities of different input values leading to specific outcome categories.</p> <code>input_to_grouping_probs</code> <code>DataFrame</code> <p>A DataFrame that stores the computed probabilities of input values being associated with different grouping values.</p> <code>special_params</code> <code>(dict, optional)</code> <p>The special category parameters used for filtering, only populated if apply_special_category_filtering=True.</p> <code>metrics</code> <code>dict</code> <p>A dictionary to store metrics related to the training process.</p> Source code in <code>src/patientflow/predictors/value_to_outcome_predictor.py</code> <pre><code>class ValueToOutcomePredictor(BaseEstimator, TransformerMixin):\n    \"\"\"\n    A class to model predictions for categorical data using a single input value and grouping variable.\n    This class implements both the `fit` and `predict` methods from the parent sklearn classes.\n\n    Parameters\n    ----------\n    input_var : str\n        Name of the column representing the input value in the DataFrame.\n    grouping_var : str\n        Name of the column representing the grouping value in the DataFrame.\n    outcome_var : str\n        Name of the column representing the outcome category in the DataFrame.\n    apply_special_category_filtering : bool, default=True\n        Whether to filter out special categories of patients before fitting the model.\n    admit_col : str, default='is_admitted'\n        Name of the column indicating whether a patient was admitted.\n\n    Attributes\n    ----------\n    weights : dict\n        A dictionary storing the probabilities of different input values leading to specific outcome categories.\n    input_to_grouping_probs : pd.DataFrame\n        A DataFrame that stores the computed probabilities of input values being associated with different grouping values.\n    special_params : dict, optional\n        The special category parameters used for filtering, only populated if apply_special_category_filtering=True.\n    metrics : dict\n        A dictionary to store metrics related to the training process.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_var,\n        grouping_var,\n        outcome_var,\n        apply_special_category_filtering=True,\n        admit_col=\"is_admitted\",\n    ):\n        self.input_var = input_var\n        self.grouping_var = grouping_var\n        self.outcome_var = outcome_var\n        self.apply_special_category_filtering = apply_special_category_filtering\n        self.admit_col = admit_col\n        self.weights = None\n        self.special_params = None\n        self.metrics = {}\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the estimator.\"\"\"\n        class_name = self.__class__.__name__\n        return (\n            f\"{class_name}(\\n\"\n            f\"    input_var='{self.input_var}',\\n\"\n            f\"    grouping_var='{self.grouping_var}',\\n\"\n            f\"    outcome_var='{self.outcome_var}',\\n\"\n            f\"    apply_special_category_filtering={self.apply_special_category_filtering},\\n\"\n            f\"    admit_col='{self.admit_col}'\\n\"\n            f\")\"\n        )\n\n    def _preprocess_data(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Preprocesses the input data before fitting the model.\n\n        Steps include:\n        1. Selecting only admitted patients with a non-null specialty\n        2. Optionally filtering out special categories\n        3. Converting input values to strings and handling nulls\n\n        Parameters\n        ----------\n        X : pd.DataFrame\n            DataFrame containing patient data.\n\n        Returns\n        -------\n        pd.DataFrame\n            Preprocessed DataFrame ready for model fitting.\n        \"\"\"\n        # Make a copy to avoid modifying the original\n        df = X.copy()\n\n        # Step 1: Select only admitted patients with a non-null specialty\n        if self.admit_col in df.columns:\n            df = df[df[self.admit_col] &amp; ~df[self.outcome_var].isnull()]\n\n        # Step 2: Optionally apply filtering for special categories\n        if self.apply_special_category_filtering:\n            # Get configuration for categorizing patients based on columns\n            self.special_params = create_special_category_objects(df.columns)\n\n            # Extract function that identifies non-special category patients\n            opposite_special_category_func = self.special_params[\"special_func_map\"][\n                \"default\"\n            ]\n\n            # Determine which category is the special category\n            special_category_key = next(\n                key\n                for key, value in self.special_params[\"special_category_dict\"].items()\n                if value == 1.0\n            )\n\n            # Filter out special category patients\n            df = df[\n                df.apply(opposite_special_category_func, axis=1)\n                &amp; (df[self.outcome_var] != special_category_key)\n            ]\n\n        # Step 3: Convert input values to strings and handle nulls\n        if self.input_var in df.columns:\n            df[self.input_var] = df[self.input_var].fillna(\"\").astype(str)\n\n        if self.grouping_var in df.columns:\n            df[self.grouping_var] = df[self.grouping_var].fillna(\"\").astype(str)\n\n        return df\n\n    def fit(self, X: pd.DataFrame) -&gt; \"ValueToOutcomePredictor\":\n        \"\"\"\n        Fits the predictor based on training data by computing the proportion of each input value\n        ending in specific outcome variable categories.\n\n        Automatically preprocesses the data before fitting. During preprocessing, any null values in the\n        input and grouping variables are converted to empty strings. These empty strings are then used\n        as keys in the model's weights dictionary.\n\n        Parameters\n        ----------\n        X : pd.DataFrame\n            A pandas DataFrame containing at least the columns specified by `input_var`, `grouping_var`, and `outcome_var`.\n\n        Returns\n        -------\n        self : ValueToOutcomePredictor\n            The fitted ValueToOutcomePredictor model with calculated probabilities for each input value.\n            The weights dictionary will contain an empty string key ('') for any null values from the input data.\n        \"\"\"\n\n        # Store metrics about the training data\n        self.metrics[\"train_dttm\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n        self.metrics[\"train_set_no\"] = len(X)\n        if not X.empty:\n            self.metrics[\"start_date\"] = X[\"snapshot_date\"].min()\n            self.metrics[\"end_date\"] = X[\"snapshot_date\"].max()\n\n        # Preprocess the data\n        X = self._preprocess_data(X)\n\n        # For each grouping value count the number of observed categories\n        X_grouped = (\n            X.groupby(self.grouping_var)[self.outcome_var]\n            .value_counts()\n            .unstack(fill_value=0)\n        )\n\n        # Calculate the total number of times each grouping value occurred\n        row_totals = X_grouped.sum(axis=1)\n\n        # Calculate for each grouping value, the proportion of ending with each observed specialty\n        proportions = X_grouped.div(row_totals, axis=0).fillna(0)\n\n        # Calculate probabilities for each input value\n        input_probs = {}\n        for input_val in X[self.input_var].unique():\n            # Get all grouping values associated with this input value\n            grouping_vals = X[X[self.input_var] == input_val][\n                self.grouping_var\n            ].unique()\n\n            # Calculate probability distribution of grouping values for this input value\n            input_to_group_probs = X[X[self.input_var] == input_val][\n                self.grouping_var\n            ].value_counts(normalize=True)\n\n            # Get the probability distribution of outcomes for all relevant grouping values\n            # This includes all rows in proportions where the grouping value appears for this input\n            group_to_outcome_probs = proportions.loc[grouping_vals]\n\n            # Ensure the rows are aligned by reindexing group_to_outcome_probs\n            aligned_group_to_outcome = group_to_outcome_probs.reindex(\n                input_to_group_probs.index\n            )\n\n            # Create outer product matrix of probabilities:\n            # - Rows represent grouping values\n            # - Columns represent outcome categories\n            # Each cell contains the joint probability of the grouping value and outcome\n            input_to_outcome_probs = pd.DataFrame(\n                input_to_group_probs.values.reshape(-1, 1)\n                * aligned_group_to_outcome.values,\n                index=input_to_group_probs.index,\n                columns=group_to_outcome_probs.columns,\n            )\n\n            # Sum across grouping values to get final probability distribution for this input value\n            input_probs[input_val] = input_to_outcome_probs.sum().to_dict()\n\n        # Clean the keys to remove excess string quotes\n        def clean_key(key):\n            if isinstance(key, str):\n                # Remove surrounding quotes if they exist\n                if key.startswith(\"'\") and key.endswith(\"'\"):\n                    return key[1:-1]\n            return key\n\n        # Note: cleaned_dict will contain an empty string key ('') for any null values from the input data\n        # This is because null values are converted to empty strings during preprocessing\n        cleaned_dict = {clean_key(k): v for k, v in input_probs.items()}\n\n        # save probabilities as weights within the model\n        self.weights = cleaned_dict\n\n        # save the input to grouping probabilities for use as a reference\n        self.input_to_grouping_probs = self._probability_of_input_to_grouping_value(X)\n\n        return self\n\n    def _probability_of_input_to_grouping_value(self, X):\n        \"\"\"\n        Computes the probabilities of different input values leading to specific grouping values.\n\n        Parameters\n        ----------\n        X : pd.DataFrame\n            A pandas DataFrame containing at least the columns specified by `input_var` and `grouping_var`.\n\n        Returns\n        -------\n        pd.DataFrame\n            A DataFrame containing the probabilities of input values leading to grouping values.\n        \"\"\"\n        # For each input value count the number of grouping values\n        X_grouped = (\n            X.groupby(self.input_var)[self.grouping_var]\n            .value_counts()\n            .unstack(fill_value=0)\n        )\n\n        # Calculate the total number of times each input value occurred\n        row_totals = X_grouped.sum(axis=1)\n\n        # Calculate for each grouping value, the proportion of ending with each grouping value\n        proportions = X_grouped.div(row_totals, axis=0)\n\n        # Calculate the probability of each input value occurring in the original data\n        proportions[\"probability_of_input_value\"] = row_totals / row_totals.sum()\n\n        return proportions\n\n    def predict(self, input_value: str) -&gt; Dict[str, float]:\n        \"\"\"\n        Predicts the probabilities of ending in various outcome categories for a given input value.\n\n        Parameters\n        ----------\n        input_value : str\n            The input value to predict outcomes for. None values will be handled appropriately.\n\n        Returns\n        -------\n        dict\n            A dictionary of categories and the probabilities that the input value will end in them.\n        \"\"\"\n        if input_value is None or pd.isna(input_value):\n            return self.weights.get(\"\", {})\n\n        # Convert input to string if it isn't already\n        input_value = str(input_value)\n\n        # Return a direct lookup of probabilities if possible\n        if input_value in self.weights:\n            return self.weights[input_value]\n\n        # If no relevant data is found, return null probabilities\n        return self.weights.get(None, {})\n</code></pre>"},{"location":"api/#patientflow.predictors.value_to_outcome_predictor.ValueToOutcomePredictor.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the estimator.</p> Source code in <code>src/patientflow/predictors/value_to_outcome_predictor.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a string representation of the estimator.\"\"\"\n    class_name = self.__class__.__name__\n    return (\n        f\"{class_name}(\\n\"\n        f\"    input_var='{self.input_var}',\\n\"\n        f\"    grouping_var='{self.grouping_var}',\\n\"\n        f\"    outcome_var='{self.outcome_var}',\\n\"\n        f\"    apply_special_category_filtering={self.apply_special_category_filtering},\\n\"\n        f\"    admit_col='{self.admit_col}'\\n\"\n        f\")\"\n    )\n</code></pre>"},{"location":"api/#patientflow.predictors.value_to_outcome_predictor.ValueToOutcomePredictor.fit","title":"<code>fit(X)</code>","text":"<p>Fits the predictor based on training data by computing the proportion of each input value ending in specific outcome variable categories.</p> <p>Automatically preprocesses the data before fitting. During preprocessing, any null values in the input and grouping variables are converted to empty strings. These empty strings are then used as keys in the model's weights dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>DataFrame</code> <p>A pandas DataFrame containing at least the columns specified by <code>input_var</code>, <code>grouping_var</code>, and <code>outcome_var</code>.</p> required <p>Returns:</p> Name Type Description <code>self</code> <code>ValueToOutcomePredictor</code> <p>The fitted ValueToOutcomePredictor model with calculated probabilities for each input value. The weights dictionary will contain an empty string key ('') for any null values from the input data.</p> Source code in <code>src/patientflow/predictors/value_to_outcome_predictor.py</code> <pre><code>def fit(self, X: pd.DataFrame) -&gt; \"ValueToOutcomePredictor\":\n    \"\"\"\n    Fits the predictor based on training data by computing the proportion of each input value\n    ending in specific outcome variable categories.\n\n    Automatically preprocesses the data before fitting. During preprocessing, any null values in the\n    input and grouping variables are converted to empty strings. These empty strings are then used\n    as keys in the model's weights dictionary.\n\n    Parameters\n    ----------\n    X : pd.DataFrame\n        A pandas DataFrame containing at least the columns specified by `input_var`, `grouping_var`, and `outcome_var`.\n\n    Returns\n    -------\n    self : ValueToOutcomePredictor\n        The fitted ValueToOutcomePredictor model with calculated probabilities for each input value.\n        The weights dictionary will contain an empty string key ('') for any null values from the input data.\n    \"\"\"\n\n    # Store metrics about the training data\n    self.metrics[\"train_dttm\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n    self.metrics[\"train_set_no\"] = len(X)\n    if not X.empty:\n        self.metrics[\"start_date\"] = X[\"snapshot_date\"].min()\n        self.metrics[\"end_date\"] = X[\"snapshot_date\"].max()\n\n    # Preprocess the data\n    X = self._preprocess_data(X)\n\n    # For each grouping value count the number of observed categories\n    X_grouped = (\n        X.groupby(self.grouping_var)[self.outcome_var]\n        .value_counts()\n        .unstack(fill_value=0)\n    )\n\n    # Calculate the total number of times each grouping value occurred\n    row_totals = X_grouped.sum(axis=1)\n\n    # Calculate for each grouping value, the proportion of ending with each observed specialty\n    proportions = X_grouped.div(row_totals, axis=0).fillna(0)\n\n    # Calculate probabilities for each input value\n    input_probs = {}\n    for input_val in X[self.input_var].unique():\n        # Get all grouping values associated with this input value\n        grouping_vals = X[X[self.input_var] == input_val][\n            self.grouping_var\n        ].unique()\n\n        # Calculate probability distribution of grouping values for this input value\n        input_to_group_probs = X[X[self.input_var] == input_val][\n            self.grouping_var\n        ].value_counts(normalize=True)\n\n        # Get the probability distribution of outcomes for all relevant grouping values\n        # This includes all rows in proportions where the grouping value appears for this input\n        group_to_outcome_probs = proportions.loc[grouping_vals]\n\n        # Ensure the rows are aligned by reindexing group_to_outcome_probs\n        aligned_group_to_outcome = group_to_outcome_probs.reindex(\n            input_to_group_probs.index\n        )\n\n        # Create outer product matrix of probabilities:\n        # - Rows represent grouping values\n        # - Columns represent outcome categories\n        # Each cell contains the joint probability of the grouping value and outcome\n        input_to_outcome_probs = pd.DataFrame(\n            input_to_group_probs.values.reshape(-1, 1)\n            * aligned_group_to_outcome.values,\n            index=input_to_group_probs.index,\n            columns=group_to_outcome_probs.columns,\n        )\n\n        # Sum across grouping values to get final probability distribution for this input value\n        input_probs[input_val] = input_to_outcome_probs.sum().to_dict()\n\n    # Clean the keys to remove excess string quotes\n    def clean_key(key):\n        if isinstance(key, str):\n            # Remove surrounding quotes if they exist\n            if key.startswith(\"'\") and key.endswith(\"'\"):\n                return key[1:-1]\n        return key\n\n    # Note: cleaned_dict will contain an empty string key ('') for any null values from the input data\n    # This is because null values are converted to empty strings during preprocessing\n    cleaned_dict = {clean_key(k): v for k, v in input_probs.items()}\n\n    # save probabilities as weights within the model\n    self.weights = cleaned_dict\n\n    # save the input to grouping probabilities for use as a reference\n    self.input_to_grouping_probs = self._probability_of_input_to_grouping_value(X)\n\n    return self\n</code></pre>"},{"location":"api/#patientflow.predictors.value_to_outcome_predictor.ValueToOutcomePredictor.predict","title":"<code>predict(input_value)</code>","text":"<p>Predicts the probabilities of ending in various outcome categories for a given input value.</p> <p>Parameters:</p> Name Type Description Default <code>input_value</code> <code>str</code> <p>The input value to predict outcomes for. None values will be handled appropriately.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of categories and the probabilities that the input value will end in them.</p> Source code in <code>src/patientflow/predictors/value_to_outcome_predictor.py</code> <pre><code>def predict(self, input_value: str) -&gt; Dict[str, float]:\n    \"\"\"\n    Predicts the probabilities of ending in various outcome categories for a given input value.\n\n    Parameters\n    ----------\n    input_value : str\n        The input value to predict outcomes for. None values will be handled appropriately.\n\n    Returns\n    -------\n    dict\n        A dictionary of categories and the probabilities that the input value will end in them.\n    \"\"\"\n    if input_value is None or pd.isna(input_value):\n        return self.weights.get(\"\", {})\n\n    # Convert input to string if it isn't already\n    input_value = str(input_value)\n\n    # Return a direct lookup of probabilities if possible\n    if input_value in self.weights:\n        return self.weights[input_value]\n\n    # If no relevant data is found, return null probabilities\n    return self.weights.get(None, {})\n</code></pre>"},{"location":"api/#patientflow.prepare","title":"<code>prepare</code>","text":"<p>Module for preparing data, loading models, and organizing snapshots for inference.</p> <p>This module provides functionality to load a trained model, prepare data for making predictions, calculate arrival rates, and organize snapshot data. It allows for selecting one snapshot per visit, filtering snapshots by prediction time, and mapping snapshot dates to corresponding indices.</p> <p>Functions:</p> Name Description <code>git select_one_snapshot_per_visit</code> <p>Selects one snapshot per visit based on a random number and returns the filtered DataFrame.</p> <code>prepare_patient_snapshots</code> <p>Filters the DataFrame by prediction time and optionally selects one snapshot per visit.</p> <code>prepare_group_snapshot_dict</code> <p>Prepares a dictionary mapping snapshot dates to their corresponding snapshot indices.</p> <code>calculate_time_varying_arrival_rates</code> <p>Calculates the time-varying arrival rates for a dataset indexed by datetime.</p>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams","title":"<code>SpecialCategoryParams</code>","text":"<p>A picklable implementation of special category parameters for patient classification.</p> <p>This class identifies pediatric patients based on available age-related columns in the dataset and provides functions to categorise patients accordingly. It's designed to be serializable with pickle by implementing the reduce method.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>list or Index</code> <p>Column names from the dataset used to determine the appropriate age identification method</p> required <p>Attributes:</p> Name Type Description <code>columns</code> <code>list</code> <p>List of column names from the dataset</p> <code>method_type</code> <code>str</code> <p>The method used for age detection ('age_on_arrival' or 'age_group')</p> <code>special_category_dict</code> <code>dict</code> <p>Default category values mapping</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither 'age_on_arrival' nor 'age_group' columns are found</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>class SpecialCategoryParams:\n    \"\"\"A picklable implementation of special category parameters for patient classification.\n\n    This class identifies pediatric patients based on available age-related columns\n    in the dataset and provides functions to categorise patients accordingly.\n    It's designed to be serializable with pickle by implementing the __reduce__ method.\n\n    Parameters\n    ----------\n    columns : list or pandas.Index\n        Column names from the dataset used to determine the appropriate age identification method\n\n    Attributes\n    ----------\n    columns : list\n        List of column names from the dataset\n    method_type : str\n        The method used for age detection ('age_on_arrival' or 'age_group')\n    special_category_dict : dict\n        Default category values mapping\n\n    Raises\n    ------\n    ValueError\n        If neither 'age_on_arrival' nor 'age_group' columns are found\n    \"\"\"\n\n    def __init__(self, columns):\n        \"\"\"Initialize the SpecialCategoryParams object.\n\n        Parameters\n        ----------\n        columns : list or pandas.Index\n            Column names from the dataset used to determine the appropriate age identification method\n\n        Raises\n        ------\n        ValueError\n            If neither 'age_on_arrival' nor 'age_group' columns are found\n        \"\"\"\n        self.columns = columns\n        self.special_category_dict = {\n            \"medical\": 0.0,\n            \"surgical\": 0.0,\n            \"haem/onc\": 0.0,\n            \"paediatric\": 1.0,\n        }\n\n        if \"age_on_arrival\" in columns:\n            self.method_type = \"age_on_arrival\"\n        elif \"age_group\" in columns:\n            self.method_type = \"age_group\"\n        else:\n            raise ValueError(\"Unknown data format: could not find expected age columns\")\n\n    def special_category_func(self, row: Union[dict, pd.Series]) -&gt; bool:\n        \"\"\"Identify if a patient is pediatric based on age data.\n\n        Parameters\n        ----------\n        row : Union[dict, pd.Series]\n            A row of patient data containing either 'age_on_arrival' or 'age_group'\n\n        Returns\n        -------\n        bool\n            True if the patient is pediatric (age &lt; 18 or age_group is '0-17'),\n            False otherwise\n        \"\"\"\n        if self.method_type == \"age_on_arrival\":\n            return row[\"age_on_arrival\"] &lt; 18\n        else:  # age_group\n            return row[\"age_group\"] == \"0-17\"\n\n    def opposite_special_category_func(self, row: Union[dict, pd.Series]) -&gt; bool:\n        \"\"\"Identify if a patient is NOT pediatric.\n\n        Parameters\n        ----------\n        row : Union[dict, pd.Series]\n            A row of patient data\n\n        Returns\n        -------\n        bool\n            True if the patient is NOT pediatric, False if they are pediatric\n        \"\"\"\n        return not self.special_category_func(row)\n\n    def get_params_dict(\n        self,\n    ) -&gt; Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]:\n        \"\"\"Get the special parameter dictionary in the format expected by the SequencePredictor.\n\n        Returns\n        -------\n        Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]\n            A dictionary containing:\n            - 'special_category_func': Function to identify pediatric patients\n            - 'special_category_dict': Default category values (float)\n            - 'special_func_map': Mapping of category names to detection functions\n        \"\"\"\n        return {\n            \"special_category_func\": self.special_category_func,\n            \"special_category_dict\": self.special_category_dict,\n            \"special_func_map\": {\n                \"paediatric\": self.special_category_func,\n                \"default\": self.opposite_special_category_func,\n            },\n        }\n\n    def __reduce__(self) -&gt; Tuple[Type[\"SpecialCategoryParams\"], Tuple[list]]:\n        \"\"\"Support for pickle serialization.\n\n        Returns\n        -------\n        Tuple[Type['SpecialCategoryParams'], Tuple[list]]\n            A tuple containing:\n            - The class itself (to be called as a function)\n            - A tuple of arguments to pass to the class constructor\n        \"\"\"\n        return (self.__class__, (self.columns,))\n</code></pre>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams.__init__","title":"<code>__init__(columns)</code>","text":"<p>Initialize the SpecialCategoryParams object.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>list or Index</code> <p>Column names from the dataset used to determine the appropriate age identification method</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither 'age_on_arrival' nor 'age_group' columns are found</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def __init__(self, columns):\n    \"\"\"Initialize the SpecialCategoryParams object.\n\n    Parameters\n    ----------\n    columns : list or pandas.Index\n        Column names from the dataset used to determine the appropriate age identification method\n\n    Raises\n    ------\n    ValueError\n        If neither 'age_on_arrival' nor 'age_group' columns are found\n    \"\"\"\n    self.columns = columns\n    self.special_category_dict = {\n        \"medical\": 0.0,\n        \"surgical\": 0.0,\n        \"haem/onc\": 0.0,\n        \"paediatric\": 1.0,\n    }\n\n    if \"age_on_arrival\" in columns:\n        self.method_type = \"age_on_arrival\"\n    elif \"age_group\" in columns:\n        self.method_type = \"age_group\"\n    else:\n        raise ValueError(\"Unknown data format: could not find expected age columns\")\n</code></pre>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams.__reduce__","title":"<code>__reduce__()</code>","text":"<p>Support for pickle serialization.</p> <p>Returns:</p> Type Description <code>Tuple[Type[SpecialCategoryParams], Tuple[list]]</code> <p>A tuple containing: - The class itself (to be called as a function) - A tuple of arguments to pass to the class constructor</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def __reduce__(self) -&gt; Tuple[Type[\"SpecialCategoryParams\"], Tuple[list]]:\n    \"\"\"Support for pickle serialization.\n\n    Returns\n    -------\n    Tuple[Type['SpecialCategoryParams'], Tuple[list]]\n        A tuple containing:\n        - The class itself (to be called as a function)\n        - A tuple of arguments to pass to the class constructor\n    \"\"\"\n    return (self.__class__, (self.columns,))\n</code></pre>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams.get_params_dict","title":"<code>get_params_dict()</code>","text":"<p>Get the special parameter dictionary in the format expected by the SequencePredictor.</p> <p>Returns:</p> Type Description <code>Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]</code> <p>A dictionary containing: - 'special_category_func': Function to identify pediatric patients - 'special_category_dict': Default category values (float) - 'special_func_map': Mapping of category names to detection functions</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def get_params_dict(\n    self,\n) -&gt; Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]:\n    \"\"\"Get the special parameter dictionary in the format expected by the SequencePredictor.\n\n    Returns\n    -------\n    Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]\n        A dictionary containing:\n        - 'special_category_func': Function to identify pediatric patients\n        - 'special_category_dict': Default category values (float)\n        - 'special_func_map': Mapping of category names to detection functions\n    \"\"\"\n    return {\n        \"special_category_func\": self.special_category_func,\n        \"special_category_dict\": self.special_category_dict,\n        \"special_func_map\": {\n            \"paediatric\": self.special_category_func,\n            \"default\": self.opposite_special_category_func,\n        },\n    }\n</code></pre>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams.opposite_special_category_func","title":"<code>opposite_special_category_func(row)</code>","text":"<p>Identify if a patient is NOT pediatric.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Union[dict, Series]</code> <p>A row of patient data</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the patient is NOT pediatric, False if they are pediatric</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def opposite_special_category_func(self, row: Union[dict, pd.Series]) -&gt; bool:\n    \"\"\"Identify if a patient is NOT pediatric.\n\n    Parameters\n    ----------\n    row : Union[dict, pd.Series]\n        A row of patient data\n\n    Returns\n    -------\n    bool\n        True if the patient is NOT pediatric, False if they are pediatric\n    \"\"\"\n    return not self.special_category_func(row)\n</code></pre>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams.special_category_func","title":"<code>special_category_func(row)</code>","text":"<p>Identify if a patient is pediatric based on age data.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Union[dict, Series]</code> <p>A row of patient data containing either 'age_on_arrival' or 'age_group'</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the patient is pediatric (age &lt; 18 or age_group is '0-17'), False otherwise</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def special_category_func(self, row: Union[dict, pd.Series]) -&gt; bool:\n    \"\"\"Identify if a patient is pediatric based on age data.\n\n    Parameters\n    ----------\n    row : Union[dict, pd.Series]\n        A row of patient data containing either 'age_on_arrival' or 'age_group'\n\n    Returns\n    -------\n    bool\n        True if the patient is pediatric (age &lt; 18 or age_group is '0-17'),\n        False otherwise\n    \"\"\"\n    if self.method_type == \"age_on_arrival\":\n        return row[\"age_on_arrival\"] &lt; 18\n    else:  # age_group\n        return row[\"age_group\"] == \"0-17\"\n</code></pre>"},{"location":"api/#patientflow.prepare.additional_details","title":"<code>additional_details(column, col_name)</code>","text":"<p>Generate additional statistical details about a column's contents.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>Series</code> <p>The column to analyze</p> required <code>col_name</code> <code>str</code> <p>Name of the column (used for context)</p> required <p>Returns:</p> Type Description <code>str</code> <p>A string containing statistical details about the column's contents, including: - For dates: Date range - For categorical data: Frequency of values - For numeric data: Range, mean, standard deviation, and NA count - For datetime: Date range with time</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def additional_details(column, col_name):\n    \"\"\"Generate additional statistical details about a column's contents.\n\n    Parameters\n    ----------\n    column : pandas.Series\n        The column to analyze\n    col_name : str\n        Name of the column (used for context)\n\n    Returns\n    -------\n    str\n        A string containing statistical details about the column's contents, including:\n        - For dates: Date range\n        - For categorical data: Frequency of values\n        - For numeric data: Range, mean, standard deviation, and NA count\n        - For datetime: Date range with time\n    \"\"\"\n\n    def is_date(string):\n        try:\n            # Try to parse the string using the strptime method\n            datetime.strptime(\n                string, \"%Y-%m-%d\"\n            )  # You can adjust the format to match your date format\n            return True\n        except (ValueError, TypeError):\n            return False\n\n    # Convert to datetime if it's an object but formatted as a date\n    if column.dtype == \"object\" and all(\n        is_date(str(x)) for x in column.dropna().unique()\n    ):\n        column = pd.to_datetime(column)\n        return f\"Date Range: {column.min().strftime('%Y-%m-%d')} - {column.max().strftime('%Y-%m-%d')}\"\n\n    if column.dtype in [\"object\", \"category\", \"bool\"]:\n        # Categorical data: Frequency of unique values\n        # Handle enum instances\n        try:\n            from enum import Enum\n\n            if any(isinstance(x, Enum) for x in column.dropna().unique()):\n                # Convert enum instances to their values for counting\n                column = column.apply(lambda x: x.value if isinstance(x, Enum) else x)\n        except ImportError:\n            pass\n\n        if len(column.value_counts()) &lt;= 12:\n            value_counts = column.value_counts(dropna=False).to_dict()\n            value_counts = dict(sorted(value_counts.items(), key=lambda x: str(x[0])))\n            value_counts_formatted = {k: f\"{v:,}\" for k, v in value_counts.items()}\n            return f\"Frequencies: {value_counts_formatted}\"\n        value_counts = column.value_counts(dropna=False)[0:12].to_dict()\n        value_counts = dict(sorted(value_counts.items(), key=lambda x: str(x[0])))\n        value_counts_formatted = {k: f\"{v:,}\" for k, v in value_counts.items()}\n        return f\"Frequencies (highest 12): {value_counts_formatted}\"\n\n    if pd.api.types.is_float_dtype(column):\n        # Float data: Range with rounding\n        na_count = column.isna().sum()\n        column = column.dropna()\n        return f\"Range: {column.min():.2f} - {column.max():.2f},  Mean: {column.mean():.2f}, Std Dev: {column.std():.2f}, NA: {na_count}\"\n    if pd.api.types.is_integer_dtype(column):\n        # Float data: Range without rounding\n        na_count = column.isna().sum()\n        column = column.dropna()\n        return f\"Range: {column.min()} - {column.max()}, Mean: {column.mean():.2f}, Std Dev: {column.std():.2f}, NA: {na_count}\"\n    if pd.api.types.is_datetime64_any_dtype(column):\n        # Datetime data: Minimum and Maximum dates\n        return f\"Date Range: {column.min().strftime('%Y-%m-%d %H:%M')} - {column.max().strftime('%Y-%m-%d %H:%M')}\"\n    else:\n        return \"N/A\"\n</code></pre>"},{"location":"api/#patientflow.prepare.apply_set","title":"<code>apply_set(row)</code>","text":"<p>Randomly assign a set label based on weighted probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Series</code> <p>Series containing 'training_set', 'validation_set', and 'test_set' weights</p> required <p>Returns:</p> Type Description <code>str</code> <p>One of 'train', 'valid', or 'test' based on weighted random choice</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def apply_set(row: pd.Series) -&gt; str:\n    \"\"\"Randomly assign a set label based on weighted probabilities.\n\n    Parameters\n    ----------\n    row : pandas.Series\n        Series containing 'training_set', 'validation_set', and 'test_set' weights\n\n    Returns\n    -------\n    str\n        One of 'train', 'valid', or 'test' based on weighted random choice\n    \"\"\"\n    return random.choices(\n        [\"train\", \"valid\", \"test\"],\n        weights=[row.training_set, row.validation_set, row.test_set],\n    )[0]\n</code></pre>"},{"location":"api/#patientflow.prepare.assign_patient_ids","title":"<code>assign_patient_ids(df, start_training_set, start_validation_set, start_test_set, end_test_set, date_col='arrival_datetime', patient_id='mrn', visit_col='encounter', seed=42)</code>","text":"<p>Probabilistically assign patient IDs to train/validation/test sets.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with patient_id, encounter, and temporal columns</p> required <code>start_training_set</code> <code>date</code> <p>Start date for training period</p> required <code>start_validation_set</code> <code>date</code> <p>Start date for validation period</p> required <code>start_test_set</code> <code>date</code> <p>Start date for test period</p> required <code>end_test_set</code> <code>date</code> <p>End date for test period</p> required <code>date_col</code> <code>str</code> <p>Column name for temporal splitting, by default \"arrival_datetime\"</p> <code>'arrival_datetime'</code> <code>patient_id</code> <code>str</code> <p>Column name for patient identifier, by default \"mrn\"</p> <code>'mrn'</code> <code>visit_col</code> <code>str</code> <p>Column name for visit identifier, by default \"encounter\"</p> <code>'encounter'</code> <code>seed</code> <code>int</code> <p>Random seed for reproducible results, by default 42</p> <code>42</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with patient ID assignments based on weighted random sampling</p> Notes <ul> <li>Counts encounters in each time period per patient ID</li> <li>Randomly assigns each patient ID to one set, weighted by their temporal distribution</li> <li>Patient with 70% encounters in training, 30% in validation has 70% chance of training assignment</li> </ul> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def assign_patient_ids(\n    df: pd.DataFrame,\n    start_training_set: date,\n    start_validation_set: date,\n    start_test_set: date,\n    end_test_set: date,\n    date_col: str = \"arrival_datetime\",\n    patient_id: str = \"mrn\",\n    visit_col: str = \"encounter\",\n    seed: int = 42,\n) -&gt; pd.DataFrame:\n    \"\"\"Probabilistically assign patient IDs to train/validation/test sets.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame with patient_id, encounter, and temporal columns\n    start_training_set : datetime.date\n        Start date for training period\n    start_validation_set : datetime.date\n        Start date for validation period\n    start_test_set : datetime.date\n        Start date for test period\n    end_test_set : datetime.date\n        End date for test period\n    date_col : str, optional\n        Column name for temporal splitting, by default \"arrival_datetime\"\n    patient_id : str, optional\n        Column name for patient identifier, by default \"mrn\"\n    visit_col : str, optional\n        Column name for visit identifier, by default \"encounter\"\n    seed : int, optional\n        Random seed for reproducible results, by default 42\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with patient ID assignments based on weighted random sampling\n\n    Notes\n    -----\n    - Counts encounters in each time period per patient ID\n    - Randomly assigns each patient ID to one set, weighted by their temporal distribution\n    - Patient with 70% encounters in training, 30% in validation has 70% chance of training assignment\n    \"\"\"\n    # Set random seed for reproducibility\n    random.seed(seed)\n\n    patients: pd.DataFrame = (\n        df.groupby([patient_id, visit_col])[date_col].max().reset_index()\n    )\n\n    # Handle date_col as string, datetime, or date type\n    if pd.api.types.is_datetime64_any_dtype(patients[date_col]):\n        # Already datetime, extract date if needed\n        if hasattr(patients[date_col].iloc[0], \"date\"):\n            date_series = patients[date_col].dt.date\n        else:\n            # Already date type\n            date_series = patients[date_col]\n    else:\n        # Try to convert string to datetime\n        try:\n            patients[date_col] = pd.to_datetime(patients[date_col])\n            date_series = patients[date_col].dt.date\n        except (TypeError, ValueError) as e:\n            raise ValueError(\n                f\"Could not convert column '{date_col}' to datetime format: {str(e)}\"\n            )\n\n    # Filter out patient IDs outside temporal bounds\n    pre_training_patients = patients[date_series &lt; start_training_set]\n    post_test_patients = patients[date_series &gt;= end_test_set]\n\n    if len(pre_training_patients) &gt; 0:\n        print(\n            f\"Filtered out {len(pre_training_patients)} patients with only pre-training visits\"\n        )\n    if len(post_test_patients) &gt; 0:\n        print(\n            f\"Filtered out {len(post_test_patients)} patients with only post-test visits\"\n        )\n\n    valid_patients = patients[\n        (date_series &gt;= start_training_set) &amp; (date_series &lt; end_test_set)\n    ]\n    patients = valid_patients\n\n    # Use the date_series for set assignment\n    patients[\"training_set\"] = (date_series &gt;= start_training_set) &amp; (\n        date_series &lt; start_validation_set\n    )\n    patients[\"validation_set\"] = (date_series &gt;= start_validation_set) &amp; (\n        date_series &lt; start_test_set\n    )\n    patients[\"test_set\"] = (date_series &gt;= start_test_set) &amp; (\n        date_series &lt; end_test_set\n    )\n\n    patients = patients.groupby(patient_id)[\n        [\"training_set\", \"validation_set\", \"test_set\"]\n    ].sum()\n    patients[\"training_validation_test\"] = patients.apply(apply_set, axis=1)\n\n    print(\n        f\"\\nPatient Set Overlaps (before random assignment):\"\n        f\"\\nTrain-Valid: {patients[patients.training_set * patients.validation_set != 0].shape[0]} of {patients[patients.training_set + patients.validation_set &gt; 0].shape[0]}\"\n        f\"\\nValid-Test: {patients[patients.validation_set * patients.test_set != 0].shape[0]} of {patients[patients.validation_set + patients.test_set &gt; 0].shape[0]}\"\n        f\"\\nTrain-Test: {patients[patients.training_set * patients.test_set != 0].shape[0]} of {patients[patients.training_set + patients.test_set &gt; 0].shape[0]}\"\n        f\"\\nAll Sets: {patients[patients.training_set * patients.validation_set * patients.test_set != 0].shape[0]} of {patients.shape[0]} total patients\"\n    )\n\n    return patients\n</code></pre>"},{"location":"api/#patientflow.prepare.convert_dict_to_values","title":"<code>convert_dict_to_values(df, column, prefix)</code>","text":"<p>Convert a column containing dictionaries into separate columns.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame containing the dictionary column</p> required <code>column</code> <code>str</code> <p>Name of the column containing dictionaries to convert</p> required <code>prefix</code> <code>str</code> <p>Prefix to use for the new column names</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing separate columns for each dictionary key, with values extracted from 'value_as_real' or 'value_as_text' if present</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def convert_dict_to_values(df, column, prefix):\n    \"\"\"Convert a column containing dictionaries into separate columns.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Input DataFrame containing the dictionary column\n    column : str\n        Name of the column containing dictionaries to convert\n    prefix : str\n        Prefix to use for the new column names\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame containing separate columns for each dictionary key,\n        with values extracted from 'value_as_real' or 'value_as_text' if present\n    \"\"\"\n\n    def extract_relevant_value(d):\n        if isinstance(d, dict):\n            if \"value_as_real\" in d or \"value_as_text\" in d:\n                return (\n                    d.get(\"value_as_real\")\n                    if d.get(\"value_as_real\") is not None\n                    else d.get(\"value_as_text\")\n                )\n            else:\n                return d  # Return the dictionary as is if it does not contain 'value_as_real' or 'value_as_text'\n        return d  # Return the value as is if it is not a dictionary\n\n    # Apply the extraction function to each entry in the dictionary column\n    extracted_values = df[column].apply(\n        lambda x: {k: extract_relevant_value(v) for k, v in x.items()}\n    )\n\n    # Create a DataFrame from the processed dictionary column\n    dict_df = extracted_values.apply(pd.Series)\n\n    # Add a prefix to the column names\n    dict_df.columns = [f\"{prefix}_{col}\" for col in dict_df.columns]\n\n    return dict_df\n</code></pre>"},{"location":"api/#patientflow.prepare.convert_set_to_dummies","title":"<code>convert_set_to_dummies(df, column, prefix)</code>","text":"<p>Convert a column containing sets into dummy variables.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame containing the set column</p> required <code>column</code> <code>str</code> <p>Name of the column containing sets to convert</p> required <code>prefix</code> <code>str</code> <p>Prefix to use for the dummy variable column names</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing dummy variables for each unique item in the sets</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def convert_set_to_dummies(df, column, prefix):\n    \"\"\"Convert a column containing sets into dummy variables.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Input DataFrame containing the set column\n    column : str\n        Name of the column containing sets to convert\n    prefix : str\n        Prefix to use for the dummy variable column names\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame containing dummy variables for each unique item in the sets\n    \"\"\"\n    # Explode the set into rows\n    exploded_df = df[column].explode().dropna().to_frame()\n\n    # Create dummy variables for each unique item with a specified prefix\n    dummies = pd.get_dummies(exploded_df[column], prefix=prefix)\n\n    # # Sum the dummies back to the original DataFrame's index\n    dummies = dummies.groupby(dummies.index).sum()\n\n    # Convert dummy variables to boolean\n    dummies = dummies.astype(bool)\n\n    return dummies\n</code></pre>"},{"location":"api/#patientflow.prepare.create_special_category_objects","title":"<code>create_special_category_objects(columns)</code>","text":"<p>Create a configuration for categorising patients with special handling for pediatric cases.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>list or Index</code> <p>The column names available in the dataset. Used to determine which age format is present.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing special category configuration with: - 'special_category_func': Function to identify pediatric patients - 'special_category_dict': Default category values - 'special_func_map': Mapping of category names to detection functions</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def create_special_category_objects(columns):\n    \"\"\"Create a configuration for categorising patients with special handling for pediatric cases.\n\n    Parameters\n    ----------\n    columns : list or pandas.Index\n        The column names available in the dataset. Used to determine which age format is present.\n\n    Returns\n    -------\n    dict\n        A dictionary containing special category configuration with:\n        - 'special_category_func': Function to identify pediatric patients\n        - 'special_category_dict': Default category values\n        - 'special_func_map': Mapping of category names to detection functions\n    \"\"\"\n    # Create the class instance and return its parameter dictionary\n    params_obj = SpecialCategoryParams(columns)\n    return params_obj.get_params_dict()\n</code></pre>"},{"location":"api/#patientflow.prepare.create_temporal_splits","title":"<code>create_temporal_splits(df, start_train, start_valid, start_test, end_test, col_name='arrival_datetime', patient_id='mrn', visit_col='encounter', seed=42)</code>","text":"<p>Split dataset into temporal train/validation/test sets.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input dataframe</p> required <code>start_train</code> <code>date</code> <p>Training start (inclusive)</p> required <code>start_valid</code> <code>date</code> <p>Validation start (inclusive)</p> required <code>start_test</code> <code>date</code> <p>Test start (inclusive)</p> required <code>end_test</code> <code>date</code> <p>Test end (exclusive)</p> required <code>col_name</code> <code>str</code> <p>Primary datetime column for splitting, by default \"arrival_datetime\"</p> <code>'arrival_datetime'</code> <code>patient_id</code> <code>str</code> <p>Column name for patient identifier, by default \"mrn\"</p> <code>'mrn'</code> <code>visit_col</code> <code>str</code> <p>Column name for visit identifier, by default \"encounter\"</p> <code>'encounter'</code> <code>seed</code> <code>int</code> <p>Random seed for reproducible results, by default 42</p> <code>42</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, DataFrame, DataFrame]</code> <p>Tuple containing (train_df, valid_df, test_df) split dataframes</p> Notes <p>Creates temporal data splits using primary datetime column and optional snapshot dates. Handles patient ID grouping if present to prevent data leakage.</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def create_temporal_splits(\n    df: pd.DataFrame,\n    start_train: date,\n    start_valid: date,\n    start_test: date,\n    end_test: date,\n    col_name: str = \"arrival_datetime\",\n    patient_id: str = \"mrn\",\n    visit_col: str = \"encounter\",\n    seed: int = 42,\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n    \"\"\"Split dataset into temporal train/validation/test sets.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Input dataframe\n    start_train : datetime.date\n        Training start (inclusive)\n    start_valid : datetime.date\n        Validation start (inclusive)\n    start_test : datetime.date\n        Test start (inclusive)\n    end_test : datetime.date\n        Test end (exclusive)\n    col_name : str, optional\n        Primary datetime column for splitting, by default \"arrival_datetime\"\n    patient_id : str, optional\n        Column name for patient identifier, by default \"mrn\"\n    visit_col : str, optional\n        Column name for visit identifier, by default \"encounter\"\n    seed : int, optional\n        Random seed for reproducible results, by default 42\n\n    Returns\n    -------\n    Tuple[pandas.DataFrame, pandas.DataFrame, pandas.DataFrame]\n        Tuple containing (train_df, valid_df, test_df) split dataframes\n\n    Notes\n    -----\n    Creates temporal data splits using primary datetime column and optional snapshot dates.\n    Handles patient ID grouping if present to prevent data leakage.\n    \"\"\"\n\n    def get_date_value(series: pd.Series) -&gt; pd.Series:\n        \"\"\"Convert timestamp or date column to date, handling both types.\n\n        Parameters\n        ----------\n        series : pandas.Series\n            Series containing datetime or date values\n\n        Returns\n        -------\n        pandas.Series\n            Series with date values\n        \"\"\"\n        try:\n            return pd.to_datetime(series).dt.date\n        except (AttributeError, TypeError):\n            return series\n\n    if patient_id in df.columns:\n        set_assignment: pd.DataFrame = assign_patient_ids(\n            df,\n            start_train,\n            start_valid,\n            start_test,\n            end_test,\n            col_name,\n            patient_id,\n            visit_col,\n            seed=seed,\n        )\n        patient_sets: Dict[str, Set] = {\n            k: set(set_assignment[set_assignment.training_validation_test == v].index)\n            for k, v in {\"train\": \"train\", \"valid\": \"valid\", \"test\": \"test\"}.items()\n        }\n\n    splits: List[pd.DataFrame] = []\n    for start, end, set_key in [\n        (start_train, start_valid, \"train\"),\n        (start_valid, start_test, \"valid\"),\n        (start_test, end_test, \"test\"),\n    ]:\n        mask = (get_date_value(df[col_name]) &gt;= start) &amp; (\n            get_date_value(df[col_name]) &lt; end\n        )\n\n        if \"snapshot_date\" in df.columns:\n            mask &amp;= (get_date_value(df.snapshot_date) &gt;= start) &amp; (\n                get_date_value(df.snapshot_date) &lt; end\n            )\n\n        if patient_id in df.columns:\n            mask &amp;= df[patient_id].isin(patient_sets[set_key])\n\n        splits.append(df[mask].copy())\n\n    print(f\"Split sizes: {[len(split) for split in splits]}\")\n    return tuple(splits)\n</code></pre>"},{"location":"api/#patientflow.prepare.create_yta_filters","title":"<code>create_yta_filters(df)</code>","text":"<p>Create specialty filters for categorizing patients by specialty and age group.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing patient data with columns that include either 'age_on_arrival' or 'age_group' for pediatric classification</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary mapping specialty names to filter configurations. Each configuration contains: - For pediatric specialty: {\"is_child\": True} - For other specialties: {\"specialty\": specialty_name, \"is_child\": False}</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({'patient_id': [1, 2], 'age_on_arrival': [10, 40]})\n&gt;&gt;&gt; filters = create_yta_filters(df)\n&gt;&gt;&gt; print(filters['paediatric'])\n{'is_child': True}\n&gt;&gt;&gt; print(filters['medical'])\n{'specialty': 'medical', 'is_child': False}\n</code></pre> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def create_yta_filters(df):\n    \"\"\"Create specialty filters for categorizing patients by specialty and age group.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame containing patient data with columns that include either\n        'age_on_arrival' or 'age_group' for pediatric classification\n\n    Returns\n    -------\n    dict\n        A dictionary mapping specialty names to filter configurations.\n        Each configuration contains:\n        - For pediatric specialty: {\"is_child\": True}\n        - For other specialties: {\"specialty\": specialty_name, \"is_child\": False}\n\n    Examples\n    --------\n    &gt;&gt;&gt; df = pd.DataFrame({'patient_id': [1, 2], 'age_on_arrival': [10, 40]})\n    &gt;&gt;&gt; filters = create_yta_filters(df)\n    &gt;&gt;&gt; print(filters['paediatric'])\n    {'is_child': True}\n    &gt;&gt;&gt; print(filters['medical'])\n    {'specialty': 'medical', 'is_child': False}\n    \"\"\"\n    # Get the special category parameters using the picklable implementation\n    special_params = create_special_category_objects(df.columns)\n\n    # Extract necessary data from the special_params\n    special_category_dict = special_params[\"special_category_dict\"]\n\n    # Create the specialty_filters dictionary\n    specialty_filters = {}\n\n    for specialty, is_paediatric_flag in special_category_dict.items():\n        if is_paediatric_flag == 1.0:\n            # For the paediatric specialty, set `is_child` to True\n            specialty_filters[specialty] = {\"is_child\": True}\n        else:\n            # For other specialties, set `is_child` to False\n            specialty_filters[specialty] = {\"specialty\": specialty, \"is_child\": False}\n\n    return specialty_filters\n</code></pre>"},{"location":"api/#patientflow.prepare.find_group_for_colname","title":"<code>find_group_for_colname(column, dict_col_groups)</code>","text":"<p>Find the group name that a column belongs to in the column groups dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Name of the column to find the group for</p> required <code>dict_col_groups</code> <code>dict</code> <p>Dictionary mapping group names to lists of column names</p> required <p>Returns:</p> Type Description <code>str or None</code> <p>The name of the group the column belongs to, or None if not found</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def find_group_for_colname(column, dict_col_groups):\n    \"\"\"Find the group name that a column belongs to in the column groups dictionary.\n\n    Parameters\n    ----------\n    column : str\n        Name of the column to find the group for\n    dict_col_groups : dict\n        Dictionary mapping group names to lists of column names\n\n    Returns\n    -------\n    str or None\n        The name of the group the column belongs to, or None if not found\n    \"\"\"\n    for key, values_list in dict_col_groups.items():\n        if column in values_list:\n            return key\n    return None\n</code></pre>"},{"location":"api/#patientflow.prepare.generate_description","title":"<code>generate_description(col_name)</code>","text":"<p>Generate a description for a column based on its name and manual descriptions.</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Name of the column to generate a description for</p> required <p>Returns:</p> Type Description <code>str</code> <p>A descriptive string explaining the column's purpose and content</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def generate_description(col_name):\n    \"\"\"Generate a description for a column based on its name and manual descriptions.\n\n    Parameters\n    ----------\n    col_name : str\n        Name of the column to generate a description for\n\n    Returns\n    -------\n    str\n        A descriptive string explaining the column's purpose and content\n    \"\"\"\n    manual_descriptions = get_manual_descriptions()\n\n    # Check if manual description is provided\n    if col_name in manual_descriptions:\n        return manual_descriptions[col_name]\n\n    if (\n        col_name.startswith(\"num\")\n        and not col_name.startswith(\"num_obs\")\n        and not col_name.startswith(\"num_orders\")\n    ):\n        return \"Number of times \" + col_name[4:] + \" has been recorded\"\n    if col_name.startswith(\"num_obs\"):\n        return \"Number of observations of \" + col_name[8:]\n    if col_name.startswith(\"latest_obs\"):\n        return \"Latest result for \" + col_name[11:]\n    if col_name.startswith(\"latest_lab\"):\n        return \"Latest result for \" + col_name[19:]\n    if col_name.startswith(\"lab_orders\"):\n        return \"Request for lab battery \" + col_name[11:] + \" has been placed\"\n    if col_name.startswith(\"visited\"):\n        return \"Patient visited \" + col_name[8:] + \" previously or is there now\"\n    else:\n        return col_name\n</code></pre>"},{"location":"api/#patientflow.prepare.prepare_group_snapshot_dict","title":"<code>prepare_group_snapshot_dict(df, start_dt=None, end_dt=None)</code>","text":"<p>Prepare a dictionary mapping snapshot dates to their corresponding snapshot indices.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing at least a 'snapshot_date' column</p> required <code>start_dt</code> <code>date</code> <p>Start date for filtering snapshots, by default None</p> <code>None</code> <code>end_dt</code> <code>date</code> <p>End date for filtering snapshots, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary where: - Keys are dates - Values are arrays of indices corresponding to each date's snapshots - Empty arrays for dates with no snapshots (if start_dt and end_dt are provided)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If 'snapshot_date' column is not present in the DataFrame</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def prepare_group_snapshot_dict(df, start_dt=None, end_dt=None):\n    \"\"\"Prepare a dictionary mapping snapshot dates to their corresponding snapshot indices.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame containing at least a 'snapshot_date' column\n    start_dt : datetime.date, optional\n        Start date for filtering snapshots, by default None\n    end_dt : datetime.date, optional\n        End date for filtering snapshots, by default None\n\n    Returns\n    -------\n    dict\n        A dictionary where:\n        - Keys are dates\n        - Values are arrays of indices corresponding to each date's snapshots\n        - Empty arrays for dates with no snapshots (if start_dt and end_dt are provided)\n\n    Raises\n    ------\n    ValueError\n        If 'snapshot_date' column is not present in the DataFrame\n    \"\"\"\n    # Ensure 'snapshot_date' is in the DataFrame\n    if \"snapshot_date\" not in df.columns:\n        raise ValueError(\"DataFrame must include a 'snapshot_date' column\")\n\n    # Filter DataFrame to date range if provided\n    filtered_df = df.copy()\n    if start_dt and end_dt:\n        filtered_df = df[\n            (df[\"snapshot_date\"] &gt;= start_dt) &amp; (df[\"snapshot_date\"] &lt; end_dt)\n        ]\n\n    # Group the DataFrame by 'snapshot_date' and collect the indices for each group\n    snapshots_dict = {\n        date: group.index.tolist()\n        for date, group in filtered_df.groupby(\"snapshot_date\")\n    }\n\n    # If start_dt and end_dt are specified, add any missing keys from prediction_dates\n    if start_dt:\n        prediction_dates = pd.date_range(\n            start=start_dt, end=end_dt, freq=\"D\"\n        ).date.tolist()[:-1]\n        for dt in prediction_dates:\n            if dt not in snapshots_dict:\n                snapshots_dict[dt] = []\n\n    return snapshots_dict\n</code></pre>"},{"location":"api/#patientflow.prepare.prepare_patient_snapshots","title":"<code>prepare_patient_snapshots(df, prediction_time, exclude_columns=[], single_snapshot_per_visit=True, visit_col=None, label_col='is_admitted')</code>","text":"<p>Prepare patient snapshots for model training or prediction.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame containing patient visit data</p> required <code>prediction_time</code> <code>str or datetime</code> <p>The specific prediction time to filter for</p> required <code>exclude_columns</code> <code>list</code> <p>List of columns to exclude from the final DataFrame, by default []</p> <code>[]</code> <code>single_snapshot_per_visit</code> <code>bool</code> <p>Whether to select only one snapshot per visit, by default True</p> <code>True</code> <code>visit_col</code> <code>str</code> <p>Name of the column containing visit identifiers, required if single_snapshot_per_visit is True</p> <code>None</code> <code>label_col</code> <code>str</code> <p>Name of the column containing the target labels, by default \"is_admitted\"</p> <code>'is_admitted'</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, Series]</code> <p>A tuple containing: - DataFrame: Processed DataFrame with features - Series: Corresponding labels</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If single_snapshot_per_visit is True but visit_col is not provided</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def prepare_patient_snapshots(\n    df,\n    prediction_time,\n    exclude_columns=[],\n    single_snapshot_per_visit=True,\n    visit_col=None,\n    label_col=\"is_admitted\",\n) -&gt; Tuple[pd.DataFrame, pd.Series]:\n    \"\"\"Prepare patient snapshots for model training or prediction.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Input DataFrame containing patient visit data\n    prediction_time : str or datetime\n        The specific prediction time to filter for\n    exclude_columns : list, optional\n        List of columns to exclude from the final DataFrame, by default []\n    single_snapshot_per_visit : bool, optional\n        Whether to select only one snapshot per visit, by default True\n    visit_col : str, optional\n        Name of the column containing visit identifiers, required if single_snapshot_per_visit is True\n    label_col : str, optional\n        Name of the column containing the target labels, by default \"is_admitted\"\n\n    Returns\n    -------\n    Tuple[pandas.DataFrame, pandas.Series]\n        A tuple containing:\n        - DataFrame: Processed DataFrame with features\n        - Series: Corresponding labels\n\n    Raises\n    ------\n    ValueError\n        If single_snapshot_per_visit is True but visit_col is not provided\n    \"\"\"\n    if single_snapshot_per_visit and visit_col is None:\n        raise ValueError(\n            \"visit_col must be provided when single_snapshot_per_visit is True\"\n        )\n\n    # Filter by the time of day while keeping the original index\n    df_tod = df[df[\"prediction_time\"] == prediction_time].copy()\n\n    if single_snapshot_per_visit:\n        # Select one row for each visit\n        df_single = select_one_snapshot_per_visit(df_tod, visit_col)\n        # Create label array with the same index\n        y = df_single.pop(label_col).astype(int)\n        # Drop specified columns and ensure we do not reset the index\n        df_single.drop(columns=exclude_columns, inplace=True)\n        return df_single, y\n    else:\n        # Directly modify df_tod without resetting the index\n        df_tod.drop(\n            columns=[\"random_number\"] + exclude_columns, inplace=True, errors=\"ignore\"\n        )\n        y = df_tod.pop(label_col).astype(int)\n        return df_tod, y\n</code></pre>"},{"location":"api/#patientflow.prepare.select_one_snapshot_per_visit","title":"<code>select_one_snapshot_per_visit(df, visit_col, seed=42)</code>","text":"<p>Select one random snapshot per visit from a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame containing visit snapshots</p> required <code>visit_col</code> <code>str</code> <p>Name of the column containing visit identifiers</p> required <code>seed</code> <code>int</code> <p>Random seed for reproducibility, by default 42</p> <code>42</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing one randomly selected snapshot per visit</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def select_one_snapshot_per_visit(df, visit_col, seed=42):\n    \"\"\"Select one random snapshot per visit from a DataFrame.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Input DataFrame containing visit snapshots\n    visit_col : str\n        Name of the column containing visit identifiers\n    seed : int, optional\n        Random seed for reproducibility, by default 42\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame containing one randomly selected snapshot per visit\n    \"\"\"\n    # Generate random numbers if not present\n    if \"random_number\" not in df.columns:\n        if seed is not None:\n            np.random.seed(seed)\n        df[\"random_number\"] = np.random.random(size=len(df))\n\n    # Select the row with the maximum random_number for each visit\n    max_indices = df.groupby(visit_col)[\"random_number\"].idxmax()\n    return df.loc[max_indices].drop(columns=[\"random_number\"])\n</code></pre>"},{"location":"api/#patientflow.prepare.validate_special_category_objects","title":"<code>validate_special_category_objects(special_params)</code>","text":"<p>Validate that a special category parameters dictionary contains all required keys.</p> <p>Parameters:</p> Name Type Description Default <code>special_params</code> <code>Dict[str, Any]</code> <p>Dictionary of special category parameters to validate</p> required <p>Raises:</p> Type Description <code>MissingKeysError</code> <p>If any required keys are missing from the dictionary</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def validate_special_category_objects(special_params: Dict[str, Any]) -&gt; None:\n    \"\"\"Validate that a special category parameters dictionary contains all required keys.\n\n    Parameters\n    ----------\n    special_params : Dict[str, Any]\n        Dictionary of special category parameters to validate\n\n    Raises\n    ------\n    MissingKeysError\n        If any required keys are missing from the dictionary\n    \"\"\"\n    required_keys = [\n        \"special_category_func\",\n        \"special_category_dict\",\n        \"special_func_map\",\n    ]\n    missing_keys = [key for key in required_keys if key not in special_params]\n\n    if missing_keys:\n        raise MissingKeysError(missing_keys)\n</code></pre>"},{"location":"api/#patientflow.prepare.write_data_dict","title":"<code>write_data_dict(df, dict_name, dict_path)</code>","text":"<p>Write a data dictionary for a DataFrame to both Markdown and CSV formats.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame to create a data dictionary for</p> required <code>dict_name</code> <code>str</code> <p>Base name for the output files (without extension)</p> required <code>dict_path</code> <code>str or Path</code> <p>Directory path where the data dictionary files will be written</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The created data dictionary as a DataFrame</p> Notes <p>Creates two files: - {dict_name}.md: Markdown format data dictionary - {dict_name}.csv: CSV format data dictionary</p> <p>For visit data, includes separate statistics for admitted and non-admitted patients.</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def write_data_dict(df, dict_name, dict_path):\n    \"\"\"Write a data dictionary for a DataFrame to both Markdown and CSV formats.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Input DataFrame to create a data dictionary for\n    dict_name : str\n        Base name for the output files (without extension)\n    dict_path : str or pathlib.Path\n        Directory path where the data dictionary files will be written\n\n    Returns\n    -------\n    pandas.DataFrame\n        The created data dictionary as a DataFrame\n\n    Notes\n    -----\n    Creates two files:\n    - {dict_name}.md: Markdown format data dictionary\n    - {dict_name}.csv: CSV format data dictionary\n\n    For visit data, includes separate statistics for admitted and non-admitted patients.\n    \"\"\"\n    cols_to_exclude = [\"snapshot_id\", \"visit_number\"]\n\n    df = df.copy(deep=True)\n\n    if \"visits\" in dict_name:\n        df.consultation_sequence = df.consultation_sequence.apply(\n            lambda x: str(x)\n        ).to_frame()\n        df.final_sequence = df.final_sequence.apply(lambda x: str(x)).to_frame()\n        df_admitted = df[df.is_admitted]\n        df_not_admitted = df[~df.is_admitted]\n        dict_col_groups = get_dict_cols(df)\n\n        data_dict = pd.DataFrame(\n            {\n                \"Variable type\": [\n                    find_group_for_colname(col, dict_col_groups) for col in df.columns\n                ],\n                \"Column Name\": df.columns,\n                \"Data Type\": df.dtypes,\n                \"Description\": [generate_description(col) for col in df.columns],\n                \"Whole dataset\": [\n                    additional_details(df[col], col)\n                    if col not in cols_to_exclude\n                    else \"\"\n                    for col in df.columns\n                ],\n                \"Admitted\": [\n                    additional_details(df_admitted[col], col)\n                    if col not in cols_to_exclude\n                    else \"\"\n                    for col in df_admitted.columns\n                ],\n                \"Not admitted\": [\n                    additional_details(df_not_admitted[col], col)\n                    if col not in cols_to_exclude\n                    else \"\"\n                    for col in df_not_admitted.columns\n                ],\n            }\n        )\n        data_dict[\"Whole dataset\"] = data_dict[\"Whole dataset\"].str.replace(\"'\", \"\")\n        data_dict[\"Admitted\"] = data_dict[\"Admitted\"].str.replace(\"'\", \"\")\n        data_dict[\"Not admitted\"] = data_dict[\"Not admitted\"].str.replace(\"'\", \"\")\n\n    else:\n        data_dict = pd.DataFrame(\n            {\n                \"Column Name\": df.columns,\n                \"Data Type\": df.dtypes,\n                \"Description\": [generate_description(col) for col in df.columns],\n                \"Additional Details\": [\n                    additional_details(df[col], col)\n                    if col not in cols_to_exclude\n                    else \"\"\n                    for col in df.columns\n                ],\n            }\n        )\n        data_dict[\"Additional Details\"] = data_dict[\"Additional Details\"].str.replace(\n            \"'\", \"\"\n        )\n\n    # Export to Markdown and csv for data dictionary\n    data_dict.to_markdown(str(dict_path) + \"/\" + dict_name + \".md\", index=False)\n    data_dict.to_csv(str(dict_path) + \"/\" + dict_name + \".csv\", index=False)\n\n    return data_dict\n</code></pre>"},{"location":"api/#patientflow.survival_curve","title":"<code>survival_curve</code>","text":"<p>Core survival curve calculation functions for patient flow analysis.</p> <p>This module provides the mathematical computation functions for survival analysis without visualization dependencies.</p> <p>Functions:</p> Name Description <code>calculate_survival_curve : function</code> <p>Calculate survival curve data from patient visit data</p>"},{"location":"api/#patientflow.survival_curve.calculate_survival_curve","title":"<code>calculate_survival_curve(df, start_time_col, end_time_col)</code>","text":"<p>Calculate survival curve data from patient visit data.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing patient visit data</p> required <code>start_time_col</code> <code>str</code> <p>Name of the column containing the start time (e.g., arrival time)</p> required <code>end_time_col</code> <code>str</code> <p>Name of the column containing the end time (e.g., admission time)</p> required <p>Returns:</p> Type Description <code>tuple of (numpy.ndarray, numpy.ndarray, pandas.DataFrame)</code> <ul> <li>unique_times: Array of time points in hours</li> <li>survival_prob: Array of survival probabilities at each time point</li> <li>df_clean: Cleaned DataFrame with wait_time_hours column added</li> </ul> Source code in <code>src/patientflow/survival_curve.py</code> <pre><code>def calculate_survival_curve(df, start_time_col, end_time_col):\n    \"\"\"Calculate survival curve data from patient visit data.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame containing patient visit data\n    start_time_col : str\n        Name of the column containing the start time (e.g., arrival time)\n    end_time_col : str\n        Name of the column containing the end time (e.g., admission time)\n\n    Returns\n    -------\n    tuple of (numpy.ndarray, numpy.ndarray, pandas.DataFrame)\n        - unique_times: Array of time points in hours\n        - survival_prob: Array of survival probabilities at each time point\n        - df_clean: Cleaned DataFrame with wait_time_hours column added\n    \"\"\"\n    # Calculate the wait time in hours\n    df = df.copy()\n    df[\"wait_time_hours\"] = (\n        df[end_time_col] - df[start_time_col]\n    ).dt.total_seconds() / 3600\n\n    # Drop any rows with missing wait times\n    df_clean = df.dropna(subset=[\"wait_time_hours\"]).copy()\n\n    # Sort the data by wait time\n    df_clean = df_clean.sort_values(\"wait_time_hours\")\n\n    # Calculate the number of patients\n    n_patients = len(df_clean)\n\n    # Calculate the survival function manually\n    # For each time point, calculate proportion of patients who are still waiting\n    unique_times = np.sort(df_clean[\"wait_time_hours\"].unique())\n    survival_prob = []\n\n    for t in unique_times:\n        # Number of patients who experienced the event after this time point\n        n_event_after = sum(df_clean[\"wait_time_hours\"] &gt; t)\n        # Proportion of patients still waiting\n        survival_prob.append(n_event_after / n_patients)\n\n    # Add zero hours wait time (everyone is waiting at time 0)\n    unique_times = np.insert(unique_times, 0, 0)\n    survival_prob = np.insert(survival_prob, 0, 1.0)\n\n    return unique_times, survival_prob, df_clean\n</code></pre>"},{"location":"api/#patientflow.train","title":"<code>train</code>","text":"<p>Training module for patient flow models.</p> <p>This module provides functionality for training various predictive models used in patient flow analysis, including classifiers and demand forecasting models.</p>"},{"location":"api/#patientflow.train.classifiers","title":"<code>classifiers</code>","text":"<p>Machine learning classifiers for patient flow prediction.</p> <p>This module provides functions for training and evaluating machine learning classifiers for patient admission prediction. It includes utilities for data preparation, model training, hyperparameter tuning, and evaluation using time series cross-validation.</p> <p>Functions:</p> Name Description <code>evaluate_predictions</code> <p>Calculate multiple metrics (AUC, log loss, AUPRC) for given predictions</p> <code>chronological_cross_validation</code> <p>Perform time series cross-validation with multiple metrics</p> <code>initialise_model</code> <p>Initialize a model with given hyperparameters</p> <code>create_column_transformer</code> <p>Create a column transformer for a dataframe with dynamic column handling</p> <code>calculate_class_balance</code> <p>Calculate class balance ratios for target labels</p> <code>get_feature_metadata</code> <p>Extract feature names and importances from pipeline</p> <code>get_dataset_metadata</code> <p>Get dataset sizes and class balances</p> <code>create_balance_info</code> <p>Create a dictionary with balance information</p> <code>evaluate_model</code> <p>Evaluate model on test set</p> <code>train_classifier</code> <p>Train a single model including data preparation and balancing</p> <code>train_multiple_classifiers</code> <p>Train admission prediction models for multiple prediction times</p>"},{"location":"api/#patientflow.train.classifiers.calculate_class_balance","title":"<code>calculate_class_balance(y)</code>","text":"<p>Calculate class balance ratios for target labels.</p> <p>Parameters:</p> Name Type Description Default <code>y</code> <code>Series</code> <p>Target labels</p> required <p>Returns:</p> Type Description <code>Dict[Any, float]</code> <p>Dictionary mapping each class to its proportion</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def calculate_class_balance(y: Series) -&gt; Dict[Any, float]:\n    \"\"\"Calculate class balance ratios for target labels.\n\n    Parameters\n    ----------\n    y : Series\n        Target labels\n\n    Returns\n    -------\n    Dict[Any, float]\n        Dictionary mapping each class to its proportion\n    \"\"\"\n    counter = Counter(y)\n    total = len(y)\n    return {cls: count / total for cls, count in counter.items()}\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.chronological_cross_validation","title":"<code>chronological_cross_validation(pipeline, X, y, n_splits=5)</code>","text":"<p>Perform time series cross-validation with multiple metrics.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>Pipeline</code> <p>Sklearn pipeline to evaluate</p> required <code>X</code> <code>DataFrame</code> <p>Feature matrix</p> required <code>y</code> <code>Series</code> <p>Target labels</p> required <code>n_splits</code> <code>int</code> <p>Number of time series splits, by default 5</p> <code>5</code> <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Dictionary containing training and validation metrics</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def chronological_cross_validation(\n    pipeline: Pipeline, X: DataFrame, y: Series, n_splits: int = 5\n) -&gt; Dict[str, float]:\n    \"\"\"Perform time series cross-validation with multiple metrics.\n\n    Parameters\n    ----------\n    pipeline : Pipeline\n        Sklearn pipeline to evaluate\n    X : DataFrame\n        Feature matrix\n    y : Series\n        Target labels\n    n_splits : int, optional\n        Number of time series splits, by default 5\n\n    Returns\n    -------\n    Dict[str, float]\n        Dictionary containing training and validation metrics\n    \"\"\"\n    tscv = TimeSeriesSplit(n_splits=n_splits)\n\n    train_metrics: List[FoldResults] = []\n    valid_metrics: List[FoldResults] = []\n\n    for train_idx, valid_idx in tscv.split(X):\n        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\n        pipeline.fit(X_train, y_train)\n        train_preds = pipeline.predict_proba(X_train)[:, 1]\n        valid_preds = pipeline.predict_proba(X_valid)[:, 1]\n\n        train_metrics.append(evaluate_predictions(y_train, train_preds))\n        valid_metrics.append(evaluate_predictions(y_valid, valid_preds))\n\n    def aggregate_metrics(metrics_list: List[FoldResults]) -&gt; Dict[str, float]:\n        return {\n            field: np.mean([getattr(m, field) for m in metrics_list])\n            for field in FoldResults.__dataclass_fields__\n        }\n\n    train_means = aggregate_metrics(train_metrics)\n    valid_means = aggregate_metrics(valid_metrics)\n\n    return {f\"train_{metric}\": value for metric, value in train_means.items()} | {\n        f\"valid_{metric}\": value for metric, value in valid_means.items()\n    }\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.create_balance_info","title":"<code>create_balance_info(is_balanced, original_size, balanced_size, original_positive_rate, balanced_positive_rate, majority_to_minority_ratio)</code>","text":"<p>Create a dictionary with balance information.</p> <p>Parameters:</p> Name Type Description Default <code>is_balanced</code> <code>bool</code> <p>Whether the dataset was balanced</p> required <code>original_size</code> <code>int</code> <p>Original dataset size</p> required <code>balanced_size</code> <code>int</code> <p>Size after balancing</p> required <code>original_positive_rate</code> <code>float</code> <p>Positive class rate before balancing</p> required <code>balanced_positive_rate</code> <code>float</code> <p>Positive class rate after balancing</p> required <code>majority_to_minority_ratio</code> <code>float</code> <p>Ratio of majority to minority class samples</p> required <p>Returns:</p> Type Description <code>Dict[str, Union[bool, int, float]]</code> <p>Dictionary containing balance information</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def create_balance_info(\n    is_balanced: bool,\n    original_size: int,\n    balanced_size: int,\n    original_positive_rate: float,\n    balanced_positive_rate: float,\n    majority_to_minority_ratio: float,\n) -&gt; Dict[str, Union[bool, int, float]]:\n    \"\"\"Create a dictionary with balance information.\n\n    Parameters\n    ----------\n    is_balanced : bool\n        Whether the dataset was balanced\n    original_size : int\n        Original dataset size\n    balanced_size : int\n        Size after balancing\n    original_positive_rate : float\n        Positive class rate before balancing\n    balanced_positive_rate : float\n        Positive class rate after balancing\n    majority_to_minority_ratio : float\n        Ratio of majority to minority class samples\n\n    Returns\n    -------\n    Dict[str, Union[bool, int, float]]\n        Dictionary containing balance information\n    \"\"\"\n    return {\n        \"is_balanced\": is_balanced,\n        \"original_size\": original_size,\n        \"balanced_size\": balanced_size,\n        \"original_positive_rate\": original_positive_rate,\n        \"balanced_positive_rate\": balanced_positive_rate,\n        \"majority_to_minority_ratio\": majority_to_minority_ratio,\n    }\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.create_column_transformer","title":"<code>create_column_transformer(df, ordinal_mappings=None)</code>","text":"<p>Create a column transformer for a dataframe with dynamic column handling.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input dataframe</p> required <code>ordinal_mappings</code> <code>Dict[str, List[Any]]</code> <p>Mappings for ordinal categorical features, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>ColumnTransformer</code> <p>Configured column transformer</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def create_column_transformer(\n    df: DataFrame, ordinal_mappings: Optional[Dict[str, List[Any]]] = None\n) -&gt; ColumnTransformer:\n    \"\"\"Create a column transformer for a dataframe with dynamic column handling.\n\n    Parameters\n    ----------\n    df : DataFrame\n        Input dataframe\n    ordinal_mappings : Dict[str, List[Any]], optional\n        Mappings for ordinal categorical features, by default None\n\n    Returns\n    -------\n    ColumnTransformer\n        Configured column transformer\n    \"\"\"\n    transformers: List[\n        Tuple[str, Union[OrdinalEncoder, OneHotEncoder, StandardScaler], List[str]]\n    ] = []\n\n    if ordinal_mappings is None:\n        ordinal_mappings = {}\n\n    for col in df.columns:\n        if col in ordinal_mappings:\n            transformers.append(\n                (\n                    col,\n                    OrdinalEncoder(\n                        categories=[ordinal_mappings[col]],\n                        handle_unknown=\"use_encoded_value\",\n                        unknown_value=np.nan,\n                    ),\n                    [col],\n                )\n            )\n        elif df[col].dtype == \"object\" or (\n            df[col].dtype == \"bool\" or df[col].nunique() == 2\n        ):\n            transformers.append((col, OneHotEncoder(handle_unknown=\"ignore\"), [col]))\n        else:\n            transformers.append((col, StandardScaler(), [col]))\n\n    return ColumnTransformer(transformers)\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.evaluate_model","title":"<code>evaluate_model(pipeline, X_test, y_test)</code>","text":"<p>Evaluate model on test set.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>Pipeline</code> <p>Trained sklearn pipeline</p> required <code>X_test</code> <code>DataFrame</code> <p>Test features</p> required <code>y_test</code> <code>Series</code> <p>Test labels</p> required <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Dictionary containing test metrics</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def evaluate_model(\n    pipeline: Pipeline, X_test: DataFrame, y_test: Series\n) -&gt; Dict[str, float]:\n    \"\"\"Evaluate model on test set.\n\n    Parameters\n    ----------\n    pipeline : Pipeline\n        Trained sklearn pipeline\n    X_test : DataFrame\n        Test features\n    y_test : Series\n        Test labels\n\n    Returns\n    -------\n    Dict[str, float]\n        Dictionary containing test metrics\n    \"\"\"\n    y_test_pred = pipeline.predict_proba(X_test)[:, 1]\n    return {\n        \"test_auc\": float(roc_auc_score(y_test, y_test_pred)),\n        \"test_logloss\": float(log_loss(y_test, y_test_pred)),\n        \"test_auprc\": float(average_precision_score(y_test, y_test_pred)),\n    }\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.evaluate_predictions","title":"<code>evaluate_predictions(y_true, y_pred)</code>","text":"<p>Calculate multiple metrics for given predictions.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>NDArray[int_]</code> <p>True binary labels</p> required <code>y_pred</code> <code>NDArray[float64]</code> <p>Predicted probabilities</p> required <p>Returns:</p> Type Description <code>FoldResults</code> <p>Object containing AUC, log loss, and AUPRC metrics</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def evaluate_predictions(\n    y_true: npt.NDArray[np.int_], y_pred: npt.NDArray[np.float64]\n) -&gt; FoldResults:\n    \"\"\"Calculate multiple metrics for given predictions.\n\n    Parameters\n    ----------\n    y_true : npt.NDArray[np.int_]\n        True binary labels\n    y_pred : npt.NDArray[np.float64]\n        Predicted probabilities\n\n    Returns\n    -------\n    FoldResults\n        Object containing AUC, log loss, and AUPRC metrics\n    \"\"\"\n    return FoldResults(\n        auc=roc_auc_score(y_true, y_pred),\n        logloss=log_loss(y_true, y_pred),\n        auprc=average_precision_score(y_true, y_pred),\n    )\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.get_dataset_metadata","title":"<code>get_dataset_metadata(X_train, X_valid, y_train, y_valid, X_test=None, y_test=None)</code>","text":"<p>Get dataset sizes and class balances.</p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>DataFrame</code> <p>Training features</p> required <code>X_valid</code> <code>DataFrame</code> <p>Validation features</p> required <code>y_train</code> <code>Series</code> <p>Training labels</p> required <code>y_valid</code> <code>Series</code> <p>Validation labels</p> required <code>X_test</code> <code>DataFrame</code> <p>Test features. If None, test set information will be set to None.</p> <code>None</code> <code>y_test</code> <code>Series</code> <p>Test labels. If None, test set information will be set to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DatasetMetadata</code> <p>Dictionary containing dataset sizes and class balances</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def get_dataset_metadata(\n    X_train: DataFrame,\n    X_valid: DataFrame,\n    y_train: Series,\n    y_valid: Series,\n    X_test: Optional[DataFrame] = None,\n    y_test: Optional[Series] = None,\n) -&gt; DatasetMetadata:\n    \"\"\"Get dataset sizes and class balances.\n\n    Parameters\n    ----------\n    X_train : DataFrame\n        Training features\n    X_valid : DataFrame\n        Validation features\n    y_train : Series\n        Training labels\n    y_valid : Series\n        Validation labels\n    X_test : DataFrame, optional\n        Test features. If None, test set information will be set to None.\n    y_test : Series, optional\n        Test labels. If None, test set information will be set to None.\n\n    Returns\n    -------\n    DatasetMetadata\n        Dictionary containing dataset sizes and class balances\n    \"\"\"\n    metadata: DatasetMetadata = {\n        \"train_valid_test_set_no\": {\n            \"train_set_no\": len(X_train),\n            \"valid_set_no\": len(X_valid),\n            \"test_set_no\": len(X_test) if X_test is not None else None,\n        },\n        \"train_valid_test_class_balance\": {\n            \"y_train_class_balance\": calculate_class_balance(y_train),\n            \"y_valid_class_balance\": calculate_class_balance(y_valid),\n            \"y_test_class_balance\": calculate_class_balance(y_test)\n            if y_test is not None\n            else None,\n        },\n    }\n\n    return metadata\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.get_feature_metadata","title":"<code>get_feature_metadata(pipeline)</code>","text":"<p>Extract feature names and importances from pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>pipeline</code> <code>Pipeline</code> <p>Sklearn pipeline containing feature transformer and classifier</p> required <p>Returns:</p> Type Description <code>FeatureMetadata</code> <p>Dictionary containing feature names and their importance scores (if available)</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If the classifier doesn't support feature importance</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def get_feature_metadata(pipeline: Pipeline) -&gt; FeatureMetadata:\n    \"\"\"\n    Extract feature names and importances from pipeline.\n\n    Parameters\n    ----------\n    pipeline : Pipeline\n        Sklearn pipeline containing feature transformer and classifier\n\n    Returns\n    -------\n    FeatureMetadata\n        Dictionary containing feature names and their importance scores (if available)\n\n    Raises\n    ------\n    AttributeError\n        If the classifier doesn't support feature importance\n    \"\"\"\n    transformed_cols = pipeline.named_steps[\n        \"feature_transformer\"\n    ].get_feature_names_out()\n    classifier = pipeline.named_steps[\"classifier\"]\n\n    # Try different common feature importance attributes\n    if hasattr(classifier, \"feature_importances_\"):\n        importances = classifier.feature_importances_\n    elif hasattr(classifier, \"coef_\"):\n        importances = (\n            np.abs(classifier.coef_[0])\n            if classifier.coef_.ndim &gt; 1\n            else np.abs(classifier.coef_)\n        )\n    else:\n        raise AttributeError(\"Classifier doesn't provide feature importance scores\")\n\n    return {\n        \"feature_names\": [col.split(\"__\")[-1] for col in transformed_cols],\n        \"feature_importances\": importances.tolist(),\n    }\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.initialise_model","title":"<code>initialise_model(model_class, params, xgb_specific_params={'n_jobs': -1, 'eval_metric': 'logloss', 'enable_categorical': True})</code>","text":"<p>Initialize a model with given hyperparameters.</p> <p>Parameters:</p> Name Type Description Default <code>model_class</code> <code>Type</code> <p>The classifier class to instantiate</p> required <code>params</code> <code>Dict[str, Any]</code> <p>Model-specific parameters to set</p> required <code>xgb_specific_params</code> <code>Dict[str, Any]</code> <p>XGBoost-specific default parameters</p> <code>{'n_jobs': -1, 'eval_metric': 'logloss', 'enable_categorical': True}</code> <p>Returns:</p> Type Description <code>Any</code> <p>Initialized model instance</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def initialise_model(\n    model_class: Type,\n    params: Dict[str, Any],\n    xgb_specific_params: Dict[str, Any] = {\n        \"n_jobs\": -1,\n        \"eval_metric\": \"logloss\",\n        \"enable_categorical\": True,\n    },\n) -&gt; Any:\n    \"\"\"\n    Initialize a model with given hyperparameters.\n\n    Parameters\n    ----------\n    model_class : Type\n        The classifier class to instantiate\n    params : Dict[str, Any]\n        Model-specific parameters to set\n    xgb_specific_params : Dict[str, Any], optional\n        XGBoost-specific default parameters\n\n    Returns\n    -------\n    Any\n        Initialized model instance\n    \"\"\"\n    if model_class == XGBClassifier:\n        model = model_class(**xgb_specific_params)\n        model.set_params(**params)\n    else:\n        model = model_class(**params)\n\n    return model\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.train_classifier","title":"<code>train_classifier(train_visits, valid_visits, prediction_time, exclude_from_training_data, grid, ordinal_mappings, test_visits=None, visit_col=None, model_class=XGBClassifier, use_balanced_training=True, majority_to_minority_ratio=1.0, calibrate_probabilities=True, calibration_method='sigmoid', single_snapshot_per_visit=True, label_col='is_admitted', evaluate_on_test=False)</code>","text":"<p>Train a single model including data preparation and balancing.</p> <p>Parameters:</p> Name Type Description Default <code>train_visits</code> <code>DataFrame</code> <p>Training visits dataset</p> required <code>valid_visits</code> <code>DataFrame</code> <p>Validation visits dataset</p> required <code>prediction_time</code> <code>Tuple[int, int]</code> <p>The prediction time point to use</p> required <code>exclude_from_training_data</code> <code>List[str]</code> <p>Columns to exclude from training</p> required <code>grid</code> <code>Dict[str, List[Any]]</code> <p>Parameter grid for hyperparameter tuning</p> required <code>ordinal_mappings</code> <code>Dict[str, List[Any]]</code> <p>Mappings for ordinal categorical features</p> required <code>test_visits</code> <code>DataFrame</code> <p>Test visits dataset. Required only when evaluate_on_test=True.</p> <code>None</code> <code>visit_col</code> <code>str</code> <p>Name of the visit column. Required if single_snapshot_per_visit is True.</p> <code>None</code> <code>model_class</code> <code>Type</code> <p>The classifier class to use. Must be sklearn-compatible with fit() and predict_proba(). Defaults to XGBClassifier.</p> <code>XGBClassifier</code> <code>use_balanced_training</code> <code>bool</code> <p>Whether to use balanced training data</p> <code>True</code> <code>majority_to_minority_ratio</code> <code>float</code> <p>Ratio of majority to minority class samples</p> <code>1.0</code> <code>calibrate_probabilities</code> <code>bool</code> <p>Whether to apply probability calibration to the best model</p> <code>True</code> <code>calibration_method</code> <code>str</code> <p>Method for probability calibration ('isotonic' or 'sigmoid')</p> <code>'sigmoid'</code> <code>single_snapshot_per_visit</code> <code>bool</code> <p>Whether to select only one snapshot per visit. If True, visit_col must be provided.</p> <code>True</code> <code>label_col</code> <code>str</code> <p>Name of the column containing the target labels</p> <code>\"is_admitted\"</code> <code>evaluate_on_test</code> <code>bool</code> <p>Whether to evaluate the final model on the test set. Set to True only when satisfied with validation performance to avoid test set contamination.</p> <code>False</code> <p>Returns:</p> Type Description <code>TrainedClassifier</code> <p>Trained model, including metrics, and feature information</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def train_classifier(\n    train_visits: DataFrame,\n    valid_visits: DataFrame,\n    prediction_time: Tuple[int, int],\n    exclude_from_training_data: List[str],\n    grid: Dict[str, List[Any]],\n    ordinal_mappings: Dict[str, List[Any]],\n    test_visits: Optional[DataFrame] = None,\n    visit_col: Optional[str] = None,\n    model_class: Type = XGBClassifier,\n    use_balanced_training: bool = True,\n    majority_to_minority_ratio: float = 1.0,\n    calibrate_probabilities: bool = True,\n    calibration_method: str = \"sigmoid\",\n    single_snapshot_per_visit: bool = True,\n    label_col: str = \"is_admitted\",\n    evaluate_on_test: bool = False,\n) -&gt; TrainedClassifier:\n    \"\"\"\n    Train a single model including data preparation and balancing.\n\n    Parameters\n    ----------\n    train_visits : DataFrame\n        Training visits dataset\n    valid_visits : DataFrame\n        Validation visits dataset\n    prediction_time : Tuple[int, int]\n        The prediction time point to use\n    exclude_from_training_data : List[str]\n        Columns to exclude from training\n    grid : Dict[str, List[Any]]\n        Parameter grid for hyperparameter tuning\n    ordinal_mappings : Dict[str, List[Any]]\n        Mappings for ordinal categorical features\n    test_visits : DataFrame, optional\n        Test visits dataset. Required only when evaluate_on_test=True.\n    visit_col : str, optional\n        Name of the visit column. Required if single_snapshot_per_visit is True.\n    model_class : Type, optional\n        The classifier class to use. Must be sklearn-compatible with fit() and predict_proba().\n        Defaults to XGBClassifier.\n    use_balanced_training : bool, default=True\n        Whether to use balanced training data\n    majority_to_minority_ratio : float, default=1.0\n        Ratio of majority to minority class samples\n    calibrate_probabilities : bool, default=True\n        Whether to apply probability calibration to the best model\n    calibration_method : str, default='sigmoid'\n        Method for probability calibration ('isotonic' or 'sigmoid')\n    single_snapshot_per_visit : bool, default=True\n        Whether to select only one snapshot per visit. If True, visit_col must be provided.\n    label_col : str, default=\"is_admitted\"\n        Name of the column containing the target labels\n    evaluate_on_test : bool, default=False\n        Whether to evaluate the final model on the test set. Set to True only when\n        satisfied with validation performance to avoid test set contamination.\n\n    Returns\n    -------\n    TrainedClassifier\n        Trained model, including metrics, and feature information\n\n    \"\"\"\n    if single_snapshot_per_visit and visit_col is None:\n        raise ValueError(\n            \"visit_col must be provided when single_snapshot_per_visit is True\"\n        )\n\n    if evaluate_on_test and test_visits is None:\n        raise ValueError(\"test_visits must be provided when evaluate_on_test=True\")\n\n    # Get snapshots for each set\n    X_train, y_train = prepare_patient_snapshots(\n        train_visits,\n        prediction_time,\n        exclude_from_training_data,\n        visit_col=visit_col,\n        single_snapshot_per_visit=single_snapshot_per_visit,\n        label_col=label_col,\n    )\n    X_valid, y_valid = prepare_patient_snapshots(\n        valid_visits,\n        prediction_time,\n        exclude_from_training_data,\n        visit_col=visit_col,\n        single_snapshot_per_visit=single_snapshot_per_visit,\n        label_col=label_col,\n    )\n\n    # Only prepare test data if evaluation is requested\n    if evaluate_on_test:\n        X_test, y_test = prepare_patient_snapshots(\n            test_visits,\n            prediction_time,\n            exclude_from_training_data,\n            visit_col=visit_col,\n            single_snapshot_per_visit=single_snapshot_per_visit,\n            label_col=label_col,\n        )\n    else:\n        X_test, y_test = None, None\n\n    # Get dataset metadata before any balancing\n    dataset_metadata = get_dataset_metadata(\n        X_train, X_valid, y_train, y_valid, X_test, y_test\n    )\n\n    # Store original size and positive rate before any balancing\n    original_size = len(X_train)\n    original_positive_rate = y_train.mean()\n\n    if use_balanced_training:\n        pos_indices = y_train[y_train == 1].index\n        neg_indices = y_train[y_train == 0].index\n\n        n_pos = len(pos_indices)\n        n_neg = int(n_pos * majority_to_minority_ratio)\n\n        neg_indices_sampled = np.random.choice(\n            neg_indices, size=min(n_neg, len(neg_indices)), replace=False\n        )\n\n        train_balanced_indices = np.concatenate([pos_indices, neg_indices_sampled])\n        np.random.shuffle(train_balanced_indices)\n\n        X_train = X_train.loc[train_balanced_indices]\n        y_train = y_train.loc[train_balanced_indices]\n\n    # Create balance info after any balancing is done\n    balance_info = create_balance_info(\n        is_balanced=use_balanced_training,\n        original_size=original_size,\n        balanced_size=len(X_train),\n        original_positive_rate=original_positive_rate,\n        balanced_positive_rate=y_train.mean(),\n        majority_to_minority_ratio=majority_to_minority_ratio\n        if use_balanced_training\n        else 1.0,\n    )\n\n    # Initialize best training results with default values\n    best_training = TrainingResults(\n        prediction_time=prediction_time,\n        balance_info=balance_info,\n        # Other fields will use their default empty dictionaries\n    )\n\n    # Initialize best model container\n    best_model = TrainedClassifier(\n        training_results=best_training,\n        pipeline=None,\n        calibrated_pipeline=None,\n    )\n\n    trials_list: List[HyperParameterTrial] = []\n    best_logloss = float(\"inf\")\n\n    for params in ParameterGrid(grid):\n        # Initialize model based on provided class\n        model = initialise_model(model_class, params)\n\n        column_transformer = create_column_transformer(X_train, ordinal_mappings)\n        pipeline = Pipeline(\n            [(\"feature_transformer\", column_transformer), (\"classifier\", model)]\n        )\n\n        cv_results = chronological_cross_validation(\n            pipeline, X_train, y_train, n_splits=5\n        )\n        # Store trial results\n        trials_list.append(\n            HyperParameterTrial(\n                parameters=params.copy(),  # Make a copy to ensure immutability\n                cv_results=cv_results,\n            )\n        )\n\n        if cv_results[\"valid_logloss\"] &lt; best_logloss:\n            best_logloss = cv_results[\"valid_logloss\"]\n            best_model.pipeline = pipeline\n\n            # Get feature metadata if available\n            try:\n                feature_metadata = get_feature_metadata(pipeline)\n                has_feature_importance = True\n            except (AttributeError, NotImplementedError):\n                feature_metadata = {\n                    \"feature_names\": column_transformer.get_feature_names_out().tolist(),\n                    \"feature_importances\": [],\n                }\n                has_feature_importance = False\n\n            # Update training results\n            best_training.training_info = {\n                \"cv_trials\": trials_list,\n                \"features\": {\n                    \"names\": feature_metadata[\"feature_names\"],\n                    \"importances\": feature_metadata[\"feature_importances\"],\n                    \"has_importance_values\": has_feature_importance,\n                },\n                \"dataset_info\": dataset_metadata,\n            }\n\n            if calibrate_probabilities:\n                best_training.calibration_info = {\"method\": calibration_method}\n\n    # Apply probability calibration to the best model if requested\n    if calibrate_probabilities and best_model.pipeline is not None:\n        best_feature_transformer = best_model.pipeline.named_steps[\n            \"feature_transformer\"\n        ]\n        best_classifier = best_model.pipeline.named_steps[\"classifier\"]\n\n        X_valid_transformed = best_feature_transformer.transform(X_valid)\n\n        if sk_version &gt;= \"1.6.0\":\n            from sklearn.frozen import FrozenEstimator\n\n            calibrated_classifier = CalibratedClassifierCV(\n                estimator=FrozenEstimator(best_classifier),\n                method=calibration_method,\n            )\n        else:\n            calibrated_classifier = CalibratedClassifierCV(\n                estimator=best_classifier, method=calibration_method, cv=\"prefit\"\n            )\n        calibrated_classifier.fit(X_valid_transformed, y_valid)\n\n        calibrated_pipeline = Pipeline(\n            [\n                (\"feature_transformer\", best_feature_transformer),\n                (\"classifier\", calibrated_classifier),\n            ]\n        )\n\n        best_model.calibrated_pipeline = calibrated_pipeline\n\n        # Only evaluate on test set if requested\n        if evaluate_on_test:\n            best_training.test_results = evaluate_model(\n                calibrated_pipeline, X_test, y_test\n            )\n        else:\n            best_training.test_results = None\n\n    else:\n        # Only evaluate on test set if requested\n        if evaluate_on_test:\n            best_training.test_results = evaluate_model(\n                best_model.pipeline, X_test, y_test\n            )\n        else:\n            best_training.test_results = None\n\n    return best_model\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.train_multiple_classifiers","title":"<code>train_multiple_classifiers(train_visits, valid_visits, grid, exclude_from_training_data, ordinal_mappings, prediction_times, test_visits=None, model_name='admissions', visit_col='visit_number', calibrate_probabilities=True, calibration_method='isotonic', use_balanced_training=True, majority_to_minority_ratio=1.0, label_col='is_admitted', evaluate_on_test=False)</code>","text":"<p>Train admission prediction models for multiple prediction times.</p> <p>Parameters:</p> Name Type Description Default <code>train_visits</code> <code>DataFrame</code> <p>Training visits dataset</p> required <code>valid_visits</code> <code>DataFrame</code> <p>Validation visits dataset</p> required <code>grid</code> <code>Dict[str, List[Any]]</code> <p>Parameter grid for hyperparameter tuning</p> required <code>exclude_from_training_data</code> <code>List[str]</code> <p>Columns to exclude from training</p> required <code>ordinal_mappings</code> <code>Dict[str, List[Any]]</code> <p>Mappings for ordinal categorical features</p> required <code>prediction_times</code> <code>List[Tuple[int, int]]</code> <p>List of prediction time points</p> required <code>test_visits</code> <code>DataFrame</code> <p>Test visits dataset, by default None</p> <code>None</code> <code>model_name</code> <code>str</code> <p>Name prefix for models, by default \"admissions\"</p> <code>'admissions'</code> <code>visit_col</code> <code>str</code> <p>Name of the visit column, by default \"visit_number\"</p> <code>'visit_number'</code> <code>calibrate_probabilities</code> <code>bool</code> <p>Whether to calibrate probabilities, by default True</p> <code>True</code> <code>calibration_method</code> <code>str</code> <p>Calibration method, by default \"isotonic\"</p> <code>'isotonic'</code> <code>use_balanced_training</code> <code>bool</code> <p>Whether to use balanced training, by default True</p> <code>True</code> <code>majority_to_minority_ratio</code> <code>float</code> <p>Ratio for class balancing, by default 1.0</p> <code>1.0</code> <code>label_col</code> <code>str</code> <p>Name of the label column, by default \"is_admitted\"</p> <code>'is_admitted'</code> <code>evaluate_on_test</code> <code>bool</code> <p>Whether to evaluate on test set, by default False</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[str, TrainedClassifier]</code> <p>Dictionary mapping model keys to trained classifiers</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def train_multiple_classifiers(\n    train_visits: DataFrame,\n    valid_visits: DataFrame,\n    grid: Dict[str, List[Any]],\n    exclude_from_training_data: List[str],\n    ordinal_mappings: Dict[str, List[Any]],\n    prediction_times: List[Tuple[int, int]],\n    test_visits: Optional[DataFrame] = None,\n    model_name: str = \"admissions\",\n    visit_col: str = \"visit_number\",\n    calibrate_probabilities: bool = True,\n    calibration_method: str = \"isotonic\",\n    use_balanced_training: bool = True,\n    majority_to_minority_ratio: float = 1.0,\n    label_col: str = \"is_admitted\",\n    evaluate_on_test: bool = False,\n) -&gt; Dict[str, TrainedClassifier]:\n    \"\"\"Train admission prediction models for multiple prediction times.\n\n    Parameters\n    ----------\n    train_visits : DataFrame\n        Training visits dataset\n    valid_visits : DataFrame\n        Validation visits dataset\n    grid : Dict[str, List[Any]]\n        Parameter grid for hyperparameter tuning\n    exclude_from_training_data : List[str]\n        Columns to exclude from training\n    ordinal_mappings : Dict[str, List[Any]]\n        Mappings for ordinal categorical features\n    prediction_times : List[Tuple[int, int]]\n        List of prediction time points\n    test_visits : DataFrame, optional\n        Test visits dataset, by default None\n    model_name : str, optional\n        Name prefix for models, by default \"admissions\"\n    visit_col : str, optional\n        Name of the visit column, by default \"visit_number\"\n    calibrate_probabilities : bool, optional\n        Whether to calibrate probabilities, by default True\n    calibration_method : str, optional\n        Calibration method, by default \"isotonic\"\n    use_balanced_training : bool, optional\n        Whether to use balanced training, by default True\n    majority_to_minority_ratio : float, optional\n        Ratio for class balancing, by default 1.0\n    label_col : str, optional\n        Name of the label column, by default \"is_admitted\"\n    evaluate_on_test : bool, optional\n        Whether to evaluate on test set, by default False\n\n    Returns\n    -------\n    Dict[str, TrainedClassifier]\n        Dictionary mapping model keys to trained classifiers\n    \"\"\"\n    if evaluate_on_test and test_visits is None:\n        raise ValueError(\"test_visits must be provided when evaluate_on_test=True\")\n\n    trained_models: Dict[str, TrainedClassifier] = {}\n\n    for prediction_time in prediction_times:\n        print(f\"\\nProcessing: {prediction_time}\")\n        model_key = get_model_key(model_name, prediction_time)\n\n        # Train model with the new simplified interface\n        best_model = train_classifier(\n            train_visits,\n            valid_visits,\n            prediction_time,\n            exclude_from_training_data,\n            grid,\n            ordinal_mappings,\n            test_visits,\n            visit_col,\n            use_balanced_training=use_balanced_training,\n            majority_to_minority_ratio=majority_to_minority_ratio,\n            calibrate_probabilities=calibrate_probabilities,\n            calibration_method=calibration_method,\n            label_col=label_col,\n            evaluate_on_test=evaluate_on_test,\n        )\n\n        trained_models[model_key] = best_model\n\n    return trained_models\n</code></pre>"},{"location":"api/#patientflow.train.emergency_demand","title":"<code>emergency_demand</code>","text":"<p>Emergency demand prediction training module.</p> <p>This module provides functionality that is specific to the implementation of the patientflow package at University College London Hospital (ULCH). It trains models to predict emergency bed demand.</p> <p>The module trains three model types: 1. Admission prediction models (multiple classifiers, one for each prediction time) 2. Specialty prediction models (sequence-based) 3. Yet-to-arrive prediction models (aspirational)</p> <p>Functions:</p> Name Description <code>test_real_time_predictions : Test real-time prediction functionality</code> <p>Selects random test cases and validates that the trained models can generate predictions as if it where making a real-time prediction.</p> <code>train_all_models : Complete training pipeline</code> <p>Trains all three model types (admissions, specialty, yet-to-arrive) with proper validation and optional model saving.</p> <code>main : Entry point for training pipeline</code> <p>Loads configuration, data, and runs the complete training process.</p>"},{"location":"api/#patientflow.train.emergency_demand.main","title":"<code>main(data_folder_name=None)</code>","text":"<p>Main entry point for training patient flow models.</p> <p>This function orchestrates the complete training pipeline for emergency demand prediction models. It loads configuration, data, and trains all three model types: admission prediction models, specialty prediction models, and yet-to-arrive prediction models.</p> <p>Parameters:</p> Name Type Description Default <code>data_folder_name</code> <code>str</code> <p>Name of the data folder containing the training datasets. If None, will be extracted from command line arguments.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>The function trains and optionally saves models but does not return any values.</p> Notes <p>The function performs the following steps: 1. Loads configuration from config.yaml 2. Loads ED visits and inpatient arrivals data 3. Sets up model parameters and hyperparameters 4. Trains admission prediction classifiers 5. Trains specialty prediction sequence model 6. Trains yet-to-arrive prediction model 7. Optionally saves trained models 8. Optionally tests real-time prediction functionality</p> Source code in <code>src/patientflow/train/emergency_demand.py</code> <pre><code>def main(data_folder_name=None):\n    \"\"\"\n    Main entry point for training patient flow models.\n\n    This function orchestrates the complete training pipeline for emergency demand\n    prediction models. It loads configuration, data, and trains all three model\n    types: admission prediction models, specialty prediction models, and\n    yet-to-arrive prediction models.\n\n    Parameters\n    ----------\n    data_folder_name : str, optional\n        Name of the data folder containing the training datasets.\n        If None, will be extracted from command line arguments.\n\n    Returns\n    -------\n    None\n        The function trains and optionally saves models but does not return\n        any values.\n\n    Notes\n    -----\n    The function performs the following steps:\n    1. Loads configuration from config.yaml\n    2. Loads ED visits and inpatient arrivals data\n    3. Sets up model parameters and hyperparameters\n    4. Trains admission prediction classifiers\n    5. Trains specialty prediction sequence model\n    6. Trains yet-to-arrive prediction model\n    7. Optionally saves trained models\n    8. Optionally tests real-time prediction functionality\n\n    \"\"\"\n    # Parse arguments if not provided\n    if data_folder_name is None:\n        args = parse_args()\n        data_folder_name = (\n            data_folder_name if data_folder_name is not None else args.data_folder_name\n        )\n    print(f\"Loading data from folder: {data_folder_name}\")\n\n    project_root = set_project_root()\n\n    # Set file locations\n    data_file_path, _, model_file_path, config_path = set_file_paths(\n        project_root=project_root,\n        inference_time=False,\n        train_dttm=None,\n        data_folder_name=data_folder_name,\n        config_file=\"config.yaml\",\n    )\n\n    # Load parameters\n    config = load_config_file(config_path)\n\n    # Extract parameters\n    prediction_times = config[\"prediction_times\"]\n    start_training_set = config[\"start_training_set\"]\n    start_validation_set = config[\"start_validation_set\"]\n    start_test_set = config[\"start_test_set\"]\n    end_test_set = config[\"end_test_set\"]\n    prediction_window = timedelta(minutes=config[\"prediction_window\"])\n    epsilon = float(config[\"epsilon\"])\n    yta_time_interval = timedelta(minutes=config[\"yta_time_interval\"])\n    x1, y1, x2, y2 = config[\"x1\"], config[\"y1\"], config[\"x2\"], config[\"y2\"]\n\n    # Load data\n    ed_visits = load_data(\n        data_file_path=data_file_path,\n        file_name=\"ed_visits.csv\",\n        index_column=\"snapshot_id\",\n        sort_columns=[\"visit_number\", \"snapshot_date\", \"prediction_time\"],\n        eval_columns=[\"prediction_time\", \"consultation_sequence\", \"final_sequence\"],\n    )\n    inpatient_arrivals = load_data(\n        data_file_path=data_file_path, file_name=\"inpatient_arrivals.csv\"\n    )\n\n    # Create snapshot date\n    ed_visits[\"snapshot_date\"] = pd.to_datetime(\n        ed_visits[\"snapshot_date\"], dayfirst=True\n    ).dt.date\n\n    # Set up model parameters\n    grid_params = {\"n_estimators\": [30], \"subsample\": [0.7], \"colsample_bytree\": [0.7]}\n\n    exclude_columns = [\n        \"visit_number\",\n        \"snapshot_date\",\n        \"prediction_time\",\n        \"specialty\",\n        \"consultation_sequence\",\n        \"final_sequence\",\n    ]\n\n    ordinal_mappings = {\n        \"age_group\": [\n            \"0-17\",\n            \"18-24\",\n            \"25-34\",\n            \"35-44\",\n            \"45-54\",\n            \"55-64\",\n            \"65-74\",\n            \"75-115\",\n        ],\n        \"latest_acvpu\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n        \"latest_obs_manchester_triage_acuity\": [\n            \"Blue\",\n            \"Green\",\n            \"Yellow\",\n            \"Orange\",\n            \"Red\",\n        ],\n        \"latest_obs_objective_pain_score\": [\n            \"Nil\",\n            \"Mild\",\n            \"Moderate\",\n            \"Severe\\\\E\\\\Very Severe\",\n        ],\n        \"latest_obs_level_of_consciousness\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n    }\n\n    specialties = [\"surgical\", \"haem/onc\", \"medical\", \"paediatric\"]\n    cdf_cut_points = [0.9, 0.7]\n    curve_params = (x1, y1, x2, y2)\n    random_seed = 42\n\n    # Call train_all_models with prepared parameters\n    train_all_models(\n        visits=ed_visits,\n        start_training_set=start_training_set,\n        start_validation_set=start_validation_set,\n        start_test_set=start_test_set,\n        end_test_set=end_test_set,\n        yta=inpatient_arrivals,\n        model_file_path=model_file_path,\n        prediction_times=prediction_times,\n        prediction_window=prediction_window,\n        yta_time_interval=yta_time_interval,\n        epsilon=epsilon,\n        curve_params=curve_params,\n        grid_params=grid_params,\n        exclude_columns=exclude_columns,\n        ordinal_mappings=ordinal_mappings,\n        specialties=specialties,\n        cdf_cut_points=cdf_cut_points,\n        random_seed=random_seed,\n    )\n\n    return\n</code></pre>"},{"location":"api/#patientflow.train.emergency_demand.test_real_time_predictions","title":"<code>test_real_time_predictions(visits, models, prediction_window, specialties, cdf_cut_points, curve_params, random_seed)</code>","text":"<p>Test real-time predictions by selecting a random sample from the visits dataset and generating predictions using the trained models.</p> <p>Parameters:</p> Name Type Description Default <code>visits</code> <code>DataFrame</code> <p>DataFrame containing visit data with columns including 'prediction_time', 'snapshot_date', and other required features for predictions.</p> required <code>models</code> <code>Tuple[Dict[str, TrainedClassifier], SequenceToOutcomePredictor, ParametricIncomingAdmissionPredictor]</code> <p>Tuple containing: - trained_classifiers: TrainedClassifier containing admission predictions - spec_model: SequenceToOutcomePredictor for specialty predictions - yet_to_arrive_model: ParametricIncomingAdmissionPredictor for yet-to-arrive predictions</p> required <code>prediction_window</code> <code>int</code> <p>Size of the prediction window in minutes for which to generate forecasts.</p> required <code>specialties</code> <code>list[str]</code> <p>List of specialty names to generate predictions for (e.g., ['surgical', 'medical', 'paediatric']).</p> required <code>cdf_cut_points</code> <code>list[float]</code> <p>List of probability thresholds for cumulative distribution function cut points (e.g., [0.9, 0.7]).</p> required <code>curve_params</code> <code>tuple[float, float, float, float]</code> <p>Parameters (x1, y1, x2, y2) defining the curve used for predictions.</p> required <code>random_seed</code> <code>int</code> <p>Random seed for reproducible sampling of test cases.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing: - 'prediction_time': str, The time point for which predictions were made - 'prediction_date': str, The date for which predictions were made - 'realtime_preds': dict, The generated predictions for the sample</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If real-time inference fails, with detailed error message printed before system exit.</p> Notes <p>The function selects a single random row from the visits DataFrame and generates predictions for that specific time point using all provided models. The predictions are made using the create_predictions() function with the specified parameters.</p> Source code in <code>src/patientflow/train/emergency_demand.py</code> <pre><code>def test_real_time_predictions(\n    visits,\n    models: Tuple[\n        Dict[str, TrainedClassifier],\n        SequenceToOutcomePredictor,\n        ParametricIncomingAdmissionPredictor,\n    ],\n    prediction_window,\n    specialties,\n    cdf_cut_points,\n    curve_params,\n    random_seed,\n):\n    \"\"\"\n    Test real-time predictions by selecting a random sample from the visits dataset\n    and generating predictions using the trained models.\n\n    Parameters\n    ----------\n    visits : pd.DataFrame\n        DataFrame containing visit data with columns including 'prediction_time',\n        'snapshot_date', and other required features for predictions.\n    models : Tuple[Dict[str, TrainedClassifier], SequenceToOutcomePredictor, ParametricIncomingAdmissionPredictor]\n        Tuple containing:\n        - trained_classifiers: TrainedClassifier containing admission predictions\n        - spec_model: SequenceToOutcomePredictor for specialty predictions\n        - yet_to_arrive_model: ParametricIncomingAdmissionPredictor for yet-to-arrive predictions\n    prediction_window : int\n        Size of the prediction window in minutes for which to generate forecasts.\n    specialties : list[str]\n        List of specialty names to generate predictions for (e.g., ['surgical',\n        'medical', 'paediatric']).\n    cdf_cut_points : list[float]\n        List of probability thresholds for cumulative distribution function\n        cut points (e.g., [0.9, 0.7]).\n    curve_params : tuple[float, float, float, float]\n        Parameters (x1, y1, x2, y2) defining the curve used for predictions.\n    random_seed : int\n        Random seed for reproducible sampling of test cases.\n\n    Returns\n    -------\n    dict\n        Dictionary containing:\n        - 'prediction_time': str, The time point for which predictions were made\n        - 'prediction_date': str, The date for which predictions were made\n        - 'realtime_preds': dict, The generated predictions for the sample\n\n    Raises\n    ------\n    Exception\n        If real-time inference fails, with detailed error message printed before\n        system exit.\n\n    Notes\n    -----\n    The function selects a single random row from the visits DataFrame and\n    generates predictions for that specific time point using all provided models.\n    The predictions are made using the create_predictions() function with the\n    specified parameters.\n    \"\"\"\n    # Select random test set row\n    random_row = visits.sample(n=1, random_state=random_seed)\n    prediction_time = random_row.prediction_time.values[0]\n    prediction_date = random_row.snapshot_date.values[0]\n\n    # Get prediction snapshots\n    prediction_snapshots = visits[\n        (visits.prediction_time == prediction_time)\n        &amp; (visits.snapshot_date == prediction_date)\n    ]\n\n    trained_classifiers, spec_model, yet_to_arrive_model = models\n\n    # Find the model matching the required prediction time\n    classifier = None\n    for model_key, trained_model in trained_classifiers.items():\n        if trained_model.training_results.prediction_time == prediction_time:\n            classifier = trained_model\n            break\n\n    if classifier is None:\n        raise ValueError(f\"No model found for prediction time {prediction_time}\")\n\n    try:\n        x1, y1, x2, y2 = curve_params\n        _ = create_predictions(\n            models=(classifier, spec_model, yet_to_arrive_model),\n            prediction_time=prediction_time,\n            prediction_snapshots=prediction_snapshots,\n            specialties=specialties,\n            prediction_window=prediction_window,\n            cdf_cut_points=cdf_cut_points,\n            x1=x1,\n            y1=y1,\n            x2=x2,\n            y2=y2,\n        )\n        print(\"Real-time inference ran correctly\")\n    except Exception as e:\n        print(f\"Real-time inference failed due to this error: {str(e)}\")\n        sys.exit(1)\n\n    return\n</code></pre>"},{"location":"api/#patientflow.train.emergency_demand.train_all_models","title":"<code>train_all_models(visits, start_training_set, start_validation_set, start_test_set, end_test_set, yta, prediction_times, prediction_window, yta_time_interval, epsilon, grid_params, exclude_columns, ordinal_mappings, random_seed, visit_col='visit_number', specialties=None, cdf_cut_points=None, curve_params=None, model_file_path=None, save_models=True, test_realtime=True)</code>","text":"<p>Train and evaluate patient flow models.</p> <p>Parameters:</p> Name Type Description Default <code>visits</code> <code>DataFrame</code> <p>DataFrame containing visit data.</p> required <code>yta</code> <code>DataFrame</code> <p>DataFrame containing yet-to-arrive data.</p> required <code>prediction_times</code> <code>list</code> <p>List of times for making predictions.</p> required <code>prediction_window</code> <code>int</code> <p>Prediction window size in minutes.</p> required <code>yta_time_interval</code> <code>int</code> <p>Interval size for yet-to-arrive predictions in minutes.</p> required <code>epsilon</code> <code>float</code> <p>Epsilon parameter for model training.</p> required <code>grid_params</code> <code>dict</code> <p>Hyperparameter grid for model training.</p> required <code>exclude_columns</code> <code>list</code> <p>Columns to exclude during training.</p> required <code>ordinal_mappings</code> <code>dict</code> <p>Ordinal variable mappings for categorical features.</p> required <code>random_seed</code> <code>int</code> <p>Random seed for reproducibility.</p> required <code>visit_col</code> <code>str</code> <p>Name of column in dataset that is used to identify a hospital visit (eg visit_number, csn).</p> <code>'visit_number'</code> <code>specialties</code> <code>list</code> <p>List of specialties to consider. Required if test_realtime is True.</p> <code>None</code> <code>cdf_cut_points</code> <code>list</code> <p>CDF cut points for predictions. Required if test_realtime is True.</p> <code>None</code> <code>curve_params</code> <code>tuple</code> <p>Curve parameters (x1, y1, x2, y2). Required if test_realtime is True.</p> <code>None</code> <code>model_file_path</code> <code>Path</code> <p>Path to save trained models. Required if save_models is True.</p> <code>None</code> <code>save_models</code> <code>bool</code> <p>Whether to save the trained models to disk. Defaults to True.</p> <code>True</code> <code>test_realtime</code> <code>bool</code> <p>Whether to run real-time prediction tests. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If save_models is True but model_file_path is not provided, or if test_realtime is True but any of specialties, cdf_cut_points, or curve_params are not provided.</p> Notes <p>The function generates model names internally: - \"admissions\": \"admissions\" - \"specialty\": \"ed_specialty\" - \"yet_to_arrive\": f\"yet_to_arrive_{int(prediction_window.total_seconds()/3600)}_hours\"</p> Source code in <code>src/patientflow/train/emergency_demand.py</code> <pre><code>def train_all_models(\n    visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    yta,\n    prediction_times,\n    prediction_window: timedelta,\n    yta_time_interval: timedelta,\n    epsilon,\n    grid_params,\n    exclude_columns,\n    ordinal_mappings,\n    random_seed,\n    visit_col=\"visit_number\",\n    specialties=None,\n    cdf_cut_points=None,\n    curve_params=None,\n    model_file_path=None,\n    save_models=True,\n    test_realtime=True,\n):\n    \"\"\"\n    Train and evaluate patient flow models.\n\n    Parameters\n    ----------\n    visits : pd.DataFrame\n        DataFrame containing visit data.\n    yta : pd.DataFrame\n        DataFrame containing yet-to-arrive data.\n    prediction_times : list\n        List of times for making predictions.\n    prediction_window : int\n        Prediction window size in minutes.\n    yta_time_interval : int\n        Interval size for yet-to-arrive predictions in minutes.\n    epsilon : float\n        Epsilon parameter for model training.\n    grid_params : dict\n        Hyperparameter grid for model training.\n    exclude_columns : list\n        Columns to exclude during training.\n    ordinal_mappings : dict\n        Ordinal variable mappings for categorical features.\n    random_seed : int\n        Random seed for reproducibility.\n    visit_col : str, optional\n        Name of column in dataset that is used to identify a hospital visit (eg visit_number, csn).\n    specialties : list, optional\n        List of specialties to consider. Required if test_realtime is True.\n    cdf_cut_points : list, optional\n        CDF cut points for predictions. Required if test_realtime is True.\n    curve_params : tuple, optional\n        Curve parameters (x1, y1, x2, y2). Required if test_realtime is True.\n    model_file_path : Path, optional\n        Path to save trained models. Required if save_models is True.\n    save_models : bool, optional\n        Whether to save the trained models to disk. Defaults to True.\n    test_realtime : bool, optional\n        Whether to run real-time prediction tests. Defaults to True.\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        If save_models is True but model_file_path is not provided,\n        or if test_realtime is True but any of specialties, cdf_cut_points, or curve_params are not provided.\n\n    Notes\n    -----\n    The function generates model names internally:\n    - \"admissions\": \"admissions\"\n    - \"specialty\": \"ed_specialty\"\n    - \"yet_to_arrive\": f\"yet_to_arrive_{int(prediction_window.total_seconds()/3600)}_hours\"\n    \"\"\"\n    # Validate parameters\n    if save_models and model_file_path is None:\n        raise ValueError(\"model_file_path must be provided when save_models is True\")\n\n    if test_realtime:\n        if specialties is None:\n            raise ValueError(\"specialties must be provided when test_realtime is True\")\n        if cdf_cut_points is None:\n            raise ValueError(\n                \"cdf_cut_points must be provided when test_realtime is True\"\n            )\n        if curve_params is None:\n            raise ValueError(\"curve_params must be provided when test_realtime is True\")\n\n    # Set random seed\n    np.random.seed(random_seed)\n\n    # Define model names internally\n    model_names = {\n        \"admissions\": \"admissions\",\n        \"specialty\": \"ed_specialty\",\n        \"yet_to_arrive\": f\"yet_to_arrive_{int(prediction_window.total_seconds()/3600)}_hours\",\n    }\n\n    if \"arrival_datetime\" in visits.columns:\n        col_name = \"arrival_datetime\"\n    else:\n        col_name = \"snapshot_date\"\n\n    train_visits, valid_visits, test_visits = create_temporal_splits(\n        visits,\n        start_training_set,\n        start_validation_set,\n        start_test_set,\n        end_test_set,\n        col_name=col_name,\n    )\n\n    train_yta, _, _ = create_temporal_splits(\n        yta[(~yta.specialty.isnull())],\n        start_training_set,\n        start_validation_set,\n        start_test_set,\n        end_test_set,\n        col_name=\"arrival_datetime\",\n    )\n\n    # Use predicted_times from visits if not explicitly provided\n    if prediction_times is None:\n        prediction_times = list(visits.prediction_time.unique())\n\n    # Train admission models\n    admission_models = train_multiple_classifiers(\n        train_visits=train_visits,\n        valid_visits=valid_visits,\n        test_visits=test_visits,\n        grid=grid_params,\n        exclude_from_training_data=exclude_columns,\n        ordinal_mappings=ordinal_mappings,\n        prediction_times=prediction_times,\n        model_name=model_names[\"admissions\"],\n        visit_col=visit_col,\n    )\n\n    # Save admission models if requested\n\n    if save_models:\n        save_model(admission_models, model_names[\"admissions\"], model_file_path)\n\n    # Train specialty model\n    specialty_model = train_sequence_predictor(\n        train_visits=train_visits,\n        model_name=model_names[\"specialty\"],\n        input_var=\"consultation_sequence\",\n        grouping_var=\"final_sequence\",\n        outcome_var=\"specialty\",\n        visit_col=visit_col,\n    )\n\n    # Save specialty model if requested\n    if save_models:\n        save_model(specialty_model, model_names[\"specialty\"], model_file_path)\n\n    # Train yet-to-arrive model\n    yta_model_name = model_names[\"yet_to_arrive\"]\n\n    num_days = (start_validation_set - start_training_set).days\n\n    yta_model = train_parametric_admission_predictor(\n        train_visits=train_visits,\n        train_yta=train_yta,\n        prediction_window=prediction_window,\n        yta_time_interval=yta_time_interval,\n        prediction_times=prediction_times,\n        epsilon=epsilon,\n        num_days=num_days,\n    )\n\n    # Save yet-to-arrive model if requested\n    if save_models:\n        save_model(yta_model, yta_model_name, model_file_path)\n        print(f\"Models have been saved to {model_file_path}\")\n\n    # Test real-time predictions if requested\n    if test_realtime:\n        visits[\"elapsed_los\"] = visits[\"elapsed_los\"].apply(\n            lambda x: timedelta(seconds=x)\n        )\n        test_real_time_predictions(\n            visits=visits,\n            models=(admission_models, specialty_model, yta_model),\n            prediction_window=prediction_window,\n            specialties=specialties,\n            cdf_cut_points=cdf_cut_points,\n            curve_params=curve_params,\n            random_seed=random_seed,\n        )\n\n    return\n</code></pre>"},{"location":"api/#patientflow.train.incoming_admission_predictor","title":"<code>incoming_admission_predictor</code>","text":"<p>Training utility for parametric admission prediction models.</p> <p>This module provides functions for training parametric admission prediction models, specifically for predicting yet-to-arrive (YTA) patient volumes using parametric curves. It includes utilities for creating specialty filters and training parametric admission predictors.</p> <p>The logic in this module is specific to the implementation at UCLH.</p>"},{"location":"api/#patientflow.train.incoming_admission_predictor.create_yta_filters","title":"<code>create_yta_filters(df)</code>","text":"<p>Create specialty filters for categorizing patients by specialty and age group.</p> <p>This function generates a dictionary of filters based on specialty categories, with special handling for pediatric patients. It uses the SpecialCategoryParams class to determine which specialties correspond to pediatric care.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing patient data with columns that include either 'age_on_arrival' or 'age_group' for pediatric classification.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary mapping specialty names to filter configurations. Each configuration contains: - For pediatric specialty: {\"is_child\": True} - For other specialties: {\"specialty\": specialty_name, \"is_child\": False}</p> Source code in <code>src/patientflow/train/incoming_admission_predictor.py</code> <pre><code>def create_yta_filters(df):\n    \"\"\"\n    Create specialty filters for categorizing patients by specialty and age group.\n\n    This function generates a dictionary of filters based on specialty categories,\n    with special handling for pediatric patients. It uses the SpecialCategoryParams\n    class to determine which specialties correspond to pediatric care.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame containing patient data with columns that include either\n        'age_on_arrival' or 'age_group' for pediatric classification.\n\n    Returns\n    -------\n    dict\n        A dictionary mapping specialty names to filter configurations.\n        Each configuration contains:\n        - For pediatric specialty: {\"is_child\": True}\n        - For other specialties: {\"specialty\": specialty_name, \"is_child\": False}\n\n    \"\"\"\n    # Get the special category parameters using the picklable implementation\n    special_params = create_special_category_objects(df.columns)\n\n    # Extract necessary data from the special_params\n    special_category_dict = special_params[\"special_category_dict\"]\n\n    # Create the specialty_filters dictionary\n    specialty_filters = {}\n\n    for specialty, is_paediatric_flag in special_category_dict.items():\n        if is_paediatric_flag == 1.0:\n            # For the paediatric specialty, set `is_child` to True\n            specialty_filters[specialty] = {\"is_child\": True}\n        else:\n            # For other specialties, set `is_child` to False\n            specialty_filters[specialty] = {\"specialty\": specialty, \"is_child\": False}\n\n    return specialty_filters\n</code></pre>"},{"location":"api/#patientflow.train.incoming_admission_predictor.train_parametric_admission_predictor","title":"<code>train_parametric_admission_predictor(train_visits, train_yta, prediction_window, yta_time_interval, prediction_times, num_days, epsilon=1e-06)</code>","text":"<p>Train a parametric yet-to-arrive prediction model.</p> <p>Parameters:</p> Name Type Description Default <code>train_visits</code> <code>DataFrame</code> <p>Visits dataset (used for identifying special categories).</p> required <code>train_yta</code> <code>DataFrame</code> <p>Training data for yet-to-arrive predictions.</p> required <code>prediction_window</code> <code>timedelta</code> <p>Time window for predictions as a timedelta.</p> required <code>yta_time_interval</code> <code>timedelta</code> <p>Time interval for predictions as a timedelta.</p> required <code>prediction_times</code> <code>List[float]</code> <p>List of prediction times.</p> required <code>num_days</code> <code>int</code> <p>Number of days to consider.</p> required <code>epsilon</code> <code>float</code> <p>Epsilon parameter for model, by default 10e-7.</p> <code>1e-06</code> <p>Returns:</p> Type Description <code>ParametricIncomingAdmissionPredictor</code> <p>Trained ParametricIncomingAdmissionPredictor model.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If prediction_window or yta_time_interval are not timedelta objects.</p> Source code in <code>src/patientflow/train/incoming_admission_predictor.py</code> <pre><code>def train_parametric_admission_predictor(\n    train_visits: DataFrame,\n    train_yta: DataFrame,\n    prediction_window: timedelta,\n    yta_time_interval: timedelta,\n    prediction_times: List[float],\n    num_days: int,\n    epsilon: float = 10e-7,\n) -&gt; ParametricIncomingAdmissionPredictor:\n    \"\"\"\n    Train a parametric yet-to-arrive prediction model.\n\n    Parameters\n    ----------\n    train_visits : DataFrame\n        Visits dataset (used for identifying special categories).\n    train_yta : DataFrame\n        Training data for yet-to-arrive predictions.\n    prediction_window : timedelta\n        Time window for predictions as a timedelta.\n    yta_time_interval : timedelta\n        Time interval for predictions as a timedelta.\n    prediction_times : List[float]\n        List of prediction times.\n    num_days : int\n        Number of days to consider.\n    epsilon : float, optional\n        Epsilon parameter for model, by default 10e-7.\n\n    Returns\n    -------\n    ParametricIncomingAdmissionPredictor\n        Trained ParametricIncomingAdmissionPredictor model.\n\n    Raises\n    ------\n    TypeError\n        If prediction_window or yta_time_interval are not timedelta objects.\n    \"\"\"\n\n    if not isinstance(prediction_window, timedelta):\n        raise TypeError(\"prediction_window must be a timedelta object\")\n    if not isinstance(yta_time_interval, timedelta):\n        raise TypeError(\"yta_time_interval must be a timedelta object\")\n\n    if train_yta.index.name is None:\n        if \"arrival_datetime\" in train_yta.columns:\n            # Convert to datetime using the actual values, not pandas objects\n            train_yta = train_yta.copy()\n            train_yta[\"arrival_datetime\"] = pd.to_datetime(\n                train_yta[\"arrival_datetime\"].values, utc=True\n            )\n            train_yta.set_index(\"arrival_datetime\", inplace=True)\n\n    elif train_yta.index.name != \"arrival_datetime\":\n        print(\"Dataset needs arrival_datetime column\")\n\n    specialty_filters = create_yta_filters(train_visits)\n\n    yta_model = ParametricIncomingAdmissionPredictor(filters=specialty_filters)\n    yta_model.fit(\n        train_df=train_yta,\n        prediction_window=prediction_window,\n        yta_time_interval=yta_time_interval,\n        prediction_times=prediction_times,\n        epsilon=epsilon,\n        num_days=num_days,\n    )\n\n    return yta_model\n</code></pre>"},{"location":"api/#patientflow.train.sequence_predictor","title":"<code>sequence_predictor</code>","text":"<p>Training utility for sequence prediction models.</p> <p>This module provides functions for training sequence-based prediction models, specifically for predicting patient outcomes based on visit sequences. It includes utilities for filtering patient data and training specialized sequence predictors.</p> <p>The logic in this module is specific to the implementation at UCLH.</p>"},{"location":"api/#patientflow.train.sequence_predictor.get_default_visits","title":"<code>get_default_visits(admitted)</code>","text":"<p>Filter a dataframe of patient visits to include only non-pediatric patients.</p> <p>This function identifies and removes pediatric patients from the dataset based on both age criteria and specialty assignment. It automatically detects the appropriate age column format from the provided dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>admitted</code> <code>DataFrame</code> <p>A pandas DataFrame containing patient visit information. Must include either 'age_on_arrival' or 'age_group' columns, and a 'specialty' column.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A filtered DataFrame containing only non-pediatric patients (adults).</p> Notes <p>The function automatically detects which age-related columns are present in the dataframe and configures the appropriate filtering logic. It removes patients who are either: 1. Identified as pediatric based on age criteria, or 2. Assigned to a pediatric specialty</p> Source code in <code>src/patientflow/train/sequence_predictor.py</code> <pre><code>def get_default_visits(admitted: DataFrame) -&gt; DataFrame:\n    \"\"\"\n    Filter a dataframe of patient visits to include only non-pediatric patients.\n\n    This function identifies and removes pediatric patients from the dataset based on\n    both age criteria and specialty assignment. It automatically detects the appropriate\n    age column format from the provided dataframe.\n\n    Parameters\n    ----------\n    admitted : DataFrame\n        A pandas DataFrame containing patient visit information. Must include either\n        'age_on_arrival' or 'age_group' columns, and a 'specialty' column.\n\n    Returns\n    -------\n    DataFrame\n        A filtered DataFrame containing only non-pediatric patients (adults).\n\n    Notes\n    ------\n    The function automatically detects which age-related columns are present in the\n    dataframe and configures the appropriate filtering logic. It removes patients who\n    are either:\n    1. Identified as pediatric based on age criteria, or\n    2. Assigned to a pediatric specialty\n\n    \"\"\"\n    # Get configuration for categorizing patients based on age columns\n    special_params = create_special_category_objects(admitted.columns)\n\n    # Extract function that identifies non-pediatric patients\n    opposite_special_category_func = special_params[\"special_func_map\"][\"default\"]\n\n    # Determine which category is the special category (should be \"paediatric\")\n    special_category_key = next(\n        key\n        for key, value in special_params[\"special_category_dict\"].items()\n        if value == 1.0\n    )\n\n    # Filter out pediatric patients based on both age criteria and specialty\n    filtered_admitted = admitted[\n        admitted.apply(opposite_special_category_func, axis=1)\n        &amp; (admitted[\"specialty\"] != special_category_key)\n    ]\n\n    return filtered_admitted\n</code></pre>"},{"location":"api/#patientflow.train.sequence_predictor.train_sequence_predictor","title":"<code>train_sequence_predictor(train_visits, model_name, visit_col, input_var, grouping_var, outcome_var)</code>","text":"<p>Train a specialty prediction model.</p> <p>Parameters:</p> Name Type Description Default <code>train_visits</code> <code>DataFrame</code> <p>Training data containing visit information.</p> required <code>model_name</code> <code>str</code> <p>Name identifier for the model.</p> required <code>visit_col</code> <code>str</code> <p>Column name containing visit identifiers.</p> required <code>input_var</code> <code>str</code> <p>Column name for input sequence.</p> required <code>grouping_var</code> <code>str</code> <p>Column name for grouping sequence.</p> required <code>outcome_var</code> <code>str</code> <p>Column name for target variable.</p> required <p>Returns:</p> Type Description <code>SequencePredictor</code> <p>Trained SequencePredictor model.</p> Source code in <code>src/patientflow/train/sequence_predictor.py</code> <pre><code>def train_sequence_predictor(\n    train_visits: DataFrame,\n    model_name: str,\n    visit_col: str,\n    input_var: str,\n    grouping_var: str,\n    outcome_var: str,\n) -&gt; SequenceToOutcomePredictor:\n    \"\"\"\n    Train a specialty prediction model.\n\n    Parameters\n    ----------\n    train_visits : DataFrame\n        Training data containing visit information.\n    model_name : str\n        Name identifier for the model.\n    visit_col : str\n        Column name containing visit identifiers.\n    input_var : str\n        Column name for input sequence.\n    grouping_var : str\n        Column name for grouping sequence.\n    outcome_var : str\n        Column name for target variable.\n\n    Returns\n    -------\n    SequencePredictor\n        Trained SequencePredictor model.\n    \"\"\"\n    visits_single = select_one_snapshot_per_visit(train_visits, visit_col)\n    admitted = visits_single[\n        (visits_single.is_admitted) &amp; ~(visits_single.specialty.isnull())\n    ]\n    filtered_admitted = get_default_visits(admitted)\n\n    filtered_admitted.loc[:, input_var] = filtered_admitted[input_var].apply(\n        lambda x: tuple(x) if x else ()\n    )\n    filtered_admitted.loc[:, grouping_var] = filtered_admitted[grouping_var].apply(\n        lambda x: tuple(x) if x else ()\n    )\n\n    spec_model = SequenceToOutcomePredictor(\n        input_var=input_var,\n        grouping_var=grouping_var,\n        outcome_var=outcome_var,\n    )\n    spec_model.fit(filtered_admitted)\n\n    return spec_model\n</code></pre>"},{"location":"api/#patientflow.train.utils","title":"<code>utils</code>","text":""},{"location":"api/#patientflow.train.utils.save_model","title":"<code>save_model(model, model_name, model_file_path)</code>","text":"<p>Save trained model(s) to disk.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>object or dict</code> <p>A single model instance or a dictionary of models to save.</p> required <code>model_name</code> <code>str</code> <p>Base name to use for saving the model(s).</p> required <code>model_file_path</code> <code>Path</code> <p>Directory path where the model(s) will be saved.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/patientflow/train/utils.py</code> <pre><code>def save_model(model, model_name, model_file_path):\n    \"\"\"\n    Save trained model(s) to disk.\n\n    Parameters\n    ----------\n    model : object or dict\n        A single model instance or a dictionary of models to save.\n    model_name : str\n        Base name to use for saving the model(s).\n    model_file_path : Path\n        Directory path where the model(s) will be saved.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    if isinstance(model, dict):\n        # Handle dictionary of models (e.g., admission models)\n        for name, m in model.items():\n            full_path = model_file_path / name\n            full_path = full_path.with_suffix(\".joblib\")\n            dump(m, full_path)\n    else:\n        # Handle single model (e.g., specialty or yet-to-arrive model)\n        full_path = model_file_path / model_name\n        full_path = full_path.with_suffix(\".joblib\")\n        dump(model, full_path)\n</code></pre>"},{"location":"api/#patientflow.viz","title":"<code>viz</code>","text":"<p>Visualization module for patient flow analysis.</p> <p>This module provides various plotting and visualization functions for analyzing patient flow data, model results, and evaluation metrics.</p>"},{"location":"api/#patientflow.viz.arrival_rates","title":"<code>arrival_rates</code>","text":"<p>Visualization functions for inpatient arrival rates and cumulative statistics.</p> <p>This module provides functions to visualize time-varying arrival rates and cumulative arrivals, over the course of a day.</p> <p>Functions:</p> Name Description <code>annotate_hour_line : function</code> <p>Annotate hour lines on a matplotlib plot</p> <code>plot_arrival_rates : function</code> <p>Plot arrival rates for one or two datasets</p> <code>plot_cumulative_arrival_rates : function</code> <p>Plot cumulative arrival rates with statistical distributions</p>"},{"location":"api/#patientflow.viz.arrival_rates.annotate_hour_line","title":"<code>annotate_hour_line(hour_line, y_value, hour_values, start_plot_index, line_styles, x_margin, annotation_prefix, text_y_offset=1, text_x_position=None, slope=None, x1=None, y1=None)</code>","text":"<p>Annotate hour lines on a matplotlib plot with consistent formatting.</p> <p>Parameters:</p> Name Type Description Default <code>hour_line</code> <code>int</code> <p>The hour to annotate on the plot.</p> required <code>y_value</code> <code>float</code> <p>The y-coordinate for annotation positioning.</p> required <code>hour_values</code> <code>list of int</code> <p>Hour values corresponding to the x-axis positions.</p> required <code>start_plot_index</code> <code>int</code> <p>Starting index for the plot's data.</p> required <code>line_styles</code> <code>dict</code> <p>Line styles for annotations keyed by hour.</p> required <code>x_margin</code> <code>float</code> <p>Margin added to x-axis for annotation positioning.</p> required <code>annotation_prefix</code> <code>str</code> <p>Prefix for the annotation text (e.g., \"On average\").</p> required <code>text_y_offset</code> <code>float</code> <p>Vertical offset for the annotation text from the line, by default 1.</p> <code>1</code> <code>text_x_position</code> <code>float</code> <p>Horizontal position for annotation text, by default None.</p> <code>None</code> <code>slope</code> <code>float</code> <p>Slope of a line for extended annotations, by default None.</p> <code>None</code> <code>x1</code> <code>float</code> <p>Reference x-coordinate for slope-based annotation, by default None.</p> <code>None</code> <code>y1</code> <code>float</code> <p>Reference y-coordinate for slope-based annotation, by default None.</p> <code>None</code> Source code in <code>src/patientflow/viz/arrival_rates.py</code> <pre><code>def annotate_hour_line(\n    hour_line,\n    y_value,\n    hour_values,\n    start_plot_index,\n    line_styles,\n    x_margin,\n    annotation_prefix,\n    text_y_offset=1,\n    text_x_position=None,\n    slope=None,\n    x1=None,\n    y1=None,\n):\n    \"\"\"Annotate hour lines on a matplotlib plot with consistent formatting.\n\n    Parameters\n    ----------\n    hour_line : int\n        The hour to annotate on the plot.\n    y_value : float\n        The y-coordinate for annotation positioning.\n    hour_values : list of int\n        Hour values corresponding to the x-axis positions.\n    start_plot_index : int\n        Starting index for the plot's data.\n    line_styles : dict\n        Line styles for annotations keyed by hour.\n    x_margin : float\n        Margin added to x-axis for annotation positioning.\n    annotation_prefix : str\n        Prefix for the annotation text (e.g., \"On average\").\n    text_y_offset : float, optional\n        Vertical offset for the annotation text from the line, by default 1.\n    text_x_position : float, optional\n        Horizontal position for annotation text, by default None.\n    slope : float, optional\n        Slope of a line for extended annotations, by default None.\n    x1 : float, optional\n        Reference x-coordinate for slope-based annotation, by default None.\n    y1 : float, optional\n        Reference y-coordinate for slope-based annotation, by default None.\n    \"\"\"\n    a = hour_values[hour_line - start_plot_index]\n    if slope is not None and x1 is not None:\n        y_a = slope * (a - x1) + y1\n        plt.plot([a, a], [0, y_a], color=\"grey\", linestyle=line_styles[hour_line])\n        plt.plot(\n            [0 - x_margin, a],\n            [y_a, y_a],\n            color=\"grey\",\n            linestyle=line_styles[hour_line],\n        )\n        annotation_text = (\n            f\"{annotation_prefix}, {int(y_a)} beds needed by {hour_line}:00\"\n        )\n        y_position = y_a + text_y_offset\n    else:\n        plt.annotate(\n            \"\",\n            xy=(a, y_value),\n            xytext=(a, 0),\n            arrowprops=dict(\n                arrowstyle=\"-\", linestyle=line_styles[hour_line], color=\"grey\"\n            ),\n        )\n        plt.annotate(\n            \"\",\n            xy=(a, y_value),\n            xytext=(hour_values[0] - x_margin, y_value),\n            arrowprops=dict(\n                arrowstyle=\"-\", linestyle=line_styles[hour_line], color=\"grey\"\n            ),\n        )\n        annotation_text = (\n            f\"{annotation_prefix}, {int(y_value)} beds needed by {hour_line}:00\"\n        ).strip()  # strip() removes leading comma if prefix is empty\n        y_position = y_value + text_y_offset\n\n    # Use custom text x position if provided, otherwise use default\n    x_position = (\n        text_x_position if text_x_position is not None else (hour_values[1] - x_margin)\n    )\n\n    plt.annotate(\n        annotation_text,\n        xy=(a / 2 if slope is not None else a, y_value),\n        xytext=(x_position, y_position),\n        va=\"bottom\",\n        ha=\"left\",\n        fontsize=10,\n    )\n</code></pre>"},{"location":"api/#patientflow.viz.arrival_rates.draw_window_visualization","title":"<code>draw_window_visualization(ax, hour_values, window_params, annotation_prefix, start_window, end_window)</code>","text":"<p>Draw the window visualization with annotations.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes to draw on</p> required <code>hour_values</code> <code>array - like</code> <p>Hour labels for x-axis</p> required <code>window_params</code> <code>tuple</code> <p>(slope, x1, y1, y2) from get_window_parameters</p> required <code>annotation_prefix</code> <code>str</code> <p>Prefix for annotations</p> required <code>start_window</code> <code>int</code> <p>Start hour for window</p> required <code>end_window</code> <code>int</code> <p>End hour for window</p> required Source code in <code>src/patientflow/viz/arrival_rates.py</code> <pre><code>def draw_window_visualization(\n    ax, hour_values, window_params, annotation_prefix, start_window, end_window\n):\n    \"\"\"Draw the window visualization with annotations.\n\n    Parameters\n    ----------\n    ax : matplotlib.axes.Axes\n        The axes to draw on\n    hour_values : array-like\n        Hour labels for x-axis\n    window_params : tuple\n        (slope, x1, y1, y2) from get_window_parameters\n    annotation_prefix : str\n        Prefix for annotations\n    start_window : int\n        Start hour for window\n    end_window : int\n        End hour for window\n    \"\"\"\n    slope, x1, y1, x2, y2 = window_params\n\n    # Draw horizontal line\n    ax.hlines(y=y2, xmin=x2, xmax=hour_values[-1], color=\"blue\", linestyle=\"--\")\n\n    # Draw diagonal line\n    ax.plot([x1, x2], [y1, y2], color=\"blue\", linestyle=\"--\")\n\n    # Add annotation\n    ax.annotate(\n        f\"{annotation_prefix}, {slope:.0f} beds need to be vacated\\n\"\n        f\"each hour between {start_window}:00 and {end_window}:00\\n\"\n        f\"to create capacity for all overnight arrivals\\n\"\n        f\"by {end_window}:00\",\n        xy=(hour_values[-1], y2 * 0.25),\n        xytext=(hour_values[-1], y2 * 0.25),\n        va=\"top\",\n        ha=\"right\",\n    )\n</code></pre>"},{"location":"api/#patientflow.viz.arrival_rates.get_window_parameters","title":"<code>get_window_parameters(data, start_window, end_window, hour_values)</code>","text":"<p>Calculate window parameters for visualization.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array - like</code> <p>Reindexed cumulative data</p> required <code>start_window</code> <code>int</code> <p>Start position in reindexed space</p> required <code>end_window</code> <code>int</code> <p>End position in reindexed space</p> required <code>hour_values</code> <code>array - like</code> <p>Original hour values for display</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>(slope, x1, y1, x2, y2) where: - slope: float, The calculated slope of the line - x1: float, Start hour value - y1: float, Start y-value - x2: float, End hour value - y2: float, End y-value</p> Source code in <code>src/patientflow/viz/arrival_rates.py</code> <pre><code>def get_window_parameters(data, start_window, end_window, hour_values):\n    \"\"\"Calculate window parameters for visualization.\n\n    Parameters\n    ----------\n    data : array-like\n        Reindexed cumulative data\n    start_window : int\n        Start position in reindexed space\n    end_window : int\n        End position in reindexed space\n    hour_values : array-like\n        Original hour values for display\n\n    Returns\n    -------\n    tuple\n        (slope, x1, y1, x2, y2) where:\n        - slope: float, The calculated slope of the line\n        - x1: float, Start hour value\n        - y1: float, Start y-value\n        - x2: float, End hour value\n        - y2: float, End y-value\n    \"\"\"\n    y1 = data[start_window]\n    y2 = data[-1]\n    x1 = hour_values[start_window]  # Get display hour\n    x2 = hour_values[end_window]  # Get display hour\n    slope = (y2 - y1) / (x2 - x1)\n\n    return slope, x1, y1, x2, y2\n</code></pre>"},{"location":"api/#patientflow.viz.arrival_rates.plot_arrival_rates","title":"<code>plot_arrival_rates(inpatient_arrivals, title, inpatient_arrivals_2=None, labels=None, lagged_by=None, curve_params=None, time_interval=60, start_plot_index=0, x_margin=0.5, file_prefix='', media_file_path=None, file_name=None, num_days=None, num_days_2=None, return_figure=False)</code>","text":"<p>Plot arrival rates for one or two datasets with optional lagged and spread rates.</p> <p>Parameters:</p> Name Type Description Default <code>inpatient_arrivals</code> <code>array - like</code> <p>Primary dataset of inpatient arrivals.</p> required <code>title</code> <code>str</code> <p>Title of the plot.</p> required <code>inpatient_arrivals_2</code> <code>array - like</code> <p>Optional second dataset for comparison, by default None.</p> <code>None</code> <code>labels</code> <code>tuple of str</code> <p>Labels for the datasets when comparing two datasets, by default None.</p> <code>None</code> <code>lagged_by</code> <code>int</code> <p>Time lag in hours to apply to the arrival rates, by default None.</p> <code>None</code> <code>curve_params</code> <code>tuple of float</code> <p>Parameters for spread arrival rates as (x1, y1, x2, y2), by default None.</p> <code>None</code> <code>time_interval</code> <code>int</code> <p>Time interval in minutes for arrival rate calculations, by default 60.</p> <code>60</code> <code>start_plot_index</code> <code>int</code> <p>Starting hour index for plotting, by default 0.</p> <code>0</code> <code>x_margin</code> <code>float</code> <p>Margin on the x-axis, by default 0.5.</p> <code>0.5</code> <code>file_prefix</code> <code>str</code> <p>Prefix for the saved file name, by default \"\".</p> <code>''</code> <code>media_file_path</code> <code>str or Path</code> <p>Directory path to save the plot, by default None.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, uses file_prefix + cleaned title.</p> <code>None</code> <code>num_days</code> <code>int</code> <p>Number of days in the first dataset, by default None.</p> <code>None</code> <code>num_days_2</code> <code>int</code> <p>Number of days in the second dataset, by default None.</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the matplotlib figure instead of displaying it, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>Returns the figure if return_figure is True, otherwise displays the plot.</p> Source code in <code>src/patientflow/viz/arrival_rates.py</code> <pre><code>def plot_arrival_rates(\n    inpatient_arrivals,\n    title,\n    inpatient_arrivals_2=None,\n    labels=None,\n    lagged_by=None,\n    curve_params=None,\n    time_interval=60,\n    start_plot_index=0,\n    x_margin=0.5,\n    file_prefix=\"\",\n    media_file_path=None,\n    file_name=None,\n    num_days=None,\n    num_days_2=None,\n    return_figure=False,\n):\n    \"\"\"Plot arrival rates for one or two datasets with optional lagged and spread rates.\n\n    Parameters\n    ----------\n    inpatient_arrivals : array-like\n        Primary dataset of inpatient arrivals.\n    title : str\n        Title of the plot.\n    inpatient_arrivals_2 : array-like, optional\n        Optional second dataset for comparison, by default None.\n    labels : tuple of str, optional\n        Labels for the datasets when comparing two datasets, by default None.\n    lagged_by : int, optional\n        Time lag in hours to apply to the arrival rates, by default None.\n    curve_params : tuple of float, optional\n        Parameters for spread arrival rates as (x1, y1, x2, y2), by default None.\n    time_interval : int, optional\n        Time interval in minutes for arrival rate calculations, by default 60.\n    start_plot_index : int, optional\n        Starting hour index for plotting, by default 0.\n    x_margin : float, optional\n        Margin on the x-axis, by default 0.5.\n    file_prefix : str, optional\n        Prefix for the saved file name, by default \"\".\n    media_file_path : str or Path, optional\n        Directory path to save the plot, by default None.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, uses file_prefix + cleaned title.\n    num_days : int, optional\n        Number of days in the first dataset, by default None.\n    num_days_2 : int, optional\n        Number of days in the second dataset, by default None.\n    return_figure : bool, optional\n        If True, returns the matplotlib figure instead of displaying it, by default False.\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        Returns the figure if return_figure is True, otherwise displays the plot.\n    \"\"\"\n    is_dual_plot = inpatient_arrivals_2 is not None\n    if is_dual_plot and labels is None:\n        labels = (\"Dataset 1\", \"Dataset 2\")\n\n    datasets = [(inpatient_arrivals, \"C0\", \"o\", num_days)]\n    if is_dual_plot:\n        datasets.append((inpatient_arrivals_2, \"C1\", \"s\", num_days_2))\n\n    # Calculate and process arrival rates for all datasets\n    processed_data = []\n    max_y_values = []\n\n    for dataset, color, marker, num_days in datasets:\n        # Calculate base arrival rates\n        arrival_rates_dict = time_varying_arrival_rates(\n            dataset, time_interval, num_days=num_days\n        )\n        arrival_rates, hour_labels, hour_values = process_arrival_rates(\n            arrival_rates_dict\n        )\n        max_y_values.append(max(arrival_rates))\n\n        # Calculate lagged rates if needed\n        arrival_rates_lagged = None\n        if lagged_by is not None:\n            arrival_rates_lagged_dict = time_varying_arrival_rates_lagged(\n                dataset, lagged_by, yta_time_interval=time_interval, num_days=num_days\n            )\n            arrival_rates_lagged, _, _ = process_arrival_rates(\n                arrival_rates_lagged_dict\n            )\n            max_y_values.append(max(arrival_rates_lagged))\n\n        # Calculate spread rates if needed\n        arrival_rates_spread = None\n        if curve_params is not None:\n            x1, y1, x2, y2 = curve_params\n            arrival_rates_spread_dict = unfettered_demand_by_hour(\n                dataset, x1, y1, x2, y2, num_days=num_days\n            )\n            arrival_rates_spread, _, _ = process_arrival_rates(\n                arrival_rates_spread_dict\n            )\n            max_y_values.append(max(arrival_rates_spread))\n\n        processed_data.append(\n            {\n                \"arrival_rates\": arrival_rates,\n                \"arrival_rates_lagged\": arrival_rates_lagged,\n                \"arrival_rates_spread\": arrival_rates_spread,\n                \"color\": color,\n                \"marker\": marker,\n                \"dataset_label\": labels[len(processed_data)] if is_dual_plot else None,\n            }\n        )\n\n    # Helper function to create cyclic data\n    def get_cyclic_data(data):\n        return data[start_plot_index:] + data[0:start_plot_index]\n\n    # Plot setup\n    fig = plt.figure(figsize=(10, 6))\n    x_values = get_cyclic_data(hour_labels)\n\n    # Plot data for each dataset\n    for data in processed_data:\n        dataset_suffix = f\" ({data['dataset_label']})\" if data[\"dataset_label\"] else \"\"\n\n        # Base arrival rates\n        base_label = f\"Arrival rates of admitted patients{dataset_suffix}\"\n        plt.plot(\n            x_values,\n            get_cyclic_data(data[\"arrival_rates\"]),\n            marker=\"x\",\n            color=data[\"color\"],\n            markersize=4,\n            linestyle=\":\" if (curve_params or lagged_by) else \"-\",\n            linewidth=1 if (curve_params or lagged_by) else None,\n            label=base_label,\n        )\n\n        if lagged_by is not None:\n            # Lagged arrival rates\n            lagged_label = f\"Average number of beds needed assuming admission\\nexactly {lagged_by} hours after arrival{dataset_suffix}\"\n            plt.plot(\n                x_values,\n                get_cyclic_data(data[\"arrival_rates_lagged\"]),\n                marker=\"o\",\n                markersize=4,\n                color=data[\"color\"],\n                linestyle=\"--\",\n                linewidth=1,\n                label=lagged_label,\n            )\n\n        if curve_params is not None and data[\"arrival_rates_spread\"] is not None:\n            # Spread arrival rates\n            spread_label = f\"Average number of beds applying ED targets of {int(y1*100)}% in {int(x1)} hours{dataset_suffix}\"\n            plt.plot(\n                x_values,\n                get_cyclic_data(data[\"arrival_rates_spread\"]),\n                marker=data[\"marker\"],  # Keep original dataset marker\n                color=data[\"color\"],  # Keep original dataset color\n                label=spread_label,\n            )\n\n    # Set plot limits and labels\n    plt.ylim(0, max(max_y_values) + 0.25)\n    plt.xlim(hour_values[0] - x_margin, hour_values[-1] + x_margin)\n\n    plt.xlabel(\"Hour of day\")\n    plt.ylabel(\"Arrival Rate (patients per hour)\")\n    plt.title(title)\n    plt.grid(True, alpha=0.3)\n\n    # Always show legend if there are multiple datasets or multiple rate types\n    if is_dual_plot or lagged_by is not None or curve_params is not None:\n        plt.legend()\n\n    plt.tight_layout()\n\n    # Save if path provided\n    if media_file_path:\n        if file_name:\n            filename = file_name\n        else:\n            filename = f\"{file_prefix}{clean_title_for_filename(title)}\"\n        plt.savefig(media_file_path / filename, dpi=300)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n</code></pre>"},{"location":"api/#patientflow.viz.arrival_rates.plot_cumulative_arrival_rates","title":"<code>plot_cumulative_arrival_rates(inpatient_arrivals, title, curve_params=None, lagged_by=None, time_interval=60, start_plot_index=0, draw_window=None, x_margin=0.5, file_prefix='', set_y_lim=None, hour_lines=[12, 17], line_styles={12: '--', 17: ':', 20: '--'}, annotation_prefix='On average', line_colour='red', media_file_path=None, file_name=None, plot_centiles=False, highlight_centile=0.9, centiles=[0.3, 0.5, 0.7, 0.9, 0.99], markers=['D', 's', '^', 'o', 'v'], line_styles_centiles=['-.', '--', ':', '-', '-'], bed_type_spec='', text_y_offset=1, num_days=None, return_figure=False)</code>","text":"<p>Plot cumulative arrival rates with optional statistical distributions.</p> <p>Parameters:</p> Name Type Description Default <code>inpatient_arrivals</code> <code>array - like</code> <p>Dataset of inpatient arrivals.</p> required <code>title</code> <code>str</code> <p>Title of the plot.</p> required <code>curve_params</code> <code>tuple of float</code> <p>Parameters for spread rates as (x1, y1, x2, y2), by default None.</p> <code>None</code> <code>lagged_by</code> <code>int</code> <p>Time lag in hours for cumulative rates, by default None.</p> <code>None</code> <code>time_interval</code> <code>int</code> <p>Time interval in minutes for rate calculations, by default 60.</p> <code>60</code> <code>start_plot_index</code> <code>int</code> <p>Starting hour index for plotting, by default 0.</p> <code>0</code> <code>draw_window</code> <code>tuple of int</code> <p>Time window for detailed annotation, by default None.</p> <code>None</code> <code>x_margin</code> <code>float</code> <p>Margin on the x-axis, by default 0.5.</p> <code>0.5</code> <code>file_prefix</code> <code>str</code> <p>Prefix for the saved file name, by default \"\".</p> <code>''</code> <code>set_y_lim</code> <code>float</code> <p>Upper limit for the y-axis, by default None.</p> <code>None</code> <code>hour_lines</code> <code>list of int</code> <p>Specific hours to annotate, by default [12, 17].</p> <code>[12, 17]</code> <code>line_styles</code> <code>dict</code> <p>Line styles for hour annotations keyed by hour, by default {12: \"--\", 17: \":\", 20: \"--\"}.</p> <code>{12: '--', 17: ':', 20: '--'}</code> <code>annotation_prefix</code> <code>str</code> <p>Prefix for annotations, by default \"On average\".</p> <code>'On average'</code> <code>line_colour</code> <code>str</code> <p>Color for the main line plot, by default \"red\".</p> <code>'red'</code> <code>media_file_path</code> <code>str or Path</code> <p>Directory path to save the plot, by default None.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, uses file_prefix + cleaned title.</p> <code>None</code> <code>plot_centiles</code> <code>bool</code> <p>Whether to include percentile visualization, by default False.</p> <code>False</code> <code>highlight_centile</code> <code>float</code> <p>Percentile to emphasize, by default 0.9. If 1.0 is provided, will use 0.9999 instead.</p> <code>0.9</code> <code>centiles</code> <code>list of float</code> <p>List of percentiles to calculate, by default [0.3, 0.5, 0.7, 0.9, 0.99].</p> <code>[0.3, 0.5, 0.7, 0.9, 0.99]</code> <code>markers</code> <code>list of str</code> <p>Marker styles for percentile lines, by default [\"D\", \"s\", \"^\", \"o\", \"v\"].</p> <code>['D', 's', '^', 'o', 'v']</code> <code>line_styles_centiles</code> <code>list of str</code> <p>Line styles for percentile visualization, by default [\"-.\", \"--\", \":\", \"-\", \"-\"].</p> <code>['-.', '--', ':', '-', '-']</code> <code>bed_type_spec</code> <code>str</code> <p>Specification for bed type in annotations, by default \"\".</p> <code>''</code> <code>text_y_offset</code> <code>float</code> <p>Vertical offset for text annotations, by default 1.</p> <code>1</code> <code>num_days</code> <code>int</code> <p>Number of days in the dataset, by default None.</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the matplotlib figure instead of displaying it, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>Returns the figure if return_figure is True, otherwise displays the plot.</p> Source code in <code>src/patientflow/viz/arrival_rates.py</code> <pre><code>def plot_cumulative_arrival_rates(\n    inpatient_arrivals,\n    title,\n    curve_params=None,\n    lagged_by=None,\n    time_interval=60,\n    start_plot_index=0,\n    draw_window=None,\n    x_margin=0.5,\n    file_prefix=\"\",\n    set_y_lim=None,\n    hour_lines=[12, 17],\n    line_styles={12: \"--\", 17: \":\", 20: \"--\"},\n    annotation_prefix=\"On average\",\n    line_colour=\"red\",\n    media_file_path=None,\n    file_name=None,\n    plot_centiles=False,\n    highlight_centile=0.9,\n    centiles=[0.3, 0.5, 0.7, 0.9, 0.99],\n    markers=[\"D\", \"s\", \"^\", \"o\", \"v\"],\n    line_styles_centiles=[\"-.\", \"--\", \":\", \"-\", \"-\"],\n    bed_type_spec=\"\",\n    text_y_offset=1,\n    num_days=None,\n    return_figure=False,\n):\n    \"\"\"Plot cumulative arrival rates with optional statistical distributions.\n\n    Parameters\n    ----------\n    inpatient_arrivals : array-like\n        Dataset of inpatient arrivals.\n    title : str\n        Title of the plot.\n    curve_params : tuple of float, optional\n        Parameters for spread rates as (x1, y1, x2, y2), by default None.\n    lagged_by : int, optional\n        Time lag in hours for cumulative rates, by default None.\n    time_interval : int, optional\n        Time interval in minutes for rate calculations, by default 60.\n    start_plot_index : int, optional\n        Starting hour index for plotting, by default 0.\n    draw_window : tuple of int, optional\n        Time window for detailed annotation, by default None.\n    x_margin : float, optional\n        Margin on the x-axis, by default 0.5.\n    file_prefix : str, optional\n        Prefix for the saved file name, by default \"\".\n    set_y_lim : float, optional\n        Upper limit for the y-axis, by default None.\n    hour_lines : list of int, optional\n        Specific hours to annotate, by default [12, 17].\n    line_styles : dict, optional\n        Line styles for hour annotations keyed by hour, by default {12: \"--\", 17: \":\", 20: \"--\"}.\n    annotation_prefix : str, optional\n        Prefix for annotations, by default \"On average\".\n    line_colour : str, optional\n        Color for the main line plot, by default \"red\".\n    media_file_path : str or Path, optional\n        Directory path to save the plot, by default None.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, uses file_prefix + cleaned title.\n    plot_centiles : bool, optional\n        Whether to include percentile visualization, by default False.\n    highlight_centile : float, optional\n        Percentile to emphasize, by default 0.9. If 1.0 is provided, will use 0.9999 instead.\n    centiles : list of float, optional\n        List of percentiles to calculate, by default [0.3, 0.5, 0.7, 0.9, 0.99].\n    markers : list of str, optional\n        Marker styles for percentile lines, by default [\"D\", \"s\", \"^\", \"o\", \"v\"].\n    line_styles_centiles : list of str, optional\n        Line styles for percentile visualization, by default [\"-.\", \"--\", \":\", \"-\", \"-\"].\n    bed_type_spec : str, optional\n        Specification for bed type in annotations, by default \"\".\n    text_y_offset : float, optional\n        Vertical offset for text annotations, by default 1.\n    num_days : int, optional\n        Number of days in the dataset, by default None.\n    return_figure : bool, optional\n        If True, returns the matplotlib figure instead of displaying it, by default False.\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        Returns the figure if return_figure is True, otherwise displays the plot.\n    \"\"\"\n\n    # Handle edge case for highlight_centile = 1.0\n    original_highlight_centile = highlight_centile\n    if highlight_centile &gt;= 1.0:\n        highlight_centile = 0.9999  # Use a very high but not exactly 1.0 value\n\n    # Ensure centiles are all valid (no 1.0 values)\n    processed_centiles = [min(c, 0.9999) if c &gt;= 1.0 else c for c in centiles]\n\n    # Data processing\n    if curve_params is not None:\n        x1, y1, x2, y2 = curve_params\n        arrival_rates_dict = unfettered_demand_by_hour(\n            inpatient_arrivals, x1, y1, x2, y2, num_days=num_days\n        )\n    elif lagged_by is not None:\n        arrival_rates_dict = time_varying_arrival_rates_lagged(\n            inpatient_arrivals, lagged_by, time_interval, num_days=num_days\n        )\n    else:\n        arrival_rates_dict = time_varying_arrival_rates(\n            inpatient_arrivals, time_interval, num_days=num_days\n        )\n\n    # Process arrival rates\n    arrival_rates, hour_labels, hour_values = process_arrival_rates(arrival_rates_dict)\n\n    # Reindex based on start_plot_index\n    rates_reindexed = (\n        list(arrival_rates)[start_plot_index:] + list(arrival_rates)[0:start_plot_index]\n    )\n    labels_reindexed = (\n        list(hour_labels)[start_plot_index:] + list(hour_labels)[0:start_plot_index]\n    )\n\n    # Calculate percentiles\n    percentiles = [[] for _ in range(len(processed_centiles))]\n    cumulative_value_at_centile = np.zeros(len(processed_centiles))\n\n    for hour in range(len(rates_reindexed)):\n        for i, centile in enumerate(processed_centiles):\n            value_at_centile = stats.poisson.ppf(centile, rates_reindexed[hour])\n            cumulative_value_at_centile[i] += value_at_centile\n            percentiles[i].append(value_at_centile)\n\n    # Set up plot\n    fig = plt.figure(figsize=(10, 6))\n    ax = plt.gca()\n\n    # Plot mean line\n    label_suffix = f\" {bed_type_spec} beds needed\" if bed_type_spec else \" beds needed\"\n    cumsum_rates = np.cumsum(rates_reindexed)\n\n    plt.plot(\n        labels_reindexed,\n        cumsum_rates,\n        marker=\"o\",\n        markersize=3,\n        color=line_colour,\n        linewidth=2,\n        alpha=0.7,\n        label=f\"Average number of{label_suffix}\",\n    )\n\n    # set max y value assuming centiles not plotted\n    max_y = cumsum_rates[-1]\n\n    if plot_centiles:\n        # Calculate and plot percentiles\n        percentiles = [[] for _ in range(len(processed_centiles))]\n        cumulative_value_at_centile = np.zeros(len(processed_centiles))\n        highlight_percentile_data = None\n\n        # Find the index of highlight_centile in processed_centiles\n        highlight_index = -1\n        for i, c in enumerate(processed_centiles):\n            if (\n                abs(c - highlight_centile) &lt; 0.0001\n            ):  # Use small epsilon for float comparison\n                highlight_index = i\n                break\n\n        # If highlight_centile is not in processed_centiles, add it\n        if highlight_index == -1:\n            processed_centiles.append(highlight_centile)\n            percentiles.append([])\n            cumulative_value_at_centile = np.append(cumulative_value_at_centile, 0)\n\n        for hour in range(len(rates_reindexed)):\n            for i, centile in enumerate(processed_centiles):\n                try:\n                    # Add error handling for ppf calculation\n                    value_at_centile = stats.poisson.ppf(centile, rates_reindexed[hour])\n\n                    # Apply a reasonable upper limit if the value is extremely large\n                    if (\n                        np.isinf(value_at_centile)\n                        or value_at_centile &gt; 1000 * rates_reindexed[hour]\n                    ):\n                        value_at_centile = 10 * rates_reindexed[hour]\n\n                    cumulative_value_at_centile[i] += value_at_centile\n                    percentiles[i].append(value_at_centile)\n                except (ValueError, OverflowError, RuntimeError):\n                    # Fallback if calculation fails\n                    fallback_value = 10 * rates_reindexed[hour]\n                    cumulative_value_at_centile[i] += fallback_value\n                    percentiles[i].append(fallback_value)\n\n                # Match the highlight centile to the processed value\n                if (\n                    abs(centile - highlight_centile) &lt; 0.0001\n                ):  # Use a small epsilon for floating point comparison\n                    highlight_percentile_data = np.cumsum(percentiles[i])\n\n        # Plot percentile lines\n        for i, centile in enumerate(processed_centiles):\n            marker = markers[i % len(markers)]\n            line_style = line_styles_centiles[i % len(line_styles_centiles)]\n            linewidth = 2 if centile == highlight_centile else 1\n            alpha = 1.0 if centile == highlight_centile else 0.7\n\n            # If the user requested 1.0, display as 99.99% since a Poisson distribution\n            # cannot provide exact 100% probability with any finite value\n            display_centile = processed_centiles[i]\n            if centile == highlight_centile and original_highlight_centile &gt;= 1.0:\n                display_centile = (\n                    0.9999  # Use 99.99% as the highest displayable probability\n                )\n\n            # Format the label text with appropriate precision\n            if display_centile &gt;= 0.999:\n                # For very high probabilities, show as 99.9% or 99.99% to avoid implying exact 100%\n                label_text = f\"{display_centile*100:.2f}% probability\"\n            else:\n                label_text = f\"{display_centile*100:.0f}% probability\"\n\n            cumsum_percentile = np.cumsum(percentiles[i])\n            plt.plot(\n                labels_reindexed,\n                cumsum_percentile,\n                marker=marker,\n                markersize=3,\n                linestyle=line_style,\n                color=\"C0\",\n                linewidth=linewidth,\n                alpha=alpha,\n                label=label_text,\n            )\n        # update max y\n        max_y = max(cumulative_value_at_centile)\n\n        # Draw window visualization if requested\n        if draw_window:\n            start_window, end_window = draw_window\n            reindexed_start = (start_window - start_plot_index) % len(\n                highlight_percentile_data\n            )\n            reindexed_end = (end_window - start_plot_index) % len(\n                highlight_percentile_data\n            )\n            window_params = get_window_parameters(\n                highlight_percentile_data, reindexed_start, reindexed_end, hour_values\n            )\n            draw_window_visualization(\n                ax,\n                hour_values,\n                window_params,\n                annotation_prefix,\n                start_window,\n                end_window,\n            )\n            slope, x1, y1, x2, y2 = window_params\n            for hour_line in hour_lines:\n                annotate_hour_line(\n                    hour_line=hour_line,\n                    y_value=y1,\n                    hour_values=hour_values,\n                    start_plot_index=start_plot_index,\n                    line_styles=line_styles,\n                    x_margin=x_margin,\n                    annotation_prefix=annotation_prefix,\n                    slope=slope,\n                    x1=x1,\n                    y1=y1,\n                )\n\n        else:\n            # Regular percentile annotations\n            for hour_line in hour_lines:\n                # Check if highlight_percentile_data is available\n                if highlight_percentile_data is None:\n                    # Fall back to mean line if no highlight data\n                    cumsum_at_hour = cumsum_rates[hour_line - start_plot_index]\n                else:\n                    cumsum_at_hour = highlight_percentile_data[\n                        hour_line - start_plot_index\n                    ]\n                annotate_hour_line(\n                    hour_line=hour_line,\n                    y_value=cumsum_at_hour,\n                    hour_values=hour_values,\n                    start_plot_index=start_plot_index,\n                    line_styles=line_styles,\n                    x_margin=x_margin,\n                    annotation_prefix=annotation_prefix,\n                    text_y_offset=text_y_offset,\n                )\n\n        # Reverse legend order\n        handles, labels = plt.gca().get_legend_handles_labels()\n        plt.legend(handles[::-1], labels[::-1], loc=\"upper left\")\n    else:\n        plt.legend(loc=\"upper left\")\n\n        if draw_window:\n            start_window, end_window = draw_window\n            reindexed_start = (start_window - start_plot_index) % len(cumsum_rates)\n            reindexed_end = (end_window - start_plot_index) % len(cumsum_rates)\n            window_params = get_window_parameters(\n                cumsum_rates, reindexed_start, reindexed_end, hour_values\n            )\n            draw_window_visualization(\n                ax,\n                hour_values,\n                window_params,\n                annotation_prefix,\n                start_window,\n                end_window,\n            )\n            slope, x1, y1, x2, y2 = window_params\n            for hour_line in hour_lines:\n                annotate_hour_line(\n                    hour_line=hour_line,\n                    y_value=y1,\n                    hour_values=hour_values,\n                    start_plot_index=start_plot_index,\n                    line_styles=line_styles,\n                    x_margin=x_margin,\n                    annotation_prefix=annotation_prefix,\n                    slope=slope,\n                    x1=x1,\n                    y1=y1,\n                )\n        else:\n            # Regular mean line annotations\n            for hour_line in hour_lines:\n                annotate_hour_line(\n                    hour_line=hour_line,\n                    y_value=cumsum_rates[hour_line - start_plot_index],\n                    hour_values=hour_values,\n                    start_plot_index=start_plot_index,\n                    line_styles=line_styles,\n                    x_margin=x_margin,\n                    annotation_prefix=annotation_prefix,\n                )\n\n    plt.xlabel(\"Hour of day\")\n    plt.ylabel(\"Cumulative number of beds needed\")\n    plt.xlim(hour_values[0] - x_margin, hour_values[-1] + x_margin)\n    plt.ylim(0, set_y_lim if set_y_lim else max(max_y + 2, max_y * 1.2))\n    plt.minorticks_on()\n    plt.gca().yaxis.set_minor_locator(plt.MultipleLocator(5))\n\n    plt.title(title)\n    plt.tight_layout()\n\n    if media_file_path:\n        if file_name:\n            filename = file_name\n        else:\n            filename = f\"{file_prefix}{clean_title_for_filename(title)}\"\n        plt.savefig(media_file_path / filename, dpi=300)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n</code></pre>"},{"location":"api/#patientflow.viz.aspirational_curve","title":"<code>aspirational_curve</code>","text":"<p>Visualization module for plotting aspirational curves in patient flow analysis.</p> <p>This module provides functionality for creating and customizing plots of aspirational curves, which represent the probability of admission over time. These curves are useful for setting aspirational targets in healthcare settings.</p> <p>Functions:</p> Name Description <code>plot_curve : function</code> <p>Plot an aspirational curve with specified points and optional annotations</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; plot_curve(\n...     title=\"Admission Probability Curve\",\n...     x1=4,\n...     y1=0.2,\n...     x2=24,\n...     y2=0.8,\n...     include_titles=True\n... )\n</code></pre>"},{"location":"api/#patientflow.viz.aspirational_curve.plot_curve","title":"<code>plot_curve(title, x1, y1, x2, y2, figsize=(10, 5), include_titles=False, text_size=14, media_file_path=None, file_name=None, return_figure=False, annotate_points=False)</code>","text":"<p>Plot an aspirational curve with specified points and optional annotations.</p> <p>This function creates a plot of an aspirational curve between two points, with options for customization of the visualization including titles, annotations, and saving to a file.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>The title of the plot.</p> required <code>x1</code> <code>float</code> <p>x-coordinate of the first point.</p> required <code>y1</code> <code>float</code> <p>y-coordinate of the first point (probability value).</p> required <code>x2</code> <code>float</code> <p>x-coordinate of the second point.</p> required <code>y2</code> <code>float</code> <p>y-coordinate of the second point (probability value).</p> required <code>figsize</code> <code>tuple of int</code> <p>Figure size in inches (width, height), by default (10, 5).</p> <code>(10, 5)</code> <code>include_titles</code> <code>bool</code> <p>Whether to include axis labels and title, by default False.</p> <code>False</code> <code>text_size</code> <code>int</code> <p>Font size for text elements, by default 14.</p> <code>14</code> <code>media_file_path</code> <code>str or Path</code> <p>Path to save the plot image, by default None.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename for saving the plot. If not provided, uses a cleaned version of the title.</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>Whether to return the figure object instead of displaying it, by default False.</p> <code>False</code> <code>annotate_points</code> <code>bool</code> <p>Whether to add coordinate annotations to the points, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>The figure object if return_figure is True, otherwise None.</p> Notes <p>The function creates a curve between two points using the create_curve function and adds various visualization elements including grid lines, annotations, and optional titles.</p> Source code in <code>src/patientflow/viz/aspirational_curve.py</code> <pre><code>def plot_curve(\n    title,\n    x1,\n    y1,\n    x2,\n    y2,\n    figsize=(10, 5),\n    include_titles=False,\n    text_size=14,\n    media_file_path=None,\n    file_name=None,\n    return_figure=False,\n    annotate_points=False,\n):\n    \"\"\"Plot an aspirational curve with specified points and optional annotations.\n\n    This function creates a plot of an aspirational curve between two points,\n    with options for customization of the visualization including titles,\n    annotations, and saving to a file.\n\n    Parameters\n    ----------\n    title : str\n        The title of the plot.\n    x1 : float\n        x-coordinate of the first point.\n    y1 : float\n        y-coordinate of the first point (probability value).\n    x2 : float\n        x-coordinate of the second point.\n    y2 : float\n        y-coordinate of the second point (probability value).\n    figsize : tuple of int, optional\n        Figure size in inches (width, height), by default (10, 5).\n    include_titles : bool, optional\n        Whether to include axis labels and title, by default False.\n    text_size : int, optional\n        Font size for text elements, by default 14.\n    media_file_path : str or Path, optional\n        Path to save the plot image, by default None.\n    file_name : str, optional\n        Custom filename for saving the plot. If not provided, uses a cleaned version of the title.\n    return_figure : bool, optional\n        Whether to return the figure object instead of displaying it, by default False.\n    annotate_points : bool, optional\n        Whether to add coordinate annotations to the points, by default False.\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        The figure object if return_figure is True, otherwise None.\n\n    Notes\n    -----\n    The function creates a curve between two points using the create_curve function\n    and adds various visualization elements including grid lines, annotations,\n    and optional titles.\n    \"\"\"\n    gamma, lamda, a, x_values, y_values = create_curve(\n        x1, y1, x2, y2, generate_values=True\n    )\n\n    # Plot the curve\n    fig = plt.figure(figsize=figsize)\n\n    plt.plot(x_values, y_values)\n    plt.scatter(x1, y1, color=\"red\")  # Mark the point (x1, y1)\n    plt.scatter(x2, y2, color=\"red\")  # Mark the point (x2, y2)\n\n    if annotate_points:\n        plt.annotate(\n            f\"({x1}, {y1:.2f})\",\n            (x1, y1),\n            xytext=(10, -15),\n            textcoords=\"offset points\",\n            fontsize=text_size,\n        )\n        plt.annotate(\n            f\"({x2}, {y2:.2f})\",\n            (x2, y2),\n            xytext=(10, -15),\n            textcoords=\"offset points\",\n            fontsize=text_size,\n        )\n\n    if text_size:\n        plt.tick_params(axis=\"both\", which=\"major\", labelsize=text_size)\n\n    x_ticks = np.arange(min(x_values), max(x_values) + 1, 2)\n    plt.xticks(x_ticks)\n\n    if include_titles:\n        plt.title(title, fontsize=text_size)\n        plt.xlabel(\"Hours since admission\", fontsize=text_size)\n        plt.ylabel(\"Probability of admission by this point\", fontsize=text_size)\n\n    plt.axhline(y=y1, color=\"green\", linestyle=\"--\", label=f\"y ={int(y1*100)}%\")\n    plt.axvline(x=x1, color=\"gray\", linestyle=\"--\", label=\"x = 4 hours\")\n    plt.legend(fontsize=text_size)\n\n    plt.tight_layout()\n\n    if media_file_path:\n        os.makedirs(media_file_path, exist_ok=True)\n        if file_name:\n            filename = file_name\n        else:\n            filename = clean_title_for_filename(title)\n        plt.savefig(media_file_path / filename, dpi=300)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n</code></pre>"},{"location":"api/#patientflow.viz.calibration","title":"<code>calibration</code>","text":"<p>Calibration plot visualization module.</p> <p>This module creates calibration plots for trained models, showing how well the predicted probabilities align with actual outcomes.</p> <p>Functions:</p> Name Description <code>plot_calibration : function</code> <p>Plot calibration curves for multiple models</p>"},{"location":"api/#patientflow.viz.calibration.plot_calibration","title":"<code>plot_calibration(trained_models, test_visits, exclude_from_training_data, strategy='uniform', media_file_path=None, file_name=None, suptitle=None, return_figure=False, label_col='is_admitted')</code>","text":"<p>Plot calibration curves for multiple models.</p> <p>A calibration plot shows how well the predicted probabilities from a model align with the actual outcomes. The plot compares the mean predicted probability with the fraction of positive outcomes for different probability bins.</p> <p>Parameters:</p> Name Type Description Default <code>trained_models</code> <code>list[TrainedClassifier] or dict[str, TrainedClassifier]</code> <p>List of TrainedClassifier objects or dictionary with TrainedClassifier values.</p> required <code>test_visits</code> <code>DataFrame</code> <p>DataFrame containing test visit data.</p> required <code>exclude_from_training_data</code> <code>list</code> <p>Columns to exclude from the test data.</p> required <code>strategy</code> <code>(uniform, quantile)</code> <p>Strategy for calibration curve binning. - 'uniform': Bins are of equal width - 'quantile': Bins have equal number of samples</p> <code>'uniform'</code> <code>media_file_path</code> <code>Path</code> <p>Path where the plot should be saved.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"calibration_plot.png\".</p> <code>None</code> <code>suptitle</code> <code>str</code> <p>Optional super title for the entire figure.</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure instead of displaying it.</p> <code>False</code> <code>label_col</code> <code>str</code> <p>Name of the column containing the target labels.</p> <code>'is_admitted'</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>If return_figure is True, returns the figure object. Otherwise, displays the plot and returns None.</p> Notes <p>The function creates a subplot for each trained model, sorted by prediction time. Each subplot shows the calibration curve and a reference line for perfect calibration.</p> Source code in <code>src/patientflow/viz/calibration.py</code> <pre><code>def plot_calibration(\n    trained_models: list[TrainedClassifier] | dict[str, TrainedClassifier],\n    test_visits,\n    exclude_from_training_data,\n    strategy=\"uniform\",\n    media_file_path: Optional[Path] = None,\n    file_name=None,\n    suptitle=None,\n    return_figure=False,\n    label_col: str = \"is_admitted\",\n):\n    \"\"\"Plot calibration curves for multiple models.\n\n    A calibration plot shows how well the predicted probabilities from a model\n    align with the actual outcomes. The plot compares the mean predicted probability\n    with the fraction of positive outcomes for different probability bins.\n\n    Parameters\n    ----------\n    trained_models : list[TrainedClassifier] or dict[str, TrainedClassifier]\n        List of TrainedClassifier objects or dictionary with TrainedClassifier values.\n    test_visits : pandas.DataFrame\n        DataFrame containing test visit data.\n    exclude_from_training_data : list\n        Columns to exclude from the test data.\n    strategy : {'uniform', 'quantile'}, default='uniform'\n        Strategy for calibration curve binning.\n        - 'uniform': Bins are of equal width\n        - 'quantile': Bins have equal number of samples\n    media_file_path : Path, optional\n        Path where the plot should be saved.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"calibration_plot.png\".\n    suptitle : str, optional\n        Optional super title for the entire figure.\n    return_figure : bool, default=False\n        If True, returns the figure instead of displaying it.\n    label_col : str, default='is_admitted'\n        Name of the column containing the target labels.\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        If return_figure is True, returns the figure object. Otherwise, displays\n        the plot and returns None.\n\n    Notes\n    -----\n    The function creates a subplot for each trained model, sorted by prediction time.\n    Each subplot shows the calibration curve and a reference line for perfect calibration.\n    \"\"\"\n    # Convert dict to list if needed\n    if isinstance(trained_models, dict):\n        trained_models = list(trained_models.values())\n\n    # Sort trained_models by prediction time\n    trained_models_sorted = sorted(\n        trained_models,\n        key=lambda x: x.training_results.prediction_time[0] * 60\n        + x.training_results.prediction_time[1],\n    )\n    num_plots = len(trained_models_sorted)\n    fig, axs = plt.subplots(1, num_plots, figsize=(num_plots * 5, 4))\n\n    # Handle case of single prediction time\n    if num_plots == 1:\n        axs = [axs]\n\n    for i, trained_model in enumerate(trained_models_sorted):\n        # Use calibrated pipeline if available, otherwise use regular pipeline\n        if (\n            hasattr(trained_model, \"calibrated_pipeline\")\n            and trained_model.calibrated_pipeline is not None\n        ):\n            pipeline = trained_model.calibrated_pipeline\n        else:\n            pipeline = trained_model.pipeline\n\n        prediction_time = trained_model.training_results.prediction_time\n\n        # Get test data for this prediction time\n        X_test, y_test = prepare_patient_snapshots(\n            df=test_visits,\n            prediction_time=prediction_time,\n            exclude_columns=exclude_from_training_data,\n            single_snapshot_per_visit=False,\n            label_col=label_col,\n        )\n\n        X_test = add_missing_columns(pipeline, X_test)\n\n        prob_true, prob_pred = calibration_curve(\n            y_test, pipeline.predict_proba(X_test)[:, 1], n_bins=10, strategy=strategy\n        )\n\n        ax = axs[i]\n        hour, minutes = prediction_time\n\n        ax.plot(\n            prob_pred,\n            prob_true,\n            marker=\"o\",\n            linewidth=1,\n            label=\"Predictions\",\n            color=primary_color,\n        )\n        ax.plot(\n            [0, 1],\n            [0, 1],\n            linestyle=\"--\",\n            label=\"Perfectly calibrated\",\n            color=secondary_color,\n        )\n        ax.set_title(f\"Calibration Plot for {hour}:{minutes:02}\", fontsize=14)\n        ax.set_xlabel(\"Mean Estimated Probability\", fontsize=12)\n        ax.set_ylabel(\"Fraction of Positives\", fontsize=12)\n        ax.legend()\n\n    plt.tight_layout()\n\n    # Add suptitle if provided\n    if suptitle:\n        plt.suptitle(suptitle, fontsize=16, y=1.05)\n\n    if media_file_path:\n        if file_name:\n            calib_plot_path = media_file_path / file_name\n        else:\n            calib_plot_path = media_file_path / \"calibration_plot.png\"\n        plt.savefig(calib_plot_path)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n        plt.close()\n</code></pre>"},{"location":"api/#patientflow.viz.data_distribution","title":"<code>data_distribution</code>","text":"<p>Visualisation module for plotting data distributions.</p> <p>This module provides functions for creating distribution plots of data variables grouped by categories.</p> <p>Functions:</p> Name Description <code>plot_data_distribution : function</code> <p>Plot distributions of data variables grouped by categories</p>"},{"location":"api/#patientflow.viz.data_distribution.plot_data_distribution","title":"<code>plot_data_distribution(df, col_name, grouping_var, grouping_var_name, plot_type='both', title=None, rotate_x_labels=False, is_discrete=False, ordinal_order=None, media_file_path=None, file_name=None, return_figure=False, truncate_outliers=True, outlier_method='zscore', outlier_threshold=2.0)</code>","text":"<p>Plot distributions of data variables grouped by categories.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame containing the data to plot</p> required <code>col_name</code> <code>str</code> <p>Name of the column to plot distributions for</p> required <code>grouping_var</code> <code>str</code> <p>Name of the column to group the data by</p> required <code>grouping_var_name</code> <code>str</code> <p>Display name for the grouping variable</p> required <code>plot_type</code> <code>(both, hist, kde)</code> <p>Type of plot to create. 'both' shows histogram with KDE, 'hist' shows only histogram, 'kde' shows only KDE plot</p> <code>'both'</code> <code>title</code> <code>str</code> <p>Title for the plot</p> <code>None</code> <code>rotate_x_labels</code> <code>bool</code> <p>Whether to rotate x-axis labels by 90 degrees</p> <code>False</code> <code>is_discrete</code> <code>bool</code> <p>Whether the data is discrete</p> <code>False</code> <code>ordinal_order</code> <code>list</code> <p>Order of categories for ordinal data</p> <code>None</code> <code>media_file_path</code> <code>Path</code> <p>Path where the plot should be saved</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"data_distributions.png\".</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure instead of displaying it</p> <code>False</code> <code>truncate_outliers</code> <code>bool</code> <p>Whether to truncate the x-axis to exclude extreme outliers</p> <code>True</code> <code>outlier_method</code> <code>(iqr, zscore)</code> <p>Method to detect outliers. 'iqr' uses interquartile range, 'zscore' uses z-score</p> <code>'iqr'</code> <code>outlier_threshold</code> <code>float</code> <p>Threshold for outlier detection. For IQR method, this is the multiplier. For z-score method, this is the number of standard deviations.</p> <code>1.5</code> <p>Returns:</p> Type Description <code>FacetGrid or None</code> <p>If return_figure is True, returns the FacetGrid object. Otherwise, displays the plot and returns None.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If plot_type is not one of 'both', 'hist', or 'kde' If outlier_method is not one of 'iqr' or 'zscore'</p> Source code in <code>src/patientflow/viz/data_distribution.py</code> <pre><code>def plot_data_distribution(\n    df,\n    col_name,\n    grouping_var,\n    grouping_var_name,\n    plot_type=\"both\",\n    title=None,\n    rotate_x_labels=False,\n    is_discrete=False,\n    ordinal_order=None,\n    media_file_path=None,\n    file_name=None,\n    return_figure=False,\n    truncate_outliers=True,\n    outlier_method=\"zscore\",\n    outlier_threshold=2.0,\n):\n    \"\"\"Plot distributions of data variables grouped by categories.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Input DataFrame containing the data to plot\n    col_name : str\n        Name of the column to plot distributions for\n    grouping_var : str\n        Name of the column to group the data by\n    grouping_var_name : str\n        Display name for the grouping variable\n    plot_type : {'both', 'hist', 'kde'}, default='both'\n        Type of plot to create. 'both' shows histogram with KDE, 'hist' shows\n        only histogram, 'kde' shows only KDE plot\n    title : str, optional\n        Title for the plot\n    rotate_x_labels : bool, default=False\n        Whether to rotate x-axis labels by 90 degrees\n    is_discrete : bool, default=False\n        Whether the data is discrete\n    ordinal_order : list, optional\n        Order of categories for ordinal data\n    media_file_path : Path, optional\n        Path where the plot should be saved\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"data_distributions.png\".\n    return_figure : bool, default=False\n        If True, returns the figure instead of displaying it\n    truncate_outliers : bool, default=True\n        Whether to truncate the x-axis to exclude extreme outliers\n    outlier_method : {'iqr', 'zscore'}, default='zscore'\n        Method to detect outliers. 'iqr' uses interquartile range, 'zscore' uses z-score\n    outlier_threshold : float, default=1.5\n        Threshold for outlier detection. For IQR method, this is the multiplier.\n        For z-score method, this is the number of standard deviations.\n\n    Returns\n    -------\n    seaborn.FacetGrid or None\n        If return_figure is True, returns the FacetGrid object. Otherwise,\n        displays the plot and returns None.\n\n    Raises\n    ------\n    ValueError\n        If plot_type is not one of 'both', 'hist', or 'kde'\n        If outlier_method is not one of 'iqr' or 'zscore'\n    \"\"\"\n    sns.set_theme(style=\"whitegrid\")\n\n    if ordinal_order is not None:\n        df[col_name] = pd.Categorical(\n            df[col_name], categories=ordinal_order, ordered=True\n        )\n\n    # Calculate outlier bounds if truncation is requested\n    x_limits = None\n    if truncate_outliers:\n        values = df[col_name].dropna()\n        if pd.api.types.is_numeric_dtype(values) and len(values) &gt; 0:\n            # Check if data is actually discrete (all values are integers)\n            is_actually_discrete = np.allclose(values, values.round())\n\n            # Apply outlier truncation to continuous data OR discrete data with outliers\n            # For discrete data, we still want to truncate if there are extreme outliers\n            if outlier_method == \"iqr\":\n                Q1 = values.quantile(0.25)\n                Q3 = values.quantile(0.75)\n                IQR = Q3 - Q1\n                lower_bound = Q1 - outlier_threshold * IQR\n                upper_bound = Q3 + outlier_threshold * IQR\n            elif outlier_method == \"zscore\":\n                mean_val = values.mean()\n                std_val = values.std()\n                lower_bound = mean_val - outlier_threshold * std_val\n                upper_bound = mean_val + outlier_threshold * std_val\n            else:\n                raise ValueError(\n                    \"Invalid outlier_method. Choose from 'iqr' or 'zscore'.\"\n                )\n\n            # Only apply truncation if there are actual outliers\n            # For discrete data, ensure lower bound is at least 0\n            if values.min() &lt; lower_bound or values.max() &gt; upper_bound:\n                if is_actually_discrete:\n                    # For discrete data, ensure bounds are reasonable\n                    lower_bound = max(0, lower_bound)\n                x_limits = (lower_bound, upper_bound)\n\n    g = sns.FacetGrid(df, col=grouping_var, height=3, aspect=1.5)\n\n    if is_discrete:\n        valid_values = sorted([x for x in df[col_name].unique() if pd.notna(x)])\n        min_val = min(valid_values)\n        max_val = max(valid_values)\n        bins = np.arange(min_val - 0.5, max_val + 1.5, 1)\n    else:\n        # Handle numeric data\n        values = df[col_name].dropna()\n        if pd.api.types.is_numeric_dtype(values):\n            if np.allclose(values, values.round()):\n                bins = np.arange(values.min() - 0.5, values.max() + 1.5, 1)\n            else:\n                n_bins = min(100, max(10, int(np.sqrt(len(values)))))\n                bins = n_bins\n        else:\n            bins = \"auto\"\n\n    if plot_type == \"both\":\n        g.map(sns.histplot, col_name, kde=True, bins=bins)\n    elif plot_type == \"hist\":\n        g.map(sns.histplot, col_name, kde=False, bins=bins)\n    elif plot_type == \"kde\":\n        g.map(sns.kdeplot, col_name, fill=True)\n    else:\n        raise ValueError(\"Invalid plot_type. Choose from 'both', 'hist', or 'kde'.\")\n\n    g.set_axis_labels(\n        col_name, \"Frequency\" if plot_type != \"kde\" else \"Density\", fontsize=10\n    )\n\n    # Set facet titles with smaller font\n    g.set_titles(col_template=f\"{grouping_var}: {{col_name}}\", size=11)\n\n    # Add thousands separators to y-axis\n    for ax in g.axes.flat:\n        ax.yaxis.set_major_formatter(\n            plt.FuncFormatter(lambda x, p: format(int(x), \",\"))\n        )\n\n    if rotate_x_labels:\n        for ax in g.axes.flat:\n            for label in ax.get_xticklabels():\n                label.set_rotation(90)\n\n    if is_discrete:\n        for ax in g.axes.flat:\n            ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n            # Apply outlier truncation if available, otherwise use default discrete limits\n            if x_limits is not None:\n                # Ensure discrete limits are reasonable: min \u2265 0, max \u2265 1, and use integers\n                lower_limit = max(0, int(x_limits[0]))\n                upper_limit = max(\n                    1, int(x_limits[1] + 0.5)\n                )  # Round up to ensure we include the max value\n                ax.set_xlim(lower_limit - 0.5, upper_limit + 0.5)\n            else:\n                # Ensure default discrete limits are reasonable: min \u2265 0, max \u2265 1\n                # Use the actual min/max values to center the bars properly\n                lower_limit = max(0, min_val)\n                upper_limit = max(1, max_val)\n                ax.set_xlim(lower_limit - 0.5, upper_limit + 0.5)\n    elif x_limits is not None:\n        # Apply outlier truncation to x-axis\n        for ax in g.axes.flat:\n            ax.set_xlim(x_limits)\n            # Ensure integer tick marks for numeric data with outliers\n            ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n    else:\n        # Let matplotlib auto-scale the x-axis\n        pass\n\n    plt.subplots_adjust(top=0.80)\n    if title:\n        g.figure.suptitle(title, fontsize=14)\n    else:\n        g.figure.suptitle(\n            f\"Distribution of {col_name} grouped by {grouping_var_name}\", fontsize=14\n        )\n\n    if media_file_path:\n        if file_name:\n            filename = file_name\n        else:\n            filename = \"data_distributions.png\"\n        plt.savefig(media_file_path / filename, dpi=300)\n\n    if return_figure:\n        return g\n    else:\n        plt.show()\n        plt.close()\n</code></pre>"},{"location":"api/#patientflow.viz.epudd","title":"<code>epudd</code>","text":"<p>Generate plots comparing observed values with model predictions for discrete distributions.</p> <p>An Evaluating Predictions for Unique, Discrete, Distributions (EPUDD) plot displays the model's predicted CDF values alongside the actual observed values' positions within their predicted CDF intervals. For discrete distributions, each predicted value has an associated probability, and the CDF is calculated by sorting the values and computing cumulative probabilities.</p> <p>The plot can show three possible positions for each observation within its predicted interval:</p> <pre><code>* lower bound of the interval\n* midpoint of the interval\n* upper bound of the interval\n</code></pre> <p>By default, the plot only shows the midpoint of the interval.</p> <p>For a well-calibrated model, the observed values should fall within their predicted intervals, with the distribution of positions showing appropriate uncertainty.</p> <p>The visualisation helps assess model calibration by comparing: 1. The predicted cumulative distribution function (CDF) values 2. The actual positions of observations within their predicted intervals 3. The spread and distribution of these positions</p> <p>Functions:</p> Name Description <code>plot_epudd : function</code> <p>Generates and plots the comparison of model predictions with observed values.</p>"},{"location":"api/#patientflow.viz.epudd.plot_epudd","title":"<code>plot_epudd(prediction_times, prob_dist_dict_all, model_name='admissions', return_figure=False, return_dataframe=False, figsize=None, suptitle=None, media_file_path=None, file_name=None, plot_all_bounds=False)</code>","text":"<p>Generates plots comparing model predictions with observed values for discrete distributions.</p> <p>For discrete distributions, each predicted value has an associated probability. The CDF is calculated by sorting the values and computing cumulative probabilities, normalized by the number of time points.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_times</code> <code>list of tuple</code> <p>List of (hour, minute) tuples representing times for which predictions were made.</p> required <code>prob_dist_dict_all</code> <code>dict</code> <p>Dictionary of probability distributions keyed by model_key. Each entry contains information about predicted distributions and observed values for different snapshot dates. The predicted distributions should be discrete probability mass functions, with each value having an associated probability.</p> required <code>model_name</code> <code>str</code> <p>Base name of the model to construct model keys, by default \"admissions\".</p> <code>'admissions'</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure object instead of displaying it, by default False.</p> <code>False</code> <code>return_dataframe</code> <code>bool</code> <p>If True, returns a dictionary of observation dataframes by model_key, by default False. The dataframes contain the merged observation and prediction data for analysis.</p> <code>False</code> <code>figsize</code> <code>tuple of (float, float)</code> <p>Size of the figure in inches as (width, height). If None, calculated automatically based on number of plots, by default None.</p> <code>None</code> <code>suptitle</code> <code>str</code> <p>Super title for the entire figure, displayed above all subplots, by default None.</p> <code>None</code> <code>media_file_path</code> <code>Path</code> <p>Path to save the plot, by default None. If provided, saves the plot as a PNG file.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"plot_epudd.png\".</p> <code>None</code> <code>plot_all_bounds</code> <code>bool</code> <p>If True, plots all bounds (lower, mid, upper). If False, only plots mid bounds. By default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The figure object containing the plots, if return_figure is True.</p> <code>dict</code> <p>Dictionary of observation dataframes by model_key, if return_dataframe is True.</p> <code>tuple</code> <p>Tuple of (figure, dataframes_dict) if both return_figure and return_dataframe are True.</p> <code>None</code> <p>If neither return_figure nor return_dataframe is True, displays the plots and returns None.</p> Notes <p>For discrete distributions, the CDF is calculated by:</p> <pre><code>1. Sorting the predicted values\n2. Computing cumulative probabilities for each value\n3. Normalizing by the number of time points\n</code></pre> <p>The plot shows three possible positions for each observation:</p> <pre><code>* lower_cdf (pink): Uses the lower bound of the CDF interval\n* mid_cdf (green): Uses the midpoint of the CDF interval\n* upper_cdf (light blue): Uses the upper bound of the CDF interval\n</code></pre> <p>The black points represent the model's predicted CDF values, calculated from the sorted values and their associated probabilities, while the colored points show where the actual observations fall within their predicted intervals. For a well-calibrated model, the observed values should fall within their predicted intervals, with the distribution of positions showing appropriate uncertainty.</p> Source code in <code>src/patientflow/viz/epudd.py</code> <pre><code>def plot_epudd(\n    prediction_times: List[Tuple[int, int]],\n    prob_dist_dict_all: Dict[str, Dict],\n    model_name: str = \"admissions\",\n    return_figure: bool = False,\n    return_dataframe: bool = False,\n    figsize: Optional[Tuple[float, float]] = None,\n    suptitle: Optional[str] = None,\n    media_file_path: Optional[Path] = None,\n    file_name=None,\n    plot_all_bounds: bool = False,\n) -&gt; Union[\n    Figure, Dict[str, pd.DataFrame], Tuple[Figure, Dict[str, pd.DataFrame]], None\n]:\n    \"\"\"\n    Generates plots comparing model predictions with observed values for discrete distributions.\n\n    For discrete distributions, each predicted value has an associated probability. The CDF\n    is calculated by sorting the values and computing cumulative probabilities, normalized\n    by the number of time points.\n\n    Parameters\n    ----------\n    prediction_times : list of tuple\n        List of (hour, minute) tuples representing times for which predictions were made.\n    prob_dist_dict_all : dict\n        Dictionary of probability distributions keyed by model_key. Each entry contains\n        information about predicted distributions and observed values for different\n        snapshot dates. The predicted distributions should be discrete probability mass\n        functions, with each value having an associated probability.\n    model_name : str, optional\n        Base name of the model to construct model keys, by default \"admissions\".\n    return_figure : bool, optional\n        If True, returns the figure object instead of displaying it, by default False.\n    return_dataframe : bool, optional\n        If True, returns a dictionary of observation dataframes by model_key, by default False.\n        The dataframes contain the merged observation and prediction data for analysis.\n    figsize : tuple of (float, float), optional\n        Size of the figure in inches as (width, height). If None, calculated automatically\n        based on number of plots, by default None.\n    suptitle : str, optional\n        Super title for the entire figure, displayed above all subplots, by default None.\n    media_file_path : Path, optional\n        Path to save the plot, by default None. If provided, saves the plot as a PNG file.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"plot_epudd.png\".\n    plot_all_bounds : bool, optional\n        If True, plots all bounds (lower, mid, upper). If False, only plots mid bounds.\n        By default False.\n\n    Returns\n    -------\n    matplotlib.figure.Figure\n        The figure object containing the plots, if return_figure is True.\n    dict\n        Dictionary of observation dataframes by model_key, if return_dataframe is True.\n    tuple\n        Tuple of (figure, dataframes_dict) if both return_figure and return_dataframe are True.\n    None\n        If neither return_figure nor return_dataframe is True, displays the plots and returns None.\n\n    Notes\n    -----\n    For discrete distributions, the CDF is calculated by:\n\n        1. Sorting the predicted values\n        2. Computing cumulative probabilities for each value\n        3. Normalizing by the number of time points\n\n    The plot shows three possible positions for each observation:\n\n        * lower_cdf (pink): Uses the lower bound of the CDF interval\n        * mid_cdf (green): Uses the midpoint of the CDF interval\n        * upper_cdf (light blue): Uses the upper bound of the CDF interval\n\n    The black points represent the model's predicted CDF values, calculated from the sorted\n    values and their associated probabilities, while the colored points show where the actual\n    observations fall within their predicted intervals. For a well-calibrated model, the\n    observed values should fall within their predicted intervals, with the distribution of\n    positions showing appropriate uncertainty.\n\n    \"\"\"\n    # Sort prediction times by converting to minutes since midnight\n    prediction_times_sorted: List[Tuple[int, int]] = sorted(\n        prediction_times,\n        key=lambda x: x[0] * 60 + x[1],\n    )\n\n    # Calculate figure parameters\n    num_plots: int = len(prediction_times_sorted)\n    figsize = figsize or (num_plots * 5, 4)\n\n    # Create subplot layout\n    fig: Figure\n    axs: np.ndarray\n    fig, axs = plt.subplots(1, num_plots, figsize=figsize)\n    axs = [axs] if num_plots == 1 else axs\n\n    # Define plotting types and colors\n    all_types = [\"lower\", \"mid\", \"upper\"]\n    plot_types = all_types if plot_all_bounds else [\"mid\"]\n    colors: Dict[str, str] = {\n        \"lower\": \"#FF1493\",  # deeppink\n        \"mid\": \"#228B22\",  # chartreuse4/forest green\n        \"upper\": \"#ADD8E6\",  # lightblue\n    }\n\n    all_obs_dfs: Dict[str, pd.DataFrame] = {}\n\n    # Process each subplot\n    for i, prediction_time in enumerate(prediction_times_sorted):\n        model_key: str = get_model_key(model_name, prediction_time)\n        prob_dist_dict: Dict = prob_dist_dict_all[model_key]\n\n        if not prob_dist_dict:\n            continue\n\n        # Create distribution and observation dataframes\n        all_distributions = _create_distribution_records(prob_dist_dict, all_types)\n        distr_coll: pd.DataFrame = pd.DataFrame(all_distributions)\n\n        all_observations = _create_observation_records(prob_dist_dict)\n        adm_coll: pd.DataFrame = pd.DataFrame(all_observations)\n\n        # For each actual observation, find its position in the predicted CDF\n        # by matching datetime and admission count to get lower/mid/upper bounds\n        merged_df: pd.DataFrame = pd.merge(\n            adm_coll,\n            distr_coll.rename(\n                columns={\n                    \"num_adm_pred\": \"num_adm\",\n                    **{f\"{t}_predicted_cdf\": f\"{t}_observed_cdf\" for t in all_types},\n                }\n            ),\n            on=[\"dt\", \"num_adm\"],\n            how=\"inner\",\n        )\n\n        if merged_df.empty:\n            continue\n\n        all_obs_dfs[model_key] = merged_df\n        ax = axs[i]\n        num_time_points: int = len(prob_dist_dict)\n\n        # Plot predictions and observations\n        _plot_predictions(ax, distr_coll, num_time_points, plot_types)\n        _plot_observations(ax, merged_df, plot_types, colors, i == 0)\n        _setup_subplot(ax, prediction_time, i == 0)\n\n    # Final plot configuration\n    plt.tight_layout()\n    if suptitle:\n        plt.suptitle(suptitle, fontsize=16, y=1.05)\n    if media_file_path:\n        if file_name:\n            filename = file_name\n        else:\n            filename = \"plot_epudd.png\"\n        plt.savefig(media_file_path / filename, dpi=300)\n\n    # Return based on flags\n    if return_figure and return_dataframe:\n        return fig, all_obs_dfs\n    elif return_figure:\n        return fig\n    elif return_dataframe:\n        plt.show()\n        plt.close()\n        return all_obs_dfs\n    else:\n        plt.show()\n        plt.close()\n        return None\n</code></pre>"},{"location":"api/#patientflow.viz.estimated_probabilities","title":"<code>estimated_probabilities</code>","text":"<p>Visualization module for plotting estimated probabilities from trained models.</p> <p>This module provides functions for creating distribution plots of estimated probabilities from trained classification models.</p> <p>Functions:</p> Name Description <code>plot_estimated_probabilities : function</code> <p>Plot estimated probability distributions for multiple models</p>"},{"location":"api/#patientflow.viz.estimated_probabilities.plot_estimated_probabilities","title":"<code>plot_estimated_probabilities(trained_models, test_visits, exclude_from_training_data, bins=30, media_file_path=None, file_name=None, suptitle=None, return_figure=False, label_col='is_admitted')</code>","text":"<p>Plot estimated probability distributions for multiple models.</p> <p>Parameters:</p> Name Type Description Default <code>trained_models</code> <code>list[TrainedClassifier] or dict[str, TrainedClassifier]</code> <p>List of TrainedClassifier objects or dict with TrainedClassifier values</p> required <code>test_visits</code> <code>DataFrame</code> <p>DataFrame containing test visit data</p> required <code>exclude_from_training_data</code> <code>list</code> <p>Columns to exclude from the test data</p> required <code>bins</code> <code>int</code> <p>Number of bins for the histograms</p> <code>30</code> <code>media_file_path</code> <code>Path</code> <p>Path where the plot should be saved</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"estimated_probabilities.png\".</p> <code>None</code> <code>suptitle</code> <code>str</code> <p>Optional super title for the entire figure</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure instead of displaying it</p> <code>False</code> <code>label_col</code> <code>str</code> <p>Name of the column containing the target labels</p> <code>\"is_admitted\"</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>If return_figure is True, returns the figure object. Otherwise, displays the plot and returns None.</p> Source code in <code>src/patientflow/viz/estimated_probabilities.py</code> <pre><code>def plot_estimated_probabilities(\n    trained_models: list[TrainedClassifier] | dict[str, TrainedClassifier],\n    test_visits,\n    exclude_from_training_data,\n    bins=30,\n    media_file_path: Optional[Path] = None,\n    file_name=None,\n    suptitle: Optional[str] = None,\n    return_figure=False,\n    label_col: str = \"is_admitted\",\n):\n    \"\"\"Plot estimated probability distributions for multiple models.\n\n    Parameters\n    ----------\n    trained_models : list[TrainedClassifier] or dict[str, TrainedClassifier]\n        List of TrainedClassifier objects or dict with TrainedClassifier values\n    test_visits : pandas.DataFrame\n        DataFrame containing test visit data\n    exclude_from_training_data : list\n        Columns to exclude from the test data\n    bins : int, default=30\n        Number of bins for the histograms\n    media_file_path : Path, optional\n        Path where the plot should be saved\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"estimated_probabilities.png\".\n    suptitle : str, optional\n        Optional super title for the entire figure\n    return_figure : bool, default=False\n        If True, returns the figure instead of displaying it\n    label_col : str, default=\"is_admitted\"\n        Name of the column containing the target labels\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        If return_figure is True, returns the figure object. Otherwise, displays\n        the plot and returns None.\n    \"\"\"\n    # Convert dict to list if needed\n    if isinstance(trained_models, dict):\n        trained_models = list(trained_models.values())\n\n    # Sort trained_models by prediction time\n    trained_models_sorted = sorted(\n        trained_models,\n        key=lambda x: x.training_results.prediction_time[0] * 60\n        + x.training_results.prediction_time[1],\n    )\n    num_plots = len(trained_models_sorted)\n    fig, axs = plt.subplots(1, num_plots, figsize=(num_plots * 5, 4))\n\n    # Handle case of single prediction time\n    if num_plots == 1:\n        axs = [axs]\n\n    for i, trained_model in enumerate(trained_models_sorted):\n        # Use calibrated pipeline if available, otherwise use regular pipeline\n        if (\n            hasattr(trained_model, \"calibrated_pipeline\")\n            and trained_model.calibrated_pipeline is not None\n        ):\n            pipeline = trained_model.calibrated_pipeline\n        else:\n            pipeline = trained_model.pipeline\n\n        prediction_time = trained_model.training_results.prediction_time\n\n        # Get test data for this prediction time\n        X_test, y_test = prepare_patient_snapshots(\n            df=test_visits,\n            prediction_time=prediction_time,\n            exclude_columns=exclude_from_training_data,\n            single_snapshot_per_visit=False,\n            label_col=label_col,\n        )\n\n        X_test = add_missing_columns(pipeline, X_test)\n\n        # Get predictions\n        y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n\n        # Separate predictions for positive and negative cases\n        pos_preds = y_pred_proba[y_test == 1]\n        neg_preds = y_pred_proba[y_test == 0]\n\n        ax = axs[i]\n        hour, minutes = prediction_time\n\n        # Plot distributions\n        ax.hist(\n            neg_preds,\n            bins=bins,\n            alpha=0.5,\n            color=primary_color,\n            density=True,\n            label=\"Negative Cases\",\n            histtype=\"step\",\n            linewidth=2,\n        )\n        ax.hist(\n            pos_preds,\n            bins=bins,\n            alpha=0.5,\n            color=secondary_color,\n            density=True,\n            label=\"Positive Cases\",\n            histtype=\"step\",\n            linewidth=2,\n        )\n\n        # Optional: Fill with lower opacity\n        ax.hist(neg_preds, bins=bins, alpha=0.2, color=primary_color, density=True)\n        ax.hist(pos_preds, bins=bins, alpha=0.2, color=secondary_color, density=True)\n\n        ax.set_title(\n            f\"Distribution of Estimated Probabilities at {hour}:{minutes:02}\",\n            fontsize=14,\n        )\n        ax.set_xlabel(\"Estimated Probability\", fontsize=12)\n        ax.set_ylabel(\"Density\", fontsize=12)\n        ax.set_xlim(0, 1)\n        ax.legend()\n\n    plt.tight_layout()\n\n    # Add suptitle if provided\n    if suptitle is not None:\n        plt.suptitle(suptitle, y=1.05, fontsize=16)\n\n    if media_file_path:\n        if file_name:\n            filename = file_name\n        else:\n            filename = \"estimated_probabilities.png\"\n        plt.savefig(media_file_path / filename, dpi=300)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n        plt.close()\n</code></pre>"},{"location":"api/#patientflow.viz.features","title":"<code>features</code>","text":"<p>Visualisation module for plotting feature importances from trained models.</p> <p>This module provides functionality to visualize feature importances from trained classifiers, allowing for comparison across different prediction time points.</p> <p>Functions:</p> Name Description <code>plot_features : function</code> <p>Plot feature importance for multiple models</p>"},{"location":"api/#patientflow.viz.features.plot_features","title":"<code>plot_features(trained_models, media_file_path=None, file_name=None, top_n=20, suptitle=None, return_figure=False)</code>","text":"<p>Plot feature importance for multiple models.</p> <p>Parameters:</p> Name Type Description Default <code>trained_models</code> <code>list[TrainedClassifier] or dict[str, TrainedClassifier]</code> <p>List of TrainedClassifier objects or dictionary with TrainedClassifier values.</p> required <code>media_file_path</code> <code>Path</code> <p>Path where the plot should be saved. If None, the plot is only displayed.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"feature_importance_plots.png\".</p> <code>None</code> <code>top_n</code> <code>int</code> <p>Number of top features to display.</p> <code>20</code> <code>suptitle</code> <code>str</code> <p>Super title for the entire figure.</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure instead of displaying it.</p> <code>False</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>The matplotlib figure if return_figure is True, otherwise None.</p> Notes <p>The function sorts models by prediction time and creates a horizontal bar plot for each model showing the top N most important features. Feature names are truncated to 25 characters for better display.</p> Source code in <code>src/patientflow/viz/features.py</code> <pre><code>def plot_features(\n    trained_models: list[TrainedClassifier] | dict[str, TrainedClassifier],\n    media_file_path: Optional[Path] = None,\n    file_name=None,\n    top_n: int = 20,\n    suptitle: Optional[str] = None,\n    return_figure: bool = False,\n) -&gt; Optional[plt.Figure]:\n    \"\"\"Plot feature importance for multiple models.\n\n    Parameters\n    ----------\n    trained_models : list[TrainedClassifier] or dict[str, TrainedClassifier]\n        List of TrainedClassifier objects or dictionary with TrainedClassifier values.\n    media_file_path : Path, optional\n        Path where the plot should be saved. If None, the plot is only displayed.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"feature_importance_plots.png\".\n    top_n : int, default=20\n        Number of top features to display.\n    suptitle : str, optional\n        Super title for the entire figure.\n    return_figure : bool, default=False\n        If True, returns the figure instead of displaying it.\n\n    Returns\n    -------\n    plt.Figure or None\n        The matplotlib figure if return_figure is True, otherwise None.\n\n    Notes\n    -----\n    The function sorts models by prediction time and creates a horizontal bar plot\n    for each model showing the top N most important features. Feature names are\n    truncated to 25 characters for better display.\n    \"\"\"\n    # Convert dict to list if needed\n    if isinstance(trained_models, dict):\n        trained_models = list(trained_models.values())\n\n    # Sort trained_models by prediction time\n    trained_models_sorted = sorted(\n        trained_models,\n        key=lambda x: x.training_results.prediction_time[0] * 60\n        + x.training_results.prediction_time[1],\n    )\n\n    num_plots = len(trained_models_sorted)\n    fig, axs = plt.subplots(1, num_plots, figsize=(num_plots * 6, 12))\n\n    # Handle case of single prediction time\n    if num_plots == 1:\n        axs = [axs]\n\n    for i, trained_model in enumerate(trained_models_sorted):\n        # Always use regular pipeline\n        pipeline: Pipeline = trained_model.pipeline\n        prediction_time = trained_model.training_results.prediction_time\n\n        # Get feature names from the pipeline\n        transformed_cols = pipeline.named_steps[\n            \"feature_transformer\"\n        ].get_feature_names_out()\n        transformed_cols = [col.split(\"__\")[-1] for col in transformed_cols]\n        truncated_cols = [col[:25] for col in transformed_cols]\n\n        # Get feature importances\n        feature_importances = pipeline.named_steps[\"classifier\"].feature_importances_\n        indices = np.argsort(feature_importances)[\n            -top_n:\n        ]  # Get indices of the top N features\n\n        # Plot for this prediction time\n        ax = axs[i]\n        hour, minutes = prediction_time\n        ax.barh(range(len(indices)), feature_importances[indices], align=\"center\")\n        ax.set_yticks(range(len(indices)))\n        ax.set_yticklabels(np.array(truncated_cols)[indices])\n        ax.set_xlabel(\"Importance\")\n        ax.set_ylabel(\"Features\")\n        ax.set_title(f\"Feature Importances for {hour}:{minutes:02}\")\n\n    plt.tight_layout()\n\n    # Add suptitle if provided\n    if suptitle is not None:\n        plt.suptitle(suptitle, y=1.05, fontsize=16)\n\n    if media_file_path:\n        # Save and display plot\n        if file_name:\n            feature_plot_path = media_file_path / file_name\n        else:\n            feature_plot_path = media_file_path / \"feature_importance_plots.png\"\n        plt.savefig(feature_plot_path, bbox_inches=\"tight\")\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n        plt.close()\n        return None\n</code></pre>"},{"location":"api/#patientflow.viz.madcap","title":"<code>madcap</code>","text":"<p>Module for generating MADCAP (Model Accuracy and Discriminative Calibration Plots) visualizations.</p> <p>MADCAP plots compare model-predicted probabilities to observed outcomes, helping to assess model calibration and discrimination. The plots can be generated for individual prediction times or for specific groups (e.g., age groups).</p> <p>Functions:</p> Name Description <code>classify_age : function</code> <p>Classifies age into categories based on numeric values or age group strings.</p> <code>plot_madcap : function</code> <p>Generates MADCAP plots for a list of trained models, comparing estimated probabilities to observed values.</p> <code>_plot_madcap_subplot : function</code> <p>Plots a single MADCAP subplot showing cumulative predicted and observed values.</p> <code>_plot_madcap_by_group_single : function</code> <p>Generates MADCAP plots for specific groups at a given prediction time.</p> <code>plot_madcap_by_group : function</code> <p>Generates MADCAP plots for different groups across multiple prediction times.</p> <code>plot_madcap_by_group</code> <p>Generates MADCAP plots for groups (e.g., age groups) across a series of prediction times.</p>"},{"location":"api/#patientflow.viz.madcap.classify_age","title":"<code>classify_age(age, age_categories=None)</code>","text":"<p>Classify age into categories based on numeric values or age group strings.</p> <p>Parameters:</p> Name Type Description Default <code>age</code> <code>int, float, or str</code> <p>Age value (e.g., 30) or age group string (e.g., '18-24').</p> required <code>age_categories</code> <code>dict</code> <p>Dictionary defining age categories and their ranges. If not provided, uses DEFAULT_AGE_CATEGORIES. Expected format: {     \"category_name\": {         \"numeric\": {\"min\": min_age, \"max\": max_age},         \"groups\": [\"age_group1\", \"age_group2\", ...]     } }</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Category name based on the age or age group, or 'unknown' for unexpected or invalid values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; classify_age(25)\n'adults'\n&gt;&gt;&gt; classify_age('65-74')\n'65 or over'\n</code></pre> Source code in <code>src/patientflow/viz/madcap.py</code> <pre><code>def classify_age(age, age_categories=None):\n    \"\"\"Classify age into categories based on numeric values or age group strings.\n\n    Parameters\n    ----------\n    age : int, float, or str\n        Age value (e.g., 30) or age group string (e.g., '18-24').\n    age_categories : dict, optional\n        Dictionary defining age categories and their ranges. If not provided, uses DEFAULT_AGE_CATEGORIES.\n        Expected format:\n        {\n            \"category_name\": {\n                \"numeric\": {\"min\": min_age, \"max\": max_age},\n                \"groups\": [\"age_group1\", \"age_group2\", ...]\n            }\n        }\n\n    Returns\n    -------\n    str\n        Category name based on the age or age group, or 'unknown' for unexpected or invalid values.\n\n    Examples\n    --------\n    &gt;&gt;&gt; classify_age(25)\n    'adults'\n    &gt;&gt;&gt; classify_age('65-74')\n    '65 or over'\n    \"\"\"\n    if age_categories is None:\n        age_categories = DEFAULT_AGE_CATEGORIES\n\n    if isinstance(age, (int, float)):\n        for category, rules in age_categories.items():\n            numeric_rules = rules.get(\"numeric\", {})\n            min_age = numeric_rules.get(\"min\", float(\"-inf\"))\n            max_age = numeric_rules.get(\"max\", float(\"inf\"))\n\n            if min_age &lt;= age &lt;= max_age:\n                return category\n        return \"unknown\"\n    elif isinstance(age, str):\n        for category, rules in age_categories.items():\n            if age in rules.get(\"groups\", []):\n                return category\n        return \"unknown\"\n    else:\n        return \"unknown\"\n</code></pre>"},{"location":"api/#patientflow.viz.madcap.plot_madcap","title":"<code>plot_madcap(trained_models, test_visits, exclude_from_training_data, media_file_path=None, file_name=None, suptitle=None, return_figure=False, label_col='is_admitted')</code>","text":"<p>Generate MADCAP plots for a list of trained models.</p> <p>Parameters:</p> Name Type Description Default <code>trained_models</code> <code>list[TrainedClassifier] or dict[str, TrainedClassifier]</code> <p>List of trained classifier objects or dictionary with TrainedClassifier values.</p> required <code>test_visits</code> <code>DataFrame</code> <p>DataFrame containing test visit data.</p> required <code>exclude_from_training_data</code> <code>List[str]</code> <p>List of columns to exclude from training data.</p> required <code>media_file_path</code> <code>Path</code> <p>Directory path where the generated plots will be saved.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"madcap_plot.png\".</p> <code>None</code> <code>suptitle</code> <code>str</code> <p>Suptitle for the plot.</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure object instead of displaying it.</p> <code>False</code> <code>label_col</code> <code>str</code> <p>Name of the column containing the target labels.</p> <code>\"is_admitted\"</code> <p>Returns:</p> Type Description <code>Optional[Figure]</code> <p>The figure if return_figure is True, None otherwise.</p> Source code in <code>src/patientflow/viz/madcap.py</code> <pre><code>def plot_madcap(\n    trained_models: list[TrainedClassifier] | dict[str, TrainedClassifier],\n    test_visits: pd.DataFrame,\n    exclude_from_training_data: List[str],\n    media_file_path: Optional[Path] = None,\n    file_name: Optional[str] = None,\n    suptitle: Optional[str] = None,\n    return_figure: bool = False,\n    label_col: str = \"is_admitted\",\n) -&gt; Optional[plt.Figure]:\n    \"\"\"Generate MADCAP plots for a list of trained models.\n\n    Parameters\n    ----------\n    trained_models : list[TrainedClassifier] or dict[str, TrainedClassifier]\n        List of trained classifier objects or dictionary with TrainedClassifier values.\n    test_visits : pd.DataFrame\n        DataFrame containing test visit data.\n    exclude_from_training_data : List[str]\n        List of columns to exclude from training data.\n    media_file_path : Path, optional\n        Directory path where the generated plots will be saved.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"madcap_plot.png\".\n    suptitle : str, optional\n        Suptitle for the plot.\n    return_figure : bool, default=False\n        If True, returns the figure object instead of displaying it.\n    label_col : str, default=\"is_admitted\"\n        Name of the column containing the target labels.\n\n    Returns\n    -------\n    Optional[plt.Figure]\n        The figure if return_figure is True, None otherwise.\n    \"\"\"\n    # Convert dict to list if needed\n    if isinstance(trained_models, dict):\n        trained_models = list(trained_models.values())\n\n    # Sort trained_models by prediction time\n    trained_models_sorted = sorted(\n        trained_models,\n        key=lambda x: x.training_results.prediction_time[0] * 60\n        + x.training_results.prediction_time[1],\n    )\n    num_plots = len(trained_models_sorted)\n\n    # Calculate the number of rows and columns for the subplots\n    num_cols = min(num_plots, 5)  # Maximum 5 columns\n    num_rows = math.ceil(num_plots / num_cols)\n\n    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_plots * 5, 4))\n\n    # Handle the case of a single plot differently\n    if num_plots == 1:\n        # When there's only one plot, axes is a single Axes object, not an array\n        trained_model = trained_models_sorted[0]\n\n        # Use calibrated pipeline if available, otherwise use regular pipeline\n        if (\n            hasattr(trained_model, \"calibrated_pipeline\")\n            and trained_model.calibrated_pipeline is not None\n        ):\n            pipeline = trained_model.calibrated_pipeline\n        else:\n            pipeline = trained_model.pipeline\n\n        prediction_time = trained_model.training_results.prediction_time\n\n        # Get test data for this prediction time\n        X_test, y_test = prepare_patient_snapshots(\n            df=test_visits,\n            prediction_time=prediction_time,\n            exclude_columns=exclude_from_training_data,\n            single_snapshot_per_visit=False,\n            label_col=label_col,\n        )\n\n        X_test = add_missing_columns(pipeline, X_test)\n        predict_proba = pipeline.predict_proba(X_test)[:, 1]\n\n        # Plot directly on the single axes\n        _plot_madcap_subplot(predict_proba, y_test, prediction_time, axes)\n    else:\n        # For multiple plots, ensure axes is always a 2D array\n        if num_rows == 1:\n            axes = axes.reshape(1, -1)\n\n        for i, trained_model in enumerate(trained_models_sorted):\n            # Use calibrated pipeline if available, otherwise use regular pipeline\n            if (\n                hasattr(trained_model, \"calibrated_pipeline\")\n                and trained_model.calibrated_pipeline is not None\n            ):\n                pipeline = trained_model.calibrated_pipeline\n            else:\n                pipeline = trained_model.pipeline\n\n            prediction_time = trained_model.training_results.prediction_time\n\n            # Get test data for this prediction time\n            X_test, y_test = prepare_patient_snapshots(\n                df=test_visits,\n                prediction_time=prediction_time,\n                exclude_columns=exclude_from_training_data,\n                single_snapshot_per_visit=False,\n                label_col=label_col,\n            )\n\n            X_test = add_missing_columns(pipeline, X_test)\n            predict_proba = pipeline.predict_proba(X_test)[:, 1]\n\n            row = i // num_cols\n            col = i % num_cols\n            _plot_madcap_subplot(predict_proba, y_test, prediction_time, axes[row, col])\n\n        # Hide any unused subplots\n        for j in range(i + 1, num_rows * num_cols):\n            row = j // num_cols\n            col = j % num_cols\n            axes[row, col].axis(\"off\")\n\n    plt.tight_layout()\n\n    # Add suptitle if provided\n    if suptitle:\n        fig.suptitle(suptitle, fontsize=16, y=1.05)\n        # Adjust layout to accommodate suptitle\n        plt.subplots_adjust(top=0.85)\n\n    if media_file_path:\n        plot_name = file_name if file_name else \"madcap_plot.png\"\n        madcap_plot_path = Path(media_file_path) / plot_name\n        plt.savefig(madcap_plot_path, bbox_inches=\"tight\")\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n        plt.close(fig)\n        return None\n</code></pre>"},{"location":"api/#patientflow.viz.madcap.plot_madcap_by_group","title":"<code>plot_madcap_by_group(trained_models, test_visits, exclude_from_training_data, grouping_var, grouping_var_name, media_file_path=None, file_name=None, plot_difference=False, return_figure=False, label_col='is_admitted')</code>","text":"<p>Generate MADCAP plots for different groups across multiple prediction times.</p> <p>Parameters:</p> Name Type Description Default <code>trained_models</code> <code>list[TrainedClassifier] or dict[str, TrainedClassifier]</code> <p>List of trained classifier objects or dictionary with TrainedClassifier values.</p> required <code>test_visits</code> <code>DataFrame</code> <p>DataFrame containing the test visit data.</p> required <code>exclude_from_training_data</code> <code>List[str]</code> <p>List of columns to exclude from training data.</p> required <code>grouping_var</code> <code>str</code> <p>The column name in the dataset that defines the grouping variable.</p> required <code>grouping_var_name</code> <code>str</code> <p>A descriptive name for the grouping variable, used in plot titles.</p> required <code>media_file_path</code> <code>Path</code> <p>Directory path where the generated plots will be saved.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to a generated name based on group and time.</p> <code>None</code> <code>plot_difference</code> <code>bool</code> <p>If True, includes difference plot between predicted and observed outcomes.</p> <code>False</code> <code>return_figure</code> <code>bool</code> <p>If True, returns a list of figure objects instead of displaying them.</p> <code>False</code> <code>label_col</code> <code>str</code> <p>Name of the column containing the target labels.</p> <code>\"is_admitted\"</code> <p>Returns:</p> Type Description <code>Optional[List[Figure]]</code> <p>List of figures if return_figure is True, None otherwise.</p> Source code in <code>src/patientflow/viz/madcap.py</code> <pre><code>def plot_madcap_by_group(\n    trained_models: list[TrainedClassifier] | dict[str, TrainedClassifier],\n    test_visits: pd.DataFrame,\n    exclude_from_training_data: List[str],\n    grouping_var: str,\n    grouping_var_name: str,\n    media_file_path: Optional[Path] = None,\n    file_name: Optional[str] = None,\n    plot_difference: bool = False,\n    return_figure: bool = False,\n    label_col: str = \"is_admitted\",\n) -&gt; Optional[List[plt.Figure]]:\n    \"\"\"Generate MADCAP plots for different groups across multiple prediction times.\n\n    Parameters\n    ----------\n    trained_models : list[TrainedClassifier] or dict[str, TrainedClassifier]\n        List of trained classifier objects or dictionary with TrainedClassifier values.\n    test_visits : pd.DataFrame\n        DataFrame containing the test visit data.\n    exclude_from_training_data : List[str]\n        List of columns to exclude from training data.\n    grouping_var : str\n        The column name in the dataset that defines the grouping variable.\n    grouping_var_name : str\n        A descriptive name for the grouping variable, used in plot titles.\n    media_file_path : Path, optional\n        Directory path where the generated plots will be saved.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to a generated name based on group and time.\n    plot_difference : bool, default=False\n        If True, includes difference plot between predicted and observed outcomes.\n    return_figure : bool, default=False\n        If True, returns a list of figure objects instead of displaying them.\n    label_col : str, default=\"is_admitted\"\n        Name of the column containing the target labels.\n\n    Returns\n    -------\n    Optional[List[plt.Figure]]\n        List of figures if return_figure is True, None otherwise.\n    \"\"\"\n    # Convert dict to list if needed\n    if isinstance(trained_models, dict):\n        trained_models = list(trained_models.values())\n\n    # Sort trained_models by prediction time\n    trained_models_sorted = sorted(\n        trained_models,\n        key=lambda x: x.training_results.prediction_time[0] * 60\n        + x.training_results.prediction_time[1],\n    )\n\n    figures = []\n    for trained_model in trained_models_sorted:\n        # Use calibrated pipeline if available, otherwise use regular pipeline\n        if (\n            hasattr(trained_model, \"calibrated_pipeline\")\n            and trained_model.calibrated_pipeline is not None\n        ):\n            pipeline = trained_model.calibrated_pipeline\n        else:\n            pipeline = trained_model.pipeline\n\n        prediction_time = trained_model.training_results.prediction_time\n\n        # Get test data for this prediction time\n        X_test, y_test = prepare_patient_snapshots(\n            df=test_visits,\n            prediction_time=prediction_time,\n            exclude_columns=exclude_from_training_data,\n            single_snapshot_per_visit=False,\n            label_col=label_col,\n        )\n\n        # Check if the grouping variable exists in X_test columns\n        if grouping_var not in X_test.columns:\n            raise ValueError(f\"'{grouping_var}' not found in the dataset columns.\")\n\n        X_test = add_missing_columns(pipeline, X_test)\n        predict_proba = pipeline.predict_proba(X_test)[:, 1]\n\n        # Apply classification based on the grouping variable\n        if grouping_var == \"age_group\":\n            group = X_test[\"age_group\"].apply(classify_age)\n        elif grouping_var == \"age_on_arrival\":\n            group = X_test[\"age_on_arrival\"].apply(classify_age)\n        else:\n            group = X_test[grouping_var]\n\n        fig = _plot_madcap_by_group_single(\n            predict_proba,\n            y_test,\n            group,\n            prediction_time,\n            grouping_var_name,\n            media_file_path,\n            file_name=file_name,\n            plot_difference=plot_difference,\n            return_figure=True,\n        )\n        if return_figure:\n            figures.append(fig)\n\n    if return_figure:\n        return figures\n    else:\n        return None\n</code></pre>"},{"location":"api/#patientflow.viz.observed_against_expected","title":"<code>observed_against_expected</code>","text":"<p>Visualisation utilities for evaluating patient flow predictions.</p> <p>This module provides functions for creating visualizations to evaluate the accuracy and performance of patient flow predictions, particularly focusing on comparing observed versus expected values.</p> <p>Functions:</p> Name Description <code>plot_deltas : function</code> <p>Plot histograms of observed minus expected values</p> <code>plot_arrival_delta_single_instance : function</code> <p>Plot comparison between observed arrivals and expected arrival rates</p> <code>plot_arrival_deltas : function</code> <p>Plot delta charts for multiple snapshot dates on the same figure</p>"},{"location":"api/#patientflow.viz.observed_against_expected.plot_arrival_delta_single_instance","title":"<code>plot_arrival_delta_single_instance(df, prediction_time, snapshot_date, prediction_window, yta_time_interval=timedelta(minutes=15), show_delta=True, show_only_delta=False, media_file_path=None, file_name=None, return_figure=False, fig_size=(10, 4))</code>","text":"<p>Plot comparison between observed arrivals and expected arrival rates.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing arrival data</p> required <code>prediction_time</code> <code>tuple</code> <p>(hour, minute) of prediction time</p> required <code>snapshot_date</code> <code>date</code> <p>Date to analyze</p> required <code>prediction_window</code> <code>int</code> <p>Prediction window in minutes</p> required <code>show_delta</code> <code>bool</code> <p>If True, plot the difference between actual and expected arrivals</p> <code>True</code> <code>show_only_delta</code> <code>bool</code> <p>If True, only plot the delta between actual and expected arrivals</p> <code>False</code> <code>yta_time_interval</code> <code>int</code> <p>Time interval in minutes for calculating arrival rates</p> <code>15</code> <code>media_file_path</code> <code>Path</code> <p>Path to save the plot</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"arrival_comparison.png\"</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure instead of displaying it</p> <code>False</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height) in inches</p> <code>(10, 4)</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>The figure object if return_figure is True, otherwise None</p> Source code in <code>src/patientflow/viz/observed_against_expected.py</code> <pre><code>def plot_arrival_delta_single_instance(\n    df,\n    prediction_time,\n    snapshot_date,\n    prediction_window: timedelta,\n    yta_time_interval: timedelta = timedelta(minutes=15),\n    show_delta=True,\n    show_only_delta=False,\n    media_file_path=None,\n    file_name=None,\n    return_figure=False,\n    fig_size=(10, 4),\n):\n    \"\"\"Plot comparison between observed arrivals and expected arrival rates.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        DataFrame containing arrival data\n    prediction_time : tuple\n        (hour, minute) of prediction time\n    snapshot_date : datetime.date\n        Date to analyze\n    prediction_window : int\n        Prediction window in minutes\n    show_delta : bool, default=True\n        If True, plot the difference between actual and expected arrivals\n    show_only_delta : bool, default=False\n        If True, only plot the delta between actual and expected arrivals\n    yta_time_interval : int, default=15\n        Time interval in minutes for calculating arrival rates\n    media_file_path : Path, optional\n        Path to save the plot\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"arrival_comparison.png\"\n    return_figure : bool, default=False\n        If True, returns the figure instead of displaying it\n    fig_size : tuple, default=(10, 4)\n        Figure size as (width, height) in inches\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        The figure object if return_figure is True, otherwise None\n    \"\"\"\n    # Prepare data\n    df_copy, snapshot_datetime, default_datetime, prediction_time_obj = (\n        _prepare_arrival_data(\n            df, prediction_time, snapshot_date, prediction_window, yta_time_interval\n        )\n    )\n\n    # Get arrivals within the prediction window\n    arrivals = df_copy[\n        (df_copy.index &gt; snapshot_datetime)\n        &amp; (df_copy.index &lt;= snapshot_datetime + prediction_window)\n    ]\n\n    # Sort arrivals by time and create cumulative count\n    arrivals = arrivals.sort_values(\"arrival_datetime\")\n    arrivals[\"cumulative_count\"] = range(1, len(arrivals) + 1)\n\n    # Calculate arrival rates and prepare time points\n    mean_arrival_rates = _calculate_arrival_rates(\n        df_copy, prediction_time_obj, prediction_window, yta_time_interval\n    )\n\n    # Prepare arrival times\n    arrival_times_piecewise = _prepare_arrival_times(\n        mean_arrival_rates, prediction_time_obj, default_date=datetime(2024, 1, 1)\n    )\n\n    # Calculate cumulative rates\n    cumulative_rates = _calculate_cumulative_rates(\n        arrival_times_piecewise, mean_arrival_rates\n    )\n\n    # Create figure with subplots if showing delta\n    if show_delta and not show_only_delta:\n        fig, (ax1, ax2) = plt.subplots(\n            2, 1, figsize=(fig_size[0], fig_size[1] * 2), sharex=True\n        )\n        ax = ax1\n    else:\n        plt.figure(figsize=fig_size)\n        ax = plt.gca()\n\n    # Ensure arrivals index is timezone-aware\n    if arrivals.index.tz is None:\n        arrivals.index = arrivals.index.tz_localize(\"UTC\")\n\n    # Convert arrival times to use default date for plotting\n    arrival_times_plot = [\n        default_datetime + (t - snapshot_datetime) for t in arrivals.index\n    ]\n\n    # Create combined timeline\n    all_times = _create_combined_timeline(\n        default_datetime, arrival_times_plot, prediction_window, arrival_times_piecewise\n    )\n\n    # Interpolate both actual and expected to the combined timeline\n    actual_counts = np.interp(\n        [t.timestamp() for t in all_times],\n        [\n            t.timestamp()\n            for t in [default_datetime]\n            + arrival_times_plot\n            + [default_datetime + prediction_window]\n        ],\n        [0]\n        + list(arrivals[\"cumulative_count\"])\n        + [arrivals[\"cumulative_count\"].iloc[-1] if len(arrivals) &gt; 0 else 0],\n    )\n\n    expected_counts = np.interp(\n        [t.timestamp() for t in all_times],\n        [t.timestamp() for t in arrival_times_piecewise],\n        cumulative_rates,\n    )\n\n    # Calculate delta\n    delta = actual_counts - expected_counts\n    delta[0] = 0  # Ensure delta starts at 0\n\n    if not show_only_delta:\n        # Plot actual and expected arrivals\n        ax.step(\n            [default_datetime]\n            + arrival_times_plot\n            + [default_datetime + prediction_window],\n            [0]\n            + list(arrivals[\"cumulative_count\"])\n            + [arrivals[\"cumulative_count\"].iloc[-1] if len(arrivals) &gt; 0 else 0],\n            where=\"post\",\n            label=\"Actual Arrivals\",\n        )\n        ax.scatter(\n            arrival_times_piecewise,\n            cumulative_rates,\n            label=\"Expected Arrivals\",\n            color=\"orange\",\n        )\n\n        ax.set_xlabel(\"Time\")\n        ax.set_title(\n            f\"Cumulative Arrivals in the {int(prediction_window.total_seconds()/3600)} hours after {format_prediction_time(prediction_time)} on {snapshot_date}\"\n        )\n        ax.legend()\n\n    if show_delta or show_only_delta:\n        if show_only_delta:\n            _plot_arrival_delta_chart(\n                ax, all_times, delta, prediction_time, prediction_window, snapshot_date\n            )\n        else:\n            _plot_arrival_delta_chart(\n                ax2, all_times, delta, prediction_time, prediction_window, snapshot_date\n            )\n        plt.tight_layout()\n\n    # Format time axis for all subplots\n    for ax in plt.gcf().get_axes():\n        _format_time_axis(ax, all_times)\n\n    if media_file_path:\n        filename = file_name if file_name else \"arrival_comparison.png\"\n        plt.savefig(media_file_path / filename, dpi=300)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n        plt.close()\n</code></pre>"},{"location":"api/#patientflow.viz.observed_against_expected.plot_arrival_deltas","title":"<code>plot_arrival_deltas(df, prediction_time, snapshot_dates, prediction_window, yta_time_interval=timedelta(minutes=15), media_file_path=None, file_name=None, return_figure=False, fig_size=(15, 6))</code>","text":"<p>Plot delta charts for multiple snapshot dates on the same figure.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing arrival data</p> required <code>prediction_time</code> <code>tuple</code> <p>(hour, minute) of prediction time</p> required <code>snapshot_dates</code> <code>list</code> <p>List of datetime.date objects to analyze</p> required <code>prediction_window</code> <code>timedelta</code> <p>Prediction window in minutes</p> required <code>yta_time_interval</code> <code>int</code> <p>Time interval in minutes for calculating arrival rates</p> <code>15</code> <code>media_file_path</code> <code>Path</code> <p>Path to save the plot</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"multiple_deltas.png\"</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure instead of displaying it</p> <code>False</code> <code>fig_size</code> <code>tuple</code> <p>Figure size as (width, height) in inches</p> <code>(15, 6)</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>The figure object if return_figure is True, otherwise None</p> Source code in <code>src/patientflow/viz/observed_against_expected.py</code> <pre><code>def plot_arrival_deltas(\n    df,\n    prediction_time,\n    snapshot_dates,\n    prediction_window: timedelta,\n    yta_time_interval: timedelta = timedelta(minutes=15),\n    media_file_path=None,\n    file_name=None,\n    return_figure=False,\n    fig_size=(15, 6),\n):\n    \"\"\"Plot delta charts for multiple snapshot dates on the same figure.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        DataFrame containing arrival data\n    prediction_time : tuple\n        (hour, minute) of prediction time\n    snapshot_dates : list\n        List of datetime.date objects to analyze\n    prediction_window : timedelta\n        Prediction window in minutes\n    yta_time_interval : int, default=15\n        Time interval in minutes for calculating arrival rates\n    media_file_path : Path, optional\n        Path to save the plot\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"multiple_deltas.png\"\n    return_figure : bool, default=False\n        If True, returns the figure instead of displaying it\n    fig_size : tuple, default=(15, 6)\n        Figure size as (width, height) in inches\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        The figure object if return_figure is True, otherwise None\n    \"\"\"\n    # Create figure with subplots\n    fig = plt.figure(figsize=fig_size)\n    gs = plt.GridSpec(1, 2, width_ratios=[2, 1])\n    ax1 = plt.subplot(gs[0])\n    ax2 = plt.subplot(gs[1])\n\n    # Store all deltas for averaging\n    all_deltas = []\n    all_times_list = []\n    final_deltas = []  # Store final delta values for histogram\n\n    # Calculate common values once\n    prediction_time_obj, default_datetime = _prepare_common_values(prediction_time)\n\n    for snapshot_date in snapshot_dates:\n        # Prepare data for this date\n        df_copy, snapshot_datetime, _, _ = _prepare_arrival_data(\n            df, prediction_time, snapshot_date, prediction_window, yta_time_interval\n        )\n\n        # Get arrivals within the prediction window\n        arrivals = df_copy[\n            (df_copy.index &gt; snapshot_datetime)\n            &amp; (df_copy.index &lt;= snapshot_datetime + pd.Timedelta(prediction_window))\n        ]\n\n        if len(arrivals) == 0:\n            continue\n\n        # Sort arrivals by time and create cumulative count\n        arrivals = arrivals.sort_values(\"arrival_datetime\")\n        arrivals[\"cumulative_count\"] = range(1, len(arrivals) + 1)\n\n        # Calculate arrival rates and prepare time points\n        mean_arrival_rates = _calculate_arrival_rates(\n            df_copy, prediction_time_obj, prediction_window, yta_time_interval\n        )\n\n        # Prepare arrival times\n        arrival_times_piecewise = _prepare_arrival_times(\n            mean_arrival_rates, prediction_time_obj, default_date=datetime(2024, 1, 1)\n        )\n\n        # Calculate cumulative rates\n        cumulative_rates = _calculate_cumulative_rates(\n            arrival_times_piecewise, mean_arrival_rates\n        )\n\n        # Convert arrival times to use default date for plotting\n        arrival_times_plot = [\n            default_datetime + (t - snapshot_datetime) for t in arrivals.index\n        ]\n\n        # Create combined timeline\n        all_times = _create_combined_timeline(\n            default_datetime,\n            arrival_times_plot,\n            prediction_window,\n            arrival_times_piecewise,\n        )\n\n        # Interpolate both actual and expected to the combined timeline\n        actual_counts = np.interp(\n            [t.timestamp() for t in all_times],\n            [\n                t.timestamp()\n                for t in [default_datetime]\n                + arrival_times_plot\n                + [default_datetime + pd.Timedelta(prediction_window)]\n            ],\n            [0]\n            + list(arrivals[\"cumulative_count\"])\n            + [arrivals[\"cumulative_count\"].iloc[-1]],\n        )\n\n        expected_counts = np.interp(\n            [t.timestamp() for t in all_times],\n            [t.timestamp() for t in arrival_times_piecewise],\n            cumulative_rates,\n        )\n\n        # Calculate delta\n        delta = actual_counts - expected_counts\n        delta[0] = 0  # Ensure delta starts at 0\n\n        # Store for averaging\n        all_deltas.append(delta)\n        all_times_list.append(all_times)\n\n        # Store final delta value for histogram\n        final_deltas.append(delta[-1])\n\n        # Plot delta for this snapshot date\n        ax1.step(all_times, delta, where=\"post\", color=\"grey\", alpha=0.5)\n\n    # Calculate and plot average delta\n    if all_deltas:\n        # Find the common time points across all dates\n        common_times = sorted(set().union(*[set(times) for times in all_times_list]))\n\n        # Interpolate all deltas to common time points\n        interpolated_deltas = []\n        for times, delta in zip(all_times_list, all_deltas):\n            # Only interpolate within the actual time range for each date\n            min_time = min(times)\n            max_time = max(times)\n            valid_times = [t for t in common_times if min_time &lt;= t &lt;= max_time]\n\n            if valid_times:\n                interpolated = np.interp(\n                    [t.timestamp() for t in valid_times],\n                    [t.timestamp() for t in times],\n                    delta,\n                )\n                # Pad with NaN for times outside the valid range\n                padded = np.full(len(common_times), np.nan)\n                valid_indices = [\n                    i for i, t in enumerate(common_times) if t in valid_times\n                ]\n                padded[valid_indices] = interpolated\n                interpolated_deltas.append(padded)\n\n        # Calculate average delta, ignoring NaN values\n        avg_delta = np.nanmean(interpolated_deltas, axis=0)\n\n        # Plot average delta as a solid line\n        # Only plot where we have valid data (not NaN)\n        valid_mask = ~np.isnan(avg_delta)\n        if np.any(valid_mask):\n            ax1.step(\n                [t for t, m in zip(common_times, valid_mask) if m],\n                avg_delta[valid_mask],\n                where=\"post\",\n                color=\"red\",\n                linewidth=2,\n            )\n\n    # Add horizontal line at y=0\n    ax1.axhline(y=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n\n    # Format the main plot\n    ax1.set_xlabel(\"Time\")\n    ax1.set_ylabel(\"Difference (Actual - Expected)\")\n    ax1.set_title(\n        f\"Difference Between Actual and Expected Arrivals in the {(int(prediction_window.total_seconds()/3600))} hours after {format_prediction_time(prediction_time)} on all dates\"\n    )\n\n    # Format time axis\n    _format_time_axis(ax1, common_times)\n\n    # Create histogram of final delta values\n    if final_deltas:\n        # Round values to nearest integer for binning\n        rounded_deltas = np.round(final_deltas)\n        unique_values = np.unique(rounded_deltas)\n\n        # Create bins centered on integer values\n        bin_edges = np.arange(unique_values.min() - 0.5, unique_values.max() + 1.5, 1)\n\n        ax2.hist(final_deltas, bins=bin_edges, color=\"grey\", alpha=0.7)\n        ax2.axvline(x=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n        ax2.set_xlabel(\"Final Difference (Actual - Expected)\")\n        ax2.set_ylabel(\"Count\")\n        ax2.set_title(\"Distribution of Final Differences\")\n\n        # Set x-axis ticks to integer values with appropriate spacing\n        value_range = unique_values.max() - unique_values.min()\n        step_size = max(1, int(value_range / 10))  # Aim for about 10 ticks\n        ax2.set_xticks(\n            np.arange(unique_values.min(), unique_values.max() + 1, step_size)\n        )\n\n    plt.tight_layout()\n\n    if media_file_path:\n        filename = file_name if file_name else \"multiple_deltas.png\"\n        plt.savefig(media_file_path / filename, dpi=300)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n        plt.close()\n</code></pre>"},{"location":"api/#patientflow.viz.observed_against_expected.plot_deltas","title":"<code>plot_deltas(results1, results2=None, title1=None, title2=None, main_title='Histograms of Observed - Expected Values', xlabel='Observed minus expected', media_file_path=None, file_name=None, return_figure=False)</code>","text":"<p>Plot histograms of observed minus expected values.</p> <p>Creates a grid of histograms showing the distribution of differences between observed and expected values for different prediction times. Optionally compares two sets of results side by side.</p> <p>Parameters:</p> Name Type Description Default <code>results1</code> <code>dict</code> <p>First set of results containing observed and expected values for different prediction times. Keys are prediction times, values are dicts with 'observed' and 'expected' arrays.</p> required <code>results2</code> <code>dict</code> <p>Second set of results for comparison, following the same format as results1.</p> <code>None</code> <code>title1</code> <code>str</code> <p>Title for the first set of results.</p> <code>None</code> <code>title2</code> <code>str</code> <p>Title for the second set of results.</p> <code>None</code> <code>main_title</code> <code>str</code> <p>Main title for the entire plot.</p> <code>\"Histograms of Observed - Expected Values\"</code> <code>xlabel</code> <code>str</code> <p>Label for the x-axis of each histogram.</p> <code>\"Observed minus expected\"</code> <code>media_file_path</code> <code>Path</code> <p>Path where the plot should be saved. If provided, saves the plot as a PNG file.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"observed_vs_expected.png\".</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the matplotlib figure object instead of displaying it.</p> <code>False</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>The figure object if return_figure is True, otherwise None.</p> Notes <p>The function creates a grid of histograms with a maximum of 5 columns. Each histogram shows the distribution of differences between observed and expected values for a specific prediction time. A red dashed line at x=0 indicates where observed equals expected.</p> Source code in <code>src/patientflow/viz/observed_against_expected.py</code> <pre><code>def plot_deltas(\n    results1,\n    results2=None,\n    title1=None,\n    title2=None,\n    main_title=\"Histograms of Observed - Expected Values\",\n    xlabel=\"Observed minus expected\",\n    media_file_path=None,\n    file_name=None,\n    return_figure=False,\n):\n    \"\"\"Plot histograms of observed minus expected values.\n\n    Creates a grid of histograms showing the distribution of differences between\n    observed and expected values for different prediction times. Optionally compares\n    two sets of results side by side.\n\n    Parameters\n    ----------\n    results1 : dict\n        First set of results containing observed and expected values for different\n        prediction times. Keys are prediction times, values are dicts with 'observed'\n        and 'expected' arrays.\n    results2 : dict, optional\n        Second set of results for comparison, following the same format as results1.\n    title1 : str, optional\n        Title for the first set of results.\n    title2 : str, optional\n        Title for the second set of results.\n    main_title : str, default=\"Histograms of Observed - Expected Values\"\n        Main title for the entire plot.\n    xlabel : str, default=\"Observed minus expected\"\n        Label for the x-axis of each histogram.\n    media_file_path : Path, optional\n        Path where the plot should be saved. If provided, saves the plot as a PNG file.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"observed_vs_expected.png\".\n    return_figure : bool, default=False\n        If True, returns the matplotlib figure object instead of displaying it.\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        The figure object if return_figure is True, otherwise None.\n\n    Notes\n    -----\n    The function creates a grid of histograms with a maximum of 5 columns.\n    Each histogram shows the distribution of differences between observed and\n    expected values for a specific prediction time. A red dashed line at x=0\n    indicates where observed equals expected.\n    \"\"\"\n    # Calculate the number of subplots needed\n    num_plots = len(results1)\n\n    # Calculate the number of rows and columns for the subplots\n    num_cols = min(5, num_plots)  # Maximum of 5 columns\n    num_rows = math.ceil(num_plots / num_cols)\n\n    if results2:\n        num_rows *= 2  # Double the number of rows if we have two result sets\n\n    # Set a minimum width for the figure\n    min_width = 8  # minimum width in inches\n    width = max(min_width, 4 * num_cols)\n    height = 4 * num_rows\n\n    # Create the plot\n    fig, axes = plt.subplots(num_rows, num_cols, figsize=(width, height), squeeze=False)\n    fig.suptitle(main_title, fontsize=14)\n\n    # Flatten the axes array\n    axes = axes.flatten()\n\n    def plot_results(\n        results, start_index, result_title, global_min, global_max, max_freq\n    ):\n        # Convert prediction times to minutes for sorting\n        prediction_times_sorted = sorted(\n            results.items(),\n            key=lambda x: int(x[0].split(\"_\")[-1][:2]) * 60\n            + int(x[0].split(\"_\")[-1][2:]),\n        )\n\n        # Create symmetric bins around zero\n        bins = np.arange(global_min, global_max + 2) - 0.5\n\n        for i, (_prediction_time, values) in enumerate(prediction_times_sorted):\n            observed = np.array(values[\"observed\"])\n            expected = np.array(values[\"expected\"])\n            difference = observed - expected\n\n            ax = axes[start_index + i]\n\n            ax.hist(difference, bins=bins, edgecolor=\"black\", alpha=0.7)\n            ax.axvline(x=0, color=\"r\", linestyle=\"--\", linewidth=1)\n\n            # Format the prediction time\n            formatted_time = format_prediction_time(_prediction_time)\n\n            # Combine the result_title and formatted_time\n            if result_title:\n                ax.set_title(f\"{result_title} {formatted_time}\")\n            else:\n                ax.set_title(formatted_time)\n\n            ax.set_xlabel(xlabel)\n            ax.set_ylabel(\"Frequency\")\n            ax.set_xlim(global_min - 0.5, global_max + 0.5)\n            ax.set_ylim(0, max_freq)\n\n    # Calculate global min and max differences for consistent x-axis across both result sets\n    all_differences = []\n    max_counts = []\n\n    # Gather all differences and compute histogram data for both result sets\n    for results in [results1] + ([results2] if results2 else []):\n        for _, values in results.items():\n            observed = np.array(values[\"observed\"])\n            expected = np.array(values[\"expected\"])\n            differences = observed - expected\n            all_differences.extend(differences)\n            # Compute histogram data to find maximum frequency\n            counts, _ = np.histogram(differences)\n            max_counts.append(max(counts))\n\n    # Find the symmetric range around zero\n    abs_max = max(abs(min(all_differences)), abs(max(all_differences)))\n    global_min = -math.ceil(abs_max)\n    global_max = math.ceil(abs_max)\n\n    # Find the maximum frequency across all histograms\n    max_freq = math.ceil(max(max_counts) * 1.1)  # Add 10% padding\n\n    # Plot the first results set\n    plot_results(results1, 0, title1, global_min, global_max, max_freq)\n\n    # Plot the second results set if provided\n    if results2:\n        plot_results(results2, num_plots, title2, global_min, global_max, max_freq)\n\n    # Hide any unused subplots\n    for j in range(num_plots * (2 if results2 else 1), len(axes)):\n        fig.delaxes(axes[j])\n\n    plt.tight_layout()\n\n    if media_file_path:\n        if file_name:\n            plt.savefig(media_file_path / file_name, dpi=300)\n        else:\n            plt.savefig(media_file_path / \"observed_vs_expected.png\", dpi=300)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n        plt.close()\n</code></pre>"},{"location":"api/#patientflow.viz.probability_distribution","title":"<code>probability_distribution</code>","text":"<p>Module for generating probability distribution visualizations.</p> <p>Functions:</p> Name Description <code>plot_prob_dist : Plot a probability distribution as a bar chart with enhanced plotting options.</code>"},{"location":"api/#patientflow.viz.probability_distribution.plot_prob_dist","title":"<code>plot_prob_dist(prob_dist_data, title, media_file_path=None, figsize=(6, 3), include_titles=False, truncate_at_beds=None, text_size=None, bar_colour='#5B9BD5', file_name=None, probability_thresholds=None, show_probability_thresholds=True, probability_levels=None, plot_bed_base=None, xlabel='Number of beds', return_figure=False)</code>","text":"<p>Plot a probability distribution as a bar chart with enhanced plotting options.</p> <p>This function generates a bar plot for a given probability distribution, either as a pandas DataFrame, a scipy.stats distribution object (e.g., Poisson), or a dictionary. The plot can be customized with titles, axis labels, markers, and additional visual properties.</p> <p>Parameters:</p> Name Type Description Default <code>prob_dist_data</code> <code>pandas.DataFrame, dict, scipy.stats distribution, or array-like</code> <p>The probability distribution data to be plotted. Can be: - pandas DataFrame - dictionary (keys are indices, values are probabilities) - scipy.stats distribution (e.g., Poisson). If a <code>scipy.stats</code> distribution is provided, the function computes probabilities for integer values within the specified range. - array-like of probabilities (indices will be 0 to len(array)-1)</p> required <code>title</code> <code>str</code> <p>The title of the plot, used for display and optionally as the file name.</p> required <code>media_file_path</code> <code>str or Path</code> <p>Directory where the plot image will be saved. If not provided, the plot is displayed without saving.</p> <code>None</code> <code>figsize</code> <code>tuple of float</code> <p>The size of the figure, specified as (width, height). Default is (6, 3)</p> <code>(6, 3)</code> <code>include_titles</code> <code>bool</code> <p>Whether to include titles and axis labels in the plot. Default is False</p> <code>False</code> <code>truncate_at_beds</code> <code>int or tuple of (int, int)</code> <p>Either a single number specifying the upper bound, or a tuple of (lower_bound, upper_bound) for the x-axis range. If None, the full range of the data will be displayed.</p> <code>None</code> <code>text_size</code> <code>int</code> <p>Font size for plot text, including titles and tick labels.</p> <code>None</code> <code>bar_colour</code> <code>str</code> <p>The color of the bars in the plot. Default is \"#5B9BD5\"</p> <code>'#5B9BD5'</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to a generated name based on the title.</p> <code>None</code> <code>probability_thresholds</code> <code>dict</code> <p>A dictionary where keys are points on the cumulative distribution function (as decimals, e.g., 0.9 for 90%) and values are the corresponding resource thresholds (bed counts). For example, {0.9: 15} indicates there is a 90% probability that at least 15 beds will be needed (represents the lower tail of the distribution).</p> <code>None</code> <code>show_probability_thresholds</code> <code>bool</code> <p>Whether to show vertical lines indicating the resource requirements at different points on the cumulative distribution function. Default is True</p> <code>True</code> <code>probability_levels</code> <code>list of float</code> <p>List of probability levels for automatic threshold calculation.</p> <code>None</code> <code>plot_bed_base</code> <code>dict</code> <p>Dictionary of bed balance lines to plot in red. Keys are labels and values are x-axis positions.</p> <code>None</code> <code>xlabel</code> <code>str</code> <p>A label for the x axis. Default is \"Number of beds\"</p> <code>'Number of beds'</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the matplotlib figure instead of displaying it. Default is False</p> <code>False</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>Returns the figure if return_figure is True, otherwise displays the plot</p> <p>Examples:</p> <p>Basic usage with an array of probabilities:</p> <pre><code>&gt;&gt;&gt; probabilities = [0.05, 0.1, 0.2, 0.3, 0.2, 0.1, 0.05]\n&gt;&gt;&gt; plot_prob_dist(probabilities, \"Bed Demand Distribution\")\n</code></pre> <p>With thresholds:</p> <pre><code>&gt;&gt;&gt; thresholds = _calculate_probability_thresholds(probabilities, [0.8, 0.95])\n&gt;&gt;&gt; plot_prob_dist(probabilities, \"Bed Demand with Confidence Levels\",\n...                probability_thresholds=thresholds)\n</code></pre> <p>Using with a scipy stats distribution:</p> <pre><code>&gt;&gt;&gt; from scipy import stats\n&gt;&gt;&gt; poisson_dist = stats.poisson(mu=5)  # Poisson with mean of 5\n&gt;&gt;&gt; plot_prob_dist(poisson_dist, \"Poisson Distribution (\u03bc=5)\",\n...                truncate_at_beds=(0, 15))\n</code></pre> Source code in <code>src/patientflow/viz/probability_distribution.py</code> <pre><code>def plot_prob_dist(\n    prob_dist_data,\n    title,\n    media_file_path=None,\n    figsize=(6, 3),\n    include_titles=False,\n    truncate_at_beds=None,\n    text_size=None,\n    bar_colour=\"#5B9BD5\",\n    file_name=None,\n    probability_thresholds=None,\n    show_probability_thresholds=True,\n    probability_levels=None,\n    plot_bed_base=None,\n    xlabel=\"Number of beds\",\n    return_figure=False,\n):\n    \"\"\"Plot a probability distribution as a bar chart with enhanced plotting options.\n\n    This function generates a bar plot for a given probability distribution, either\n    as a pandas DataFrame, a scipy.stats distribution object (e.g., Poisson), or a\n    dictionary. The plot can be customized with titles, axis labels, markers, and\n    additional visual properties.\n\n    Parameters\n    ----------\n    prob_dist_data : pandas.DataFrame, dict, scipy.stats distribution, or array-like\n        The probability distribution data to be plotted. Can be:\n        - pandas DataFrame\n        - dictionary (keys are indices, values are probabilities)\n        - scipy.stats distribution (e.g., Poisson). If a `scipy.stats` distribution is provided,\n        the function computes probabilities for integer values within the specified range.\n        - array-like of probabilities (indices will be 0 to len(array)-1)\n    title : str\n        The title of the plot, used for display and optionally as the file name.\n    media_file_path : str or pathlib.Path, optional\n        Directory where the plot image will be saved. If not provided, the plot is\n        displayed without saving.\n    figsize : tuple of float, optional\n        The size of the figure, specified as (width, height).\n        Default is (6, 3)\n    include_titles : bool, optional\n        Whether to include titles and axis labels in the plot.\n        Default is False\n    truncate_at_beds : int or tuple of (int, int), optional\n        Either a single number specifying the upper bound, or a tuple of\n        (lower_bound, upper_bound) for the x-axis range. If None, the full\n        range of the data will be displayed.\n    text_size : int, optional\n        Font size for plot text, including titles and tick labels.\n    bar_colour : str, optional\n        The color of the bars in the plot.\n        Default is \"#5B9BD5\"\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to a generated name based on the title.\n    probability_thresholds : dict, optional\n        A dictionary where keys are points on the cumulative distribution function (as decimals, e.g., 0.9 for 90%)\n        and values are the corresponding resource thresholds (bed counts).\n        For example, {0.9: 15} indicates there is a 90% probability that\n        at least 15 beds will be needed (represents the lower tail of the distribution).\n    show_probability_thresholds : bool, optional\n        Whether to show vertical lines indicating the resource requirements\n        at different points on the cumulative distribution function.\n        Default is True\n    probability_levels : list of float, optional\n        List of probability levels for automatic threshold calculation.\n    plot_bed_base : dict, optional\n        Dictionary of bed balance lines to plot in red.\n        Keys are labels and values are x-axis positions.\n    xlabel : str, optional\n        A label for the x axis.\n        Default is \"Number of beds\"\n    return_figure : bool, optional\n        If True, returns the matplotlib figure instead of displaying it.\n        Default is False\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        Returns the figure if return_figure is True, otherwise displays the plot\n\n    Examples\n    --------\n    Basic usage with an array of probabilities:\n\n    &gt;&gt;&gt; probabilities = [0.05, 0.1, 0.2, 0.3, 0.2, 0.1, 0.05]\n    &gt;&gt;&gt; plot_prob_dist(probabilities, \"Bed Demand Distribution\")\n\n    With thresholds:\n\n    &gt;&gt;&gt; thresholds = _calculate_probability_thresholds(probabilities, [0.8, 0.95])\n    &gt;&gt;&gt; plot_prob_dist(probabilities, \"Bed Demand with Confidence Levels\",\n    ...                probability_thresholds=thresholds)\n\n    Using with a scipy stats distribution:\n\n    &gt;&gt;&gt; from scipy import stats\n    &gt;&gt;&gt; poisson_dist = stats.poisson(mu=5)  # Poisson with mean of 5\n    &gt;&gt;&gt; plot_prob_dist(poisson_dist, \"Poisson Distribution (\u03bc=5)\",\n    ...                truncate_at_beds=(0, 15))\n    \"\"\"\n\n    # Handle array-like input\n    if isinstance(prob_dist_data, (np.ndarray, list)):\n        array_length = len(prob_dist_data)\n        prob_dist_data = pd.DataFrame(\n            {\"agg_proba\": prob_dist_data}, index=range(array_length)\n        )\n\n    # Handle scipy.stats distribution input\n    elif hasattr(prob_dist_data, \"pmf\") and callable(prob_dist_data.pmf):\n        # Determine range for the distribution\n        if truncate_at_beds is None:\n            # Default range for distributions if not specified\n            lower_bound = 0\n            upper_bound = 20  # Reasonable default for most discrete distributions\n        elif isinstance(truncate_at_beds, (int, float)):\n            lower_bound = 0\n            upper_bound = truncate_at_beds\n        else:\n            lower_bound, upper_bound = truncate_at_beds\n\n        # Generate x values and probabilities\n        x = np.arange(lower_bound, upper_bound + 1)\n        probs = prob_dist_data.pmf(x)\n        prob_dist_data = pd.DataFrame({\"agg_proba\": probs}, index=x)\n\n        # No need to filter later\n        truncate_at_beds = None\n\n    # Handle dictionary input\n    elif isinstance(prob_dist_data, dict):\n        prob_dist_data = pd.DataFrame(\n            {\"agg_proba\": list(prob_dist_data.values())},\n            index=list(prob_dist_data.keys()),\n        )\n\n    # Apply truncation if specified\n    if truncate_at_beds is not None:\n        # Determine bounds\n        if isinstance(truncate_at_beds, (int, float)):\n            lower_bound = 0\n            upper_bound = truncate_at_beds\n        else:\n            lower_bound, upper_bound = truncate_at_beds\n\n        # Apply filtering\n        mask = (prob_dist_data.index &gt;= lower_bound) &amp; (\n            prob_dist_data.index &lt;= upper_bound\n        )\n        filtered_data = prob_dist_data[mask]\n    else:\n        # Use all available data\n        filtered_data = prob_dist_data\n\n    # Calculate probability thresholds if probability_levels is provided\n    if probability_thresholds is None and probability_levels is not None:\n        probability_thresholds = _calculate_probability_thresholds(\n            filtered_data[\"agg_proba\"].values, probability_levels\n        )\n\n    # Create the plot\n    fig = plt.figure(figsize=figsize)\n\n    if not file_name:\n        file_name = (\n            title.replace(\" \", \"_\").replace(\"/n\", \"_\").replace(\"%\", \"percent\") + \".png\"\n        )\n\n    # Plot bars\n    plt.bar(\n        filtered_data.index,\n        filtered_data[\"agg_proba\"].values,\n        color=bar_colour,\n    )\n\n    # Generate appropriate ticks based on data range\n    if len(filtered_data) &gt; 0:\n        data_min = min(filtered_data.index)\n        data_max = max(filtered_data.index)\n        data_range = data_max - data_min\n\n        if data_range &lt;= 10:\n            tick_step = 1\n        elif data_range &lt;= 50:\n            tick_step = 5\n        else:\n            tick_step = 10\n\n        tick_start = (data_min // tick_step) * tick_step\n        tick_end = data_max + 1\n        plt.xticks(np.arange(tick_start, tick_end, tick_step))\n\n    # Plot probability threshold lines\n    if show_probability_thresholds and probability_thresholds:\n        colors = itertools.cycle(\n            plt.cm.gray(np.linspace(0.3, 0.7, len(probability_thresholds)))\n        )\n        for probability, bed_count in probability_thresholds.items():\n            plt.axvline(\n                x=bed_count,\n                linestyle=\"--\",\n                linewidth=2,\n                color=next(colors),\n                label=f\"{probability*100:.0f}% probability of needing \u2265 {bed_count} beds\",\n            )\n        plt.legend(loc=\"upper right\")\n\n    # Add bed balance lines\n    if plot_bed_base:\n        for point in plot_bed_base:\n            plt.axvline(\n                x=plot_bed_base[point],\n                linewidth=2,\n                color=\"red\",\n                label=f\"bed balance: {point}\",\n            )\n        plt.legend(loc=\"upper right\")\n\n    # Add text and labels\n    if text_size:\n        plt.tick_params(axis=\"both\", which=\"major\", labelsize=text_size)\n        plt.xlabel(xlabel, fontsize=text_size)\n        if include_titles:\n            plt.title(title, fontsize=text_size)\n            plt.ylabel(\"Probability\", fontsize=text_size)\n    else:\n        plt.xlabel(xlabel)\n        if include_titles:\n            plt.title(title)\n            plt.ylabel(\"Probability\")\n\n    plt.tight_layout()\n\n    # Save or display the figure\n    if media_file_path:\n        plt.savefig(media_file_path / file_name.replace(\" \", \"_\"), dpi=300)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n</code></pre>"},{"location":"api/#patientflow.viz.quantile_quantile","title":"<code>quantile_quantile</code>","text":"<p>Generate Quantile-Quantile (QQ) plots to compare observed values with model predictions.</p> <p>This module creates QQ plots for healthcare bed demand predictions, comparing observed values with model predictions. A QQ plot is a graphical technique for determining if two data sets come from populations with a common distribution. If the points form a line approximately along the reference line y=x, this suggests the distributions are similar.</p> <p>Functions:</p> Name Description <code>qq_plot : function</code> <p>Generate multiple QQ plots comparing observed values with model predictions</p> Notes <p>To prepare the predicted distribution: * Treat the predicted distributions (saved as cdfs) for all time points of interest as if they were one distribution * Within this predicted distribution, because each probability is over a discrete rather than continuous number of input values, the upper and lower of values of the probability range are saved at each value * The mid point between upper and lower is calculated and saved * The distribution of cdf mid points (one for each horizon date) is sorted by value of the mid point and a cdf of this is calculated (this is a cdf of cdfs, in effect) * These are weighted by the probability of each value occurring</p> <p>To prepare the observed distribution: * Take observed number each horizon date and save the cdf of that value from its predicted distribution * The distribution of cdf values (one per horizon date) is sorted * These are weighted by the probability of each value occurring, which is a uniform probability (1 / over the number of horizon dates)</p>"},{"location":"api/#patientflow.viz.quantile_quantile.qq_plot","title":"<code>qq_plot(prediction_times, prob_dist_dict_all, model_name='admissions', return_figure=False, figsize=None, suptitle=None, media_file_path=None, file_name=None)</code>","text":"<p>Generate multiple QQ plots comparing observed values with model predictions.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_times</code> <code>list of tuple</code> <p>List of (hour, minute) tuples for prediction times.</p> required <code>prob_dist_dict_all</code> <code>dict</code> <p>Dictionary of probability distributions keyed by model_key.</p> required <code>model_name</code> <code>str</code> <p>Base name of the model to construct model keys.</p> <code>\"admissions\"</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure object instead of displaying it.</p> <code>False</code> <code>figsize</code> <code>tuple of float</code> <p>Size of the figure in inches as (width, height). If None, calculated automatically based on number of plots.</p> <code>None</code> <code>suptitle</code> <code>str</code> <p>Super title for the entire figure, displayed above all subplots.</p> <code>None</code> <code>media_file_path</code> <code>Path</code> <p>Path to save the plot.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"qq_plot.png\".</p> <code>None</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>Returns the figure if return_figure is True, otherwise displays the plot and returns None.</p> Notes <p>The function creates a QQ plot for each prediction time, comparing the observed distribution with the predicted distribution. Each subplot shows how well the model's predictions match the actual observations.</p> Source code in <code>src/patientflow/viz/quantile_quantile.py</code> <pre><code>def qq_plot(\n    prediction_times,\n    prob_dist_dict_all,\n    model_name=\"admissions\",\n    return_figure=False,\n    figsize=None,\n    suptitle=None,\n    media_file_path=None,\n    file_name=None,\n):\n    \"\"\"Generate multiple QQ plots comparing observed values with model predictions.\n\n    Parameters\n    ----------\n    prediction_times : list of tuple\n        List of (hour, minute) tuples for prediction times.\n    prob_dist_dict_all : dict\n        Dictionary of probability distributions keyed by model_key.\n    model_name : str, default=\"admissions\"\n        Base name of the model to construct model keys.\n    return_figure : bool, default=False\n        If True, returns the figure object instead of displaying it.\n    figsize : tuple of float, optional\n        Size of the figure in inches as (width, height). If None, calculated automatically\n        based on number of plots.\n    suptitle : str, optional\n        Super title for the entire figure, displayed above all subplots.\n    media_file_path : Path, optional\n        Path to save the plot.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"qq_plot.png\".\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        Returns the figure if return_figure is True, otherwise displays the plot and returns None.\n\n    Notes\n    -----\n    The function creates a QQ plot for each prediction time, comparing the observed\n    distribution with the predicted distribution. Each subplot shows how well the\n    model's predictions match the actual observations.\n    \"\"\"\n    # Sort prediction times by converting to minutes since midnight\n    prediction_times_sorted = sorted(\n        prediction_times,\n        key=lambda x: x[0] * 60\n        + x[1],  # Convert (hour, minute) to minutes since midnight\n    )\n\n    num_plots = len(prediction_times_sorted)\n    if figsize is None:\n        figsize = (num_plots * 5, 4)\n\n    # Create subplot layout\n    fig, axs = plt.subplots(1, num_plots, figsize=figsize)\n\n    # Handle case of single prediction time\n    if num_plots == 1:\n        axs = [axs]\n\n    # Loop through each subplot\n    for i, prediction_time in enumerate(prediction_times_sorted):\n        # Initialize lists to store CDF and observed data\n        cdf_data = []\n        observed_data = []\n\n        # Get model key and corresponding prob_dist_dict\n        model_key = get_model_key(model_name, prediction_time)\n        prob_dist_dict = prob_dist_dict_all[model_key]\n\n        # Process data for current subplot\n        for dt in prob_dist_dict:\n            agg_predicted = np.array(prob_dist_dict[dt][\"agg_predicted\"])\n            agg_observed = prob_dist_dict[dt][\"agg_observed\"]\n\n            upper = agg_predicted.cumsum()\n            lower = np.hstack((0, upper[:-1]))\n            mid = (upper + lower) / 2\n\n            cdf_data.append(np.column_stack((upper, lower, mid, agg_predicted)))\n            # Round the observed data to nearest integer before using as index\n            agg_observed_int = int(round(agg_observed))\n            observed_data.append(mid[agg_observed_int])\n\n        if not cdf_data:\n            continue\n\n        # Prepare data for plotting\n        cdf_data = np.vstack(cdf_data)\n        qq_model = pd.DataFrame(\n            cdf_data, columns=[\"cdf_upper\", \"cdf_mid\", \"cdf_lower\", \"weights\"]\n        )\n        qq_model = qq_model.sort_values(\"cdf_mid\")\n        qq_model[\"cum_weight\"] = qq_model[\"weights\"].cumsum()\n        qq_model[\"cum_weight_normed\"] = (\n            qq_model[\"cum_weight\"] / qq_model[\"weights\"].sum()\n        )\n\n        qq_observed = pd.DataFrame(observed_data, columns=[\"cdf_observed\"])\n        qq_observed = qq_observed.sort_values(\"cdf_observed\")\n        qq_observed[\"weights\"] = 1 / len(observed_data)\n        qq_observed[\"cum_weight_normed\"] = qq_observed[\"weights\"].cumsum()\n\n        qq_observed[\"max_model_cdf_at_this_value\"] = qq_observed[\"cdf_observed\"].apply(\n            lambda x: qq_model[qq_model[\"cdf_mid\"] &lt;= x][\"cum_weight_normed\"].max()\n        )\n\n        # Plot on current subplot\n        ax = axs[i]\n        ax.set_aspect(\"equal\")\n        ax.set_xlim([0, 1])\n        ax.set_ylim([0, 1])\n\n        # Reference line y=x\n        ax.plot([0, 1], [0, 1], linestyle=\"--\")\n\n        # Plot QQ data points\n        ax.plot(\n            qq_observed[\"max_model_cdf_at_this_value\"],\n            qq_observed[\"cum_weight_normed\"],\n            marker=\".\",\n            linewidth=0,\n        )\n\n        # Set labels and title for subplot with hour:minute format\n        hour, minutes = prediction_time\n        ax.set_xlabel(\"Cdf of model distribution\")\n        ax.set_ylabel(\"Cdf of observed distribution\")\n        ax.set_title(f\"QQ Plot for {hour}:{minutes:02}\")\n\n    plt.tight_layout()\n\n    # Add suptitle if provided\n    if suptitle:\n        plt.suptitle(suptitle, fontsize=16, y=1.05)\n\n    if media_file_path:\n        plt.savefig(media_file_path / (file_name or \"qq_plot.png\"), dpi=300)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n        plt.close(fig)\n</code></pre>"},{"location":"api/#patientflow.viz.randomised_pit","title":"<code>randomised_pit</code>","text":""},{"location":"api/#patientflow.viz.randomised_pit.plot_randomised_pit","title":"<code>plot_randomised_pit(prediction_times, prob_dist_dict_all, model_name='admissions', return_figure=False, return_dataframe=False, figsize=None, suptitle=None, media_file_path=None, file_name=None, n_bins=10, seed=42)</code>","text":"<p>Generate randomised PIT histograms for multiple prediction times side by side.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_times</code> <code>list of tuple</code> <p>List of (hour, minute) tuples representing times for which predictions were made.</p> required <code>prob_dist_dict_all</code> <code>dict</code> <p>Dictionary of probability distributions keyed by model_key. Each entry contains information about predicted distributions and observed values for different snapshot dates.</p> required <code>model_name</code> <code>str</code> <p>Base name of the model to construct model keys, by default \"admissions\".</p> <code>'admissions'</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure object instead of displaying it, by default False.</p> <code>False</code> <code>return_dataframe</code> <code>bool</code> <p>If True, returns a dictionary of PIT values by model_key, by default False.</p> <code>False</code> <code>figsize</code> <code>tuple of (float, float)</code> <p>Size of the figure in inches as (width, height). If None, calculated automatically based on number of plots, by default None.</p> <code>None</code> <code>suptitle</code> <code>str</code> <p>Super title for the entire figure, displayed above all subplots, by default None.</p> <code>None</code> <code>media_file_path</code> <code>Path</code> <p>Path to save the plot, by default None. If provided, saves the plot as a PNG file.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"plot_randomised_pit.png\".</p> <code>None</code> <code>n_bins</code> <code>int</code> <p>Number of histogram bins, by default 10.</p> <code>10</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility, by default 42.</p> <code>42</code> <p>Returns:</p> Type Description <code>Figure</code> <p>The figure object containing the plots, if return_figure is True.</p> <code>dict</code> <p>Dictionary of PIT values by model_key, if return_dataframe is True.</p> <code>tuple</code> <p>Tuple of (figure, pit_values_dict) if both return_figure and return_dataframe are True.</p> <code>None</code> <p>If neither return_figure nor return_dataframe is True, displays the plots and returns None.</p> Source code in <code>src/patientflow/viz/randomised_pit.py</code> <pre><code>def plot_randomised_pit(\n    prediction_times: List[Tuple[int, int]],\n    prob_dist_dict_all: Dict[str, Dict],\n    model_name: str = \"admissions\",\n    return_figure: bool = False,\n    return_dataframe: bool = False,\n    figsize: Optional[Tuple[float, float]] = None,\n    suptitle: Optional[str] = None,\n    media_file_path: Optional[Path] = None,\n    file_name: Optional[str] = None,\n    n_bins: int = 10,\n    seed: Optional[int] = 42,\n) -&gt; Union[\n    plt.Figure, Dict[str, List[float]], Tuple[plt.Figure, Dict[str, List[float]]], None\n]:\n    \"\"\"\n    Generate randomised PIT histograms for multiple prediction times side by side.\n\n    Parameters\n    ----------\n    prediction_times : list of tuple\n        List of (hour, minute) tuples representing times for which predictions were made.\n    prob_dist_dict_all : dict\n        Dictionary of probability distributions keyed by model_key. Each entry contains\n        information about predicted distributions and observed values for different\n        snapshot dates.\n    model_name : str, optional\n        Base name of the model to construct model keys, by default \"admissions\".\n    return_figure : bool, optional\n        If True, returns the figure object instead of displaying it, by default False.\n    return_dataframe : bool, optional\n        If True, returns a dictionary of PIT values by model_key, by default False.\n    figsize : tuple of (float, float), optional\n        Size of the figure in inches as (width, height). If None, calculated automatically\n        based on number of plots, by default None.\n    suptitle : str, optional\n        Super title for the entire figure, displayed above all subplots, by default None.\n    media_file_path : Path, optional\n        Path to save the plot, by default None. If provided, saves the plot as a PNG file.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"plot_randomised_pit.png\".\n    n_bins : int, optional\n        Number of histogram bins, by default 10.\n    seed : int, optional\n        Random seed for reproducibility, by default 42.\n\n    Returns\n    -------\n    matplotlib.figure.Figure\n        The figure object containing the plots, if return_figure is True.\n    dict\n        Dictionary of PIT values by model_key, if return_dataframe is True.\n    tuple\n        Tuple of (figure, pit_values_dict) if both return_figure and return_dataframe are True.\n    None\n        If neither return_figure nor return_dataframe is True, displays the plots and returns None.\n    \"\"\"\n    if seed is not None:\n        np.random.seed(seed)\n\n    # Sort prediction times by converting to minutes since midnight\n    prediction_times_sorted = sorted(\n        prediction_times,\n        key=lambda x: x[0] * 60 + x[1],\n    )\n\n    # Calculate figure parameters\n    num_plots = len(prediction_times_sorted)\n    figsize = figsize or (num_plots * 5, 4)\n\n    # Create subplot layout\n    fig, axs = plt.subplots(1, num_plots, figsize=figsize)\n    axs = [axs] if num_plots == 1 else axs\n\n    all_pit_values: Dict[str, List[float]] = {}\n    max_density = 0.0  # Track maximum density across all histograms\n\n    # Process each subplot\n    for i, prediction_time in enumerate(prediction_times_sorted):\n        model_key = get_model_key(model_name, prediction_time)\n        prob_dist_dict = prob_dist_dict_all[model_key]\n\n        if not prob_dist_dict:\n            continue\n\n        observations = []\n        cdf_functions = []\n\n        # Extract data for each date\n        for dt in prob_dist_dict:\n            try:\n                observation = prob_dist_dict[dt][\"agg_observed\"]\n                predicted_dist = prob_dist_dict[dt][\"agg_predicted\"][\"agg_proba\"]\n\n                # Convert probability distribution to CDF function\n                cdf_func = _prob_to_cdf(predicted_dist)\n\n                observations.append(observation)\n                cdf_functions.append(cdf_func)\n\n            except Exception as e:\n                print(f\"Skipping date {dt} due to error: {e}\")\n                continue\n\n        if len(observations) == 0:\n            continue\n\n        # Generate PIT values\n        pit_values = []\n\n        for obs, cdf_func in zip(observations, cdf_functions):\n            try:\n                # Calculate PIT range bounds\n                lower = cdf_func(obs - 1) if obs &gt; 0 else 0.0\n                upper = cdf_func(obs)\n\n                # Sample randomly within the range\n                pit_value = np.random.uniform(lower, upper)\n                pit_values.append(pit_value)\n\n            except Exception as e:\n                print(f\"Error processing observation {obs}: {e}\")\n                continue\n\n        all_pit_values[model_key] = pit_values\n\n        # Calculate histogram to get density\n        hist, _ = np.histogram(pit_values, bins=n_bins, density=True)\n        max_density = max(max_density, np.max(hist))\n\n    # Now plot with consistent y-axis scale\n    for i, prediction_time in enumerate(prediction_times_sorted):\n        model_key = get_model_key(model_name, prediction_time)\n        pit_values = all_pit_values.get(model_key, [])\n\n        if not pit_values:\n            continue\n\n        # Plot histogram\n        ax = axs[i]\n        ax.hist(\n            pit_values,\n            bins=n_bins,\n            density=True,\n            alpha=0.7,\n            edgecolor=\"black\",\n            label=\"Randomised PIT\",\n        )\n\n        # Add uniform reference line\n        ax.axhline(\n            y=1.0, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Perfect Uniform\"\n        )\n\n        # Set labels and title\n        hour, minutes = prediction_time\n        ax.set_xlabel(\"PIT Value\")\n        ax.set_ylabel(\"Density\")\n        ax.set_title(f\"PIT Histogram for {hour}:{minutes:02}\")\n        ax.set_xlim(0, 1)\n        ax.set_ylim(0, max_density * 1.1)  # Add 10% padding\n        ax.grid(True, alpha=0.3)\n\n        if i == 0:  # Only show legend on first subplot\n            ax.legend()\n\n    # Final plot configuration\n    plt.tight_layout()\n    if suptitle:\n        plt.suptitle(suptitle, fontsize=16, y=1.05)\n    if media_file_path:\n        plt.savefig(media_file_path / (file_name or \"plot_randomised_pit.png\"), dpi=300)\n\n    # Return based on flags\n    if return_figure and return_dataframe:\n        return fig, all_pit_values\n    elif return_figure:\n        return fig\n    elif return_dataframe:\n        plt.show()\n        plt.close()\n        return all_pit_values\n    else:\n        plt.show()\n        plt.close()\n        return None\n</code></pre>"},{"location":"api/#patientflow.viz.shap","title":"<code>shap</code>","text":"<p>SHAP (SHapley Additive exPlanations) visualization module.</p> <p>This module provides functionality for generating SHAP plots. These are useful for visualizing feature importance and their impact on model decisions.</p> <p>Functions:</p> Name Description <code>plot_shap : function</code> <p>Generate SHAP plots for multiple trained models.</p>"},{"location":"api/#patientflow.viz.shap.plot_shap","title":"<code>plot_shap(trained_models, test_visits, exclude_from_training_data, media_file_path=None, file_name=None, return_figure=False, label_col='is_admitted')</code>","text":"<p>Generate SHAP plots for multiple trained models.</p> <p>This function creates SHAP (SHapley Additive exPlanations) summary plots for each trained model, showing the impact of features on model predictions. The plots can be saved to a specified media file path or displayed directly.</p> <p>Parameters:</p> Name Type Description Default <code>trained_models</code> <code>list[TrainedClassifier] or dict[str, TrainedClassifier]</code> <p>List of trained classifier objects or dictionary with TrainedClassifier values.</p> required <code>test_visits</code> <code>DataFrame</code> <p>DataFrame containing the test visit data.</p> required <code>exclude_from_training_data</code> <code>list[str]</code> <p>List of columns to exclude from training data.</p> required <code>media_file_path</code> <code>Path</code> <p>Directory path where the generated plots will be saved. If None, plots are only displayed.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"shap_plot.png\".</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, returns the figure instead of displaying it.</p> <code>False</code> <code>label_col</code> <code>str</code> <p>Name of the column containing the target labels.</p> <code>\"is_admitted\"</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>If return_figure is True, returns the generated figure. Otherwise, returns None.</p> Source code in <code>src/patientflow/viz/shap.py</code> <pre><code>def plot_shap(\n    trained_models: list[TrainedClassifier] | dict[str, TrainedClassifier],\n    test_visits,\n    exclude_from_training_data,\n    media_file_path: Optional[Path] = None,\n    file_name: Optional[str] = None,\n    return_figure=False,\n    label_col: str = \"is_admitted\",\n):\n    \"\"\"Generate SHAP plots for multiple trained models.\n\n    This function creates SHAP (SHapley Additive exPlanations) summary plots for each\n    trained model, showing the impact of features on model predictions. The plots can\n    be saved to a specified media file path or displayed directly.\n\n    Parameters\n    ----------\n    trained_models : list[TrainedClassifier] or dict[str, TrainedClassifier]\n        List of trained classifier objects or dictionary with TrainedClassifier values.\n    test_visits : pandas.DataFrame\n        DataFrame containing the test visit data.\n    exclude_from_training_data : list[str]\n        List of columns to exclude from training data.\n    media_file_path : Path, optional\n        Directory path where the generated plots will be saved. If None, plots are\n        only displayed.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"shap_plot.png\".\n    return_figure : bool, default=False\n        If True, returns the figure instead of displaying it.\n    label_col : str, default=\"is_admitted\"\n        Name of the column containing the target labels.\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        If return_figure is True, returns the generated figure. Otherwise, returns None.\n    \"\"\"\n    # Convert dict to list if needed\n    if isinstance(trained_models, dict):\n        trained_models = list(trained_models.values())\n\n    # Sort trained_models by prediction time\n    trained_models_sorted = sorted(\n        trained_models,\n        key=lambda x: x.training_results.prediction_time[0] * 60\n        + x.training_results.prediction_time[1],\n    )\n\n    for trained_model in trained_models_sorted:\n        fig, ax = plt.subplots(figsize=(8, 12))\n\n        # use non-calibrated pipeline\n        pipeline: Pipeline = trained_model.pipeline\n        prediction_time = trained_model.training_results.prediction_time\n\n        # Get test data for this prediction time\n        X_test, _ = prepare_patient_snapshots(\n            df=test_visits,\n            prediction_time=prediction_time,\n            exclude_columns=exclude_from_training_data,\n            single_snapshot_per_visit=False,\n            label_col=label_col,\n        )\n\n        X_test = add_missing_columns(pipeline, X_test)\n        transformed_cols = pipeline.named_steps[\n            \"feature_transformer\"\n        ].get_feature_names_out()\n        transformed_cols = [col.split(\"__\")[-1] for col in transformed_cols]\n        truncated_cols = [col[:45] for col in transformed_cols]\n\n        # Transform features\n        X_test = pipeline.named_steps[\"feature_transformer\"].transform(X_test)\n\n        # Create SHAP explainer\n        explainer = shap.TreeExplainer(pipeline.named_steps[\"classifier\"])\n\n        # Convert sparse matrix to dense if necessary\n        if scipy.sparse.issparse(X_test):\n            X_test = X_test.toarray()\n\n        shap_values = explainer.shap_values(X_test)\n\n        # Print prediction distribution\n        predictions = pipeline.named_steps[\"classifier\"].predict(X_test)\n        print(\n            \"Predicted classification (not admitted, admitted): \",\n            np.bincount(predictions),\n        )\n\n        # Print mean SHAP values for each class\n        if isinstance(shap_values, list):\n            print(\"SHAP values shape:\", [arr.shape for arr in shap_values])\n            print(\"Mean SHAP values (class 0):\", np.abs(shap_values[0]).mean(0))\n            print(\"Mean SHAP values (class 1):\", np.abs(shap_values[1]).mean(0))\n\n        # Create SHAP summary plot\n        rng = np.random.default_rng()\n        shap.summary_plot(\n            shap_values,\n            X_test,\n            feature_names=truncated_cols,\n            show=False,\n            rng=rng,\n        )\n\n        hour, minutes = prediction_time\n        ax.set_title(f\"SHAP Values for Time of Day: {hour}:{minutes:02}\")\n        ax.set_xlabel(\"SHAP Value\")\n        plt.tight_layout()\n\n        if media_file_path:\n            # Save plot\n            if file_name:\n                shap_plot_path = str(media_file_path / file_name)\n            else:\n                shap_plot_path = str(\n                    media_file_path / f\"shap_plot_{hour:02}{minutes:02}.png\"\n                )\n            plt.savefig(shap_plot_path)\n\n        if return_figure:\n            return fig\n        else:\n            plt.show()\n            plt.close(fig)\n</code></pre>"},{"location":"api/#patientflow.viz.survival_curve","title":"<code>survival_curve</code>","text":"<p>Visualization tools for patient flow analysis using survival curves.</p> <p>This module provides functions to create and analyze survival curves for time-to-event analysis.</p> <p>Functions:</p> Name Description <code>plot_admission_time_survival_curve : function</code> <p>Create single or multiple survival curves for ward admission times</p> Notes <ul> <li>The survival curves show the proportion of patients who have not yet   experienced an event (e.g., admission to ward) over time</li> <li>Time is measured in hours from the initial event (e.g., arrival)</li> <li>A 4-hour target line is included by default to show performance   against common healthcare targets</li> <li>The curves are created without external survival analysis packages   for simplicity and transparency</li> <li>Multiple curves can be plotted on the same figure for comparison</li> </ul>"},{"location":"api/#patientflow.viz.survival_curve.plot_admission_time_survival_curve","title":"<code>plot_admission_time_survival_curve(df, start_time_col='arrival_datetime', end_time_col='departure_datetime', title='Time to Event Survival Curve', target_hours=[4], xlabel='Elapsed time from start', ylabel='Proportion not yet experienced event', annotation_string='{:.1%} experienced event\\nwithin {:.0f} hours', labels=None, media_file_path=None, file_name=None, return_figure=False, return_df=False)</code>","text":"<p>Create a survival curve for time-to-event analysis.</p> <pre><code>This function creates a survival curve showing the proportion of patients\nwho have not yet experienced an event over time. Can plot single or multiple\nsurvival curves on the same plot.\n</code></pre> <pre><code>Parameters\n</code></pre> <pre><code>df : pandas.DataFrame or list of pandas.DataFrame\n    DataFrame(s) containing patient visit data. If a list is provided,\n    multiple survival curves will be plotted on the same figure.\nstart_time_col : str, default=\"arrival_datetime\"\n    Name of the column containing the start time (e.g., arrival time)\nend_time_col : str, default=\"admitted_to_ward_datetime\"\n    Name of the column containing the end time (e.g., admission time)\ntitle : str, default=\"Time to Event Survival Curve\"\n    Title for the plot\ntarget_hours : list of float, default=[4]\n    List of target times in hours to show on the plot\nxlabel : str, default=\"Elapsed time from start\"\n    Label for the x-axis\nylabel : str, default=\"Proportion not yet experienced event\"\n    Label for the y-axis\nannotation_string : str, default=\"{:.1%} experienced event\n</code></pre> <p>within {:.0f} hours\"         String template for the text annotation. Use {:.1%} for the proportion and {:.0f} for the hours.         Annotations are only shown for the first curve when plotting multiple curves.     labels : list of str, optional         Labels for each survival curve when plotting multiple curves.         If None and multiple dataframes are provided, default labels will be used.         Ignored when plotting a single curve.     media_file_path : pathlib.Path, optional         Path to save the plot. If None, the plot is not saved.     file_name : str, optional         Custom filename to use when saving the plot. If not provided, defaults to \"survival_curve.png\".     return_figure : bool, default=False         If True, returns the figure instead of displaying it     return_df : bool, default=False         If True, returns a DataFrame containing the survival curve data.         For multiple curves, returns a list of DataFrames.</p> <pre><code>Returns\n</code></pre> <pre><code>matplotlib.figure.Figure or pandas.DataFrame or list or tuple or None\n    - If return_figure is True and return_df is False: returns the figure object\n    - If return_figure is False and return_df is True: returns the DataFrame(s) with survival curve data\n    - If both return_figure and return_df are True: returns a tuple of (figure, DataFrame(s))\n    - If both are False: returns None\n</code></pre> <pre><code>Notes\n</code></pre> <pre><code>The survival curve shows the proportion of patients who have not yet experienced\nthe event at each time point. Vertical lines are drawn at each target hour\nto indicate the target times, with the corresponding proportion of patients\nwho experienced the event within these timeframes.\n\nWhen plotting multiple curves, different colors are automatically assigned\nand a legend is displayed. Target line annotations are only shown for the\nfirst curve to avoid visual clutter.\n</code></pre> Source code in <code>src/patientflow/viz/survival_curve.py</code> <pre><code>def plot_admission_time_survival_curve(\n    df,\n    start_time_col=\"arrival_datetime\",\n    end_time_col=\"departure_datetime\",\n    title=\"Time to Event Survival Curve\",\n    target_hours=[4],\n    xlabel=\"Elapsed time from start\",\n    ylabel=\"Proportion not yet experienced event\",\n    annotation_string=\"{:.1%} experienced event\\nwithin {:.0f} hours\",\n    labels=None,\n    media_file_path=None,\n    file_name=None,\n    return_figure=False,\n    return_df=False,\n):\n    \"\"\"Create a survival curve for time-to-event analysis.\n\n    This function creates a survival curve showing the proportion of patients\n    who have not yet experienced an event over time. Can plot single or multiple\n    survival curves on the same plot.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame or list of pandas.DataFrame\n        DataFrame(s) containing patient visit data. If a list is provided,\n        multiple survival curves will be plotted on the same figure.\n    start_time_col : str, default=\"arrival_datetime\"\n        Name of the column containing the start time (e.g., arrival time)\n    end_time_col : str, default=\"admitted_to_ward_datetime\"\n        Name of the column containing the end time (e.g., admission time)\n    title : str, default=\"Time to Event Survival Curve\"\n        Title for the plot\n    target_hours : list of float, default=[4]\n        List of target times in hours to show on the plot\n    xlabel : str, default=\"Elapsed time from start\"\n        Label for the x-axis\n    ylabel : str, default=\"Proportion not yet experienced event\"\n        Label for the y-axis\n    annotation_string : str, default=\"{:.1%} experienced event\\nwithin {:.0f} hours\"\n        String template for the text annotation. Use {:.1%} for the proportion and {:.0f} for the hours.\n        Annotations are only shown for the first curve when plotting multiple curves.\n    labels : list of str, optional\n        Labels for each survival curve when plotting multiple curves.\n        If None and multiple dataframes are provided, default labels will be used.\n        Ignored when plotting a single curve.\n    media_file_path : pathlib.Path, optional\n        Path to save the plot. If None, the plot is not saved.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"survival_curve.png\".\n    return_figure : bool, default=False\n        If True, returns the figure instead of displaying it\n    return_df : bool, default=False\n        If True, returns a DataFrame containing the survival curve data.\n        For multiple curves, returns a list of DataFrames.\n\n    Returns\n    -------\n    matplotlib.figure.Figure or pandas.DataFrame or list or tuple or None\n        - If return_figure is True and return_df is False: returns the figure object\n        - If return_figure is False and return_df is True: returns the DataFrame(s) with survival curve data\n        - If both return_figure and return_df are True: returns a tuple of (figure, DataFrame(s))\n        - If both are False: returns None\n\n    Notes\n    -----\n    The survival curve shows the proportion of patients who have not yet experienced\n    the event at each time point. Vertical lines are drawn at each target hour\n    to indicate the target times, with the corresponding proportion of patients\n    who experienced the event within these timeframes.\n\n    When plotting multiple curves, different colors are automatically assigned\n    and a legend is displayed. Target line annotations are only shown for the\n    first curve to avoid visual clutter.\n    \"\"\"\n    # Handle single dataframe vs list of dataframes\n    if isinstance(df, pd.DataFrame):\n        dataframes = [df]\n        is_single_curve = True\n    else:\n        dataframes = df\n        is_single_curve = False\n\n    # Handle labels\n    if labels is None:\n        if is_single_curve:\n            curve_labels = [None]\n        else:\n            curve_labels = [f\"Curve {i+1}\" for i in range(len(dataframes))]\n    else:\n        curve_labels = labels\n\n    # Validate inputs\n    if len(dataframes) != len(curve_labels):\n        raise ValueError(\"Number of dataframes must match number of labels\")\n\n    # Create the plot\n    fig = plt.figure(figsize=(10, 6))\n\n    # Define colors for multiple curves\n    colors = plt.cm.Set1(np.linspace(0, 1, len(dataframes)))\n\n    survival_dfs = []\n\n    # Process each dataframe\n    for idx, (current_df, label) in enumerate(zip(dataframes, curve_labels)):\n        # Calculate survival curve using the extracted function\n        survival_df = calculate_survival_curve(current_df, start_time_col, end_time_col)\n\n        # Extract arrays for plotting\n        unique_times = survival_df[\"time_hours\"].values\n        survival_prob = survival_df[\"survival_probability\"].values\n\n        # Store DataFrame if requested\n        if return_df:\n            survival_dfs.append(survival_df)\n\n        # Plot the survival curve\n        color = colors[idx] if not is_single_curve else None\n        plt.step(\n            unique_times,\n            survival_prob,\n            where=\"post\",\n            color=color,\n            label=label if not is_single_curve else None,\n        )\n\n        # Plot target lines and annotations only for the first curve (or single curve)\n        if idx == 0:\n            # Plot target lines for each target hour\n            for target_hour in target_hours:\n                # Find the survival probability at target hours\n                closest_time_idx = np.abs(unique_times - target_hour).argmin()\n                if closest_time_idx &lt; len(survival_prob):\n                    survival_at_target = survival_prob[closest_time_idx]\n                    event_at_target = 1 - survival_at_target\n\n                    # Add text annotation to the plot (only for single curve or first curve)\n                    if is_single_curve or len(dataframes) == 1:\n                        plt.text(\n                            target_hour + 0.5,\n                            survival_at_target,\n                            annotation_string.format(event_at_target, target_hour),\n                            bbox=dict(facecolor=\"white\", alpha=0.8),\n                        )\n\n                        # Draw a vertical line from x-axis to the curve at target hours\n                        plt.plot(\n                            [target_hour, target_hour],\n                            [0, survival_at_target],\n                            color=\"grey\",\n                            linestyle=\"--\",\n                            linewidth=2,\n                        )\n\n                        # Draw a horizontal line from the curve to the y-axis at the survival probability level\n                        plt.plot(\n                            [0, target_hour],\n                            [survival_at_target, survival_at_target],\n                            color=\"grey\",\n                            linestyle=\"--\",\n                            linewidth=2,\n                        )\n\n    # Configure the plot\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.grid(True, alpha=0.3)\n\n    # Make axes meet at the origin\n    plt.xlim(left=0)\n    plt.ylim(bottom=0)\n\n    # Move spines to the origin\n    ax = plt.gca()\n    ax.spines[\"left\"].set_position((\"data\", 0))\n    ax.spines[\"bottom\"].set_position((\"data\", 0))\n\n    # Hide the top and right spines\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n\n    # Add legend for multiple curves\n    if not is_single_curve:\n        plt.legend()\n\n    plt.tight_layout()\n\n    if media_file_path:\n        if file_name:\n            plt.savefig(media_file_path / file_name, dpi=300)\n        else:\n            plt.savefig(media_file_path / \"survival_curve.png\", dpi=300)\n\n    # Handle return values\n    return_data = (\n        survival_dfs[0]\n        if (return_df and is_single_curve)\n        else survival_dfs\n        if return_df\n        else None\n    )\n\n    if return_figure and return_df:\n        return fig, return_data\n    elif return_figure:\n        return fig\n    elif return_df:\n        return return_data\n    else:\n        plt.show()\n        plt.close()\n</code></pre>"},{"location":"api/#patientflow.viz.trial_results","title":"<code>trial_results</code>","text":"<p>Charts for hyperparameter optimisation trials.</p> <p>This module provides tools to visualise the performance metrics of multiple hyperparameter tuning trials, highlighting the best trials for each metric.</p> <p>Functions:</p> Name Description <code>plot_trial_results : function</code> <p>Plot selected performance metrics for a list of hyperparameter trials.</p>"},{"location":"api/#patientflow.viz.trial_results.plot_trial_results","title":"<code>plot_trial_results(trials_list, metrics=None, media_file_path=None, file_name=None, return_figure=False)</code>","text":"<p>Plot selected performance metrics from hyperparameter trials as scatter plots.</p> <p>This function visualizes the performance metrics of a series of hyperparameter trials. It creates scatter plots for each selected metric, with the best-performing trial highlighted and annotated with its hyperparameters.</p> <p>Optionally, the plot can be saved to disk or returned as a figure object.</p> <p>Parameters:</p> Name Type Description Default <code>trials_list</code> <code>List[HyperParameterTrial]</code> <p>A list of <code>HyperParameterTrial</code> instances containing validation set results (not cross-validation fold results) and hyperparameter settings. Each trial's <code>cv_results</code> dictionary contains metrics such as 'valid_auc' and 'valid_logloss', which are computed on a held-out validation set for each hyperparameter configuration.</p> required <code>metrics</code> <code>List[str]</code> <p>List of metric names to plot. If None, defaults to [\"valid_auc\", \"valid_logloss\"]. Each metric should be a key in the trial's cv_results dictionary.</p> <code>None</code> <code>media_file_path</code> <code>Path or None</code> <p>Directory path where the generated plot image will be saved as \"trial_results.png\". If None, the plot is not saved.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>Custom filename to use when saving the plot. If not provided, defaults to \"trial_results.png\".</p> <code>None</code> <code>return_figure</code> <code>bool</code> <p>If True, the matplotlib figure is returned instead of being displayed directly. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Figure or None</code> <p>The matplotlib figure object if <code>return_figure</code> is True; otherwise, None.</p> Notes <ul> <li>Assumes that each <code>HyperParameterTrial</code> in <code>trials_list</code> has a <code>cv_results</code> dictionary   containing the requested metrics, which are computed on the validation set.</li> <li>Parameters from the best-performing trials are shown in the plots.</li> </ul> Source code in <code>src/patientflow/viz/trial_results.py</code> <pre><code>def plot_trial_results(\n    trials_list: List[HyperParameterTrial],\n    metrics: Optional[List[str]] = None,\n    media_file_path=None,\n    file_name=None,\n    return_figure=False,\n):\n    \"\"\"\n    Plot selected performance metrics from hyperparameter trials as scatter plots.\n\n    This function visualizes the performance metrics of a series of hyperparameter trials.\n    It creates scatter plots for each selected metric, with the best-performing trial\n    highlighted and annotated with its hyperparameters.\n\n    Optionally, the plot can be saved to disk or returned as a figure object.\n\n    Parameters\n    ----------\n    trials_list : List[HyperParameterTrial]\n        A list of `HyperParameterTrial` instances containing validation set results\n        (not cross-validation fold results) and hyperparameter settings. Each trial's\n        `cv_results` dictionary contains metrics such as 'valid_auc' and 'valid_logloss',\n        which are computed on a held-out validation set for each hyperparameter configuration.\n    metrics : List[str], optional\n        List of metric names to plot. If None, defaults to [\"valid_auc\", \"valid_logloss\"].\n        Each metric should be a key in the trial's cv_results dictionary.\n    media_file_path : pathlib.Path or None, optional\n        Directory path where the generated plot image will be saved as \"trial_results.png\".\n        If None, the plot is not saved.\n    file_name : str, optional\n        Custom filename to use when saving the plot. If not provided, defaults to \"trial_results.png\".\n    return_figure : bool, optional\n        If True, the matplotlib figure is returned instead of being displayed directly.\n        Default is False.\n\n    Returns\n    -------\n    matplotlib.figure.Figure or None\n        The matplotlib figure object if `return_figure` is True; otherwise, None.\n\n    Notes\n    -----\n    - Assumes that each `HyperParameterTrial` in `trials_list` has a `cv_results` dictionary\n      containing the requested metrics, which are computed on the validation set.\n    - Parameters from the best-performing trials are shown in the plots.\n    \"\"\"\n    # Set default metrics if none provided\n    if metrics is None:\n        metrics = [\"valid_auc\", \"valid_logloss\"]\n\n    # Extract metrics from trials\n    metric_values = {\n        metric: [trial.cv_results.get(metric, 0) for trial in trials_list]\n        for metric in metrics\n    }\n\n    # Create trial indices\n    trial_indices = list(range(len(trials_list)))\n\n    # Create figure with subplots\n    n_metrics = len(metrics)\n    fig, axes = plt.subplots(1, n_metrics, figsize=(7 * n_metrics, 6))\n    if n_metrics == 1:\n        axes = [axes]\n\n    # Plot each metric\n    for idx, (metric, values) in enumerate(metric_values.items()):\n        ax = axes[idx]\n\n        # Plot metric as dots\n        ax.scatter(trial_indices, values, s=50, alpha=0.7)\n        ax.set_xlabel(\"Trial Number\")\n        ax.set_ylabel(metric.replace(\"valid_\", \"\").upper())\n        ax.set_title(metric.replace(\"valid_\", \"\").replace(\"_\", \" \").title())\n        ax.grid(True, linestyle=\"--\", alpha=0.7)\n\n        # Set x-axis to display integers\n        ax.set_xticks(trial_indices)\n        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: str(int(x))))\n\n        # Set y-axis limits\n        if \"loss\" in metric.lower():\n            best_idx = values.index(min(values))\n            ax.set_ylim(bottom=0, top=max(values) * 1.1)\n        else:\n            best_idx = values.index(max(values))\n            ax.set_ylim(bottom=0, top=max(values) * 1.1)\n\n        # Highlight best value\n        highlight_color = \"green\" if \"loss\" not in metric.lower() else \"darkred\"\n        ax.scatter(\n            [best_idx],\n            [values[best_idx]],\n            color=highlight_color,\n            s=150,\n            edgecolor=\"black\",\n            zorder=5,\n        )\n\n        # Add annotation with best parameters\n        best_trial = trials_list[best_idx]\n        param_text = \"\\n\".join([f\"{k}: {v}\" for k, v in best_trial.parameters.items()])\n        best_value = values[best_idx]\n        ax.text(\n            0.05,\n            0.05,\n            f\"Best {metric.replace('valid_', '').upper()}: {best_value:.4f}\\n\\nParameters:\\n{param_text}\",\n            transform=ax.transAxes,\n            bbox=dict(facecolor=\"white\", alpha=0.7),\n            fontsize=9,\n        )\n\n    # Add overall title\n    fig.suptitle(\"Hyperparameter Trial Results\", fontsize=14)\n\n    # Adjust layout\n    plt.tight_layout()\n\n    if media_file_path:\n        if file_name:\n            plt.savefig(media_file_path / file_name, dpi=300)\n        else:\n            plt.savefig(media_file_path / \"trial_results.png\", dpi=300)\n\n    if return_figure:\n        return fig\n    else:\n        plt.show()\n        plt.close()\n</code></pre>"},{"location":"api/#patientflow.viz.utils","title":"<code>utils</code>","text":"<p>Utility functions for visualization and data formatting.</p> <p>This module provides helper functions for cleaning and formatting data for visualization purposes, including filename cleaning and prediction time formatting.</p> <p>Functions:</p> Name Description <code>clean_title_for_filename : function</code> <p>Clean a title string to make it suitable for use in filenames</p> <code>format_prediction_time : function</code> <p>Format prediction time to 'HH:MM' format</p>"},{"location":"api/#patientflow.viz.utils.clean_title_for_filename","title":"<code>clean_title_for_filename(title)</code>","text":"<p>Clean a title string to make it suitable for use in filenames.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>The title to clean.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The cleaned title, safe for use in filenames.</p> Source code in <code>src/patientflow/viz/utils.py</code> <pre><code>def clean_title_for_filename(title):\n    \"\"\"Clean a title string to make it suitable for use in filenames.\n\n    Parameters\n    ----------\n    title : str\n        The title to clean.\n\n    Returns\n    -------\n    str\n        The cleaned title, safe for use in filenames.\n    \"\"\"\n    replacements = {\" \": \"_\", \"%\": \"\", \"\\n\": \"\", \",\": \"\", \".\": \"\"}\n\n    clean_title = title\n    for old, new in replacements.items():\n        clean_title = clean_title.replace(old, new)\n    return clean_title\n</code></pre>"},{"location":"api/#patientflow.viz.utils.format_prediction_time","title":"<code>format_prediction_time(prediction_time)</code>","text":"<p>Format prediction time to 'HH:MM' format.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_time</code> <code>str or tuple</code> <p>Either:     - A string in 'HHMM' format, possibly containing underscores     - A tuple of (hour, minute)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted time string in 'HH:MM' format.</p> Source code in <code>src/patientflow/viz/utils.py</code> <pre><code>def format_prediction_time(prediction_time):\n    \"\"\"Format prediction time to 'HH:MM' format.\n\n    Parameters\n    ----------\n    prediction_time : str or tuple\n        Either:\n            - A string in 'HHMM' format, possibly containing underscores\n            - A tuple of (hour, minute)\n\n    Returns\n    -------\n    str\n        Formatted time string in 'HH:MM' format.\n    \"\"\"\n    if isinstance(prediction_time, tuple):\n        hour, minute = prediction_time\n        return f\"{hour:02d}:{minute:02d}\"\n    else:\n        # Split the string by underscores and take the last element\n        last_part = prediction_time.split(\"_\")[-1]\n        # Add a colon in the middle\n        return f\"{last_part[:2]}:{last_part[2:]}\"\n</code></pre>"},{"location":"notebooks/","title":"About the notebooks","text":""},{"location":"notebooks/#background","title":"Background","text":"<p>The notebooks in this folder demonstrate the core functionality of the <code>patientflow</code> package. They have been written by me, Dr Zella King, the primary author of this repository. My aim is to introduce, in a step-by-step approach, how to structure your data for use with the package, and how to use the functions. I conclude with a fully worked example of how we use these functions at University College London Hospital (UCLH) to predict emergency demand for beds.</p>"},{"location":"notebooks/#outline-of-the-notebooks","title":"Outline of the notebooks","text":"<p>The first notebook explains how to set up your environment to run the notebooks that follow. Instructions are also provided at the bottom of this README.</p> <ul> <li>0_Set_up_your_environment: Shows how to set things up if you want to run these notebooks in a Jupyter environment</li> </ul> <p>I then explain who are the intended users of predictive models of patient flow.</p> <ul> <li>1_Meet_the_users_of_our_predictions: Talks about the users of patient flow predictions in acute hospitals.</li> </ul> <p>There is then a series of notebooks on preparing patient snapshots, training models on them, and evaluating the performance of those models. I also introduce the real data provided by UCLH in a summary notebook.</p> <ul> <li>2a_Create_patient_snapshots: Shows how to convert finished hospital visits into patient snapshots.</li> <li>2b_Predict_using_patient_snapshots: Shows how to make predictions using patient snapshots, handling multiple visits for a single patient, and multiple snapshots in a single visit.</li> <li>2c_Evaluate_patient_snapshot_models: Demonstrates the use of convenient function to help you evaluate predictive models trained on patient snapshots.</li> <li>2d_Explore_the_datasets_provided: Provides exploratory plots of the two datasets that accompany this repository.</li> </ul> <p>Next is a series of notebooks on preparing group snapshots, generating predictions for group snapshots, and evaluating the predictions.</p> <ul> <li>3a_Prepare_group_snapshots: Show how to create group snapshots from patient snapshots.</li> <li>3b_Evaluate_group_snapshots: Show how to evaluate predicted bed count distribution generated form group snapshots.</li> <li>3c_Predict_bed_counts_without_using_patient_snapshots: Show how to predict demand, using historical data, when patient snapshots are not appropriate</li> <li>3d_Predict_bed_counts_for_subgroups: Show how to disaggregate bed count distributions by subgroups such as age or specialty of admission</li> </ul> <p>A set of notebooks follow, that show how we have used the functions in <code>patientflow</code> at UCLH to predict number of beds needed for emergency demand.</p> <ul> <li>4a_Specify_emergency_demand_model: Explains design choices that were made to develop a practical model, and shows an example of the output that is sent five times a day at UCLH.</li> <li>4b_Predict_emergency_demand: Shows a full implementation of the functions covered up to this point, to predict emergency demand at UCLH.</li> <li>4c_Evaluate_emergency_demand_predictions Shows an evaluation of the emergency demand predictions generated using the public data provided with this repo.</li> <li>4d_Predict_emergency_demand_with_special_categories Develops the logic shown in the previous notebook to include the handling of particular sub-groups of patients differently.</li> </ul>"},{"location":"notebooks/#preparing-your-notebook-environment","title":"Preparing your notebook environment","text":""},{"location":"notebooks/#installation","title":"Installation","text":"<p>You can install the <code>patientflow</code> package directly from PyPI:</p> <pre><code>pip install patientflow\n</code></pre> <p>For development purposes or to run these notebooks with the latest code, you may still want to use the Github repository directly. In that case, the <code>PATH_TO_PATIENTFLOW</code> environment variable needs to be set so notebooks know where the patientflow repository resides on your computer. You have various options:</p> <ul> <li>use a virtual environment and set PATH_TO_PATIENTFLOW up within that</li> <li>set PATH_TO_PATIENTFLOW globally on your computer</li> <li>let each notebook infer PATH_TO_PATIENTFLOW from the location of the notebook file, or specify it within the notebook</li> </ul>"},{"location":"notebooks/#to-set-the-path_to_patientflow-environment-variable-within-your-virtual-environment","title":"To set the PATH_TO_PATIENTFLOW environment variable within your virtual environment","text":"<p>Conda environments</p> <p>Add PATH_TO_PATIENTFLOW to the <code>environment.yml</code> file:</p> <pre><code>variables:\n  PATH_TO_PATIENTFLOW: /path/to/patientflow\n</code></pre> <p>venv environment</p> <p>Add path_to_patientflow to the venv activation script:</p> <pre><code>echo 'export PATH_TO_PATIENTFLOW=/path/to/patientflow' &gt;&gt; venv/bin/activate  # Linux/Mac\necho 'set PATH_TO_PATIENTFLOW=/path/to/patientflow' &gt;&gt; venv/Scripts/activate.bat  # Windows\n</code></pre> <p>The environment variable will be set whenever you activate the virtual environment and unset when you deactivate it. Replace /path/to/patientflow with your repository path.</p>"},{"location":"notebooks/#to-set-the-project_root-environment-variable-from-within-each-notebook","title":"To set the project_root environment variable from within each notebook","text":"<p>A function called <code>set_project_root()</code> can be run in each notebook. If you include the name of a environment variable as shown below, the function will look in your global environment for a variable of this name.</p> <p>Alternatively, if you call the function without any arguments, the function will try to infer the location of the patientflow repo from your currently active path.</p> <pre><code># to specify an environment variable that has been set elsewhere\nproject_root = set_project_root(env_var =\"PATH_TO_PATIENTFLOW\")\n\n# to let the notebook infer the path\nproject_root = set_project_root()\n\n</code></pre> <p>You can also set an environment variable from within a notebook cell:</p> <p>Linux/Mac:</p> <pre><code>%env PATH_TO_PATIENTFLOW=/path/to/patientflow\n</code></pre> <p>Windows:</p> <pre><code>%env PATH_TO_PATIENTFLOW=C:\\path\\to\\patientflow\n</code></pre> <p>Replace /path/to/patientflow with the actual path to your cloned repository.</p>"},{"location":"notebooks/#to-set-project_root-environment-variable-permanently-on-your-system","title":"To set project_root environment variable permanently on your system","text":"<p>Linux/Mac:</p> <pre><code># Add to ~/.bashrc or ~/.zshrc:\nexport PATH_TO_PATIENTFLOW=/path/to/patientflow\n</code></pre> <p>Windows:</p> <pre><code>Open System Properties &gt; Advanced &gt; Environment Variables\nUnder User Variables, click New\nVariable name: PATH_TO_PATIENTFLOW\nVariable value: C:\\path\\to\\patientflow\nClick OK\n</code></pre> <p>Replace /path/to/patientflow with your repository path. Restart your terminal/IDE after setting.</p>"},{"location":"notebooks/0_Set_up_your_environment/","title":"0. Set up your environment","text":"<p>In this notebook I will </p> <ul> <li>Suggest how to set up your environment. You might find the checks below useful to confirm that your environment has been set up correctly for the following notebooks to run. </li> <li>Explain where the code expects to find data and where it saves media files by default. </li> </ul> <p>Model files are not saved by these notebooks. Models are re-run for each notebook, so the notebooks will work if run in any order. </p> <p>See also the Notebooks README in this folder for information about how to set the <code>project_root</code> variable. </p>"},{"location":"notebooks/0_Set_up_your_environment/#set-notebook-to-reload-functions-every-time-a-cell-is-run","title":"Set notebook to reload functions every time a cell is run","text":"<p>This is useful if you make any changes to any underlying code.</p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre>"},{"location":"notebooks/0_Set_up_your_environment/#check-that-the-patientflow-package-has-been-installed","title":"Check that the patientflow package has been installed","text":"<pre><code>try:\n   import patientflow\n   print(f\"\u2713 patientflow {patientflow.__version__} imported successfully\")\nexcept ImportError:\n   print(\"\u274c patientflow not found - please install using one of the following methods:\")\n   print(\"   From PyPI: pip install patientflow\")\n   print(\"   For development: pip install -e '.[test]'\")\nexcept Exception as e:\n   print(f\"\u274c Error: {e}\")\n</code></pre> <pre><code>\u2713 patientflow 0.2.0 imported successfully\n</code></pre>"},{"location":"notebooks/0_Set_up_your_environment/#set-project_root-variable","title":"Set <code>project_root</code> variable","text":"<p>The variable called <code>project_root</code> tells the notebooks where the patientflow repository resides on your computer. All paths in the notebooks are set relative to <code>project_root</code>. There are various ways to set it, which are described in the notebooks README. </p> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/0_Set_up_your_environment/#set-file-paths","title":"Set file paths","text":"<p>Now that you have set the project root, you can specify where the data will be loaded from, where images and models are saved, and where to load the config file from. By default, a function called <code>set_file_paths()</code> sets these as shown here. </p> <pre><code># Basic checks\nprint(f\"patientflow version: {patientflow.__version__}\")\nprint(f\"Repository root: {project_root}\")\n\n# Verify data access\ndata_folder_name = 'data-synthetic'\ndata_file_path = project_root / data_folder_name\nif data_file_path.exists():\n    print(\"\u2713 Synthetic data found\")\nelse:\n    print(\"Synthetic data not found - check repository structure\")\n</code></pre> <pre><code>patientflow version: 0.2.0\nRepository root: /Users/zellaking/Repos/patientflow\n\u2713 Synthetic data found\n</code></pre> <p>The<code>set_file_paths</code> function will set file paths to default values within the <code>patientflow</code> folder, as shown below. File paths for saving media and models are derived from the name of the data folder. </p> <p>In the notebooks that follow, no trained models are saved by default. All notebooks load data from <code>data_file_path</code> and train models from scratch. However, you may want to make use of <code>model_file_path</code> to save a model locally, especially they are time-consuming to run in your environment. </p> <p>The config.yaml file will be loaded from the root directory. It specifies training, validation and test set dates, and some other parameters that will be discussed later.</p> <pre><code>from patientflow.load import set_file_paths\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(project_root, \n               data_folder_name=data_folder_name)\n</code></pre> <pre><code>Configuration will be loaded from: /Users/zellaking/Repos/patientflow/config.yaml\nData files will be loaded from: /Users/zellaking/Repos/patientflow/data-synthetic\nTrained models will be saved to: /Users/zellaking/Repos/patientflow/trained-models/synthetic\nImages will be saved to: /Users/zellaking/Repos/patientflow/trained-models/synthetic/media\n</code></pre>"},{"location":"notebooks/0_Set_up_your_environment/#summary","title":"Summary","text":"<p>In this notebook I have shown:</p> <ul> <li>How to configure your environment to run these notebooks</li> <li>Where the notebooks expect to find data, and where they will save media file, by default</li> </ul>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/","title":"1. Introducing our users","text":"<p>This repository offers predictive modelling to support the management of patient flow in hospitals. Here I introduce the people who manage patient flow in hospitals. </p>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/#what-is-patient-flow","title":"What is patient flow?","text":"<p>Hospitals refer to the streams of patients arriving and leaving as \u2018patient flow\u2019. Unplanned admissions create the \u2018emergency\u2019 flow, and the hospital must accommodate that flow alongside a flow of \u2018elective\u2019 or planned admissions. Sometimes outflows are reduced because patients are waiting for care to become available in another setting. \u00a0</p> <p>There are various ways people are admitted to a hospital specialty: </p> <ul> <li>via the Accident &amp; Emergency Department, which is referred to by hospitals as the ED (Emergency Department). Some patients are admitted after visiting Same Day Emergency Care (SDEC). Here, to keep it simple, I refer to the combined flows from ED and SDEC as coming via the ED</li> <li>as an emergency admission via another route, such as a transfer from another hospital</li> <li>as planned (or elective) admissions </li> <li>as an internal transfer from another specialty in the same hospital</li> </ul> <p>And various ways people leave a hospital specialty: </p> <ul> <li>as a discharge from hospital, to home or another care setting, including another hospital</li> <li>as an internal transfer to another specialty within the same hospital</li> <li>as a death while in hospital</li> </ul> <p>If patient flow works well, each patient will receive timely and appropriate care from the right specialty team, without undue delays. Unfortunately, delays are not uncommon, and they can result in poor patient flow. An example of poor patient flow is when incoming patients wait for many hours in the ED because inpatients who are ready to leave are not being discharged, so no bed is available.</p> <p>Due to imbalances in admissions and discharges, pressures can build up in certain parts of the hospital, while other parts remain relatively less pressured. When one specialty is under pressure, new patients may be housed in the wrong ward ie a ward that is not dedicated to the specialty they are under. In this case they are referred to as 'outliers'. Outlying is not ideal; evidence indicates that it can lead to worse clinical outcomes and longer stays in hospitals. </p> <p>Hospitals strive to have good patient flow, across all specialties, so far as they are able. </p>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/#who-is-responsible-for-managing-patient-flow","title":"Who is responsible for managing patient flow?","text":"<p>Typically a team of bed managers takes primary responsibility for managing patient flow. Bed managers are usually senior nurses with a clinical understanding of each patient's likely care needs. Their work involves responding to rapidly changing situations caused by delays in patient care, infection outbreaks, excess demand for beds, and other incidents.</p> <p>To keep track of the changing situation, bed managers at University College London Hospital's main site convene virtual 'flow huddles' three times a day. In these huddles, staff from the ED and from each ward meet with bed managers to discuss patients coming in (as either emergency or planned admissions), and review which inpatients are likely to be discharged. The flow huddles provide a picture of likely areas of pressure on beds.</p> <p>If bed pressures are anticipated, bed managers can take action by trying to accelerate discharges, opening up temporary beds and finding staff to cover them, or temporarily diverting ambulances to another hospital. These decisions have consequences for patients, staff and other hospitals. </p>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/#what-information-do-bed-managers-use-to-manage-patient-flow","title":"What information do bed managers use to manage patient flow?","text":"<p>Bed managers at UCLH, our partner hospital, like to anticipate how many beds will be needed for new patients by the end of the day or shift, and how many beds will become available during that time. To predict how many beds will be needed today, they commonly assume the number of emergency admissions will be the same as yesterday. To work out how many patients will leave, they apply a simple rule based on patients' expected dates of discharge. </p> <p>These are simple rules of thumb (heuristics), based on information that may not have been updated since midnight. Many hospitals have Electronic Health Records (EHRs), into which data are being entered throughout the day. That up-to-date information could provide a better view; bed managers' understanding of the current situation, and their projection of how it will develop, could be refreshed as new information comes into the EHR. That real-time view is what UCLH wanted to achieve from its EHR. </p>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/#what-modelling-is-useful-to-bed-managers","title":"What modelling is useful to bed managers?","text":"<p>I'm Zella King, a health data scientist in the Clinical Operational Research Unit (CORU) at University College London. I started working with University College London Hospital (UCLH) in 2020 because the hospital wanted to make better use of the data streaming into its EHR. My colleague Prof Sonya Crowe led a small project in 2019-2020 to create a prototype of a predictive model of emergency demand that used real-time data. Through that project, and over the subsequent years, we have come to understand the needs of bed managers from predictive modelling. </p> <p>What bed managers we have worked with want from predictive models:</p> <ul> <li> <p>Predictions issued at the times of day they need them:   Our users have a routine where they prepare a situation report of hospital capacity five times each day, and have flow huddles three times a day. They wanted predictions of bed demand to be available to them in the preparation of the reports, and at the flow huddles. </p> </li> <li> <p>Predictions over a rolling window:   The current heuristics (used at UCLH and widely across the NHS) rely on daily averages, which means that the predictions run to midnight on the same day. A rolling prediction of 8 to 12 hours is more useful, because it can better inform conversations about what needs to be done during the current day in order to head off pressures before senior staff go home, or during the night shift to ease likely build-ups of patients waiting in the morning.  </p> </li> <li> <p>Output at aggregate level rather than individual:   It is common for researchers using statistics or Machine Learning to produce models that predict each patient's probability of admission. However, that level of analysis is not useful for bed managers because, when managing capacity, they are mainly interested in overall numbers of beds needed, rather than whether any particular patient will be admitted.</p> </li> <li> <p>Predictions that are based on real-time data from the Electronic Health Record (EHR):   Predictive models can be trained on historical patterns of admissions and discharges. However, if they can make use of real-time data from the EHR, bed managers will have a better sense of today's demand, rather than that of a typical day.</p> </li> <li> <p>A breakdown of demand by specialty:   Knowing that the whole hospital is going to be short of beds is somewhat useful and does give a sense of the scale of the problem. More precise information - about which specialties are most affected - makes it easier to pinpoint where action is needed. </p> </li> <li> <p>Some sense of the uncertainty of predictions:   Simple heuristics give bed managers a single number to work with. For example, if 50 patients were admitted yesterday, they might plan for 50 today. This doesn't show how likely the number 50 is; could it be 46 or 54? A good model will give a sense of uncertainty around the suggested number of beds.</p> </li> </ul>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/#about-our-current-work-at-uclh","title":"About our current work at UCLH","text":"<p>In the last five years, we have developed and deployed a model of emergency demand for beds that is running daily at UCLH. We are now working on predictions of the net change in bed demand for each specialty in the next 8 to 24 hours. Our new approach will bring together predictions of emergency and elective admissions, transfers between specialties and discharges in that prediction window.</p> <p>The <code>patientflow</code> repository provides generic functions that serve as building blocks for that modelling. In the following notebooks I will demonstrate the use of these functions, using the example of predicting emergency demand. </p> <p>Our hope is that you may find the functions useful for your own modelling problems.</p>"},{"location":"notebooks/2a_Create_patient_snapshots/","title":"2a. Create patient-level snapshots","text":""},{"location":"notebooks/2a_Create_patient_snapshots/#about-snapshots","title":"About snapshots","text":"<p><code>patientflow</code> is organised around the following concepts:</p> <ul> <li>Prediction time: A moment in the day at which predictions are to be made, for example 09:30.</li> <li>Patient snapshot: A summary of data from the EHR capturing is known about a single patient at the prediction time. Each patient snapshot has a date and a prediction time associated with it.</li> <li>Group snapshot: A set of patient snapshots. Each group snapshot has a date and a prediction time associated with it.</li> <li>Prediction window: A period of hours that begins at the prediction time.</li> </ul> <p>To use <code>patientflow</code> your data should be in snapshot form. </p> <p>In this notebook I suggest how to you might prepare your data, starting from data on finished hospital visits. I start with fake data on Emergency Department visits, and demonstrate how to convert it into snapshots. There are two examples</p> <ul> <li>A simple example of creating snapshots assuming you have one flat table of hospital visits</li> <li>An example of creating snapshots from data structured as a relational database. </li> </ul>"},{"location":"notebooks/2a_Create_patient_snapshots/#a-note-on-creating-your-own-shapshots","title":"A note on creating your own shapshots","text":"<p>The snapshot creation shown here is designed to work with fake data generated below. You would need to create your own version of this process, to handle the data you have. </p> <p>In practice, determining from data whether a patient was admitted after the ED visit, and when they were ready to be admitted, can be tricky. How do you account for the fact that the patient may wait in the ED for a bed, due to lack of available beds? Likewise, if you are trying to predict discharge at the end of a hospital visit, should that that be the time they were ready to leave, or the time they actually left? Discharge delays are common, due to waiting for medication or transport, or waiting for onward care provision to become available. </p> <p>The outcome that you are aiming for will depend on your setting, and the information needs of the bed managers you are looking to support. You may have to infer when a patient was ready from available data. Suffice to say, think carefully about what it is you are trying to predict, and how you will identify that outcome in data. </p>"},{"location":"notebooks/2a_Create_patient_snapshots/#creating-fake-finished-visits","title":"Creating fake finished visits","text":"<p>I'll start by loading some fake data resembling the structure of EHR data on Emergency Department (ED) visits, using a function called <code>create_fake_finished_visits</code>. In my fake data, each visit has one row, with an arrival time at the ED, a discharge time from the ED, the patient's age and an outcome of whether they were admitted after the ED visit. </p> <p>The <code>is_admitted</code> column is our label, indicating the outcome in this imaginary case. </p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>from patientflow.generate import create_fake_finished_visits\nvisits_df, _, _ = create_fake_finished_visits('2023-01-01', '2023-04-01', 25)\n\nprint(f'There are {len(visits_df)} visits in the fake dataset, with arrivals between {visits_df.arrival_datetime.min().date()} and {visits_df.arrival_datetime.max().date()} inclusive.')\nvisits_df.head()\n</code></pre> <pre><code>There are 2253 visits in the fake dataset, with arrivals between 2023-01-01 and 2023-03-31 inclusive.\n</code></pre> patient_id visit_number arrival_datetime departure_datetime age is_admitted specialty 0 354 1 2023-01-01 05:21:43 2023-01-01 12:35:43 31 1 medical 1 1281 7 2023-01-01 07:22:18 2023-01-01 22:46:18 31 0 None 2 113 15 2023-01-01 07:31:29 2023-01-01 16:12:29 41 0 None 3 114 3 2023-01-01 08:01:26 2023-01-01 10:34:26 33 0 None 4 1937 18 2023-01-01 08:45:38 2023-01-01 16:30:38 14 0 None"},{"location":"notebooks/2a_Create_patient_snapshots/#example-1-create-snapshots-from-fake-data-a-simple-example","title":"Example 1: Create snapshots from fake data - a simple example","text":"<p>My goal is to create snapshots of these visits. First, I define the times of day I will be issuing predictions at. Each time is expressed as a tuple of (hour, minute)</p> <pre><code>prediction_times = [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)] # each time is expressed as a tuple of (hour, minute)\n</code></pre> <p>Then using the code below I create an array of all the snapshot dates in some date range that my data covers.</p> <pre><code>from datetime import datetime, time, timedelta, date\n\n# Create date range\nsnapshot_dates = []\nstart_date = date(2023, 1, 1)\nend_date = date(2023, 4, 1)\n\n# Iterate to create an array of dates\ncurrent_date = start_date\nwhile current_date &lt; end_date:\n    snapshot_dates.append(current_date)\n    current_date += timedelta(days=1)\n\nprint('First ten snapshot dates')\nsnapshot_dates[0:10]\n</code></pre> <pre><code>First ten snapshot dates\n\n\n\n\n\n[datetime.date(2023, 1, 1),\n datetime.date(2023, 1, 2),\n datetime.date(2023, 1, 3),\n datetime.date(2023, 1, 4),\n datetime.date(2023, 1, 5),\n datetime.date(2023, 1, 6),\n datetime.date(2023, 1, 7),\n datetime.date(2023, 1, 8),\n datetime.date(2023, 1, 9),\n datetime.date(2023, 1, 10)]\n</code></pre> <p>Next I iterate through the date array, using the arrival and departure times from the hospital visits table to identify any patients who were in the ED at each prediction time (eg 09:30 or 12.00) on each date. </p> <pre><code>import pandas as pd\n\n\n# Create empty list to store results for each snapshot date\npatient_shapshot_list = []\n\n# For each combination of date and time\nfor date_val in snapshot_dates:\n    for hour, minute in prediction_times:\n        snapshot_datetime = datetime.combine(date_val, time(hour=hour, minute=minute))\n\n        # Filter dataframe for this snapshot\n        mask = (visits_df[\"arrival_datetime\"] &lt;= snapshot_datetime) &amp; (\n            visits_df[\"departure_datetime\"] &gt; snapshot_datetime\n        )\n        snapshot_df = visits_df[mask].copy()\n\n        # Skip if no patients at this time\n        if len(snapshot_df) == 0:\n            continue\n\n        # Add snapshot information columns\n        snapshot_df[\"snapshot_date\"] = date_val\n        snapshot_df[\"prediction_time\"] = [(hour, minute)] * len(snapshot_df)\n\n        patient_shapshot_list.append(snapshot_df)\n\n# Combine all results into single dataframe\nsnapshots_df = pd.concat(patient_shapshot_list, ignore_index=True)\n\n# Name the index snapshot_id\nsnapshots_df.index.name = \"snapshot_id\"\n</code></pre> <p>Note that each record in the snapshots dataframe is indexed by a unique snapshot_id. </p> <pre><code>snapshots_df.head()\n</code></pre> patient_id visit_number arrival_datetime departure_datetime age is_admitted specialty snapshot_date prediction_time snapshot_id 0 354 1 2023-01-01 05:21:43 2023-01-01 12:35:43 31 1 medical 2023-01-01 (6, 0) 1 354 1 2023-01-01 05:21:43 2023-01-01 12:35:43 31 1 medical 2023-01-01 (9, 30) 2 1281 7 2023-01-01 07:22:18 2023-01-01 22:46:18 31 0 None 2023-01-01 (9, 30) 3 113 15 2023-01-01 07:31:29 2023-01-01 16:12:29 41 0 None 2023-01-01 (9, 30) 4 114 3 2023-01-01 08:01:26 2023-01-01 10:34:26 33 0 None 2023-01-01 (9, 30) <p>Some patients are present at more than one of the prediction times, given them more than one entry in snapshots_df</p> <pre><code># Count the number of snapshots per visit and show top five\nsnapshots_df.visit_number.value_counts().head()\n</code></pre> <pre><code>visit_number\n1940    7\n375     7\n1812    7\n1733    7\n1736    7\nName: count, dtype: int64\n</code></pre> <p>Below I show one example of a patient who was in the ED long enough to have multiple snapshots, captured at the various prediction times during their visit.</p> <pre><code># Displaying the snapshots for a visit with multiple snapshots\nexample_visit_number = snapshots_df.visit_number.value_counts().index[0]\nsnapshots_df[snapshots_df.visit_number == example_visit_number]\n\n</code></pre> patient_id visit_number arrival_datetime departure_datetime age is_admitted specialty snapshot_date prediction_time snapshot_id 2959 358 1940 2023-03-19 14:29:26 2023-03-21 03:27:26 79 0 None 2023-03-19 (15, 30) 2965 358 1940 2023-03-19 14:29:26 2023-03-21 03:27:26 79 0 None 2023-03-19 (22, 0) 2977 358 1940 2023-03-19 14:29:26 2023-03-21 03:27:26 79 0 None 2023-03-20 (6, 0) 2983 358 1940 2023-03-19 14:29:26 2023-03-21 03:27:26 79 0 None 2023-03-20 (9, 30) 2989 358 1940 2023-03-19 14:29:26 2023-03-21 03:27:26 79 0 None 2023-03-20 (12, 0) 2998 358 1940 2023-03-19 14:29:26 2023-03-21 03:27:26 79 0 None 2023-03-20 (15, 30) 3014 358 1940 2023-03-19 14:29:26 2023-03-21 03:27:26 79 0 None 2023-03-20 (22, 0)"},{"location":"notebooks/2a_Create_patient_snapshots/#example-2-creating-fake-finished-visits-from-a-relational-database","title":"Example 2: Creating fake finished visits from a relational database","text":"<p>Electronic Health Record systems and their data warehouses are often structured as relational databases, with information stored on multiple linked tables. Timestamps are used to capture how information about a patient accumulates as the ED visit progresses. Patients may visit various locations in the ED, such as triage, where their acuity is recorded, and different activities related to their care are carried out, like measurements of vital signs or lab tests. </p> <p>The function below returns three fake dataframes, meant to resemble EHR data. </p> <ul> <li>hospital visit dataframe - already seen above</li> <li>observations dataframe - with a single measurement, a triage score, plus a timestamp for when that was recorded</li> <li>lab orders dataframe - with five types of lab orders plus a timestamp for when these tests were requested</li> </ul> <p>The function that creates the fake data returns one triage score for each visit, within 10 minutes of arrival</p> <pre><code>visits_df, observations_df, lab_orders_df = create_fake_finished_visits('2023-01-01', '2023-04-01', 25)\n\nprint(f'There are {len(observations_df)} triage scores in the observations_df dataframe, for {len(observations_df.visit_number.unique())} visits')\nobservations_df.head()\n</code></pre> <pre><code>There are 2253 triage scores in the observations_df dataframe, for 2253 visits\n</code></pre> visit_number observation_datetime triage_score 0 1 2023-01-01 05:25:48.686712 2 1 7 2023-01-01 07:24:04.659833 2 2 15 2023-01-01 07:39:02.025157 4 3 3 2023-01-01 08:10:51.432211 3 4 18 2023-01-01 08:50:52.495502 4 <p>The function that creates the fake data returns a random number of lab tests for each patient, for visits over 2 hours. Not all visits will have lab orders in this fake data. </p> <pre><code>print(f'There are {len(lab_orders_df)} lab orders in the dataset, for {len(lab_orders_df.visit_number.unique())} visits')\nlab_orders_df.head()\n</code></pre> <pre><code>There are 5754 lab orders in the dataset, for 2091 visits\n</code></pre> visit_number order_datetime lab_name 0 1 2023-01-01 05:51:39.377886 BMP 1 1 2023-01-01 05:58:40.347001 D-dimer 2 1 2023-01-01 06:36:24.534586 CBC 3 1 2023-01-01 06:49:29.836402 Urinalysis 4 7 2023-01-01 07:43:33.443262 Troponin <p>The <code>create_fake_snapshots()</code> function will pull information from the three fake tables, and prepare snapshots.</p> <pre><code>from datetime import date\nstart_date = date(2023, 1, 1)\nend_date = date(2023, 4, 1)\n\nfrom patientflow.generate import create_fake_snapshots\n\n# Create snapshots\nnew_snapshots_df = create_fake_snapshots(df=visits_df, observations_df=observations_df, lab_orders_df=lab_orders_df, prediction_times=prediction_times, start_date=start_date, end_date=end_date)\nnew_snapshots_df.head()\n</code></pre> snapshot_date prediction_time patient_id visit_number is_admitted age latest_triage_score num_bmp_orders num_d-dimer_orders num_cbc_orders num_urinalysis_orders num_troponin_orders snapshot_id 0 2023-01-01 (6, 0) 354 1 1 31 2.0 1 1 0 0 0 1 2023-01-01 (9, 30) 354 1 1 31 2.0 1 1 1 1 0 2 2023-01-01 (9, 30) 1281 7 0 31 2.0 1 1 1 0 1 3 2023-01-01 (9, 30) 113 15 0 41 4.0 0 0 1 1 0 4 2023-01-01 (9, 30) 114 3 0 33 3.0 1 1 0 1 1 <p>Returning to the example visit above, we can see that at 09:30 on 2023-01-10, the first snapshot for this patient, the triage score had not yet been recorded. This, and the lab orders, were placed between 09:30 and 12:00, so they appear first in the 12:00 snapshot.</p> <pre><code>new_snapshots_df[new_snapshots_df.visit_number==example_visit_number]\n</code></pre> snapshot_date prediction_time patient_id visit_number is_admitted age latest_triage_score num_bmp_orders num_d-dimer_orders num_cbc_orders num_urinalysis_orders num_troponin_orders snapshot_id 2959 2023-03-19 (15, 30) 358 1940 0 79 3.0 1 0 0 0 0 2965 2023-03-19 (22, 0) 358 1940 0 79 3.0 1 1 0 0 1 2977 2023-03-20 (6, 0) 358 1940 0 79 3.0 1 1 0 0 1 2983 2023-03-20 (9, 30) 358 1940 0 79 3.0 1 1 0 0 1 2989 2023-03-20 (12, 0) 358 1940 0 79 3.0 1 1 0 0 1 2998 2023-03-20 (15, 30) 358 1940 0 79 3.0 1 1 0 0 1 3014 2023-03-20 (22, 0) 358 1940 0 79 3.0 1 1 0 0 1"},{"location":"notebooks/2a_Create_patient_snapshots/#summary","title":"Summary","text":"<p>Here I have shown how to create patient snapshots from finished patient visits. Note that there is a discarding of some information, or summarisation involved. The lab orders have been reduced to counts, and only the latest triage score has been taken. In the same vein, you might just take the last recorded heart rate or oxygen saturation level, or the latest value of a lab result. A snapshot loses some of the richness of the full data in an EHR, but with the benefit that you get data that replicate unfinished visits. </p> <p>Note that ED visit data can be patchy in ways that are meaningful. For example, a severely ill patient might have many heart rate values recorded and many lab orders, while a patient with a sprained ankle might have zero heart rate measurements or lab orders. For predicting probability of admission after ED, such variation in data completeness is revealing. By summarising to counts, snapshots allow us to capture that variation in data completeness without having to discard observations that have missing data. </p> <p>In the next notebook I'll show how to make predictions using patient snapshots.</p>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/","title":"2b. Make predictions using patient-level snapshots","text":"<p>Now that the data have been prepared in snapshot form, we have a dataset of unfinished visits. The ultimate goal is to make predictions about whether an outcome of interest (e.g. admission, discharge) will happen within a prediction window. For now, I will use a simple outcome variable of admission or not, without worrying about when that admission happened. </p> <p>Everything shown here is standard modelling, but there are some important considerations when working with unfinished hospital visits.</p>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#things-to-consider-when-training-predictive-models-using-snapshots","title":"Things to consider when training predictive models using snapshots","text":"<p>Random versus temporal splits</p> <p>When dividing your data into training, validation and test sets, a random allocation can give an optimistic assessment of prospective model performance, as the model\u2019s robustness to any temporal changes in patient characteristics, flow-outcomes or the relationships between these goes untested. A more robust approach for testing models intended for prospective use is to apply temporal splits, where you train on earlier data and validate/test on later data, mimicking how the model would be deployed in a real-world setting. I show the application of temporal splits here.</p> <p>Multiple snapshots per visit</p> <p>To use <code>patientflow</code> your data should be in snapshot form. I showed how to create this in the last notebook. I defined a series of prediction times, and then sampled finished visits to get snapshots that represent those visits while still in progress. When you follow this method, you may end up with multiple snapshots per patient visit. Is this OK, for your analysis? You will need to decide whether you include all snapshots from a single visit into the training, validation or testing of a predictive model. Snapshots from the same visit are inherently correlated, which may violate assumptions of the statistical or machine learning methods you are using. For this reason, we chose to sample only one snapshot per patient visit. </p> <p>Multiple visits per patient</p> <p>The patient identifier is also important, because if the same patient appears in training and test sets, there is the potential for data leakage. We took the decision to probabilistically allocate each patient to training, validation or test set, where the probability of being allocated to each set is in proportion to the number of visits they made in any of those time periods. </p> <p><code>patientflow</code> includes functions to handle all of these considerations. I demonstrate them here.</p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#create-fake-snapshots","title":"Create fake snapshots","text":"<p>See the previous notebook for more information about how this is done. </p> <pre><code>from patientflow.generate import create_fake_snapshots\nprediction_times = [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)] \nsnapshots_df=create_fake_snapshots(prediction_times=prediction_times, start_date='2023-01-01', end_date='2023-04-01')\nsnapshots_df.head()\n</code></pre> snapshot_date prediction_time patient_id visit_number is_admitted age latest_triage_score num_urinalysis_orders num_troponin_orders num_bmp_orders num_cbc_orders num_d-dimer_orders snapshot_id 0 2023-01-01 (6, 0) 1958 26 0 37 5.0 1 1 0 0 0 1 2023-01-01 (9, 30) 1958 26 0 37 5.0 1 1 0 0 0 2 2023-01-01 (9, 30) 2782 36 1 28 3.0 0 1 1 1 0 3 2023-01-01 (9, 30) 504 42 0 43 4.0 0 1 0 0 0 4 2023-01-01 (9, 30) 2405 29 0 28 4.0 0 0 0 0 0"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#train-a-model-to-predict-the-outcome-of-each-snapshot","title":"Train a model to predict the outcome of each snapshot","text":"<p>We decided in our work at UCLH to train a different model for each prediction time in the day. That was a design-led decision; we wanted each model to be able to pick up different signals of the outcome at different times of day. You'll see the results of this in later notebooks where I show shap plots for models at different times of day. </p> <p>For now, let's train a model to predict admission for the 9:30 prediction time. </p> <p>I will specify that the triage scores are ordinal, to make use of sklearn's OrdinalEncoder to maintain the natural order of categories. </p> <p>I exclude columns that are not relevant to the prediction of probability of admission, including <code>snapshot_date</code> and <code>prediction_time</code>.</p>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#create-temporal-splits","title":"Create temporal splits","text":"<p>The <code>create_temporal_splits()</code> function below will randomly allocate each patient_id to training, validation and test sets, where the probability of being allocated to each is in proportion to the number of visits they made in any of those time periods. </p> <pre><code>from datetime import date   \nfrom patientflow.prepare import create_temporal_splits\n\n# set the temporal split\nstart_training_set = date(2023, 1, 1) \nstart_validation_set = date(2023, 2, 15) # 6 week training set \nstart_test_set = date(2023, 3, 1) # 2 week validation set \nend_test_set = date(2023, 4, 1) # 1 month test set\n\n# create the temporal splits\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    snapshots_df,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\", # states which column contains the date to use when making the splits \n    patient_id=\"patient_id\", # states which column contains the patient id to use when making the splits \n    visit_col=\"visit_number\", # states which column contains the visit number to use when making the splits \n\n)\n</code></pre> <pre><code>Patient Set Overlaps (before random assignment):\nTrain-Valid: 0 of 2636\nValid-Test: 56 of 1851\nTrain-Test: 156 of 3061\nAll Sets: 0 of 3668 total patients\nSplit sizes: [3179, 1025, 2157]\n</code></pre> <p>The function above returned information on the final size of each split, and on how many patients were found in more than one set. In this case, 29 patients were found in the validation and test set periods. Each of these patients has been probabilistically allocated to just one set. </p>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#select-one-snapshot-per-visit","title":"Select one snapshot per visit","text":"<p>You will need to decide whether you include all snapshots from a single visit into a predictive model.</p> <p>Since we train a different model for each prediction time, then any visits spanning more than 24 hours will have multiple rows. If your snapshots are drawn from visits to ED, this should hopefully not happen too often. If your snapshots are drawn from inpatient visits, then it is very likely that you will have multiple rows per patient. </p> <p>We took the decision to select one snapshot per visit at random. The function below gives you this option. If you specify <code>single_snapshot_per_visit</code> as True, the <code>train_classifier</code> function will expect a <code>visit_col</code> parameter. </p>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#train-a-classifier-to-predict-probability-of-admission","title":"Train a classifier to predict probability of admission","text":"<p>Below I'm using <code>train_classifier()</code>, which is a wrapper on standard scikit-learn functions. There are a few parameters in this function to explain. </p> <ul> <li><code>grid</code>: specifies the grid to use in hyperparameter tuning.</li> <li><code>prediction_time</code>: is used to identify which patient snapshots to use for training.</li> <li><code>single_snapshot_per_visit</code>: if this is True, the function will randomly pick one snapshot for any visit, using <code>visit_col</code> as the column name that identifies the visit identifier. </li> <li><code>exclude_from_training_data</code>: certain columns in the data should not be used for training, including visit numbers and dates.</li> <li><code>ordinal_mappings</code>: the function makes use of SKLearn's Ordinal Mapping encoder.</li> <li><code>use_balanced_training</code>: in healthcare contexts, there are often fewer observations in the positive class. Set this to True for imbalanced samples (common for ED visits, when most patients are discharged, and for predicting inpatient discharge from hospital when most patients remain). It will downsample the negative class. </li> <li><code>calibrate_probabilities</code>: when you downsample the negative class, it is a good idea to calibrate the probabilities to account for this class imbalance. Setting this to True will use a sigmoid function to calibrate the predicted probabilities, ensuring they better reflect the probabilities in the original data distribution.</li> <li><code>calibration_method</code>: options are sigmoid or isotonic; I have found that sigmoid (the default) works better.</li> <li><code>evaluate_on_test</code>: by default, this is set to False so the function will only return performance metrics for the test set; it is good practice to evaluate on the test set only when happy with validation set performance</li> </ul> <p>By default, the function will use an XGBoost classifier, initialised with the hyperparameter grid provided, with log loss as the evaluation metric. Chronological cross-validation is used, with the best hyperparameters selected based on minimising log loss in the validation set. We chose XGBoost because it is quick to train, generally performs well, and handles missing values. </p> <p>If you wish to use a different classifier, you can use another argument:</p> <ul> <li><code>model_class</code> (not shown here):  You can pass your own model in an optional model_class argument, which expects classifier class (like XGBClassifier or other scikit-learn compatible classifiers) that can be instantiated and initialised by providing further parameters.</li> </ul> <pre><code>from patientflow.train.classifiers import train_classifier\n\n# exclude columns that are not needed for training\nexclude_from_training_data=['patient_id', 'visit_number', 'snapshot_date', 'prediction_time']\n\n# train the patient-level model\nmodel = train_classifier(\n    train_visits=train_visits,\n    valid_visits=valid_visits,\n    grid={\"n_estimators\": [20, 30, 40]},\n    prediction_time=(9, 30),\n    exclude_from_training_data=exclude_from_training_data,\n    ordinal_mappings={'latest_triage_score': [1, 2, 3, 4, 5]},\n    single_snapshot_per_visit=True,\n    visit_col='visit_number', # as we are using a single snapshot per visit, we need to specify which column contains the visit number\n    use_balanced_training=True,\n    calibrate_probabilities=True,\n    calibration_method='sigmoid',\n    evaluate_on_test=False, # by default, this is set to False; only evaluate on the test set when happy with validation set performance\n)\n\n</code></pre>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#inspecting-the-object-returned-by-train_classifier","title":"Inspecting the object returned by <code>train_classifier()</code>","text":"<p>The function returns an object of type TrainedClassifer(). Meta data and metrics from the training process are returned with it. </p> <pre><code>print(f'Object returned is of type: {type(model)}')\n\nprint(f'\\nThe metadata from the training process are returned in the `training_results` attribute:')\nmodel.training_results\n</code></pre> <pre><code>Object returned is of type: &lt;class 'patientflow.model_artifacts.TrainedClassifier'&gt;\n\nThe metadata from the training process are returned in the `training_results` attribute:\n\n\n\n\n\nTrainingResults(prediction_time=(9, 30), training_info={'cv_trials': [HyperParameterTrial(parameters={'n_estimators': 20}, cv_results={'train_auc': np.float64(0.9863488774220018), 'train_logloss': np.float64(0.2345235821107298), 'train_auprc': np.float64(0.9839960012755344), 'valid_auc': np.float64(0.7404647983595354), 'valid_logloss': np.float64(0.6777401688701863), 'valid_auprc': np.float64(0.732305765806727)}), HyperParameterTrial(parameters={'n_estimators': 30}, cv_results={'train_auc': np.float64(0.9934036840041577), 'train_logloss': np.float64(0.19339304359858095), 'train_auprc': np.float64(0.992275317414658), 'valid_auc': np.float64(0.7414445203918889), 'valid_logloss': np.float64(0.7224622072494462), 'valid_auprc': np.float64(0.739694204530856)}), HyperParameterTrial(parameters={'n_estimators': 40}, cv_results={'train_auc': np.float64(0.9966901551317282), 'train_logloss': np.float64(0.16839291934975475), 'train_auprc': np.float64(0.9957460357414476), 'valid_auc': np.float64(0.7385623148781044), 'valid_logloss': np.float64(0.7471921775214785), 'valid_auprc': np.float64(0.7319157690354547)})], 'features': {'names': ['age', 'latest_triage_score', 'num_urinalysis_orders_0', 'num_urinalysis_orders_1', 'num_troponin_orders_0', 'num_troponin_orders_1', 'num_bmp_orders_0', 'num_bmp_orders_1', 'num_cbc_orders_0', 'num_cbc_orders_1', 'num_d-dimer_orders_0', 'num_d-dimer_orders_1'], 'importances': [0.07901821285486221, 0.50030118227005, 0.10778335481882095, 0.0, 0.06226950138807297, 0.0, 0.08132454752922058, 0.0, 0.049338143318891525, 0.0, 0.11996506154537201, 0.0], 'has_importance_values': True}, 'dataset_info': {'train_valid_test_set_no': {'train_set_no': 412, 'valid_set_no': 141, 'test_set_no': None}, 'train_valid_test_class_balance': {'y_train_class_balance': {1: 0.29854368932038833, 0: 0.7014563106796117}, 'y_valid_class_balance': {0: 0.7021276595744681, 1: 0.2978723404255319}, 'y_test_class_balance': None}}}, calibration_info={'method': 'sigmoid'}, test_results=None, balance_info={'is_balanced': True, 'original_size': 412, 'balanced_size': 246, 'original_positive_rate': np.float64(0.29854368932038833), 'balanced_positive_rate': np.float64(0.5), 'majority_to_minority_ratio': 1.0})\n</code></pre> <p>To get a better view of what is included within the results, here is a list of the fields returned: </p> <pre><code>from dataclasses import fields\nprint(\"\\nDataclass fields in TrainingResults:\")\nfor field in fields(model.training_results):\n    print(field.name)\n</code></pre> <pre><code>Dataclass fields in TrainingResults:\nprediction_time\ntraining_info\ncalibration_info\ntest_results\nbalance_info\n</code></pre> <p>The prediction time has been saved with the model. When the model's predict method is used, the method will that the requested prediction time and that of the model align. </p> <pre><code>print(f'The prediction time is: {model.training_results.prediction_time}')\n</code></pre> <pre><code>The prediction time is: (9, 30)\n</code></pre> <p>An object called training_info contains information related to model training. To simplify the code below, I'll assign it to a variable called results. It will tell us the size and class balance of each set </p> <pre><code>results = model.training_results.training_info\n\nprint(f\"The training_info object contains the following keys: {results.keys()}\")\n\nprint(f\"\\nNumber in each set{results['dataset_info']['train_valid_test_set_no']}\")\n\ndef print_class_balance(d):\n    for k in d:\n        if d[k] is not None:\n            print(f\"{k.split('_')[1]}: {d[k][0]:.1%} neg, {d[k][1]:.1%} pos\")\n        else:\n            print(f\"{k.split('_')[1]}: None\")\n\n\nprint_class_balance(results['dataset_info']['train_valid_test_class_balance'])\n</code></pre> <pre><code>The training_info object contains the following keys: dict_keys(['cv_trials', 'features', 'dataset_info'])\n\nNumber in each set{'train_set_no': 412, 'valid_set_no': 141, 'test_set_no': None}\ntrain: 70.1% neg, 29.9% pos\nvalid: 70.2% neg, 29.8% pos\ntest: None\n</code></pre> <p>Class balance information is also saved in the training_results, which will store information about the differences between the class balance when forcing the training set to be balanced</p> <pre><code>model.training_results.balance_info\n</code></pre> <pre><code>{'is_balanced': True,\n 'original_size': 412,\n 'balanced_size': 246,\n 'original_positive_rate': np.float64(0.29854368932038833),\n 'balanced_positive_rate': np.float64(0.5),\n 'majority_to_minority_ratio': 1.0}\n</code></pre> <p>And the type of calibration done on balanced samples is saved in training_results also</p> <pre><code>model.training_results.calibration_info\n</code></pre> <pre><code>{'method': 'sigmoid'}\n</code></pre> <p>Results of hyperparameter tuning are saved in a HyperParameterTrial object</p> <pre><code># results are stored in a HyperParameterTrial object\nresults['cv_trials']\n</code></pre> <pre><code>[HyperParameterTrial(parameters={'n_estimators': 20}, cv_results={'train_auc': np.float64(0.9863488774220018), 'train_logloss': np.float64(0.2345235821107298), 'train_auprc': np.float64(0.9839960012755344), 'valid_auc': np.float64(0.7404647983595354), 'valid_logloss': np.float64(0.6777401688701863), 'valid_auprc': np.float64(0.732305765806727)}),\n HyperParameterTrial(parameters={'n_estimators': 30}, cv_results={'train_auc': np.float64(0.9934036840041577), 'train_logloss': np.float64(0.19339304359858095), 'train_auprc': np.float64(0.992275317414658), 'valid_auc': np.float64(0.7414445203918889), 'valid_logloss': np.float64(0.7224622072494462), 'valid_auprc': np.float64(0.739694204530856)}),\n HyperParameterTrial(parameters={'n_estimators': 40}, cv_results={'train_auc': np.float64(0.9966901551317282), 'train_logloss': np.float64(0.16839291934975475), 'train_auprc': np.float64(0.9957460357414476), 'valid_auc': np.float64(0.7385623148781044), 'valid_logloss': np.float64(0.7471921775214785), 'valid_auprc': np.float64(0.7319157690354547)})]\n</code></pre> <pre><code>\n# Find the trial with the lowest validation logloss\nbest_trial = min(results[\"cv_trials\"], key=lambda trial: trial.cv_results['valid_logloss'])\n\n# print the best parameters\nprint(f'The best parameters are: {best_trial.parameters}')\n</code></pre> <pre><code>The best parameters are: {'n_estimators': 20}\n</code></pre> <p>Note that, by default, no test set results are returned by train_classifier. To see AUROC, log loss and AUPRC on the test set, change <code>evaluate_on_test</code> parameter to True above. </p> <pre><code>print(f'The results on the test set were:')\nmodel.training_results.test_results\n\n</code></pre> <pre><code>The results on the test set were:\n</code></pre> <p>Note that each record in the snapshots dataframe is indexed by a unique snapshot_id. </p>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#evaluating-training-results","title":"Evaluating training results","text":"<p>The following function enables you to plot the results of hyperparameter trials, which have been saved with the trained model. The input to the plot is a list of <code>HyperParameterTrial</code> instances containing validation set results and hyperparameter settings. Each trial's <code>cv_results</code> dictionary contains 'valid_auc' and 'valid_logloss' metrics, which have been computed for each hyperparameter configuration using the validation set.</p> <p>As I only including one hyperparameter in my grid, and the data is made up, the plots are not that informative. With real data and a full hyperparameter grid, figures like these can help you can iterate towards an optimal set of hyperparameters. </p> <pre><code>from patientflow.viz.trial_results import plot_trial_results  \n\nplot_trial_results(trials_list = model.training_results.training_info['cv_trials'])\n</code></pre> <p></p>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#summary","title":"Summary","text":"<p>Here I have shown how <code>patientflow</code> can help you</p> <ul> <li>handle multiple snapshots per visit and multiple visits per patient</li> <li>impose a temporal split on your training and test sets, allowing for the point above </li> <li>train a model to predict some later outcome using functions that handle class imbalance and calibration</li> <li>access various attributes of the model, that are saved as part of the model object</li> <li>plot the results of hyperparameter tuning</li> </ul> <p>In the next notebook, I show how to evaluate models applied to patient snapshots. It is good practice to use your validation set results for the evaluations shown in this notebook and the next one, and to use the test set for evaluation only once you are satisified with your model.</p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/","title":"2c. Evaluate models trained on patient-level snapshots","text":""},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#things-to-consider","title":"Things to consider","text":"<p>In the last notebook, I showed how to train models on patient snapshots using <code>patientflow</code>. Now, let's think about how to evaluate those models. </p> <p>When evaluating patient snapshots, we focus on:</p> <ul> <li>How well calibrated the predicted probabilities are.</li> <li>How well the probabilities discriminate between patients with and without the outcome.</li> </ul> <p>We don't focus as much on typical classification metrics like Area under the ROC curve, accuracy or precision/recall. </p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#why-dont-we-focus-on-typical-classification-metrics","title":"Why don't we focus on typical classification metrics?","text":"<p>The ultimate goal is to predict bed count distributions for groups of patients. Bed count distributions will be calculated in two steps</p> <ol> <li>First, we predict the probability of the outcome we are interested in (admission or discharge) for each individual patient, as shown in previous notebooks.</li> <li>Then, we use these probabilities in Bernoulli trials to get bed count distributions. The Bernouill trials step will be shown in later notebooks.</li> </ol> <p>Because of this approach, the accuracy of the probability values matters more than correct classification. That is why we use log loss to optimise our classifiers. </p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#about-the-data-used-in-this-notebook","title":"About the data used in this notebook","text":"<p>I'm going to use real patient data from visits to the Emergency Department (ED) and Same Day Emergency Care (SDEC) unit at University College London Hospital (UCLH) to demonstrate the evaluation. For more information about the data, see the data exploration notebook.</p> <p>The methods shown will work on any data in the same structure. </p> <p>You can request the datasets that are used here on Zenodo. Alternatively you can use the synthetic data that has been created from the distributions of real patient data. If you don't have the public data, change the argument in the cell below from <code>data_folder_name='data-public'</code> to <code>data_folder_name='data-synthetic'</code>.</p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#loading-real-patient-data","title":"Loading real patient data","text":"<p>I load the data using a <code>load_data</code> function that will sort the data and return the tuple columns as tuples rather than strings or lists. If you run the cell below without the public dataset, you will need to change the <code>data_folder_name</code> or (better, since it will solve the problem for all notebooks) copy the synthetic data from <code>data-synthetic</code> to <code>data-public</code>. </p> <pre><code>import pandas as pd\nfrom patientflow.load import set_file_paths, load_data\n\n# set project root\nfrom patientflow.load import set_project_root\nproject_root = set_project_root()\n\n# set file paths\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n        project_root, \n        data_folder_name='data-public', # change this to data-synthetic if you don't have the public dataset\n        verbose=False) \n\n# load the data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre> <pre><code>ed_visits.age_group.value_counts()\n</code></pre> <pre><code>age_group\n25-34     23515\n35-44     17700\n18-24     15400\n45-54     14860\n55-64     14846\n0-17      13586\n75-115    12200\n65-74     11228\nName: count, dtype: int64\n</code></pre> <p>Inspecting the data that has been loaded, we can see that it is similar in structure to the fake data that was generated on the fly in the previous notebooks. The dates have been pushed into the future, to minimise the likelihood of re-identifcation of patients.</p> <p>The dates for training, validation and test sets that match this dataset are defined in the config file in the root directory of <code>patientflow</code>.</p> <pre><code>#  load config file\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set = params[\"start_training_set\"]\nprint(f\"Training set starts: {start_training_set}\")\n\nstart_validation_set = params[\"start_validation_set\"]\nprint(f\"Validation set starts: {start_validation_set}\")\n\nstart_test_set = params[\"start_test_set\"] \nprint(f\"Test set starts: {start_test_set}\")\n\nend_test_set = params[\"end_test_set\"]\nprint(f\"Test set ends: {end_test_set}\")\n\n</code></pre> <pre><code>Training set starts: 2031-03-01\nValidation set starts: 2031-09-01\nTest set starts: 2031-10-01\nTest set ends: 2032-01-01\n</code></pre>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#train-one-model-for-each-prediction-time","title":"Train one model for each prediction time","text":"<p>First, we apply the temporal splits as shown in the previous notebook. </p> <pre><code>\n\nfrom datetime import date   \nfrom patientflow.prepare import create_temporal_splits\n\n# create the temporal splits\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\", # states which column contains the date to use when making the splits \n    visit_col=\"visit_number\", # states which column contains the visit number to use when making the splits \n\n)\n\n</code></pre> <pre><code>Split sizes: [62071, 10415, 29134]\n</code></pre> <p>Next we specify the times of day at which are predictions are to be made. Here I'm deriving from the dataset. Note that there are many more snapshots in the later part of the day 12:00, 15:30 and 22:00</p> <pre><code>prediction_times = ed_visits.prediction_time.unique()\nprint(\"Models will be trained for the following prediction times. Note that each prediction time is a tuple of (hour, minute):\")\nprint(prediction_times)\n\nprint(\"\\nNumber of observations for each prediction time:\")\nprint(ed_visits.prediction_time.value_counts())\n</code></pre> <pre><code>Models will be trained for the following prediction times. Note that each prediction time is a tuple of (hour, minute):\n[(22, 0) (15, 30) (6, 0) (12, 0) (9, 30)]\n\nNumber of observations for each prediction time:\nprediction_time\n(15, 30)    35310\n(12, 0)     29942\n(22, 0)     28457\n(9, 30)     17642\n(6, 0)      11984\nName: count, dtype: int64\n</code></pre> <p>Define ordinal mappings where appropriate. These include:</p> <ul> <li><code>age_group</code> - Age on arrival at the ED, defined in groups</li> <li><code>latest_obs_manchester_triage_acuity</code> - Manchester Triage Score (where blue is the lowest acuity and red the highest)</li> <li><code>latest_obs_objective_pain_score</code> - ranging from nil to very severe </li> <li><code>latest_obs_level_of_consciousness</code> the ACVPU measure of consciousness, where A (aware) and U (unconscious) at are the extremes. </li> </ul> <pre><code>ordinal_mappings = {\n    \"age_group\": [\n        \"0-17\",\n        \"18-24\",\n        \"25-34\",\n        \"35-44\",\n        \"45-54\",\n        \"55-64\",\n        \"65-74\",\n        \"75-115\",\n    ],\n    \"latest_obs_manchester_triage_acuity\": [\n        \"Blue\",\n        \"Green\",\n        \"Yellow\",\n        \"Orange\",\n        \"Red\",\n    ],\n    \"latest_obs_objective_pain_score\": [\n        \"Nil\",\n        \"Mild\",\n        \"Moderate\",\n        \"Severe_Very Severe\",\n    ],\n    \"latest_obs_level_of_consciousness\": [\n        \"A\", #alert\n        \"C\", #confused\n        \"V\", #voice - responds to voice stimulus\n        \"P\", #pain - responds to pain stimulus\n        \"U\" #unconscious - no response to pain or voice stimulus\n    ]    }\n\n</code></pre> <p>In the real data, there are some columns that will be used for predicting admission to specialty, if admitted. I exclude them here.</p> <pre><code>exclude_from_training_data = [ 'snapshot_date', 'prediction_time','visit_number', 'consultation_sequence', 'specialty', 'final_sequence', ]\n</code></pre> <p>We loop through each prediction time, training a model. To start with, we will not balance the dataset. </p> <pre><code>from patientflow.train.classifiers import train_classifier\nfrom patientflow.load import get_model_key\n\n\ntrained_models = {} \n\n# Loop through each prediction time\nfor prediction_time in prediction_times:\n    print(f\"Training model for {prediction_time}\")\n    model = train_classifier(\n        train_visits=train_visits,\n        valid_visits=valid_visits,\n        test_visits=test_visits,\n        grid={\"n_estimators\": [20, 30, 40]},\n        exclude_from_training_data=exclude_from_training_data,\n        ordinal_mappings=ordinal_mappings,\n        prediction_time=prediction_time,\n        visit_col=\"visit_number\",\n        calibrate_probabilities=False,\n        use_balanced_training=False,\n    )\n\n    model_name = 'admissions'\n    model_key = get_model_key(model_name, prediction_time)\n\n    trained_models[model_key] = model\n</code></pre> <pre><code>Training model for (22, 0)\nTraining model for (15, 30)\nTraining model for (6, 0)\nTraining model for (12, 0)\nTraining model for (9, 30)\n</code></pre>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#inspecting-the-base-model","title":"Inspecting the base model","text":"<p>Below I show three different charts, all showing the calibration and discrimination of the models, in slightly different ways. </p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#discrimination-plots","title":"Discrimination plots","text":"<p>A discrimination plot shows the spread of predicted probabilities for positive and negative cases.</p> <ul> <li>X-axis (Predicted Probability): Represents the model's predicted probabilities from 0 to 1.</li> <li>Y-axis (Density): Shows the relative frequency of each probability value.</li> </ul> <p>The plot displays two histograms:</p> <ul> <li>Blue line/area: Distribution of predicted probabilities for negative cases (patients who weren't admitted)</li> <li>Orange line/area: Distribution of predicted probabilities for positive cases (patients who were admitted)</li> </ul> <p>Ideal separation between these distributions indicates a well-performing model:</p> <ul> <li>Negative cases (blue) should cluster toward lower probabilities (left side)</li> <li>Positive cases (orange) should cluster toward higher probabilities (right side)</li> </ul> <p>The degree of overlap between distributions helps assess model discrimination ability. Less overlap suggests the model effectively distinguishes between positive and negative cases, while significant overlap indicates areas where the model struggles to differentiate between outcomes.</p> <p>From the plot below, we see that the model is discriminating poorly, with a high degree of overlap, and very few positive cases at the higher end. </p> <pre><code># without balanced training\nfrom patientflow.viz.distribution_plots import plot_prediction_distributions\nplot_prediction_distributions(\n    trained_models=trained_models,  \n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n\n</code></pre> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#calibration-plots","title":"Calibration plots","text":"<p>A calibration plot shows how well a model's predicted probabilities match actual outcomes.</p> <ul> <li>X-axis (Mean Predicted Probability): The model's predicted probabilities, ordered from 0 to 1, grouped into bins, either using the uniform or the quantile strategy (see below).</li> <li>Y-axis (Fraction of Positives): The observed proportion of admissions for visits in that group.</li> </ul> <p>A perfectly calibrated model would align its points along the diagonal line, meaning a 70% predicted probability means the event happens 70% of the time.</p> <p>Uniform vs Quantile Strategies: - Uniform: Divides predictions into equal-width probability bins (e.g., 0.0-0.1, 0.1-0.2), so some bins may have few or many points. - Quantile: Ensures each bin has the same number of predictions, regardless of how wide or narrow each bin's probability range is.</p> <p>Below, we see reasonable calibration at the lower end, but deteriorating towards the higher end.</p> <pre><code># without balanced training\nfrom patientflow.viz.calibration_plot import plot_calibration\n\nplot_calibration(\n    trained_models=trained_models,  \n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    # strategy=\"quantile\",  # optional\n    # suptitle=\"Base model with imbalanced training data\"  # optional\n)\n</code></pre> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#madcap-model-accuracy-diagnostic-calibration-plot","title":"MADCAP (Model Accuracy Diagnostic Calibration Plot)","text":"<p>A MADCAP (Model Accuracy Diagnostic Calibration Plot) visually compares the predicted probabilities from a model with the actual outcomes (e.g., admissions or events) in a dataset. This plot helps to assess how well the model's predicted probabilities align with the observed values.</p> <p>The blue line represents the cumulative predicted outcomes, which are derived by summing the predicted probabilities as we move through the test set, ordered by increasing probability. The orange line represents the cumulative observed outcomes, calculated based on the actual labels in the dataset, averaged over the same sorted order of predicted probabilities.</p> <p>If the model is well calibrated, these two lines will closely follow each other. If the model discriminates well between positive and negative classes the curves will bow to the bottom left. </p> <p>Below, we see that some models under-predict the likelihood of admissions, as the blue line (predicted outcomes) falls below the orange line (actual outcomes). The models are assigning lower probabilities than they should, meaning that (later) we will under-predict the number of beds needed for these patients.</p> <pre><code>## without balanced training\nfrom patientflow.viz.madcap_plot import generate_madcap_plots\ngenerate_madcap_plots(\n    trained_models=trained_models,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n</code></pre> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#inspecting-a-balanced-model","title":"Inspecting a balanced model","text":"<p>These results are not bad, but it is common to attempt to handle unbalanced classes by under-sampling the majority class. </p> <p>The <code>train_classifier()</code> function will balance the training set, if <code>use_balanced_training</code> is set to True, as shown below. </p> <pre><code>from patientflow.train.classifiers import train_classifier\nfrom patientflow.load import get_model_key\n\ntrained_models = {}\n\n# Loop through each prediction time\nfor prediction_time in prediction_times:\n    print(f\"Training model for {prediction_time}\")\n    model = train_classifier(\n        train_visits=train_visits,\n        valid_visits=valid_visits,\n        test_visits=test_visits,\n        grid={\"n_estimators\": [20, 30, 40]},\n        exclude_from_training_data=exclude_from_training_data,\n        ordinal_mappings=ordinal_mappings,\n        prediction_time=prediction_time,\n        visit_col=\"visit_number\",\n        calibrate_probabilities=False,\n        calibration_method=\"sigmoid\",\n        use_balanced_training=True,\n    )\n\n    model_name = 'admissions'\n    model_key = get_model_key(model_name, prediction_time)\n\n    trained_models[model_key] = model\n\n</code></pre> <pre><code>Training model for (22, 0)\nTraining model for (15, 30)\nTraining model for (6, 0)\nTraining model for (12, 0)\nTraining model for (9, 30)\n</code></pre> <p>From the plots below, we see improved discrimination. There are positive cases clustered at the right hand end of the distribution plot. However, this gain has come at the cost of much worse calibration when the models are applied to the whole test set, without undersampling the majority class, as shown in the calibation plot and MADCAP plots. </p> <pre><code>from patientflow.viz.distribution_plots import plot_prediction_distributions\nfrom patientflow.viz.calibration_plot import plot_calibration\nfrom patientflow.viz.madcap_plot import generate_madcap_plots\n\nplot_prediction_distributions(\n    trained_models=trained_models,  \n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\nplot_calibration(\n    trained_models=trained_models,  \n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    # strategy=\"quantile\",  # optional\n    # suptitle=\"Base model with balanced training data\"  # optional\n)\n\ngenerate_madcap_plots(\n    trained_models=trained_models,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n</code></pre> <p></p> <p></p> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#inspecting-a-balanced-and-calibrated-model","title":"Inspecting a balanced and calibrated model","text":"<p>A solution is to use the validation set to re-calibrate the probabilities generated by the model, so that they generate predictions that align with the true proportion of positive classes. From the plots below, we can see that calibration has been improved, but the calibration process has led to a truncation of the range of the predicted probabilities. </p> <pre><code>from patientflow.train.classifiers import train_classifier\nfrom patientflow.viz.distribution_plots import plot_prediction_distributions\nfrom patientflow.viz.calibration_plot import plot_calibration\nfrom patientflow.viz.madcap_plot import generate_madcap_plots\nfrom patientflow.load import get_model_key\n\ntrained_models = {}\n\n# Loop through each prediction time\nfor prediction_time in prediction_times:\n    print(f\"Training model for {prediction_time}\")\n    model = train_classifier(\n        train_visits=train_visits,\n        valid_visits=valid_visits,\n        test_visits=test_visits,\n        grid={\"n_estimators\": [20, 30, 40]},\n        exclude_from_training_data=exclude_from_training_data,\n        ordinal_mappings=ordinal_mappings,\n        prediction_time=prediction_time,\n        visit_col=\"visit_number\",\n        calibrate_probabilities=True,\n        calibration_method=\"sigmoid\",\n        use_balanced_training=True,\n    )\n\n    model_name = 'admissions'\n    model_key = get_model_key(model_name, prediction_time)\n\n    trained_models[model_key] = model\n\nplot_prediction_distributions(\n    trained_models=trained_models,  \n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\nplot_calibration(\n    trained_models=trained_models,  \n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    # strategy=\"quantile\",  # optional\n    # suptitle=\"Base model with balanced training data\"  # optional\n)\n\ngenerate_madcap_plots(\n    trained_models=trained_models,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n</code></pre> <pre><code>Training model for (22, 0)\nTraining model for (15, 30)\nTraining model for (6, 0)\nTraining model for (12, 0)\nTraining model for (9, 30)\n</code></pre> <p></p> <p></p> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#madcap-plots-by-age","title":"MADCAP plots by age","text":"<p>It can be useful to look at sub-categories of patients, to understand whether models perform better for some groups. Here we show MADCAP plots by age group.</p> <p>The performance is worse for children over all. There are fewer of them in the data, which can be seen by comparing the y axis limits; the y axis maximum is the total number of snapshots in the test that were in at the prediction time. In general, there are twice as many adults as over 65s (except at 22:00), and very few children. The models perform poorly for children, and best for adults under 65. They tend to under-predict for older people, especially at 22:00 and 06:00.  </p> <p>Analysis like this helps understand the limitations of the modelling, and consider alternative approaches. For example, we might consider training a different model for older people, assuming enough data, or gathering more training data before deployment. </p> <pre><code>from patientflow.viz.madcap_plot import generate_madcap_plots_by_group\ngenerate_madcap_plots_by_group(\n    trained_models=trained_models,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    grouping_var=\"age_group\",\n    grouping_var_name=\"Age Group\",\n    plot_difference=False\n)\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#feature-importances-and-shap-plots","title":"Feature importances and Shap plots","text":"<p><code>patientflow</code> offers functions that generate Shap and feature importance plots for each prediction time. </p> <pre><code>from patientflow.viz.feature_plot import plot_features\n\nplot_features(\n    trained_models)\n\n</code></pre> <p></p> <p>Note that shap package is not loaded by default, due to dependency issues. You will need to pip install it here to generate the shap plots.</p> <pre><code>!pip install shap\n</code></pre> <pre><code>from patientflow.viz.shap_plot import plot_shap\n\nplot_shap(\n    trained_models, \n    test_visits,\n    exclude_from_training_data)\n\n\n</code></pre> <pre><code>Predicted classification (not admitted, admitted):  [1666  952]\n\n\n/Users/zellaking/Repos/patientflow/src/patientflow/viz/shap_plot.py:95: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n  shap.summary_plot(\n</code></pre> <p></p> <pre><code>Predicted classification (not admitted, admitted):  [2823 1326]\n\n\n/Users/zellaking/Repos/patientflow/src/patientflow/viz/shap_plot.py:95: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n  shap.summary_plot(\n</code></pre> <p></p> <pre><code>Predicted classification (not admitted, admitted):  [4687 2547]\n\n\n/Users/zellaking/Repos/patientflow/src/patientflow/viz/shap_plot.py:95: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n  shap.summary_plot(\n</code></pre> <p></p> <pre><code>Predicted classification (not admitted, admitted):  [5609 2914]\n\n\n/Users/zellaking/Repos/patientflow/src/patientflow/viz/shap_plot.py:95: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n  shap.summary_plot(\n</code></pre> <p></p> <pre><code>Predicted classification (not admitted, admitted):  [4256 2354]\n\n\n/Users/zellaking/Repos/patientflow/src/patientflow/viz/shap_plot.py:95: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n  shap.summary_plot(\n</code></pre> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#conclusion","title":"Conclusion","text":"<p>Here I have shown how visualations within <code>patientflow</code> can help you</p> <ul> <li>assess the discrimination and calibration of your models</li> <li>identify areas of weakness in your models by comparing predictions across different patient groups</li> </ul> <p>I have also shown how using balanced training set, and re-calibrating using the validation set, can help to improve the discrimination of models where you start with imbalanced data. Imbalance is common in healthcare data. </p> <p>I demonstrated convenient functions to plot feature importances and Shap plots for the trained models. </p> <p>This notebook concludes the set covering patient snapshots. We have created predicted probabilities for each patient, based on what is known about them at the time of the snapshot. However, bed managers really want predictions for the whole cohort of patients at a time. This is where <code>patientflow</code> comes into its own. In the next notebook, I show how to create group snapshots. </p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/","title":"2d. Explore the datasets provided","text":"<p>Two datasets have been provided with this repository.  - <code>ed_visits.csv</code>  - <code>inpatient_arrivals.csv</code></p> <p>These accompany my fully worked example of the modelling of emergency demand for beds. And they are also useful to illustrate what patient snapshots might be made up of. </p> <p>This notebook does some data exploration by plotting charts of all relevant variables in each dataset. </p> <p>The <code>inpatient_arrivals</code> dataset contains arrival times of all patients who visited the UCLH Emergency Department (ED) and the Same Day Emergency Care (SDEC) unit, over the period of the data, and were later admitted. It includes their sex, child status (whether adult or child), and which specialty they were admitted to.</p> <p>The <code>ed_visits</code> database contains a set of snapshots of patients who visited the ED and SDEC over the period of the data, including both admitted and discharged patients. Each snapshot includes information known at the time of the snapshot, and excludes anything that was recorded later, except the variables that serve a 'labels' for model training. These are:  - <code>is_admitted</code> - whether the visit ended in admission to a ward - <code>final_sequence</code> - the sequence of consultations the patient had during the visit - <code>specialty</code> - the specialty of the admission, if the patient was admitted</p> <p>See the data dictionaries for detailed information about the variables in the data provided.</p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#learn-more-about-the-data","title":"Learn more about the data","text":"<p>I recorded a webinar to demonstrate how we converted data from the UCLH Electronic Health Record in a form suitable for this modelling. If you click on the image below, the video will open at the point where I provide detail about the datasets </p> <p> </p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#set-up-the-notebook-environment","title":"Set up the notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#load-parameters-and-set-file-paths","title":"Load parameters and set file paths","text":"<p>Parameters are set in config.json and (for UCLH implementation in config-uclh.yaml). You can change these for your own purposes. I'll talk more about the role of each parameter as it becomes relevant. Here we are loading the pre-defned training, validation and test set dates.  </p> <pre><code>from patientflow.load import set_file_paths\n\n# set file paths\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n        project_root, \n        data_folder_name='data-public',  # change this to data-synthetic if you don't have the public dataset\n        verbose=False\n        ) \n\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#load-data","title":"Load data","text":"<p>This notebook has been run using real data which you can download from Zenodo on request. </p> <p>Alternatively you can use the synthetic dataset that was generated using a stratified sampling approach based on the distributions reported in the data dictionaries. Two relationships from the original data were preserved: the proportion of admitted versus non-admitted patients and the hourly arrival time patterns. All other variables were sampled independently using summary statistics stratified by admission status. This approach maintains relevant dependencies for admission outcomes while treating other variables as independent of each other.</p> <p>If you don't have the public data, change the argument in the cell above from <code>data_folder_name='data-public'</code> to <code>data_folder_name='data-synthetic'</code>.</p> <pre><code>import pandas as pd\nfrom patientflow.load import load_data\n\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n\ninpatient_arrivals = load_data(data_file_path, \n                    file_name='inpatient_arrivals.csv', \n                    index_column = 'arrival_datetime',)\n\ned_visits.head()\n</code></pre> snapshot_date prediction_time elapsed_los sex arrival_method num_obs num_obs_events num_obs_types num_lab_batteries_ordered has_consultation ... visited_waiting visited_unknown latest_obs_respirations latest_obs_temperature latest_obs_news_score_result latest_obs_objective_pain_score visit_number is_admitted specialty final_sequence snapshot_id 98242 2031-01-14 (22, 0) 20740.0 M Amb no medic 74 6 23 8 True ... True False 19.0 96.8 1.0 NaN 000019a46d7c True surgical ['surgical'] 100119 2031-01-19 (15, 30) 3780.0 F Walk-in 29 3 23 1 False ... True False 16.0 98.4 1.0 Mild 00015db18883 False NaN [] 189750 2031-09-29 (22, 0) 10466.0 F Walk-in 12 2 12 0 False ... True False 32.0 97.9 NaN Nil 0001fbabb70e False NaN [] 192732 2031-10-07 (22, 0) 13729.0 F Walk-in 14 1 14 7 True ... True False NaN 97.7 NaN Mild 00021c715ac7 False NaN ['surgical'] 119891 2031-03-12 (6, 0) 2504.0 M Walk-in 9 1 9 0 False ... True False NaN NaN NaN Mild 0002af190380 False NaN [] <p>5 rows \u00d7 68 columns</p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#explore-ed-visits-dataset","title":"Explore ED visits dataset","text":"<p>Note that each snapshot has a date and a prediction time formatted separately, with the prediction time as a tuple of (hour, minute). All functions in <code>patientflow</code> expect prediction times in this format. Each record in the snapshots dataframe is indexed by a unique snapshot_id. </p> <pre><code>ed_visits.head(10)\n</code></pre> snapshot_date prediction_time elapsed_los sex arrival_method num_obs num_obs_events num_obs_types num_lab_batteries_ordered has_consultation ... visited_waiting visited_unknown latest_obs_respirations latest_obs_temperature latest_obs_news_score_result latest_obs_objective_pain_score visit_number is_admitted specialty final_sequence snapshot_id 98242 2031-01-14 (22, 0) 20740.0 M Amb no medic 74 6 23 8 True ... True False 19.0 96.8 1.0 NaN 000019a46d7c True surgical ['surgical'] 100119 2031-01-19 (15, 30) 3780.0 F Walk-in 29 3 23 1 False ... True False 16.0 98.4 1.0 Mild 00015db18883 False NaN [] 189750 2031-09-29 (22, 0) 10466.0 F Walk-in 12 2 12 0 False ... True False 32.0 97.9 NaN Nil 0001fbabb70e False NaN [] 192732 2031-10-07 (22, 0) 13729.0 F Walk-in 14 1 14 7 True ... True False NaN 97.7 NaN Mild 00021c715ac7 False NaN ['surgical'] 119891 2031-03-12 (6, 0) 2504.0 M Walk-in 9 1 9 0 False ... True False NaN NaN NaN Mild 0002af190380 False NaN [] 157035 2031-06-27 (15, 30) 1548.0 F Walk-in 14 1 14 4 False ... True False 18.0 97.7 NaN Moderate 00033228d206 False NaN [] 209659 2031-11-30 (6, 0) 15020.0 F Walk-in 33 3 24 9 True ... True False 17.0 98.2 0.0 Nil 0003d8c503cf False NaN ['obs_gyn'] 105648 2031-02-03 (12, 0) 3502.0 M Walk-in 9 1 9 0 False ... True False NaN NaN NaN Mild 00043419ec6b False NaN [] 172620 2031-08-12 (22, 0) 7274.0 F Walk-in 14 2 14 0 False ... True False NaN 97.5 NaN Mild 0004c73468a6 False NaN ['obs_gyn'] 96560 2031-01-09 (22, 0) 19768.0 F Walk-in 30 3 21 0 False ... True False 17.0 98.2 0.0 Moderate 0004eacbae15 False NaN [] <p>10 rows \u00d7 68 columns</p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#grouping-of-columns-in-ed-visits-dataset","title":"Grouping of columns in ED visits dataset","text":"<p>The ED visits dataset contains variables of different types. </p> <p>For convenience, I use a function called <code>get_dict_cols()</code> to organise the charts below into different sections.</p> <pre><code>from patientflow.load import get_dict_cols\ndict_cols = get_dict_cols(ed_visits)\n\nfor key, value in dict_cols.items():\n    print(f\"\\nColumns in group called {key}:\")\n    print(value)\n\n\n</code></pre> <pre><code>Columns in group called not used in training:\n['snapshot_id', 'snapshot_date', 'prediction_time', 'visit_number', 'training_validation_test', 'random_number']\n\nColumns in group called arrival and demographic:\n['elapsed_los', 'sex', 'age_group', 'age_on_arrival', 'arrival_method']\n\nColumns in group called summary:\n['num_obs', 'num_obs_events', 'num_obs_types', 'num_lab_batteries_ordered']\n\nColumns in group called location:\n['current_location_type', 'total_locations_visited', 'visited_majors', 'visited_otf', 'visited_paeds', 'visited_rat', 'visited_resus', 'visited_sdec', 'visited_sdec_waiting', 'visited_taf', 'visited_utc', 'visited_waiting', 'visited_unknown']\n\nColumns in group called observations:\n['num_obs_blood_pressure', 'num_obs_pulse', 'num_obs_air_or_oxygen', 'num_obs_level_of_consciousness', 'num_obs_news_score_result', 'num_obs_temperature', 'num_obs_manchester_triage_acuity', 'num_obs_objective_pain_score', 'num_obs_subjective_pain_score', 'num_obs_glasgow_coma_scale_best_motor_response', 'num_obs_oxygen_delivery_method', 'num_obs_oxygen_flow_rate', 'num_obs_pupil_reaction_right', 'num_obs_uclh_sskin_areas_observed', 'latest_obs_pulse', 'latest_obs_level_of_consciousness', 'latest_obs_manchester_triage_acuity', 'latest_obs_respirations', 'latest_obs_temperature', 'latest_obs_news_score_result', 'latest_obs_objective_pain_score']\n\nColumns in group called lab orders and results:\n['lab_orders_bc', 'lab_orders_crp', 'lab_orders_csnf', 'lab_orders_ddit', 'lab_orders_rflu', 'latest_lab_results_crea', 'latest_lab_results_hctu', 'latest_lab_results_k', 'latest_lab_results_lac', 'latest_lab_results_na', 'latest_lab_results_pco2', 'latest_lab_results_ph', 'latest_lab_results_wcc', 'latest_lab_results_htrt', 'latest_lab_results_alb', 'lab_orders_bon', 'lab_orders_ncov', 'lab_orders_xcov']\n\nColumns in group called consults:\n['has_consultation', 'consultation_sequence', 'final_sequence', 'specialty']\n\nColumns in group called outcome:\n['is_admitted']\n</code></pre> <p>Also for the plots, I convert the boolean columns to text values.</p> <pre><code># Function to convert boolean columns to text values \"true\" or \"false\" - used for plotting format\ndef bool_to_text(df):\n    bool_cols = df.select_dtypes(include='bool').columns.drop('is_admitted')\n    for col in bool_cols:\n        df[col] = df[col].apply(lambda x: 'true' if x else 'false')\n    return df\n\n# Apply the function\ned_visits = bool_to_text(ed_visits)\n\n# temporarily add a is_admitted column to arrivals \ninpatient_arrivals['is_admitted'] = True\ninpatient_arrivals = bool_to_text(inpatient_arrivals)\n</code></pre> <p>As some variables are ordinal, I create a dictionary to record the ordering of the values. </p> <pre><code>ordinal_mappings = {\n    # age group\n    \"age_group\": [\n        \"0-17\",\n        \"18-24\",\n        \"25-34\",\n        \"35-44\",\n        \"45-54\",\n        \"55-64\",\n        \"65-74\",\n        \"75-115\",\n    ],\n    # triage score\n    \"latest_obs_manchester_triage_acuity\": [\"Blue\", \"Green\", \"Yellow\", \"Orange\", \"Red\"],\n    # pain score\n    \"latest_obs_objective_pain_score\": [\n        r\"Nil\",\n        r\"Mild\",\n        r\"Moderate\",\n        r\"Severe\\E\\Very Severe\",\n    ],\n    # level of consciousness\n    \"latest_obs_level_of_consciousness\": [\n        \"A\", #alert\n        \"C\", #confused\n        \"V\", #voice - responds to voice stimulus\n        \"P\", #pain - responds to pain stimulus\n        \"U\" #unconscious - no response to pain or voice stimulus\n    ]\n}\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#arrival-and-demographic-variables","title":"Arrival and demographic variables","text":"<p>Here I import a function called <code>plot_data_distribution</code> to provide a convenient way of requesting each plot without multiple lines of code for each.</p> <pre><code>from patientflow.viz.data_distribution import plot_data_distribution\n\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#elapsed-length-of-stay","title":"Elapsed Length of Stay","text":"<p>Both admitted and not admitted visits appear to have a long tail of visits lasting more than 24 hours. Any snapshots where the ED visit has lasted more than 72 hours are excluded.</p> <pre><code>ed_visits['elapsed_los_hrs'] = ed_visits['elapsed_los']/3600\nplot_data_distribution(df=ed_visits, col_name='elapsed_los_hrs', grouping_var='is_admitted', grouping_var_name='whether patient admitted', plot_type='both',\n                        title = 'Distribution of elapsed length of stay by whether patient admitted', truncate_outliers=False)\n</code></pre> <p></p> <p>Below, I plot the snapshots where the elapsed visit duration is greater than 24 hours. We can see that the long tail of longer visits is more numerous for discharged than for admitted patients. This could be because patients leave the ED without being recorded as discharged on the system. </p> <pre><code>if ed_visits[ed_visits.elapsed_los_hrs &gt;= 24].shape[0] &gt; 0:\n    plot_data_distribution(ed_visits[ed_visits.elapsed_los_hrs &gt;= 24], 'elapsed_los_hrs', 'is_admitted', 'whether patient admitted', plot_type='both',\n                        title = 'Distribution of elapsed length of stay by whether patient admitted (where elapsed length of stay &gt;= 24 hours)', truncate_outliers=False)\n</code></pre> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#sex-age-group-and-arrival-method","title":"Sex, age group and arrival method","text":"<p>The charts below show distributions between admitted and not admitted patients for sex, age group and arrival method. More older people are admitted. Most walk-ins are discharged.</p> <pre><code>plot_data_distribution(ed_visits, 'sex', 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p> <pre><code>if 'age_group' in ed_visits.columns:\n    plot_data_distribution(ed_visits, 'age_group', 'is_admitted', 'whether patient admitted', plot_type='hist', ordinal_order=ordinal_mappings['age_group'], rotate_x_labels = True)\nelse:\n    plot_data_distribution(ed_visits, 'age_on_arrival', 'is_admitted', 'whether patient admitted', plot_type='hist')\n\n</code></pre> <p></p> <pre><code>plot_data_distribution(ed_visits, 'arrival_method', 'is_admitted', 'whether patient admitted', plot_type='hist', rotate_x_labels = True)\n</code></pre> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#count-variables","title":"Count variables","text":"<p>The counts variables record the following, up to the moment of the snapshot * the number of observations recorded * the number of events at which observations were recorded (if heart rate and respiratory rate have the same timestamp in the original data, this is one event) * the number of different types of observations (heart rate and respiratory would be two types) * the number of lab test batteries ordered</p> <pre><code>for col_name in dict_cols['summary']:\n    plot_data_distribution(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', is_discrete = False, truncate_outliers=True)\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p>The plots above have been set to exlude outliers, for better readability. However, there are some extreme values of num_obs and num_obs_events. In such cases, you might consider removing the outliers, depending on what model is to be applied to the data</p> <pre><code>print(ed_visits.num_obs.max())\nprint(ed_visits.num_obs_events.max())\n</code></pre> <pre><code>989\n266\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#location-variables","title":"Location variables","text":"<p>The variable <code>current_location_type</code> records the location of the patient at the time of the snapshot. Refer to the data dictionary for more information about what each location type means. Patients who visit the UTC (Urgent Treatment Centre) are more likely to be discharged than admitted. The UTC provides care for patients with minor injuries and illnesses.</p> <pre><code>plot_data_distribution(ed_visits, 'current_location_type', 'is_admitted', 'whether patient admitted', plot_type='hist', rotate_x_labels = True)\n</code></pre> <p></p> <pre><code>for col_name in dict_cols['location'][1:]:\n    plot_data_distribution(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#observations-variables","title":"Observations variables","text":"<p>The variables in the observations group record vital signs, triage scores, and also the number of times certain observations have been recorded, up to the moment of the snapshot.</p> <pre><code>dict_cols['observations']\n</code></pre> <pre><code>['num_obs_blood_pressure',\n 'num_obs_pulse',\n 'num_obs_air_or_oxygen',\n 'num_obs_level_of_consciousness',\n 'num_obs_news_score_result',\n 'num_obs_temperature',\n 'num_obs_manchester_triage_acuity',\n 'num_obs_objective_pain_score',\n 'num_obs_subjective_pain_score',\n 'num_obs_glasgow_coma_scale_best_motor_response',\n 'num_obs_oxygen_delivery_method',\n 'num_obs_oxygen_flow_rate',\n 'num_obs_pupil_reaction_right',\n 'num_obs_uclh_sskin_areas_observed',\n 'latest_obs_pulse',\n 'latest_obs_level_of_consciousness',\n 'latest_obs_manchester_triage_acuity',\n 'latest_obs_respirations',\n 'latest_obs_temperature',\n 'latest_obs_news_score_result',\n 'latest_obs_objective_pain_score']\n</code></pre> <p>I first plot the variables that count the number of times something was recorded. </p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#count-variables_1","title":"Count variables","text":"<pre><code>for col_name in [item for item in dict_cols['observations'] if str(item).startswith('num')]:\n    plot_data_distribution(ed_visits, col_name, 'is_admitted', 'whether patient admitted', \n                            plot_type='hist', \n                            is_discrete = True, \n                            truncate_outliers=True)\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#news-scores-and-manchester-triage-score-values","title":"News Scores and Manchester Triage score values","text":"<p>News Scores are commonly used to track the acuity of a patient, and Manchester Triage scores are used at the door of the ED to prioritise patients</p> <pre><code>for col_name in [item for item in dict_cols['observations'] if ('manchester' in str(item) ) and str(item).startswith('latest')]:\n    plot_data_distribution(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', rotate_x_labels = True, ordinal_order=ordinal_mappings['latest_obs_manchester_triage_acuity'])\n</code></pre> <p></p> <pre><code>plot_data_distribution(ed_visits, 'latest_obs_objective_pain_score', 'is_admitted', 'whether patient admitted', \n                        plot_type='hist', \n                        rotate_x_labels = True, \n                        ordinal_order=ordinal_mappings['latest_obs_objective_pain_score'])\n\n</code></pre> <p></p> <pre><code>\nfor col_name in [item for item in dict_cols['observations'] if 'news' in str(item) and str(item).startswith('latest')]:\n    plot_data_distribution(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', is_discrete = True)\n</code></pre> <p></p> <p>The ACVPU score is commonly used to track states of consciousness</p> <pre><code>for col_name in [item for item in dict_cols['observations'] if 'consciousness' in str(item) and str(item).startswith('latest')]:\n    plot_data_distribution(ed_visits, col_name, 'is_admitted', 'whether patient admitted', \n                            plot_type='hist', \n                            ordinal_order=ordinal_mappings['latest_obs_level_of_consciousness'])\n</code></pre> <p></p> <p>Temporarily excluding the most common value of A from the ACVPU score, we can see the spread of other values</p> <pre><code>for col_name in [item for item in dict_cols['observations'] if 'consciousness' in str(item) and str(item).startswith('latest')]:\n    plot_data_distribution(ed_visits[~(ed_visits.latest_obs_level_of_consciousness == 'A')].copy(), col_name, 'is_admitted', 'whether patient admitted', \n                            plot_type='hist', \n                            ordinal_order=ordinal_mappings['latest_obs_level_of_consciousness'])\n</code></pre> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#vital-signs-values","title":"Vital signs values","text":"<p>I now plot the distributions of the vital signs values.</p> <pre><code>for col_name in [item for item in dict_cols['observations'] if str(item).startswith('latest') and ('pulse' in str(item) or 'resp' in str(item) or 'temp' in str(item))]:\n    plot_data_distribution(ed_visits, col_name, 'is_admitted', 'whether patient admitted', \n                            plot_type='hist', \n                            is_discrete = False, \n                            truncate_outliers=True)\n</code></pre> <p></p> <p></p> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#lab-variables","title":"Lab variables","text":"<p>The lab variables include boolean values for whether a lab battery was ordered, and the results of certain lab test. The data include only a small a subset of the lab battery orders and test results that might be requested for a patient in the ED. </p> <pre><code>dict_cols['lab orders and results']\n</code></pre> <pre><code>['lab_orders_bc',\n 'lab_orders_crp',\n 'lab_orders_csnf',\n 'lab_orders_ddit',\n 'lab_orders_rflu',\n 'latest_lab_results_crea',\n 'latest_lab_results_hctu',\n 'latest_lab_results_k',\n 'latest_lab_results_lac',\n 'latest_lab_results_na',\n 'latest_lab_results_pco2',\n 'latest_lab_results_ph',\n 'latest_lab_results_wcc',\n 'latest_lab_results_htrt',\n 'latest_lab_results_alb',\n 'lab_orders_bon',\n 'lab_orders_ncov',\n 'lab_orders_xcov']\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#lab-orders","title":"Lab orders","text":"<p>It is notable in the charts below, which show whether a lab battery was ordered, that battery CRP (for markers of inflammation) is very commonly ordered for admitted patients; among the patients later admitted the majority have a CRP battery ordered whereas among the non-admitted patients only a minority have it. This difference between admitted and non-admitted (where the majority of admitted have something while the majority of discharged patients do not) only applies to this lab battery order. It will show up later as a strong predictor of admission.</p> <pre><code>for col_name in [item for item in dict_cols['lab orders and results'] if str(item).startswith('lab') ]:\n    plot_data_distribution(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#lab-results","title":"Lab results","text":"<p>The plots below show the latest lab values. </p> <pre><code>for col_name in [item for item in dict_cols['lab orders and results'] if str(item).startswith('latest') ]:\n    plot_data_distribution(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', outlier_threshold=3, truncate_outliers=True)\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#consults-variables","title":"Consults variables","text":"<p>The <code>has_consultation</code> variable records whether a referral request was made to another service or specialty up to the point of the snapshot. The sequence of referrals up to that point is recorded in <code>consultation_sequence</code> and the final sequence, at the end of the ED visit in <code>final_sequence</code>. <code>specialty</code> records the specialty that the patient was admitted under, if admitted. </p> <p>The first plot shows that the number of admitted patients with consult requests at the time of the snapshots is about the same as those without. The group without consult requests will have their later in the visit, after the snapshot was recorded.</p> <pre><code>plot_data_distribution(ed_visits, 'has_consultation', 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p> <p>A very small number of non-admitted patients have a specialty of admission recorded. These are most likely patients referred from ED to SDEC, which we don't include in the admitted patients.</p> <pre><code>plot_data_distribution(ed_visits, 'specialty', 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#explore-inpatient-arrivals-dataset","title":"Explore inpatient arrivals dataset","text":"<p>The inpatient_arrivals dataset records all of the arrival dates and and times of patients who were later admitted to a ward. Other information is also recorded, such as sex and child status, as will as specialty of admission. This dataset will be used to predict the number of patients yet-to-arrive at the time of prediction. </p> <pre><code>inpatient_arrivals.head()\n</code></pre> specialty sex is_child is_admitted arrival_datetime 2031-02-26 11:28:00+00:00 medical M false True 2031-01-14 16:51:00+00:00 surgical F false True 2031-02-06 20:51:00+00:00 surgical M false True 2031-01-10 13:43:00+00:00 haem/onc M false True 2031-01-02 13:55:00+00:00 haem/onc F false True <pre><code># temporarily add is_admitted column to arrivals dataset, to be able to use the plot_data_distribution function\ninpatient_arrivals['is_admitted'] = True\nplot_data_distribution(inpatient_arrivals.reset_index().copy(), 'specialty', 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p> <pre><code>plot_data_distribution(inpatient_arrivals, 'is_child', 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#summary","title":"Summary","text":"<p>This notebook has shown how to load files that have been provided, and shows some plots of the variables included. This is an illustrative dataset, showing the type of variables that were used for the analysis at UCLH. Other sites will have different data. </p>"},{"location":"notebooks/3a_Prepare_group_snapshots/","title":"3a. Prepare group snapshots from patient snapshots","text":"<p>Collecting patient snapshots together into a group snapshot is useful when predicting a bed count distribution at a point in time. A group snapshot is a subset of patients who were in the ED on a single snapshot date, at a specific prediction time.</p> <p>In this notebook, I show how <code>patientflow</code> can be used to prepare group snapshots for current patients, by dividing patient snapshots into their groups, and storing the group snapshots as dictionary with: * <code>snapshot_date</code> as the key * <code>snapshot_ids</code> of each patient snapshot as the values </p> <p>This structure is a convenient way to organise the data when making bed count predictions for different snapshot dates and prediction times, and especially when evaluating those predictions (see next notebook).</p>"},{"location":"notebooks/3a_Prepare_group_snapshots/#about-the-examples-in-this-notebook","title":"About the examples in this notebook","text":"<p>In this notebook I use fake data that resemble visits to the Emergency Department (ED). The dataset covers mutiple snapshot dates and prediction times.</p> <p>To start with a very simple example, I apply a series of Bernoulli trials to one group snapshot and visualise the bed count distribution reflecting the sum of these trials. In that simple example, every patient has the same probability of the outcome.</p> <p>I then train a model that predicts a probability of admission for each patient within a group snapshot. This is a more realistic example, as each patient can have a different probability of admission, based on their data. I apply Bernoulli trials and again visualise the predicted distribution for the total number of beds needed for those patients. </p> <p>I demonstrate functions in <code>patientflow</code> that handle the preparation of group snapshots for making predictions. </p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</code></pre>"},{"location":"notebooks/3a_Prepare_group_snapshots/#generate-fake-snapshots","title":"Generate fake snapshots","text":"<p>See a previous notebook for more background on this. </p> <pre><code>from patientflow.generate import create_fake_snapshots\n\nprediction_times = [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)] \nsnapshots_df=create_fake_snapshots(prediction_times=prediction_times, \n                                   start_date='2023-01-01', \n                                   end_date='2023-04-01',\n                                   mean_patients_per_day=100)\nsnapshots_df.head()\n\n</code></pre> snapshot_date prediction_time patient_id visit_number is_admitted age latest_triage_score num_bmp_orders num_cbc_orders num_urinalysis_orders num_troponin_orders num_d-dimer_orders snapshot_id 0 2023-01-01 (6, 0) 5453 34 0 36 4.0 1 0 0 0 0 1 2023-01-01 (6, 0) 270 1 0 47 5.0 0 1 0 0 0 2 2023-01-01 (9, 30) 5453 34 0 36 4.0 1 0 0 0 0 3 2023-01-01 (9, 30) 5294 27 0 36 3.0 1 1 0 1 1 4 2023-01-01 (9, 30) 5274 79 0 26 4.0 0 0 0 0 0 <p>Note that each record in the snapshots dataframe is indexed by a unique snapshot_id. </p>"},{"location":"notebooks/3a_Prepare_group_snapshots/#prepare-group-snapshots","title":"Prepare group snapshots","text":"<p><code>patientflow</code> includes a <code>prepare_group_snapshot_dict()</code> function. As input, it requires a pandas dataframe with a <code>snapshot_date</code> column. If a start date and end date are provided, the function will check for any intervening snapshot dates that are missing, and create an empty group snapshot for this date</p> <p>Here I create a group snapshot dictionary, for patients in the ED at 09.30.</p> <pre><code>from patientflow.prepare import prepare_group_snapshot_dict\n\n# select the snapshots to include in the probability distribution, \ngroup_snapshots_dict = prepare_group_snapshot_dict(\n    snapshots_df[snapshots_df.prediction_time == (9,30)]\n    )\n</code></pre> <p>The keys of the dictionary are the <code>snapshot_date</code>. The values are a list of patients in the ED at that time, identified by their unique <code>snapshot_id</code>.</p> <pre><code>print(\"First 10 keys in the snapshots dictionary\")\nprint(list(group_snapshots_dict.keys())[0:10])\n\n</code></pre> <pre><code>First 10 keys in the snapshots dictionary\n[datetime.date(2023, 1, 1), datetime.date(2023, 1, 2), datetime.date(2023, 1, 3), datetime.date(2023, 1, 4), datetime.date(2023, 1, 5), datetime.date(2023, 1, 6), datetime.date(2023, 1, 7), datetime.date(2023, 1, 8), datetime.date(2023, 1, 9), datetime.date(2023, 1, 10)]\n</code></pre> <p>From the first key in the dictionary, we can see the patients belonging to this first snapshot. </p> <pre><code>first_group_snapshot_key = list(group_snapshots_dict.keys())[0]\nfirst_group_snapshot_values = group_snapshots_dict[first_group_snapshot_key]\n\nprint(f\"\\nThere are {len(first_group_snapshot_values)} patients in the first group snapshot\")\n\nprint(\"\\nUnique snapshot_ids in the first group snapshot:\")\nprint(first_group_snapshot_values)\n\n# print(\"\\nPatient snapshots belonging to the first group snapshot:\")\n# snapshots_df.loc[first_group_snapshot_values]\n</code></pre> <pre><code>There are 11 patients in the first group snapshot\n\nUnique snapshot_ids in the first group snapshot:\n[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n</code></pre> <p>We can use the indices to identify the full patient snapshots. </p> <pre><code>snapshots_df.loc[first_group_snapshot_values]\n</code></pre> snapshot_date prediction_time patient_id visit_number is_admitted age latest_triage_score num_bmp_orders num_cbc_orders num_urinalysis_orders num_troponin_orders num_d-dimer_orders snapshot_id 2 2023-01-01 (9, 30) 5453 34 0 36 4.0 1 0 0 0 0 3 2023-01-01 (9, 30) 5294 27 0 36 3.0 1 1 0 1 1 4 2023-01-01 (9, 30) 5274 79 0 26 4.0 0 0 0 0 0 5 2023-01-01 (9, 30) 6917 18 1 45 3.0 1 0 0 0 0 6 2023-01-01 (9, 30) 4234 43 0 98 4.0 1 0 1 0 0 7 2023-01-01 (9, 30) 7613 69 0 46 4.0 1 0 0 0 0 8 2023-01-01 (9, 30) 4665 83 1 45 3.0 1 1 0 1 1 9 2023-01-01 (9, 30) 6012 32 0 22 4.0 0 0 1 0 0 10 2023-01-01 (9, 30) 6846 6 0 40 4.0 0 0 0 0 0 11 2023-01-01 (9, 30) 1306 66 0 38 3.0 1 1 0 1 0 12 2023-01-01 (9, 30) 2092 71 0 100 2.0 1 1 0 0 1 <p>More useful is to return not just the indices, but also the data for each visit in the group snapshot. This can be done with the <code>prepare_patient_snapshots</code>, which makes the data ready for processing in groups. This will:</p> <ul> <li>filter visits to include only those at the requested prediction time</li> <li>randomly select one snapshot per visit, if requested. If <code>single_snapshot_per_visit</code> is set to True, a <code>visit_col</code> argument must be used, giving the name of the column containing visit identifiers</li> <li>return a tuple of (X, y) matrices, ready for inference. The column containing the outcome (ie the label) is specified in the <code>label_col</code> argument.  </li> </ul> <pre><code>from patientflow.prepare import prepare_patient_snapshots\n\nfirst_snapshot_X, first_snapshot_y = prepare_patient_snapshots(\n    df=snapshots_df.loc[first_group_snapshot_values], \n    prediction_time=(9,30),\n    single_snapshot_per_visit=False,\n    label_col=\"is_admitted\"\n)\nfirst_snapshot_X\n</code></pre> snapshot_date prediction_time patient_id visit_number age latest_triage_score num_bmp_orders num_cbc_orders num_urinalysis_orders num_troponin_orders num_d-dimer_orders snapshot_id 2 2023-01-01 (9, 30) 5453 34 36 4.0 1 0 0 0 0 3 2023-01-01 (9, 30) 5294 27 36 3.0 1 1 0 1 1 4 2023-01-01 (9, 30) 5274 79 26 4.0 0 0 0 0 0 5 2023-01-01 (9, 30) 6917 18 45 3.0 1 0 0 0 0 6 2023-01-01 (9, 30) 4234 43 98 4.0 1 0 1 0 0 7 2023-01-01 (9, 30) 7613 69 46 4.0 1 0 0 0 0 8 2023-01-01 (9, 30) 4665 83 45 3.0 1 1 0 1 1 9 2023-01-01 (9, 30) 6012 32 22 4.0 0 0 1 0 0 10 2023-01-01 (9, 30) 6846 6 40 4.0 0 0 0 0 0 11 2023-01-01 (9, 30) 1306 66 38 3.0 1 1 0 1 0 12 2023-01-01 (9, 30) 2092 71 100 2.0 1 1 0 0 1"},{"location":"notebooks/3a_Prepare_group_snapshots/#simple-example-of-making-a-prediction-for-a-group-snapshot","title":"Simple example of making a prediction for a group snapshot","text":"<p>Let's make some predictions for this group. We'll give each of them a probability of being admitted of 0.2. This is equivalent to computing the probable outcome of 12 coin flips, with probability of heads of 0.2.</p> <pre><code>from scipy import stats\nprob_dist_data = stats.binom.pmf(range(13), 12, 0.2)\nprob_dist_data\n\n</code></pre> <pre><code>array([6.87194767e-02, 2.06158430e-01, 2.83467842e-01, 2.36223201e-01,\n       1.32875551e-01, 5.31502203e-02, 1.55021476e-02, 3.32188877e-03,\n       5.19045120e-04, 5.76716800e-05, 4.32537600e-06, 1.96608000e-07,\n       4.09600000e-09])\n</code></pre> <p>We can plot the predicted distribution using the <code>plot_prob_dist</code> function from patientflow.viz</p> <pre><code>prob_admission_first_group_snapshot = 0.2*len(first_group_snapshot_values)\n\nfrom patientflow.viz.probability_distribution import plot_prob_dist\nfrom patientflow.viz.utils import format_prediction_time\ntitle = (\n    f'Probability distribution for number of beds needed by the '\n    f'{len(first_group_snapshot_values)} patients\\n'\n    f'in the ED at {format_prediction_time((9,30))} '\n    f'on {first_group_snapshot_key} if each patient has a probability of admission of 0.2'\n)\nplot_prob_dist(prob_dist_data, title,  \n    include_titles=True)\n</code></pre> <p></p>"},{"location":"notebooks/3a_Prepare_group_snapshots/#example-of-making-a-prediction-for-a-group-snapshot-with-varying-probabilities-for-each-patient","title":"Example of making a prediction for a group snapshot with varying probabilities for each patient","text":"<p>In the cell below, I'm using <code>create_temporal_splits()</code> to create a training, validation and test set and <code>train_classifier()</code> to prepare a XGBoost classifier. This classifier will be used to generate a predicted probability of admission for each patient. See the 2b_Predict_using_patient_snapshots notebook for more on the functions shown here.</p> <pre><code>from datetime import date   \nfrom patientflow.prepare import create_temporal_splits\nfrom patientflow.train.classifiers import train_classifier\n\n# set the temporal split\nstart_training_set = date(2023, 1, 1) \nstart_validation_set = date(2023, 2, 15) # 6 week training set \nstart_test_set = date(2023, 3, 1) # 2 week validation set \nend_test_set = date(2023, 4, 1) # 1 month test set\n\n# create the temporal splits\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    snapshots_df,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\", # states which column contains the date, for use when making the splits \n    patient_id=\"patient_id\", # states which column contains the patient id, for use when making the splits \n    visit_col=\"visit_number\", # states which column contains the visit number to use when making the splits \n\n)\n# exclude columns that are not needed for training\nexclude_from_training_data=['visit_number', 'snapshot_date', 'prediction_time']\n\n# train the patient-level model\nmodel = train_classifier(\n    train_visits,\n    valid_visits,\n    test_visits=test_visits,\n    grid={\"n_estimators\": [30]},\n    prediction_time=(9, 30),\n    exclude_from_training_data=exclude_from_training_data,\n    ordinal_mappings={'latest_triage_score': [1, 2, 3, 4, 5]},\n    visit_col='visit_number',\n    use_balanced_training=True,\n    calibrate_probabilities=True\n)\n\n</code></pre> <pre><code>Patient Set Overlaps (before random assignment):\nTrain-Valid: 0 of 5318\nValid-Test: 102 of 3690\nTrain-Test: 307 of 6129\nAll Sets: 0 of 7364 total patients\nSplit sizes: [6406, 2122, 4304]\n</code></pre> <p>Now, using the trained model, I will predict a bed count distribution for one snapshot using <code>get_prob_dist_for_prediction_moment()</code>. That function expects the following: </p> <ul> <li><code>X_test</code> - the dataset of patient snapshots to be passed to the model</li> <li><code>y_test</code> - the vector containing the outcome for each patient snapshot (if these are known)</li> <li><code>model</code> - a trained model</li> <li><code>inference_time</code> (defaults to True) - if set to False, the function will calculate the observed outcome for the group snapshot; set this to True if the outcomes for each patient as as yet unknown</li> <li><code>weights</code> - an optional parameter to weight the probabilities returned by the model. This will be demonstrated in later examples</li> </ul> <p>The function returns a dictionary with two keys:</p> <ul> <li><code>agg_predicted</code> contains a predicted probability distribution - in this example, for number of admissions among the patients in the snapshot</li> <li><code>agg_observed</code> counts the number of times the outcome was observed - in this case number of admissions observed</li> </ul> <pre><code>from patientflow.aggregate import get_prob_dist_for_prediction_moment\n\nbed_count_prob_dist = get_prob_dist_for_prediction_moment(\n    first_snapshot_X, \n    model, \n    inference_time=False, \n    y_test=first_snapshot_y\n)\n\nbed_count_prob_dist.keys()\n\n</code></pre> <pre><code>dict_keys(['agg_predicted', 'agg_observed'])\n</code></pre> <p>Using the <code>agg_predicted</code> key, we can plot the probability distribution:</p> <pre><code>from patientflow.viz.probability_distribution import plot_prob_dist\nfrom patientflow.viz.utils import format_prediction_time\ntitle = (\n    f'Probability distribution for number of beds needed by the '\n    f'{len(first_snapshot_X)} patients\\n'\n    f'in the ED at {format_prediction_time((9,30))} '\n    f'on {first_group_snapshot_key} using the trained model for prediction'\n)\nplot_prob_dist(bed_count_prob_dist['agg_predicted'], title,  \n    include_titles=True)\n\n</code></pre> <p></p> <p>The <code>plot_prob_dist</code> function will return the figure if requested. For example below, I have added the observed number of admissions for this group snapshot to the figure. </p> <pre><code>fig = plot_prob_dist(bed_count_prob_dist['agg_predicted'], title,  \n    include_titles=True, return_figure=True)\nax = fig.gca()  \nax.axvline(x=bed_count_prob_dist['agg_observed'], color='red', linestyle='--', label='Observed')\nax.legend();\n\n</code></pre> <p></p>"},{"location":"notebooks/3a_Prepare_group_snapshots/#make-predictions-for-group-snapshots","title":"Make predictions for group snapshots","text":"<p>Now we'll make predictions for the whole test set. </p> <pre><code>X_test, y_test = prepare_patient_snapshots(\n    df=snapshots_df, \n    prediction_time=(9,30), \n    single_snapshot_per_visit=False,\n    exclude_columns=exclude_from_training_data, \n    visit_col='visit_number'\n)\n</code></pre> <p>The <code>get_prob_dist</code> function is set up to receive as input a dictionary of group snapshots, created using the <code>prepare_group_snapshot_dict</code> function demonstrated above. It calls <code>get_prob_dist_for_prediction_moment()</code> for each entry in the dictionary. The arguments to <code>get_prob_dist</code> are: </p> <ul> <li><code>snapshots_dict</code> - a snapshots dictionary</li> <li><code>X_test</code> - the dataset of patient snapshots to be passed to the model</li> <li><code>y_test</code> - the vector containing the outcome for each patient snapshot</li> <li><code>model</code> - a trained model</li> <li><code>weights</code> - an optional parameter to weight the probabilities returned by the model. This will be demonstrated in later examples</li> </ul> <p>When calling <code>get_prob_dist_for_prediction_moment</code> the function will set the <code>inference_time</code> parameter to false. </p> <pre><code>from patientflow.aggregate import get_prob_dist\n\ngroup_snapshots_dict = prepare_group_snapshot_dict(\n    test_visits[test_visits.prediction_time == (9,30)]\n    )\n# get probability distribution for this time of day\nprob_dists_for_group_snapshots = get_prob_dist(\n        group_snapshots_dict, X_test, y_test, model\n    )\n</code></pre> <p>In the next cell I pick a date from the test set at random, and visualise the predicted distribution. </p> <pre><code>import random\nrandom_snapshot_date = random.choice(list(prob_dists_for_group_snapshots.keys()))\ntitle = (\n    f'Probability distribution for number of beds needed by the '\n    f'{len(prob_dists_for_group_snapshots[random_snapshot_date][\"agg_predicted\"])} patients\\n'\n    f'in the ED at {format_prediction_time((9,30))} '\n    f'on {random_snapshot_date} using the trained model for prediction'\n)\nfig = plot_prob_dist(prob_dists_for_group_snapshots[random_snapshot_date]['agg_predicted'], title,  \n    include_titles=True, return_figure=True)\nax = fig.gca()  \nax.axvline(x=prob_dists_for_group_snapshots[random_snapshot_date]['agg_observed'], color='red', linestyle='--', label='Observed')\nax.legend();\n</code></pre> <p></p> <p>The returned object is now ready for evaluation, which I cover in the next notebook. </p>"},{"location":"notebooks/3a_Prepare_group_snapshots/#summary","title":"Summary","text":"<p>In this notebook I have demonstrated the functions in <code>patientflow</code> that handle the preparation of group snapshots. These include: </p> <ul> <li><code>prepare_patient_snapshots</code>, which makes the data ready for processing in groups.</li> <li><code>get_prob_dist_for_prediction_moment</code>, which computes predicted and observed probabilities for a specific snapshot date and prediction time.</li> <li><code>get_prob_dist</code> which computes probability distributions for multiple snapshot dates.</li> </ul> <p>I have also shown the use of <code>plot_prob_dist</code> to visualise the predicted distribution for one group snapshot.</p>"},{"location":"notebooks/3b_Evaluate_group_snapshots/","title":"3b. Evaluate group snapshots","text":"<p>In the last notebook, I showed how to prepare group snapshots using <code>patientflow</code>. Now, let's think about how to evaluate those models. The goal is to evaluate how well a predicted bed count distribution compares with the observed bed counts at each prediction time over the period of the test set. </p> <p>There are various approaches. Here I demonstrate two approaches. </p>"},{"location":"notebooks/3b_Evaluate_group_snapshots/#comparing-observed-values-with-expected","title":"Comparing observed values with expected","text":"<p>A common approach is to express the difference between the expectation of a probability distrubion, and the observed value in terms of Mean Absolute Error (MAE), which avoids positive and negative deviations cancelling each other out. The error can also be expressed as a percentage of observed admissions to derive a mean percentage error (MPE). </p> <p>I also plot the difference between expected and observed, which is more revealing than calculating a single number, as it gives a sense of the spread of errors, and whether the model tends to over- or underestimate. </p>"},{"location":"notebooks/3b_Evaluate_group_snapshots/#visual-approaches-that-evaluate-the-whole-distribution","title":"Visual approaches that evaluate the whole distribution","text":"<p>Other methods, such as Quantile-Quantile (QQ) Plots appraise the performance of the model across the whole distribution. If a model predicts the tails of a distribution well, the observed number of beds would appear in the lowest tenth of the distribution for 10% of prediction moments, and likewise in the highest tenth for 10% of prediction moments. </p> <p>Using such methods with discrete variables (such as bed counts) is nuanced because the Cumulative Distribution Function (CDF) of a discrete distribution is not continuous. A QQ plot can be difficult to interpret if values are often low or zero. Moreover, in our case, we want to evaluate each observed value for a snapshot against the predicted distribution for that particular snapshot; we are using a different predicted distribution each time. </p> <p>I show two approaches to evaluating the performance of models that predict discrete distributions when each observations lies on its own CDF: </p> <ul> <li>Randomised Probabilility Integral Tansform (PIT) Histogram</li> <li>QQ plots adjusted to handle discrete distributions </li> </ul> <p>More information is given below. </p>"},{"location":"notebooks/3b_Evaluate_group_snapshots/#about-the-data-used-in-this-notebook","title":"About the data used in this notebook","text":"<p>I'm going to use real patient data from visits to the Emergency Department (ED) at UCLH to demonstrate the evaluation. The methods shown will work on any data in the same structure. </p> <p>You can request the datasets that are used here on Zenodo. Alternatively you can use the synthetic data that has been created from the distributions of real patient data. If you don't have the public data, change the argument in the cell below from <code>data_folder_name='data-public'</code> to <code>data_folder_name='data-synthetic'</code>.</p>"},{"location":"notebooks/3b_Evaluate_group_snapshots/#loading-real-patient-data","title":"Loading real patient data","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</code></pre> <pre><code>import pandas as pd\nfrom patientflow.load import set_file_paths, load_data\n\n# set project root\nfrom patientflow.load import set_project_root\nproject_root = set_project_root()\n\n# set file paths\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n        project_root, \n        data_folder_name='data-public', # change this to data-synthetic if you don't have the public dataset\n        verbose=False) \n\n# load the data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n\ned_visits.snapshot_date = pd.to_datetime(ed_visits.snapshot_date).dt.date\n\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre> <p>The dates for training, validation and test sets that match this dataset are defined in the config file in the root directory of <code>patientflow</code>.</p> <pre><code>#  load config file\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set = params[\"start_training_set\"]\nprint(f\"Training set starts: {start_training_set}\")\n\nstart_validation_set = params[\"start_validation_set\"]\nprint(f\"Validation set starts: {start_validation_set}\")\n\nstart_test_set = params[\"start_test_set\"] \nprint(f\"Test set starts: {start_test_set}\")\n\nend_test_set = params[\"end_test_set\"]\nprint(f\"Test set ends: {end_test_set}\")\n\n</code></pre> <pre><code>Training set starts: 2031-03-01\nValidation set starts: 2031-09-01\nTest set starts: 2031-10-01\nTest set ends: 2032-01-01\n</code></pre>"},{"location":"notebooks/3b_Evaluate_group_snapshots/#train-one-model-for-each-prediction-time","title":"Train one model for each prediction time","text":"<p>See previous notebooks for more on the code below. </p> <pre><code>from datetime import date   \nfrom patientflow.prepare import create_temporal_splits\n\n# create the temporal splits\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\", # states which column contains the date to use when making the splits \n    visit_col=\"visit_number\", # states which column contains the visit number to use when making the splits \n)\n\n# set prediction times\nprediction_times = ed_visits.prediction_time.unique()\n\n# define variables to exclude \nexclude_from_training_data = [ 'snapshot_date', 'prediction_time','visit_number', 'consultation_sequence', 'specialty', 'final_sequence', ]\n\n# set ordinal mappings\nordinal_mappings = {\n    \"age_group\": [\n        \"0-17\",\n        \"18-24\",\n        \"25-34\",\n        \"35-44\",\n        \"45-54\",\n        \"55-64\",\n        \"65-74\",\n        \"75-115\",\n    ],\n    \"latest_obs_manchester_triage_acuity\": [\n        \"Blue\",\n        \"Green\",\n        \"Yellow\",\n        \"Orange\",\n        \"Red\",\n    ],\n    \"latest_obs_objective_pain_score\": [\n        \"Nil\",\n        \"Mild\",\n        \"Moderate\",\n        \"Severe_Very Severe\",\n    ],\n    \"latest_obs_level_of_consciousness\": [\n        \"A\", #alert\n        \"C\", #confused\n        \"V\", #voice - responds to voice stimulus\n        \"P\", #pain - responds to pain stimulus\n        \"U\" #unconscious - no response to pain or voice stimulus\n    ]    }\n</code></pre> <pre><code>Split sizes: [62071, 10415, 29134]\n</code></pre> <p>We loop through each prediction time, training a model, using balanced training set and re-calibration on the validation set. Here I'm using a minimal hyperparameter grid for expediency. </p> <pre><code>from patientflow.train.classifiers import train_classifier\nfrom patientflow.load import get_model_key\n\n# create a dictionary to store the trained models\ntrained_models = {}  \n\n# Loop through each prediction time\nfor prediction_time in prediction_times:\n    print(f\"Training model for {prediction_time}\")\n    model = train_classifier(\n        train_visits=train_visits,\n        valid_visits=valid_visits,\n        test_visits=test_visits,\n        grid={\"n_estimators\": [20, 30, 40]},\n        exclude_from_training_data=exclude_from_training_data,\n        ordinal_mappings=ordinal_mappings,\n        prediction_time=prediction_time,\n        visit_col=\"visit_number\",\n        calibrate_probabilities=True,\n        calibration_method=\"isotonic\",\n        use_balanced_training=True,\n    )\n    model_name = 'admissions'\n    model_key = get_model_key(model_name, prediction_time)\n\n    trained_models[model_key] = model\n</code></pre> <pre><code>Training model for (22, 0)\nTraining model for (15, 30)\nTraining model for (6, 0)\nTraining model for (12, 0)\nTraining model for (9, 30)\n</code></pre>"},{"location":"notebooks/3b_Evaluate_group_snapshots/#prepare-group-snapshots","title":"Prepare group snapshots","text":"<p>We will now iterate over all group snapshots, to create the following</p> <ul> <li>a prediction probability distribution for all group snapshots</li> <li>the observed number of patients with the outcome for each group snapshot</li> </ul> <pre><code>from patientflow.prepare import prepare_patient_snapshots, prepare_group_snapshot_dict\nfrom patientflow.aggregate import get_prob_dist\n\nprob_dist_dict_all = {}\n# Process each time of day\nfor _prediction_time in prediction_times:\n\n    print(\"\\nProcessing :\" + str(_prediction_time))\n    model_key = get_model_key(model_name, _prediction_time)\n\n    X_test, y_test = prepare_patient_snapshots(\n        df=test_visits, \n        prediction_time=_prediction_time, \n        single_snapshot_per_visit=False,\n        exclude_columns=exclude_from_training_data, \n        visit_col='visit_number'\n    )\n\n    group_snapshots_dict = prepare_group_snapshot_dict(\n        test_visits[test_visits.prediction_time == _prediction_time]\n        )\n    # get probability distribution for this time of day\n    prob_dist_dict_all[model_key] = get_prob_dist(\n            group_snapshots_dict, X_test, y_test, trained_models[model_key]\n        )\n</code></pre> <pre><code>Processing :(22, 0)\n\nProcessing :(15, 30)\n\nProcessing :(6, 0)\n\nProcessing :(12, 0)\n\nProcessing :(9, 30)\n</code></pre>"},{"location":"notebooks/3b_Evaluate_group_snapshots/#evaluate-group-snapshots","title":"Evaluate group snapshots","text":""},{"location":"notebooks/3b_Evaluate_group_snapshots/#comparing-observed-with-expected-values","title":"Comparing observed with expected values","text":"<p>The mean difference between observed and expected values are reported below. </p> <pre><code>from patientflow.evaluate import calc_mae_mpe\nresults = calc_mae_mpe(prob_dist_dict_all)\n\nprint(\"\\nTime    MAE    MPE\")\nprint(\"----------------------\")\nfor prediction_time, values in results.items():\n    # Extract time by finding the underscore and formatting what comes after\n    time_str = prediction_time.split('_')[1]\n    formatted_time = f\"{time_str[:2]}:{time_str[2:]}\"\n    print(f\"{formatted_time}  {values['mae']:&lt;6.2f}  {values['mpe']:.2f}%\")\n\n</code></pre> <pre><code>Time    MAE    MPE\n----------------------\n06:00  1.54    33.61%\n09:30  1.62    38.87%\n12:00  2.18    31.43%\n15:30  2.70    23.35%\n22:00  3.14    23.94%\n</code></pre> <p>The 06:00 and 09:00 models have the lowest Mean Absolute Error but from a previous notebook we know that they also have the smallest number of patients admitted. Their Mean Percentage Errors were higher than for the later prediction times. While the later times have larger absolute errors, they are proportionally nearer to the actual values. </p> <p>We can plot the observed values against the expected, as shown below.</p> <pre><code>from patientflow.viz.observed_against_expected import plot_deltas\nplot_deltas(results)\n</code></pre> <p></p> <p>From the plots above:  * The 06:00 and 09:30 models data shows a slight positive bias, with more values above zero than below, suggesting under-prediction (observed values higher than expected) * The 12:00 model appears more spread out with a wider range of error * The 15:30 model has a slight negative bias * The 22:00 time slot displays a distinct positive skew, with most values above zero, suggesting consistent under-prediction</p>"},{"location":"notebooks/3b_Evaluate_group_snapshots/#visual-approaches-that-evaluate-the-whole-distribution_1","title":"Visual approaches that evaluate the whole distribution","text":""},{"location":"notebooks/3b_Evaluate_group_snapshots/#randomised-probabilility-integral-tansform-pit-histogram","title":"Randomised Probabilility Integral Tansform (PIT) Histogram","text":"<p>As noted in the introduction, we want to evaluate  each observed value against the predicted distribution for that snapshot; thus we are using a different predicted distribution each time. We have a model that determines a Cumulative Distribution Function (CDF) Fi(x) specific to the discrete random variable associated with the ith observation in a series of counts and we want to assess the accuracy of the underlying model.</p> <p>For continuous variables, there's an elegant solution called the Probability Integral Transform (PIT) developed by Czado et al, 2009. Each observation can be mapped to the corresponding value of its CDF; this is referred to as a a probability integral transform (PIT). If the underlying model is well calibrated, a histogram of these PIT values would be uniform, and a cumulative plot of PIT values would have a slope of 1.</p> <p>For a discrete random variable, instead of a single point, each observation corresponds to a range on the CDF. We identify the range of the cdf Fi(x) associated with the observation oi. For discrete integer variables, this has a lower limit, upper limit and mid-points given by li = Fi(oi-1), ui = Fi(oi) and mi = \ud835\udc59\ud835\udc56+\ud835\udc62\ud835\udc562.</p> <p>The randomized PIT histogram is obtained by allotting to each observation oi a PIT value sampled at random from the range [li,ui] and then forming a histogram of these (with one convention being to have 10 bins of width 0.1). A well performing model will give a uniform histogram (subject to randomisation and binning).</p> <pre><code>from patientflow.viz.randomised_pit import plot_randomised_pit\n\nplot_randomised_pit(prediction_times, \n                    prob_dist_dict_all,\n                    suptitle=\"Randomised Probability Integral Transform (PIT) plots for each prediction time\")\n</code></pre> <p></p>"},{"location":"notebooks/3b_Evaluate_group_snapshots/#evaluating-predictions-for-unique-discrete-distributions-epudd-plot","title":"Evaluating Predictions for Unique Discrete Distributions (EPUDD) plot","text":"<p>In prior work, we developed an alternative to the QQ plot suited to discrete random variables where each observation has a unique predicted distribution. See Figure 9 in Pagel et al (2017). We call this a Evaluating Predictions for Unique Discrete Distributions (EPUDD) plot</p> <p>In the EPUDD Plot the x axis represents the CDF from the model's predictions (in grey) and the y axis represents the proportion of cumulative probability mass that fall at or below each CDF threshold. </p> <p>Both sets of points are plotted with the predicted CDF values on the x axis. The difference is:</p> <ul> <li>Grey points: Show the full predicted CDF curve</li> <li>Colored points: Show only where the actual observations fall along that their predicted CDF</li> </ul> <p>If the observed cdf points track the model cdfs, the model is well calibrated. </p> <p>Note that the model points (grey) represent discrete probability mass, averaged over all prediction times in the test set. Because discrete probability mass may be stepped, the model points may not follow the y=x line.</p> <pre><code>from patientflow.viz.epudd import plot_epudd\n\nplot_epudd(prediction_times, \n        prob_dist_dict_all,\n        model_name=\"admissions\",\n        suptitle=\"Evaluating Predictions for Unique Discrete Distributions (EPUDD) plots for each prediction time\",\n        plot_all_bounds=False)\n</code></pre> <p></p> <p>In the two sets of plot above, the 06:00 and 09:30 perform reasonably well. At 12:00 and 15:30 the predicted probabilities are lower than the observed frequencies, and at 22:00 they are higher. At 22:00, more patients are being admitted than the model expects. </p> <p>From these plots, there appears to be some bias introduded at the aggregation to group snapshots, that has not been propogated through from the patient-level predictions. </p> <p>Further work is needed to isolate the reason for this bias. </p>"},{"location":"notebooks/3b_Evaluate_group_snapshots/#summary","title":"Summary","text":"<p>Here I have demonstrated some methods for evaluating predicted distributions, including summary statistics, Randomised PIT Histograms and Adjusted QQ Plots.  </p> <p>We prefer plots over summary statistics like MAE or MPE. Plots allow us to compare the predicted and observed distributions across the full probability range. This can be helpful for detecting issues in the tails of distributions. For instance, in the 22:00 time, the plot reveals deviations in the upper quantiles that summary statistics would obscure. This helps to identify where in the modelling pipeline model bias is being introduced, and identify aspects that need to be investigated further. </p> <p>I demonstrated two approaches to such plots. We prefer the Adjusted QQ to the Randomised PIT approach because is not subject to randomisation and binning, and can reveal sparse areas of the cdf (eg around 0.3 CDF value on the 12:00 plot). I will make use of this plot in later notebooks evaluating our emergency demand predictions by specialty. </p>"},{"location":"notebooks/3c_Predict_bed_counts_without_using_patient_snapshots/","title":"3c. Predict bed counts without using patient snapshots","text":"<p>There are situations where we might want to predict bed count distributions without having details of the patients, for example when predicting the number of beds needed for incoming patients such as:</p> <ul> <li>Incoming patients who haven't yet arrived at the Emergency Department, but who will need a bed within a prediction window</li> <li>Emergency patients who arrive via other routes than the ED, and become inpatients (such as emergency transfers from other hospitals)</li> <li>Elective admissions of patients. Planned elective admissions are recorded on a 'To Come In' (TCI) list by patient number. In data, the hospital visit (known as an encounter) for the elective procedure begins at the moment a patient arrives, but may not be recorded in data prior to that point. In a simple case without making use of any data on TCI lists, we might want to predict bed requirements for such patients based on past patterns of such arrivals between a prediction time (eg 12:00) and the end of a prediction window (eg 8 hours later).  </li> </ul> <p>For these situations, we can use <code>patientflow</code> to learn patterns from past data, and use these to predict a bed count distribution at the aggregate level.</p> <p>In this notebook, I'll use the example of predicting the number of beds needed for incoming patients (patients yet to arrive to the Emergency Department who will need a bed within a prediction window). I'll show three approaches: </p> <ul> <li>a Poisson model trained on past arrival rates of patients who both arrived and were admitted within a prediction window</li> <li>a weighted Poisson model using an empirical survival curve; arrival rates of patients who were admitted (at some point), are weighted by their probability of being admitted within a prediction window, calculated from a survival curve learned form past data</li> <li>a weighted Poisson model using an aspirational approach; instead of using a survival curve learned form past data, it is assumed that the ED is meeting 4-hour targets for time to admission. </li> </ul> <p>I also demonstrate making predictions by specialty for demand from incoming patients. </p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</code></pre>"},{"location":"notebooks/3c_Predict_bed_counts_without_using_patient_snapshots/#create-fake-arrival-times","title":"Create fake arrival times","text":"<p>I will generate some fake data on patients in an Emergency Department (ED) using the same method as in previous notebooks. This time, I only need patients who were admitted after the ED visit. </p> <pre><code>from patientflow.generate import create_fake_finished_visits\nvisits_df, _, _ = create_fake_finished_visits('2023-01-01', '2023-04-01', mean_patients_per_day=50, admitted_only=True)\nvisits_df.head()\n</code></pre> patient_id visit_number arrival_datetime departure_datetime age is_admitted specialty 0 3031 33 2023-01-01 06:12:03 2023-01-01 15:51:03 29 1 medical 1 8829 15 2023-01-01 06:55:24 2023-01-01 21:28:24 34 1 paediatric 2 10479 27 2023-01-01 07:53:54 2023-01-01 11:56:54 61 1 medical 3 10856 8 2023-01-01 08:02:10 2023-01-01 13:16:10 31 1 medical 4 6011 43 2023-01-01 10:05:20 2023-01-01 20:16:20 40 1 medical <p>I'll rename the <code>departure_datetime</code> column to <code>admitted_to_ward_datetime</code> since all admitted patients depart to a ward.</p> <p>Note - if you follow my approach using your own data, make sure you start with a dataset of arrival and admitted-to-ward times that has only one row per visit. Do not use your snapshot dataset for this, if it includes multiple rows per visit. </p> <pre><code>import pandas as pd\n\ninpatient_arrivals = visits_df.rename(columns = {'departure_datetime': 'admitted_to_ward_datetime'}).drop(columns = 'is_admitted')\ninpatient_arrivals['arrival_datetime'] = pd.to_datetime(inpatient_arrivals['arrival_datetime'])\n</code></pre> <p>I will generate an array of dates covered by the data I've loaded. I'm calling these <code>snapshot_dates</code> for consistency.</p> <pre><code>from datetime import timedelta, date\n\n# Create date range\nsnapshot_dates = []\nstart_date = date(2023, 1, 1)\nend_date = date(2023, 4, 1)\n\ncurrent_date = start_date\nwhile current_date &lt; end_date:\n    snapshot_dates.append(current_date)\n    current_date += timedelta(days=1)\n\nprint('First ten snapshot dates')\nsnapshot_dates[0:10]\n</code></pre> <pre><code>First ten snapshot dates\n\n\n\n\n\n[datetime.date(2023, 1, 1),\n datetime.date(2023, 1, 2),\n datetime.date(2023, 1, 3),\n datetime.date(2023, 1, 4),\n datetime.date(2023, 1, 5),\n datetime.date(2023, 1, 6),\n datetime.date(2023, 1, 7),\n datetime.date(2023, 1, 8),\n datetime.date(2023, 1, 9),\n datetime.date(2023, 1, 10)]\n</code></pre>"},{"location":"notebooks/3c_Predict_bed_counts_without_using_patient_snapshots/#predicting-future-arrivals-with-model-trained-on-past-data","title":"Predicting future arrivals, with model trained on past data.","text":"<p>When predicting how many patients will arrive after a prediction time, and be admitted before the end of a prediction window, we need some way to decide how long it takes admitted patients to be processed by the ED. </p> <p>The first two approaches, shown in this section, use past data to determine how long a patient will be in the ED before admission. </p> <ul> <li>A Poisson model based on counts of patients who arrived and were admitted within in a prediction window (eg arrived after 06:00 and were admitted before 14:00) during the training set period</li> <li>A survival curve based on empirical data from the training set period</li> </ul> <p>As in previous notebooks, I'll apply a temporal split to the data. </p> <pre><code>from datetime import date   \nfrom patientflow.prepare import create_temporal_splits\n\n# set the temporal split\nstart_training_set = date(2023, 1, 1) \nstart_validation_set = date(2023, 2, 15) # 6 week training set \nstart_test_set = date(2023, 3, 1) # 2 week validation set \nend_test_set = date(2023, 4, 1) # 1 month test set\n\n# create the temporal splits\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    inpatient_arrivals,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"arrival_datetime\", # states which column contains the date to use when making the splits \n\n)\n</code></pre> <pre><code>Split sizes: [2214, 710, 1584]\n</code></pre>"},{"location":"notebooks/3c_Predict_bed_counts_without_using_patient_snapshots/#approach-1-using-past-data-poisson-model-trained-on-past-arrival-rates-of-patients-who-both-arrived-and-were-admitted-within-a-prediction-window","title":"Approach 1 using past data: Poisson model trained on past arrival rates of patients who both arrived and were admitted within a prediction window","text":"<p>The function below generates counts by snapshot date of patients who arrived after the prediction time and were admitted before the end of the prediction window. </p> <p>After applying the function, the count data is shown below.</p> <pre><code>from patientflow.calculate.arrival_rates import count_yet_to_arrive\n\nprediction_times = [(6,0), (9,30), (12, 0), (15,30), (22,0)] \n\nyet_to_arrive_counts = count_yet_to_arrive(inpatient_arrivals, \n                                           snapshot_dates, \n                                           prediction_times, \n                                           prediction_window_hours=8)\nyet_to_arrive_counts.head()\n</code></pre> snapshot_date prediction_time count 0 2023-01-01 (6, 0) 2 1 2023-01-01 (9, 30) 1 2 2023-01-01 (12, 0) 6 3 2023-01-01 (15, 30) 3 4 2023-01-01 (22, 0) 1 <p>Here I use the mean daily count as the mean of a Poisson distribution. </p> <pre><code>from scipy import stats\npoisson_mean = yet_to_arrive_counts[yet_to_arrive_counts['prediction_time'] == (12, 0)]['count'].mean()\npoisson_model = stats.poisson(poisson_mean)\n</code></pre> <p>I use the Poisson model to predict a bed count distribution for the patients yet-to-arrive. </p> <pre><code>prob_dist_data = [poisson_model.pmf(k) for k in range(20)]\n\nfrom patientflow.viz.probability_distribution import plot_prob_dist\nfrom patientflow.viz.utils import format_prediction_time\ntitle = (\n    f'Probability distribution for number of beds needed for patients'\n    f'\\nwho will arrive after {format_prediction_time(prediction_times[0])} on {snapshot_dates[0]} and need a bed before 20:00'\n)\nplot_prob_dist(prob_dist_data, title,  \n    include_titles=True, truncate_at_beds=40)\n</code></pre> <p></p>"},{"location":"notebooks/3c_Predict_bed_counts_without_using_patient_snapshots/#approach-2-using-an-empirical-survival-curve","title":"Approach 2: Using an empirical survival curve","text":"<p>Another approach is to learn from past data about how long it takes patients to be admitted. To illustrate this, the <code>plot_admission_time_survival_curve</code> function will take a dataset of start and end times, and draw a survival curve. </p> <p>(Note - survival curves are often used for time to mortality or an adverse event; here 'survival' here means how long the patient remained in the ED prior to admission.)</p> <p>In the fake data I'm using here, I've deliberately set the mean length of stay to be longer than 4 hours, to illustrate the differences between learning from the past data and (later in the notebook) taking an aspirational approach and assuming the ED meets its 4-hour targets. </p> <pre><code>from patientflow.viz.survival_curve import plot_admission_time_survival_curve\ntitle = 'Survival curve showing probability of still being in the ED after a given elapsed time since arrival'\nsurvival_df = plot_admission_time_survival_curve(train_visits, \n                                   start_time_col=\"arrival_datetime\",\n                                   end_time_col=\"admitted_to_ward_datetime\",\n                                   title=title,\n                                   ylabel='Proportion of patients not yet admitted',\n                                   xlabel='Elapsed time since arrival',\n                                   target_hours=[4, 8],\n                                   annotation_string=\"{:.1%} of patients admitted\\nby {:.0f} hours\",\n                                   return_df=True\n)\n</code></pre> <p></p> <p>The function has an option to return the survival curve. </p> <pre><code>survival_df.head()\n</code></pre> time_hours survival_probability event_probability 0 0.000000 1.000000 0.000000 1 1.283333 0.999548 0.000452 2 1.333333 0.999097 0.000903 3 1.350000 0.998645 0.001355 4 1.400000 0.998193 0.001807 <p>From the curve, we can read the probability of still being in the ED seven hours after arrival. The probability of being admitted within seven hours is one minus this number. </p> <pre><code>from patientflow.calculate.admission_in_prediction_window import get_survival_probability\nprint(f'Probability of still being in the ED seven hours after arrival: {get_survival_probability(survival_df, 7):.2f}')\nprint(f'Probability of being admitted within seven hours of arrival: {1-get_survival_probability(survival_df, 7):.2f}')\n\n</code></pre> <pre><code>Probability of still being in the ED seven hours after arrival: 0.52\nProbability of being admitted within seven hours of arrival: 0.48\n</code></pre> <p>If I'm making a prediction at 12:00 for number of admissions by 20:00, I could divide that 8-hour window into 8 slices of one hour, calculate a mean arrival rate for each hour, and use the survival curve to get the probability of the patients who arrive in each hour being admitted by the end of the prediction window.</p> <p>First I calculate the arrival rate for a one hour slice: </p> <pre><code>num_days_in_training_data = (start_validation_set - start_training_set).days\nprint(f'Number of days in training data: {num_days_in_training_data}')\n\nprint(f'Number of admitted patients arriving between 19:00 and 20:00 in training data: {len(train_visits[(train_visits.arrival_datetime.dt.hour == 19) ])}')\nprint(f'Average number of admitted patients arriving between 19:00 and 20:00 in training data: {(len(train_visits[(train_visits.arrival_datetime.dt.hour == 19) ])/num_days_in_training_data):.2f}')\n</code></pre> <pre><code>Number of days in training data: 45\nNumber of admitted patients arriving between 19:00 and 20:00 in training data: 50\nAverage number of admitted patients arriving between 19:00 and 20:00 in training data: 1.11\n</code></pre> <p>The arrival rate can be multiplied by the probability of admission within the prediction window and used as a weighted mean in a Poisson distribution for each hour. The eight Poisson distributions (one for each hour) can then be convolved into a single distribution. This is shown below. </p> <p>(As noted above this may seem complicated. I show it because a similar approach informs the aspirational approach that follows.)</p> <pre><code>from scipy import stats\nimport numpy as np\n\nfrom patientflow.calculate.admission_in_prediction_window import get_survival_probability\n\n# Initialize arrays to store probabilities and rates\nhours = range(12, 20)\nprobabilities = []\nrates = []\n\n# Calculate probabilities and rates for each hour\nfor _hour in hours:\n    probability_of_admission = 1-get_survival_probability(survival_df, 20-_hour)\n    arrival_rate = len(train_visits[(train_visits.arrival_datetime.dt.hour == _hour)])/num_days_in_training_data\n    probabilities.append(probability_of_admission)\n    rates.append(arrival_rate)\n\n# Create individual Poisson distributions\npoisson_dists = [stats.poisson(r*p) for r, p in zip(rates, probabilities)]\n\n# Get PMF for each distribution \nmax_value = 20  \nx = np.arange(max_value)\npmfs = [dist.pmf(x) for dist in poisson_dists]\n\n# Convolve all distributions together\ncombined_pmf = pmfs[0]\nfor pmf in pmfs[1:]:\n    combined_pmf = np.convolve(combined_pmf, pmf)\n\n# Create final distribution\ncombined_dist = stats.rv_discrete(values=(range(len(combined_pmf)), combined_pmf))\n\n</code></pre> <p>The result is a very similar distribution to that calculated by the more simple approach above. </p> <pre><code>from patientflow.viz.probability_distribution import plot_prob_dist\nfrom patientflow.viz.utils import format_prediction_time\ntitle = (\n    f'Probability distribution for number of beds needed for patients'\n    f'\\nwho will arrive after {format_prediction_time((12,0))} on {snapshot_dates[0]} and need a bed before 20:00.'\n    f'\\nTime to admission is estimated using an empirical survival curve'\n)\nplot_prob_dist(combined_dist, title,  \n    include_titles=True, truncate_at_beds=40)\n</code></pre> <p></p>"},{"location":"notebooks/3c_Predict_bed_counts_without_using_patient_snapshots/#using-the-empiricalincomingadmissionpredictor-class","title":"Using the <code>EmpiricalIncomingAdmissionPredictor</code> class","text":"<p>A custom class <code>EmpiricalIncomingAdmissionPredictor</code> has been created, for this purpose, that follows the same logic as the code snippet above. </p> <p>A survival curve is generated from the training data, and used determine the probability of admission before the end of the prediction window, for a patient who arrives at a particular moment in the window.</p> <p>To predict how many patients will arrive and need admission within a prediction window (e.g., the next 8 hours), the class breaks this window into smaller time segments based on the <code>yta_time_interval</code> parameter. For example, with 15-minute intervals, an 8-hour window becomes 32 segments. </p> <p>For each segment, the class calculates two key values: the expected patient arrival rate and the probability that patients arriving in that segment will be admitted by the end of the full window. These values are multiplied together to create a weighted mean for a Poisson distribution representing that segment.</p> <p>Finally, all 32 segment distributions are combined to produce an overall probability distribution showing the total number of beds likely needed during the prediction window.</p> <p>I demonstrate how you fit the <code>EmpiricalIncomingAdmissionPredictor</code> below. </p> <pre><code>from patientflow.predictors.incoming_admission_predictors import EmpiricalIncomingAdmissionPredictor\n\ntrain_visits_copy = train_visits.copy(deep=True)\n\nyta_model_empirical =  EmpiricalIncomingAdmissionPredictor(verbose=True)\nnum_days = (start_validation_set - start_training_set).days\n\n# the arrival_datetime column needs to be set as the index of the dataframe\nif 'arrival_datetime' in train_visits_copy.columns:\n    train_visits_copy.set_index('arrival_datetime', inplace=True)\n\nyta_model_empirical.fit(train_visits_copy, \n                        prediction_window=timedelta(hours=8), \n                        yta_time_interval=timedelta(minutes=15), \n                        prediction_times=prediction_times, \n                        num_days=num_days,\n                        start_time_col='arrival_datetime',\n                        end_time_col='admitted_to_ward_datetime')\n</code></pre> <pre><code>Calculating time-varying arrival rates for data provided, which spans 45 unique dates\nEmpiricalIncomingAdmissionPredictor trained for these times: [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)]\nusing prediction window of 8:00:00 after the time of prediction\nand time interval of 0:15:00 within the prediction window.\nThe error value for prediction will be 1e-07\nTo see the weights saved by this model, used the get_weights() method\nEmpiricalIncomingAdmissionPredictor has been fitted with survival curve containing 881 time points\n</code></pre> <pre>EmpiricalIncomingAdmissionPredictor(filters={}, verbose=True)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.EmpiricalIncomingAdmissionPredictoriNot fitted<pre>EmpiricalIncomingAdmissionPredictor(filters={}, verbose=True)</pre> <p>The survival curve that was calculated from the training set is saved with the object returned</p> <pre><code>yta_model_empirical.survival_df\n</code></pre> time_hours survival_probability event_probability 0 0.000000 1.000000 0.000000 1 1.283333 0.999548 0.000452 2 1.333333 0.999097 0.000903 3 1.350000 0.998645 0.001355 4 1.400000 0.998193 0.001807 ... ... ... ... 876 40.333333 0.001807 0.998193 877 40.650000 0.001355 0.998645 878 41.050000 0.000903 0.999097 879 42.666667 0.000452 0.999548 880 44.383333 0.000000 1.000000 <p>881 rows \u00d7 3 columns</p> <pre><code>arrival_rates_by_time_interval = yta_model_empirical.weights['unfiltered'][(12,0)]['arrival_rates']\nprint(\n    f'The calculated arrival rates for the first 10 discrete time intervals '\n    f'for the 12:00 prediction time are: {[round(v, 3) for v in arrival_rates_by_time_interval[0:10]]}')\n</code></pre> <pre><code>The calculated arrival rates for the first 10 discrete time intervals for the 12:00 prediction time are: [1.289, 1.067, 1.356, 1.2, 1.289, 1.356, 1.2, 1.178, 0.933, 0.889]\n</code></pre> <pre><code>prediction_context = {\n    'unfiltered': {\n        'prediction_time': tuple([12,0])\n    }\n}\nweighted_poisson_empirical = yta_model_empirical.predict(prediction_context)\n\n</code></pre> <pre><code>from patientflow.viz.probability_distribution import plot_prob_dist\nfrom patientflow.viz.utils import format_prediction_time\ntitle = (\n    f'Probability distribution for number of beds needed for patients'\n    f'\\nwho will arrive after {format_prediction_time((12,0))} and need a bed before 20:00.'\n    f'\\nTime to admission is estimated using an empirical survival curve'\n)\nplot_prob_dist(weighted_poisson_empirical['unfiltered'], title,  \n    include_titles=True, truncate_at_beds=40)\n</code></pre> <p></p> <p>It is also possible to generate predictions by specialty, by passing a dictionary comprised of the required subgroups (the key) and a nested dictionary (the value) specifying how to identify them, with a column name (the nested key) and the values to filter from that column. </p> <pre><code>from patientflow.predictors.incoming_admission_predictors import EmpiricalIncomingAdmissionPredictor\n\ntrain_visits_copy = train_visits.copy(deep=True)\nnum_days = (start_validation_set - start_training_set).days\nif 'arrival_datetime' in train_visits_copy.columns:\n    train_visits_copy.set_index('arrival_datetime', inplace=True)\n\nspecialty_filters = filters={\n    'medical': {'specialty': 'medical'},\n    'surgical': {'specialty': 'surgical'},\n    'haem/onc': {'specialty': 'haem/onc'},\n    'paediatric': {'specialty': 'paediatric'}\n    }\nyta_model_by_spec_empirical =  EmpiricalIncomingAdmissionPredictor(filters = specialty_filters, verbose=True)\n\nyta_model_by_spec_empirical.fit(train_visits_copy, \n                        prediction_window=timedelta(hours=8), \n                        yta_time_interval=timedelta(minutes=15), \n                        prediction_times=prediction_times, \n                        num_days=num_days,\n                        start_time_col='arrival_datetime',\n                        end_time_col='admitted_to_ward_datetime')\n</code></pre> <pre><code>Calculating time-varying arrival rates for data provided, which spans 45 unique dates\nCalculating time-varying arrival rates for data provided, which spans 45 unique dates\nCalculating time-varying arrival rates for data provided, which spans 45 unique dates\nCalculating time-varying arrival rates for data provided, which spans 45 unique dates\nEmpiricalIncomingAdmissionPredictor trained for these times: [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)]\nusing prediction window of 8:00:00 after the time of prediction\nand time interval of 0:15:00 within the prediction window.\nThe error value for prediction will be 1e-07\nTo see the weights saved by this model, used the get_weights() method\nEmpiricalIncomingAdmissionPredictor has been fitted with survival curve containing 881 time points\n</code></pre> <pre>EmpiricalIncomingAdmissionPredictor(filters={'haem/onc': {'specialty': 'haem/onc'},\n                                             'medical': {'specialty': 'medical'},\n                                             'paediatric': {'specialty': 'paediatric'},\n                                             'surgical': {'specialty': 'surgical'}},\n                                    verbose=True)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.EmpiricalIncomingAdmissionPredictoriNot fitted<pre>EmpiricalIncomingAdmissionPredictor(filters={'haem/onc': {'specialty': 'haem/onc'},\n                                             'medical': {'specialty': 'medical'},\n                                             'paediatric': {'specialty': 'paediatric'},\n                                             'surgical': {'specialty': 'surgical'}},\n                                    verbose=True)</pre> <pre><code>from patientflow.viz.probability_distribution import plot_prob_dist\nfrom patientflow.viz.utils import format_prediction_time\n\nfor specialty in train_visits.specialty.unique():\n    prediction_context = {\n        specialty: {\n            'prediction_time': tuple([12,0])\n        }\n}\n    weighted_poisson_empirical = yta_model_by_spec_empirical.predict(prediction_context)\n\n    title = (\n        f'Probability distribution for number of {specialty} beds needed for patients'\n        f'\\nwho will arrive after {format_prediction_time((12,0))} and need a bed before 20:00.'\n        f'\\nTime to admission is estimated using an empirical survival curve'\n    )\n    plot_prob_dist(weighted_poisson_empirical[specialty], title,  \n        include_titles=True, truncate_at_beds=20)\n</code></pre> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/3c_Predict_bed_counts_without_using_patient_snapshots/#train-a-weighted-poisson-model-using-an-aspirational-approach","title":"Train a weighted Poisson model using an aspirational approach","text":"<p>The model above has learned the rates of arrivals of patients who are later admitted within a prediction window from past data. </p> <p>A problem with this approach is that rates are learned from periods of poor performance. Currently, in England Emergency Departments have a target of processing all patients within four hours of their arrival time. However, EDs across the country have not hit targets since the end of the Covid pandemic.</p> <p>The poor performance is illustrated by the chart below, which shows how performance within Emergency Departments (also known as Accident &amp; Emergency Departments, or A&amp;E) has deteriorated over time. The chart is based on NHS England data on A&amp;E Attendances and Emergency Admissions, and was copied from the King's Fund website on 9 June 2025.</p> <p>Performance is worse for Type 1 A&amp;E attendances; Type 1 refers to patients attending what are considered major emergency departments in hospitals. </p> <pre><code>from IPython.display import Image\nImage(filename='img/thumbnail_KingsFund_AE_performance.png')\n</code></pre> <p></p> <p><code>patientflow</code> offers an aspirational weighted Poisson model, that will calculate each patient's probability of being admitted within the prediction window, if targets are met. Targets are set using the parameters set in config.yaml, as shown below. </p> <pre><code>from patientflow.load import load_config_file, set_file_paths, set_project_root\nproject_root = set_project_root()\n\n_, _, _, config_path = set_file_paths(project_root, data_folder_name = 'data-public', verbose = False)\nparams = load_config_file(config_path)\n\nx1, y1, x2, y2 = params[\"x1\"], params[\"y1\"], params[\"x2\"], params[\"y2\"]\n\nprint(f'The aspiration is that within {str(x1)} hours of arrival, {str(y1*100)}% of patients will have been admitted, and that witin {str(x2)} hours of arrival, {str(y2*100)}% of patients will have been admitted')\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\nThe aspiration is that within 4.0 hours of arrival, 76.0% of patients will have been admitted, and that witin 12.0 hours of arrival, 99.0% of patients will have been admitted\n</code></pre> <p>The aspiration can be plotted as a parameterised curve, as shown below. It is the equivalent of a survival curve that has been inverted. However, unless the empirical survival curve above, this curve is defined by parameters that can be changed according to the aspirational targets set. </p> <p>To change the targets, you can vary the values of x1, y1, x2 and y2. </p> <pre><code>from patientflow.viz.aspirational_curve import plot_curve\n\nfigsize = (6,3)\n\nplot_curve(\n    title = 'Aspirational curve reflecting a ' + str(int(x1)) + ' hour target for ' + str(int(y1*100)) + \\\n        '% of patients\\nand a '+ str(int(x2)) + ' hour target for ' + str(int(y2*100)) + '% of patients',\n    x1 = x1,\n    y1 = y1,\n    x2 = x2,\n    y2 = y2,\n    include_titles=True,\n    annotate_points=True,\n)\n\n</code></pre> <p></p> <p>Below I demonstrate the use of a Weighted Poisson predictor. </p> <p>Its <code>fit()</code> method will, for each prediction time:</p> <ul> <li>filter the dataframe if a filtering criteria is given (more detail below)</li> <li>calculate arrival rates for a series of discrete time intervals (where the duration of each time interval is specified as <code>yta_time_interval</code> minutes) within a 24 hour period; <code>yta_time_interval</code> must divide evenly into a 24 hour period (ie be a factor of 24* 60)</li> <li>return the arrival rates for the intervals between the prediction time and the end of the prediction window in a dictionary; if the data is unfiltered it will use a generic key of 'unfiltered'; if the data is filtered, it will use the filters as keys</li> </ul> <p>The <code>predict()</code> method will:</p> <ul> <li>retrieve the arrival rates saved for the prediction window</li> <li>for each discrete time interval, using the aspirational curve introduced above, and taking into account the time remaining before end of window, calculate a probability of admission in prediction window </li> <li>weight the arrival rates for each time interval by this probability </li> <li>generate a Poisson distribution for each time interval</li> <li>convolute the distributions to return a single distribution for admissions within the prediction window of patients yet-to-arrive</li> </ul> <pre><code>from patientflow.predictors.incoming_admission_predictors import ParametricIncomingAdmissionPredictor\n\ntrain_visits_copy = train_visits.copy(deep=True)\n\nyta_model_parametric =  ParametricIncomingAdmissionPredictor(verbose=True)\nnum_days = (start_validation_set - start_training_set).days\nif 'arrival_datetime' in train_visits_copy.columns:\n    train_visits_copy.set_index('arrival_datetime', inplace=True)\n\nyta_model_parametric.fit(train_visits_copy, \n              prediction_window=timedelta(hours=8), \n              yta_time_interval=timedelta(minutes=15), \n              prediction_times=prediction_times, \n              num_days=num_days)\n\n</code></pre> <pre><code>Calculating time-varying arrival rates for data provided, which spans 45 unique dates\nParametricIncomingAdmissionPredictor trained for these times: [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)]\nusing prediction window of 8:00:00 after the time of prediction\nand time interval of 0:15:00 within the prediction window.\nThe error value for prediction will be 1e-07\nTo see the weights saved by this model, used the get_weights() method\n</code></pre> <pre>ParametricIncomingAdmissionPredictor(filters={}, verbose=True)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ParametricIncomingAdmissionPredictoriNot fitted<pre>ParametricIncomingAdmissionPredictor(filters={}, verbose=True)</pre> <p>Below we view the results of the fit method for the 12:00 prediction time. </p> <pre><code>arrival_rates_by_time_interval = yta_model_parametric.weights['unfiltered'][(12,0)]['arrival_rates']\nprint(\n    f'The calculated arrival rates for the first 10 discrete time intervals '\n    f'for the 12:00 prediction time are: {[round(v, 3) for v in arrival_rates_by_time_interval[0:10]]}')\n</code></pre> <pre><code>The calculated arrival rates for the first 10 discrete time intervals for the 12:00 prediction time are: [1.289, 1.067, 1.356, 1.2, 1.289, 1.356, 1.2, 1.178, 0.933, 0.889]\n</code></pre> <p>To use the weighted poisson for prediction, a <code>prediction_context</code> argument specifies the required prediction time and filtering. The aspirations for time to admission can be changed at any point. Here, I'm going to set the target at 95% within 4 hours. </p> <pre><code>from patientflow.viz.probability_distribution import plot_prob_dist\nfrom patientflow.viz.utils import format_prediction_time\n\nprediction_context = {\n    'unfiltered': {\n        'prediction_time': tuple([12,0])\n    }\n}\n\naspirational_prediction = yta_model_parametric.predict(prediction_context, x1=x1, y1=y1, x2=x2, y2=y2)\n\n</code></pre> <p>The charts below compare the results of using this weighted predictor to generate a prediction for bed needed for patients yet-to-arrive, if the ED meets the 4-hour target for 95% of patients. The numbers are higher than the equivalent chart above. </p> <pre><code>title = (\n    f'Probability distribution for number of beds needed for patients '\n    f'who will arrive after {format_prediction_time((12,0))} on {snapshot_dates[0]} '\n    f'\\nand need a bed before 20:00. Time to admission estimated using an empirical survival curve'\n)\nplot_prob_dist(combined_dist, title,  \n    include_titles=True, truncate_at_beds=40)\n\ntitle = (\n    f'Probability distribution for number of beds needed for patients '\n    f'who will arrive after {format_prediction_time((12,0))} on {snapshot_dates[0]} '\n    f'\\nand need a bed before 20:00 '\n    f'if the ED is meeting the target of {int(x1)} hours for {y1*100}% of patients'\n)\nplot_prob_dist(aspirational_prediction['unfiltered'], title,  \n    include_titles=True,\n    truncate_at_beds=40)\n</code></pre> <p></p> <p></p>"},{"location":"notebooks/3c_Predict_bed_counts_without_using_patient_snapshots/#summary","title":"Summary","text":"<p>Here I have demonstrated the use of <code>patientflow</code> to generate bed counts for groups of patients for which patient-level data is not yet available. </p> <p>If you have count data on past visits that approximate to a statistical distribution, preparing a  model to predict a bed count distribution is simple to do with standard libraries like scipy. You don't need <code>patientflow</code> functions for that. </p> <p>However there might be cases where the historical data don't reflect the desired performance of the ED, as in the example shown here. In that case, the users of your predictions might be more interested in understanding demand if their ED were performing per their aspirations. <code>patientflow</code>  provides functions that enable you to produce such predictions. </p>"},{"location":"notebooks/3c_Predict_bed_counts_without_using_patient_snapshots/#postscript-how-to-evaluate-bed-counts-based-on-survival-curves","title":"Postscript - how to evaluate bed counts based on survival curves","text":"<p>The survival curve plot function can be used with multiple datasets. This may be useful to check the alignment of training set and test set survival curves. If the ED has become slower to process patients, this difference may show up in a difference between survival curves. We encountered this issue in our own work, and showed how to mitigate it using a sliding window approach for the survival curve in our Nature Digital Medicine paper. The problem does not show up below because these curves are based on synthetic data, but it might in your dataset. </p> <pre><code>from patientflow.viz.survival_curve import plot_admission_time_survival_curve\ntitle = 'Compare survival curves for train, valid and test sets'\nsurvival_df = plot_admission_time_survival_curve([train_visits, valid_visits, test_visits], \n                                                 labels=['train', 'valid', 'test'],\n                                   start_time_col=\"arrival_datetime\",\n                                   end_time_col=\"admitted_to_ward_datetime\",\n                                   title=title,\n                                   ylabel='Proportion of patients not yet admitted',\n                                   xlabel='Elapsed time since arrival',\n                                   return_df=False\n)\n</code></pre> <p></p> <p>The function below can be used to compare the predicted with the observed bed counts. This function will retrieve the observed counts and save them alongside their predicted distribution from the model.</p> <pre><code>from patientflow.aggregate import get_prob_dist_using_survival_curve\nfrom datetime import timedelta\nfrom patientflow.load import get_model_key\n\nprob_dist_dict_all = {}\ntest_set_dates = [dt for dt in snapshot_dates if dt &gt;= start_test_set]\n\nfor prediction_time in prediction_times:\n    model_key = get_model_key('yet_to_arrive', prediction_time)\n    prob_dist_dict_all[model_key]= get_prob_dist_using_survival_curve(\n        snapshot_dates=test_set_dates,\n        test_visits=test_visits,\n        category='unfiltered',\n        prediction_time=prediction_time,\n        prediction_window=timedelta(minutes=8*60),\n        start_time_col='arrival_datetime',\n        end_time_col='admitted_to_ward_datetime',\n        model=yta_model_empirical,\n        verbose=False,\n    )\n</code></pre> <p>The result can be plotted using the same functions. The model appears as a series of vertical lines because the EmpiricalIncomingAdmissionPredictor is trained only on a time of day so there is minimal variation in the predicted distributions. I have included it here as a placeholder, to show how modelling of yet-to-arrive patients using past data on time to admission could be done, and how it could be evaluated. You could modify the function to include a weekday/weekend variable, or replace it with a different approach based on moving averages (such as ARIMA).  </p> <pre><code>from patientflow.viz.epudd import plot_epudd\n\nplot_epudd(prediction_times,\n                 prob_dist_dict_all,\n                 model_name='yet_to_arrive',\n                 suptitle=\"EPUDD plots for yet-to-arrive patients for each prediction time\",\n                 plot_all_bounds=False)\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/","title":"3d. Predict bed count distributions for subgroups","text":"<p>It is often the case that pressures build up on certain areas of the hospital, or for subgroups of patients, due to random fluctuations. Sometimes one demographic group seems to be showing up more than usual, such as older males, putting pressure on male geriatric beds. </p> <p>In this notebook I show how <code>patientflow</code> can be used to create predictions for subgroups of patients. These groups might be  * specific clinical areas of the hospital (eg medical or paediatric beds) * subgroups defined by a demographic characteristic (eg sex) </p>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#predicting-which-subgroup-a-patient-will-belong-to","title":"Predicting which subgroup a patient will belong to","text":"<p>My focus initially is on subgroups defined by the clinical area patients are admitted to after ED; I refer to the clinical areas as specialties.</p> <p>I demonstrate the use of a <code>SequenceToOutcomePredictor</code> class, that can be used to predict each patient's probability of admission to a specialty if they are admitted. I load real patient data and show how the <code>SequenceToOutcomePredictor</code> is trained using sequences of consult requests made while patients are in the ED.</p> <p>The <code>SequenceToOutcomePredictor</code> approach could be used with other sequence data, such as sequences of locations or procedures, if you deem these likely to be associated with a patient being admitted to a clinical area. The key assumption of the sequence design is that the order is meaningful; for example, a surgical consult following a medical consult, or vice versa, is meaningful for the patient's likelihood of being admitted under surgery. </p> <p>If you don't have sequences for predicting sub-groups, you might have more simple data, such as a single reason code for each visit, entered on triage (eg heart problem, broken bone), that suggests which specialty a patient will end up in. I demonstrate a <code>ValueToOutcomePredictor</code> which can be used with such data. </p>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#combining-specialty-prediction-with-admission-prediction","title":"Combining specialty prediction with admission prediction","text":"<p>I then combine the specialty prediction model with the admission probability model (shown in previous notebooks) to calculate the joint probability that a patient will both be admitted and require a specific specialty. Formally, this derives P(admitted AND specialty X) = P(admitted) \u00d7 P(specialty X | admitted). This joint probability approach means we can generate specialty-specific bed count predictions. I demonstrate the joint probability for one group snapshot. </p> <p>I deliberately excluded consult types from the admissions model to ensure the two models use independent signals, avoiding potential overfitting when combining their predictions.</p>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#stratifying-by-observed-characteristics","title":"Stratifying by observed characteristics","text":"<p>Finally, I show a different type of subgroup analysis by stratifying patients by sex. Since sex is directly observed rather than predicted, I create separate bed count distributions for male and female patients.</p>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#load-real-patient-data","title":"Load real patient data","text":"<p>Following the approach taken in the previous notebook, I'll first load some real patient data. </p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>import pandas as pd\nfrom patientflow.load import set_file_paths, load_data, load_config_file\n\n# set project root\nfrom patientflow.load import set_project_root\nproject_root = set_project_root()\n\n# set file paths\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n        project_root, \n        data_folder_name='data-public', # change this to data-synthetic if you don't have the public dataset\n        verbose=False) \n\n# load the data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\ned_visits.snapshot_date = pd.to_datetime(ed_visits.snapshot_date).dt.date\n\n# load the config file to set the dates for the training, validation and test sets\nparams = load_config_file(config_path)\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n\n# apply the temporal splits\nfrom datetime import date   \nfrom patientflow.prepare import create_temporal_splits\n\n# create the temporal splits\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\", # states which column contains the date to use when making the splits \n    visit_col=\"visit_number\", # states which column contains the visit number to use when making the splits \n\n)\n\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\nSplit sizes: [62071, 10415, 29134]\n</code></pre>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#train-a-model-to-predict-probability-of-admission-to-each-specialty","title":"Train a model to predict probability of admission to each specialty","text":""},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#predict-specialty-of-admission-using-sequences-of-consults","title":"Predict specialty of admission using sequences of consults","text":"<p>In this example, the data used as input comprise sequences of consults issued while the patient was in the ED. The <code>consultation_sequence</code> column shows the ordered sequence of consultation requests up to the moment of the snapshot, and the <code>final_sequence</code> shows the ordered sequence at the end of the ED visit. The <code>specialty</code> column records which specialty the patient was admitted to.  </p> <pre><code>ed_visits[(ed_visits.is_admitted) &amp; (ed_visits.prediction_time == (9,30))][['consultation_sequence', 'final_sequence', 'specialty']].head(10)\n\n</code></pre> consultation_sequence final_sequence specialty snapshot_id 183349 ['acute', 'discharge'] ['acute', 'discharge'] medical 132235 ['paeds'] ['paeds'] paediatric 114978 [] ['acute'] medical 199212 [] [] paediatric 202378 [] ['surgical'] medical 200273 [] ['acute'] medical 171735 [] [] NaN 140899 ['haem_onc'] ['haem_onc'] haem/onc 122882 ['acute'] ['acute', 'medical', 'elderly'] medical 159335 [] ['surgical'] surgical <p>Below I demonstrate training the model. A rooted decision-tree is used to calculate:</p> <ul> <li>the probability of an ordered sequence of consultations observed at the snapshot (which could be none) resulting in each final sequence at the end of the ED visit</li> <li>the probability of each of those final sequences being associated with admission to each specialty (the outcome)</li> </ul> <p>This sequence predictor could be applied to other types of data, such as sequences of ED locations, or sequences of clinical teams visited. Therefore, the <code>SequenceToOutcomePredictor</code> arguments have been given generic names: </p> <ul> <li><code>input_var</code> - the interim node in the decision tree, observed at the snapshot</li> <li><code>grouping_var</code> - the terminal node in the decision tree, observed in this example at the end of the ED visit</li> <li><code>outcome_var</code> - the final outcome to be predicted</li> </ul> <p>The <code>apply_special_category_filtering</code> argument provides for the handling of certain categories in a specific way. For example, under 18 patients might always be assumed to be visiting paediatric specialties. I demonstrate this in a later notebook.</p> <pre><code>from patientflow.predictors.sequence_to_outcome_predictor import SequenceToOutcomePredictor\n\nspec_model = SequenceToOutcomePredictor(\n    input_var=\"consultation_sequence\",\n    grouping_var=\"final_sequence\",\n    outcome_var=\"specialty\",\n    apply_special_category_filtering=False,\n)\n\nspec_model.fit(train_visits)\n</code></pre> <pre>SequenceToOutcomePredictor(\n    input_var='consultation_sequence',\n    grouping_var='final_sequence',\n    outcome_var='specialty',\n    apply_special_category_filtering=False,\n    admit_col='is_admitted'\n)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SequenceToOutcomePredictoriNot fitted<pre>SequenceToOutcomePredictor(\n    input_var='consultation_sequence',\n    grouping_var='final_sequence',\n    outcome_var='specialty',\n    apply_special_category_filtering=False,\n    admit_col='is_admitted'\n)</pre> <p>From the weights that are returned, we can view the probability of being admitted to each specialty for a patient who has no consultation sequence at the time of prediction</p> <pre><code>print(\n    f'Probability of being admitted to each specialty at the end of the visit if no consultation result has been made by the time of the snapshot:\\n'\n    f'{dict((k, round(v, 3)) for k, v in spec_model.weights[()].items())}'\n)\n</code></pre> <pre><code>Probability of being admitted to each specialty at the end of the visit if no consultation result has been made by the time of the snapshot:\n{'medical': 0.611, 'surgical': 0.248, 'paediatric': 0.061, 'haem/onc': 0.08}\n</code></pre> <p>Similar we can view the probability of being admitted to each specialty after a consultation request to acute medicine</p> <pre><code>print(\n    f'\\nProbability of being admitted to each specialty if one consultation request to acute medicine has taken place by the time of the snapshot:\\n'\n    f'{dict((k, round(v, 3)) for k, v in spec_model.weights[(\"acute\",)].items())}'\n)\n</code></pre> <pre><code>Probability of being admitted to each specialty if one consultation request to acute medicine has taken place by the time of the snapshot:\n{'medical': 0.95, 'surgical': 0.017, 'paediatric': 0.002, 'haem/onc': 0.032}\n</code></pre> <p>The intermediate mapping of consultation_sequence to final_sequence can be accessed from the trained model like this. The first row shows the probability of a null sequence (ie no consults yet) ending in any of the final_sequence options. </p> <pre><code>spec_model.input_to_grouping_probs.iloc[:, :10]\n</code></pre> final_sequence () (acute,) (acute, acute) (acute, acute, acute) (acute, acute, discharge) (acute, acute, icu) (acute, acute, medical) (acute, acute, medical, surgical) (acute, acute, mental_health) (acute, acute, palliative) consultation_sequence () 0.015452 0.433579 0.014760 0.000231 0.000231 0.000 0.000692 0.000231 0.000461 0.000 (acute,) 0.000000 0.820442 0.007182 0.000000 0.000000 0.000 0.000000 0.000000 0.000000 0.000 (acute, acute) 0.000000 0.000000 0.850000 0.000000 0.025000 0.025 0.075000 0.000000 0.000000 0.025 (acute, acute, medical) 0.000000 0.000000 0.000000 0.000000 0.000000 0.000 1.000000 0.000000 0.000000 0.000 (acute, allied) 0.000000 0.000000 0.000000 0.000000 0.000000 0.000 0.000000 0.000000 0.000000 0.000 ... ... ... ... ... ... ... ... ... ... ... (surgical, paeds) 0.000000 0.000000 0.000000 0.000000 0.000000 0.000 0.000000 0.000000 0.000000 0.000 (surgical, surgical) 0.000000 0.000000 0.000000 0.000000 0.000000 0.000 0.000000 0.000000 0.000000 0.000 (surgical, surgical, acute) 0.000000 0.000000 0.000000 0.000000 0.000000 0.000 0.000000 0.000000 0.000000 0.000 (surgical, surgical, icu) 0.000000 0.000000 0.000000 0.000000 0.000000 0.000 0.000000 0.000000 0.000000 0.000 (surgical, surgical, medical) 0.000000 0.000000 0.000000 0.000000 0.000000 0.000 0.000000 0.000000 0.000000 0.000 <p>123 rows \u00d7 10 columns</p>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#using-the-sequencetooutcomepredictor","title":"Using the <code>SequenceToOutcomePredictor</code>","text":"<p>Below I apply the predict function to get each patient's probability of being admitted to the four specialties.</p> <pre><code>test_visits['consultation_sequence'].head().apply(spec_model.predict)\n</code></pre> <pre><code>snapshot_id\n192732    {'medical': 0.1318359375, 'surgical': 0.826171...\n209659    {'medical': 0.09243697478991597, 'surgical': 0...\n207377    {'medical': 0.8333333333333333, 'surgical': 0....\n216864    {'medical': 0.6107109665427509, 'surgical': 0....\n207071    {'medical': 0.6107109665427509, 'surgical': 0....\nName: consultation_sequence, dtype: object\n</code></pre> <p>A dictionary is returned for each patient, with probabilites summed to 1. To get each patient's probability of admission to one specialty indexed in the dictionary, we can select that key as shown below:</p> <pre><code>print(\"Probability of admission to medical specialty for the first five patients:\")\ntest_visits['consultation_sequence'].head().apply(spec_model.predict).apply(lambda x: x['medical']).values\n\n</code></pre> <pre><code>Probability of admission to medical specialty for the first five patients:\n\n\n\n\n\narray([0.13183594, 0.09243697, 0.83333333, 0.61071097, 0.61071097])\n</code></pre>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#predicting-specialty-of-admission-using-a-simpler-input","title":"Predicting specialty of admission using a simpler input","text":"<p>If your data for predicting specialty has a simpler structure, say in the form of a string variable containing reasons for presentation at ED, <code>patientflow</code> offers a simpler model. </p> <p>To illustrate this, I create a temporary column by truncating the sequence data to the first item in the list only.  </p> <pre><code>ed_visits['temp_consultation_sequence'] = ed_visits['consultation_sequence'].apply(\n    lambda x: x[0].strip(\"'\") if isinstance(x, (list, tuple)) and len(x) &gt; 0 else None\n)\n\ned_visits['temp_final_sequence'] = ed_visits['final_sequence'].apply(\n    lambda x: x[0].strip(\"'\") if isinstance(x, (list, tuple)) and len(x) &gt; 0 else None\n)\n\ned_visits[(ed_visits.is_admitted) &amp; (ed_visits.prediction_time == (9,30))][['temp_consultation_sequence', 'temp_final_sequence', 'specialty']].head(10)\n\n</code></pre> temp_consultation_sequence temp_final_sequence specialty snapshot_id 183349 acute acute medical 132235 paeds paeds paediatric 114978 None acute medical 199212 None None paediatric 202378 None surgical medical 200273 None acute medical 171735 None None NaN 140899 haem_onc haem_onc haem/onc 122882 acute acute medical 159335 None surgical surgical <pre><code># create the temporal splits\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\", # states which column contains the date to use when making the splits \n    visit_col=\"visit_number\", # states which column contains the visit number to use when making the splits \n\n)\n\nfrom patientflow.predictors.value_to_outcome_predictor import ValueToOutcomePredictor\n\nspec_model_simple = ValueToOutcomePredictor(\n    input_var=\"temp_consultation_sequence\",\n    grouping_var=\"temp_final_sequence\",\n    outcome_var=\"specialty\",\n    apply_special_category_filtering=False,\n)\n\nspec_model_simple.fit(train_visits)\n</code></pre> <pre><code>Split sizes: [62071, 10415, 29134]\n</code></pre> <pre>ValueToOutcomePredictor(\n    input_var='temp_consultation_sequence',\n    grouping_var='temp_final_sequence',\n    outcome_var='specialty',\n    apply_special_category_filtering=False,\n    admit_col='is_admitted'\n)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ValueToOutcomePredictoriNot fitted<pre>ValueToOutcomePredictor(\n    input_var='temp_consultation_sequence',\n    grouping_var='temp_final_sequence',\n    outcome_var='specialty',\n    apply_special_category_filtering=False,\n    admit_col='is_admitted'\n)</pre> <p>The weights, which map the input variable to specialty, and the intermediate mappings from input to grouping variables can be viewed in the same way as before. The weights are returned with a key of an empty string rather than a None value for probabilities with a Null value in the input variable. </p> <pre><code>print(\n    f'Probability of being admitted to each specialty at the end of the visit if the value of the input is \"medical\" at the time of the snapshot:\\n'\n    f'{dict((k, round(v, 3)) for k, v in spec_model_simple.weights['medical'].items())}'\n)\n\nprint(\n    f'\\nProbability of being admitted to each specialty at the end of the visit if no input has been recorded by the time of the snapshot:\\n'\n    f'{dict((k, round(v, 3)) for k, v in spec_model_simple.weights[''].items())}'\n)\n</code></pre> <pre><code>Probability of being admitted to each specialty at the end of the visit if the value of the input is \"medical\" at the time of the snapshot:\n{'haem/onc': 0.019, 'medical': 0.91, 'paediatric': 0.01, 'surgical': 0.061}\n\nProbability of being admitted to each specialty at the end of the visit if no input has been recorded by the time of the snapshot:\n{'haem/onc': 0.063, 'medical': 0.652, 'paediatric': 0.057, 'surgical': 0.228}\n</code></pre> <pre><code>spec_model_simple.input_to_grouping_probs\n</code></pre> temp_final_sequence acute allied ambulatory discharge elderly haem_onc icu medical mental_health neuro obs_gyn other paeds palliative surgical probability_of_input_value temp_consultation_sequence 0.015452 0.545664 0.000231 0.00738 0.003690 0.001614 0.044742 0.007611 0.026983 0.007841 0.037131 0.030673 0.000461 0.04405 0.000231 0.226245 0.503717 acute 0.000000 1.000000 0.000000 0.00000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.230367 allied 0.000000 0.000000 1.000000 0.00000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.000116 ambulatory 0.000000 0.000000 0.000000 1.00000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.017658 discharge 0.000000 0.000000 0.000000 0.00000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.001394 elderly 0.000000 0.000000 0.000000 0.00000 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.001046 haem_onc 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.041473 icu 0.000000 0.027778 0.000000 0.00000 0.000000 0.000000 0.000000 0.972222 0.000000 0.000000 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.004182 medical 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.000000 0.000000 0.989130 0.000000 0.000000 0.000000 0.000000 0.00000 0.000000 0.010870 0.010688 mental_health 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.008713 neuro 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.002556 obs_gyn 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.00000 0.000000 0.000000 0.026022 other 0.000000 0.000000 0.000000 0.00000 0.333333 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.666667 0.00000 0.000000 0.000000 0.000349 paeds 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.00000 0.000000 0.000000 0.027765 palliative 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.00000 1.000000 0.000000 0.000116 surgical 0.000000 0.000000 0.000000 0.00000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.00000 0.000000 1.000000 0.123838"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#combining-specialty-prediction-with-admission-prediction_1","title":"Combining specialty prediction with admission prediction","text":"<p>I now have a model I can use to predict a patient's probability of admission to each of the four specialties: medical, surgical, haematology/oncology or paediatric, if admitted. I'll use this these probabilities, with each patient's probability of admission after ED, to generate predicted bed count distributions for each specialty.</p> <p>For that I'll also need an admission prediction model, which is set up below. </p> <pre><code>from patientflow.train.classifiers import train_classifier\nfrom patientflow.load import get_model_key\n\nprediction_times = [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)] \nordinal_mappings = {\n    \"age_group\": [\n        \"0-17\",\n        \"18-24\",\n        \"25-34\",\n        \"35-44\",\n        \"45-54\",\n        \"55-64\",\n        \"65-74\",\n        \"75-115\",\n    ],\n    \"latest_obs_manchester_triage_acuity\": [\n        \"Blue\",\n        \"Green\",\n        \"Yellow\",\n        \"Orange\",\n        \"Red\",\n    ],\n    \"latest_obs_objective_pain_score\": [\n        \"Nil\",\n        \"Mild\",\n        \"Moderate\",\n        \"Severe_Very Severe\",\n    ],\n    \"latest_obs_level_of_consciousness\": [\n        \"A\", #alert\n        \"C\", #confused\n        \"V\", #voice - responds to voice stimulus\n        \"P\", #pain - responds to pain stimulus\n        \"U\" #unconscious - no response to pain or voice stimulus\n    ]    }\nexclude_from_training_data = [ 'snapshot_date', 'prediction_time','visit_number', 'consultation_sequence', 'specialty', 'final_sequence', ]\n\n\nadmission_model = train_classifier(\n    train_visits=train_visits,\n    valid_visits=valid_visits,\n    test_visits=test_visits,\n    grid={\"n_estimators\": [20, 30, 40]},\n    exclude_from_training_data=exclude_from_training_data,\n    ordinal_mappings=ordinal_mappings,\n    prediction_time=(9,30),\n    visit_col=\"visit_number\",\n    calibrate_probabilities=True,\n    calibration_method=\"isotonic\",\n    use_balanced_training=True,\n)\n\n</code></pre>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#prepare-group-snapshots","title":"Prepare group snapshots","text":"<p>The preparation of group snapshots below is similar to previous notebooks.</p> <pre><code>from patientflow.prepare import prepare_patient_snapshots, prepare_group_snapshot_dict\n\nprob_dist_dict = {}\nfirst_group_snapshot_key = test_visits.snapshot_date.min()\n\nprediction_snapshots = test_visits[(test_visits.snapshot_date == first_group_snapshot_key) &amp; (test_visits.prediction_time == (9,30))]\n\n# format patient snapshots for input into the admissions model\nX_test, y_test = prepare_patient_snapshots(\n    df=prediction_snapshots, \n    prediction_time=(9,30), \n    single_snapshot_per_visit=False,\n    exclude_columns=exclude_from_training_data, \n    visit_col='visit_number'\n)\n\n# prepare group snapshots dict to indicate which patients comprise the group we want to predict for\ngroup_snapshots_dict = prepare_group_snapshot_dict(\n    prediction_snapshots\n)\n\n</code></pre> <p>Below I demonstrate predictions for each specialty in turn. </p> <pre><code>from patientflow.viz.probability_distribution import plot_prob_dist\nfrom patientflow.aggregate import get_prob_dist\nfrom patientflow.viz.utils import format_prediction_time\n\nfor specialty in ['medical', 'surgical', 'haem/onc', 'paediatric']:\n\n    prob_admission_to_specialty = prediction_snapshots['consultation_sequence'].apply(spec_model.predict).apply(lambda x: x[specialty])\n# get probability distribution for this time of day\n    prob_dist_dict = get_prob_dist(\n            group_snapshots_dict, X_test, y_test, admission_model, \n            weights=prob_admission_to_specialty\n        )\n\n    title = (\n        f'Probability distribution for number of {specialty} beds needed by the '\n        f'{len(prediction_snapshots)} patients\\n'\n        f'in the ED at {format_prediction_time((9,30))} '\n        f'on {first_group_snapshot_key} '\n    )\n    plot_prob_dist(prob_dist_dict[first_group_snapshot_key]['agg_predicted'], title, \n        include_titles=True, bar_colour='orange', truncate_at_beds=20)\n\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p>To compare these with the predictions overall (not by specialty) uses the same function without weighting the probability for each specialty. </p> <pre><code># get probability distribution for this time of day\nprob_dist_dict = get_prob_dist(\n        group_snapshots_dict, X_test, y_test, admission_model \n        # commenting out the weights argument\n        # weights=prob_admission_to_specialty\n    )\n\ntitle = (\n    f'Probability distribution for total number of beds needed by the '\n    f'{len(prediction_snapshots)} patients\\n'\n    f'in the ED at {format_prediction_time((9,30))} '\n    f'on {first_group_snapshot_key} '\n)\nplot_prob_dist(prob_dist_dict[first_group_snapshot_key]['agg_predicted'], title, \n    include_titles=True, truncate_at_beds=20)\n</code></pre> <p></p>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#stratifying-by-observed-characteristics_1","title":"Stratifying by observed characteristics","text":"<p>Disaggregation of predictions using unchanging attributes like sex is very straightforward. Here I show breakdowns by sex. </p> <pre><code>for sex in ['M', 'F']:\n\n    prediction_snapshots = test_visits[(test_visits.snapshot_date == first_group_snapshot_key) &amp; \n                                       (test_visits.sex == sex) &amp;\n                                       (test_visits.prediction_time == (9,30))]\n\n    group_snapshots_dict = prepare_group_snapshot_dict(\n        prediction_snapshots\n    )\n\n    prob_dist_dict = get_prob_dist(\n            group_snapshots_dict, X_test, y_test, admission_model\n        )\n\n    title = (\n        f'Probability distribution for number of beds needed by the '\n        f'{len(prediction_snapshots)} {\"male\" if sex == \"M\" else \"female\"} patients\\n'\n        f'in the ED at {format_prediction_time((9,30))} '\n        f'on {first_group_snapshot_key} '\n    )\n    plot_prob_dist(prob_dist_dict[first_group_snapshot_key]['agg_predicted'], title, \n        include_titles=True, truncate_at_beds=20)\n</code></pre> <p></p> <p></p>"},{"location":"notebooks/3d_Predict_bed_counts_for_subgroups/#summary","title":"Summary","text":"<p>In this notebook I have presented examples of how to disaggregate predicted bed counts according to sub-categories of interest. </p> <p>Some subgroups are straightforward to generate at inference time, if they are based on attributes of the patient that do not change during a visit, such as sex, gender or ethnicity. </p> <p>Demand on clinical areas can be predicted dynamically, using a real-time signal collected about a patient that is related to their likely clinical area. In this case I used consult requests issued while patients were in the ED.</p> <p>In the following notebooks, I demonstrate a fully worked up example of how the functions provided in <code>patientflow</code> are in use at University College London Hospital to predict emergency demand. </p>"},{"location":"notebooks/4a_Specify_emergency_demand_model/","title":"4a. Specify requirements for emergency demand prediction","text":"<p>In previous notebooks I have introduced all of the building blocks provided in <code>patientflow</code> to make predictions of bed counts within a prediction window. In the next notebook I show how we used these building blocks in our application at University College London Hospital (UCLH) to predict emergency demand for beds, by specialty, over the next 8 hours. The predictions are aspirational; they assume that ED four-hour targets are met. </p> <p>First, a brief recap on the requirements of our models. </p>"},{"location":"notebooks/4a_Specify_emergency_demand_model/#recap-on-the-requirements-of-our-users","title":"Recap on the requirements of our users","text":"<p>In the first notebook I introduced bed managers and their work. Through working closely with them over five years, we have developed an understanding their requirements for emergency demand predictions. </p> <ul> <li>They want information at specific times of day to coincide with their flow huddles, with an 8-hour view of incoming demand at these times</li> <li>The 8-hour view needs to take account of patients who are yet to arrive, who should be admitted within that time</li> <li>The predictions should be based on the assumption that the ED is meeting its 4-hour targets for performance (for example, the target that 80% of patients are to be admitted or discharged within 4 hours of arriving at the front door)</li> <li>The predictions should exclude patients who already have decisions to admit under a specialty; these should be counted as known demand for that specialty</li> <li>The predictions should be provided as numbers of bed needed (rather than predictions of whether any individual patient will be admitted) and should be grouped by speciality of admission, since a specialty breakdown helps to inform targeted actions</li> <li>The predictions should be sent by email, with a spreadsheet attached</li> <li>The output should communicate a low threshold number of beds needed with 90% probability, and with 70% probability</li> </ul> <p>For more information about these requirements, and how we tailored the UCLH application to meet them, check out this talk by me, with Craig Wood, bed manager at UCLH, at the Health and Care Analytics Conference 2023:</p> <p> </p>"},{"location":"notebooks/4a_Specify_emergency_demand_model/#the-current-output-from-the-uclh-application","title":"The current output from the UCLH application","text":"<p>The annotated figure below shows the output that our application currently generates at UCLH</p> <pre><code>from IPython.display import Image\nImage(filename='img/thumbnail_UCLH_application.jpg')\n</code></pre> <p></p> <p>The modelling output</p> <ul> <li>Differentiates between patients with a decision to admit (columns B:C) and those without (columns D:G)</li> <li>Provides separate predictions for patients in the ED and SDEC now (columns D:E), and those yet to arrive (columns F:G)</li> <li>Breaks down the output by speciality (rows 4:7); this is currently done at a high level - medical, surgical, haematology/oncology and paediatric - but a future version will provide predictions at detailed specialty level</li> <li>Shows the minimum number of beds needed with 90% probability (columns D and F) and with 70% probability (columns E and G)</li> </ul> <p>The next notebook will show the implementation in code.</p>"},{"location":"notebooks/4b_Predict_emergency_demand/","title":"4b. Predict emergency demand","text":"<p>This notebook demonstrates the full implementation in code. I show how we used these building blocks in our application at University College London Hospital (UCLH) to predict emergency demand for beds, by specialty, over the next 8 hours. The predictions are aspirational; they assume that ED four-hour targets are met. </p>"},{"location":"notebooks/4b_Predict_emergency_demand/#set-up-the-notebook-environment","title":"Set up the notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/4b_Predict_emergency_demand/#set-file-paths-and-load-data","title":"Set file paths and load data","text":"<p>I'm going to use real patient data from UCLH to demonstrate the implementation. </p> <p>You can request the datasets that are used here on Zenodo. Alternatively you can use the synthetic data that has been created from the distributions of real patient data. If you don't have the public data, change the argument in the cell below from <code>data_folder_name='data-public'</code> to <code>data_folder_name='data-synthetic'</code>.</p> <pre><code>from patientflow.load import set_file_paths\n\n# set file paths\ndata_folder_name = 'data-public'\ndata_file_path = project_root / data_folder_name\n\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n    project_root, \n    data_folder_name=data_folder_name,\n    config_file = 'config.yaml', verbose=False)\n</code></pre> <pre><code>import pandas as pd\nfrom patientflow.load import load_data\n\n# load ED snapshots data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\ned_visits.snapshot_date = pd.to_datetime(ed_visits.snapshot_date).dt.date\n\n# load data on inpatient arrivals\ninpatient_arrivals = inpatient_arrivals = load_data(data_file_path, \n                    file_name='inpatient_arrivals.csv')\ninpatient_arrivals['arrival_datetime'] = pd.to_datetime(inpatient_arrivals['arrival_datetime'], utc = True)\n\n\n</code></pre>"},{"location":"notebooks/4b_Predict_emergency_demand/#set-modelling-parameters","title":"Set modelling parameters","text":"<p>The parameters are used in training or inference. They are set in config.json in the root of the repository and loaded by <code>load_config_file()</code></p> <pre><code># load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n\nprint(f'\\nTraining set starts {start_training_set} and ends on {start_validation_set - pd.Timedelta(days=1)} inclusive')\nprint(f'Validation set starts on {start_validation_set} and ends on {start_test_set - pd.Timedelta(days=1)} inclusive' )\nprint(f'Test set starts on {start_test_set} and ends on {end_test_set- pd.Timedelta(days=1)} inclusive' )\n</code></pre> <pre><code>Training set starts 2031-03-01 and ends on 2031-08-31 inclusive\nValidation set starts on 2031-09-01 and ends on 2031-09-30 inclusive\nTest set starts on 2031-10-01 and ends on 2031-12-31 inclusive\n</code></pre>"},{"location":"notebooks/4b_Predict_emergency_demand/#prediction-times","title":"Prediction times","text":"<p>The data has been prepared as a series of snapshots of each patient's data at five moments during the day. These five moments are the times when the bed managers wish to receive predictive models of emergency demand. If a patient arrives in the ED at 4 am, and leaves at 11 am, they will be represented in the 06:00 and 09:30 prediction times. Everything known about a patient is included up until that moment is included in that snapshot.</p> <p>The predition times are presented as tuples in the form (hour, minute). </p> <p>From the output below we can see that there are most snapshots at 15:30 - since afternoons are typically the busiest times in the ED - and least at 06:00. </p> <pre><code>print(\"\\nTimes of day at which predictions will be made\")\nprint(ed_visits.prediction_time.unique())\n</code></pre> <pre><code>Times of day at which predictions will be made\n[(22, 0) (15, 30) (6, 0) (12, 0) (9, 30)]\n</code></pre> <pre><code>print(\"\\nNumber of observations for each prediction time\")\nprint(ed_visits.prediction_time.value_counts())\n</code></pre> <pre><code>Number of observations for each prediction time\nprediction_time\n(15, 30)    35310\n(12, 0)     29942\n(22, 0)     28457\n(9, 30)     17642\n(6, 0)      11984\nName: count, dtype: int64\n</code></pre>"},{"location":"notebooks/4b_Predict_emergency_demand/#apply-temporal-splits","title":"Apply temporal splits","text":"<pre><code>from patientflow.prepare import create_temporal_splits\n\ntrain_visits_df, valid_visits_df, test_visits_df = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\",\n)\n\ntrain_inpatient_arrivals_df, _, _ = create_temporal_splits(\n    inpatient_arrivals,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"arrival_datetime\",\n)\n</code></pre> <pre><code>Split sizes: [62071, 10415, 29134]\nSplit sizes: [7716, 1285, 3898]\n</code></pre>"},{"location":"notebooks/4b_Predict_emergency_demand/#train-models-to-predict-bed-count-distributions-for-patients-currently-in-the-ed","title":"Train models to predict bed count distributions for patients currently in the ED","text":"<pre><code>\nfrom patientflow.train.classifiers import train_classifier\nfrom patientflow.load import get_model_key\n\ngrid = {\"n_estimators\": [30], \"subsample\": [0.7], \"colsample_bytree\": [0.7]} # simple grid for expediency\n\nexclude_from_training_data = [ 'snapshot_date', 'prediction_time','visit_number', 'consultation_sequence', 'specialty', 'final_sequence', ]\n\nordinal_mappings = {\n    \"latest_acvpu\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n    \"latest_obs_manchester_triage_acuity\": [\n        \"Blue\",\n        \"Green\",\n        \"Yellow\",\n        \"Orange\",\n        \"Red\",\n    ],\n    \"latest_obs_objective_pain_score\": [\n        \"Nil\",\n        \"Mild\",\n        \"Moderate\",\n        \"Severe\\\\E\\\\Very Severe\",\n    ],\n    \"latest_obs_level_of_consciousness\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n}\n\n# create a dictionary to store the trained models\nadmissions_models = {}\nmodel_name = 'admissions'\n\n# Loop through each prediction time\nfor prediction_time in ed_visits.prediction_time.unique():\n    print(f\"Training model for {prediction_time}\")\n    model = train_classifier(\n        train_visits=train_visits_df,\n        valid_visits=valid_visits_df,\n        test_visits=test_visits_df,\n        grid=grid,\n        exclude_from_training_data=exclude_from_training_data,\n        ordinal_mappings=ordinal_mappings,\n        prediction_time=prediction_time,\n        visit_col=\"visit_number\",\n        calibrate_probabilities=True,\n        calibration_method=\"isotonic\",\n        use_balanced_training=True,\n    )\n    model_key = get_model_key(model_name, prediction_time)\n\n    admissions_models[model_key] = model\n</code></pre> <pre><code>Training model for (22, 0)\nTraining model for (15, 30)\nTraining model for (6, 0)\nTraining model for (12, 0)\nTraining model for (9, 30)\n</code></pre>"},{"location":"notebooks/4b_Predict_emergency_demand/#train-specialty-model","title":"Train specialty model","text":"<p>The <code>SequencePredictor</code> is used to train the probability of each patient being admitted to a specialty, if admitted. As shown in the previous notebook, ordered sequences of consult requests (also known as referrals to service) are used to train this model. </p> <p>Here the <code>apply_special_category_filtering</code> parameter has been set to True. If set to True, there will be customised treatment for particular categories of patient; for example, at UCLH, it is assumed that all patients under 18 on arrival will be admitted to a paediatric specialty. I will demonstrate this further down.</p> <pre><code>from patientflow.predictors.sequence_to_outcome_predictor import SequenceToOutcomePredictor\n\nspec_model = SequenceToOutcomePredictor(\n    input_var=\"consultation_sequence\",\n    grouping_var=\"final_sequence\",\n    outcome_var=\"specialty\",\n    apply_special_category_filtering=False,\n)\n\nspec_model = spec_model.fit(train_visits_df)\n</code></pre>"},{"location":"notebooks/4b_Predict_emergency_demand/#make-predictions-for-the-group-of-patients-currently-in-the-ed","title":"Make predictions for the group of patients currently in the ED","text":"<p>We now have models trained that we can use to create predicted probability distributions. Here is an example of how we could use those model to generate predictions at a particular moment. </p> <p>To illustrate, I'll pick a random prediction date and time from the test set. </p> <pre><code>from patientflow.viz.utils import format_prediction_time\nfrom patientflow.prepare import prepare_patient_snapshots, prepare_group_snapshot_dict\n\n# Set seed\nimport numpy as np\nnp.random.seed(42)\n\n# Randomly pick a prediction moment to do inference on\nrandom_row = test_visits_df.sample(n=1)\nrandom_prediction_time = random_row.prediction_time.values[0]\nrandom_prediction_date = random_row.snapshot_date.values[0]\n\nprediction_snapshots = ed_visits[(ed_visits.prediction_time == random_prediction_time) &amp; \\\n            (ed_visits.snapshot_date == random_prediction_date)]\n\nprint(f'Number of adult patients in the ED at {format_prediction_time(random_prediction_time)} on {random_prediction_date}:',\n      f'{len(prediction_snapshots[prediction_snapshots.age_group != \"0-17\"])}')\n\nprint(f'Number of patients under the age of 18 in the ED at {format_prediction_time(random_prediction_time)} on {random_prediction_date}:',\n      f'{len(prediction_snapshots[prediction_snapshots.age_group == \"0-17\"])}')\n\n# format patient snapshots for input into the admissions model\nX_test, y_test = prepare_patient_snapshots(\n    df=prediction_snapshots, \n    prediction_time=random_prediction_time, \n    single_snapshot_per_visit=False,\n    exclude_columns=exclude_from_training_data, \n    visit_col='visit_number'\n)\n\n# retrieve the admissions model for the prediction time\nadmission_model = admissions_models[get_model_key(model_name, random_prediction_time)]\n\n# prepare group snapshots dict to indicate which patients comprise the group we want to predict for\ngroup_snapshots_dict = prepare_group_snapshot_dict(\n    prediction_snapshots\n    )\n</code></pre> <pre><code>Number of adult patients in the ED at 22:00 on 2031-10-09: 69\nNumber of patients under the age of 18 in the ED at 22:00 on 2031-10-09: 10\n</code></pre> <p>The predicted bed counts for patients in the ED take three probabilities into account for each patient snapshots: </p> <ul> <li>probability of being admitted after the ED has ended</li> <li>probability of being admitted to each specialty, if admitted</li> <li>probability of being admitted within the prediction window, taking into account how much time has elapsed since the patient arrived, and the stated ED targets</li> </ul> <p>To set the ED targets, we use the parameters set in the config file. The config file also specifies the length of the prediction, and (for use later) the length of the discrete intervals used to calculate arrival rates for yet-to-arrive patients.</p> <pre><code># set the ED targets\nx1, y1, x2, y2 = params[\"x1\"], params[\"y1\"], params[\"x2\"], params[\"y2\"]\nprediction_window = params[\"prediction_window\"]\nyta_time_interval = params[\"yta_time_interval\"]\n</code></pre> <p>In the cell below I first calculate <code>prob_admission_in_window</code>, the probability of being admitted within the prediction window, given the elapsed time since each patient arrived, and the specified ED targets. </p> <p>Then, for each patient snapshot, I calculate 'prob_admission_to_specialty`, the probability of admission to specialty if admitted, by applying the specialty model trained earlier. </p> <p>These two probabilities for each patient snapshot are multiplied and the result passed to <code>get_prob_dist</code> function as weights. </p> <pre><code>import datetime\nlen(group_snapshots_dict[datetime.date(2031, 10, 9)])\n</code></pre> <pre><code>79\n</code></pre> <pre><code>from patientflow.viz.probability_distribution import plot_prob_dist\nfrom patientflow.aggregate import get_prob_dist\nfrom patientflow.calculate.admission_in_prediction_window import calculate_probability\nfrom datetime import timedelta\n# Calculate probability of admission within prediction window\nprob_admission_in_window = prediction_snapshots.apply(\n    lambda row: calculate_probability(\n        elapsed_los = timedelta(seconds=row[\"elapsed_los\"]), \n        prediction_window = timedelta(minutes=prediction_window),\n        x1 = x1,\n        y1 = y1,\n        x2 = x2,\n        y2 = y2\n    ),\n    axis=1,\n)\n\n# generate and plot predicted bed count distributions for each specialty\nfor specialty in ['medical', 'surgical', 'haem/onc', 'paediatric']:\n\n    prob_admission_to_specialty = prediction_snapshots['consultation_sequence'].apply(spec_model.predict).apply(lambda x: x[specialty])\n\n    # get probability distribution weighted by probability of admission to specialty and probability of admission within prediction window\n    prob_dist_dict = get_prob_dist(\n            group_snapshots_dict, X_test, y_test, admission_model, \n            weights=prob_admission_to_specialty*prob_admission_in_window\n        )\n\n    title = (\n        f'Probability distribution for number of {specialty} beds needed by the '\n        f'{len(prediction_snapshots)} patients\\n'\n        f'in the ED at {format_prediction_time(random_prediction_time)} '\n        f'on {random_prediction_date} '\n    )\n    plot_prob_dist(prob_dist_dict[random_prediction_date]['agg_predicted'], title, \n        include_titles=True, truncate_at_beds=20,\n        probability_levels=[0.7,0.9],\n        show_probability_thresholds=True, bar_colour='orange')\n</code></pre> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/4b_Predict_emergency_demand/#train-model-to-predict-bed-count-distributions-for-patients-yet-to-arrive","title":"Train model to predict bed count distributions for patients yet to arrive","text":"<p>As we are predicting by clinical area we will want the predicted bed counts for patients yet to arrive to be calculated for each separately. A dictionary, here called <code>specialty_filters</code>, is used to tell the <code>ParametricIncomingAdmissionPredictor</code> which column contains the outcome we want to split by. </p> <pre><code>from patientflow.predictors.incoming_admission_predictors import ParametricIncomingAdmissionPredictor\nfrom datetime import timedelta\n\n# set the ED targets\nx1, y1, x2, y2 = params[\"x1\"], params[\"y1\"], params[\"x2\"], params[\"y2\"]\nprediction_window = timedelta(minutes=params[\"prediction_window\"])\nyta_time_interval = timedelta(minutes=params[\"yta_time_interval\"])\n\nspecialty_filters = filters={\n    'medical': {'specialty': 'medical'},\n    'surgical': {'specialty': 'surgical'},\n    'haem/onc': {'specialty': 'haem/onc'},\n    'paediatric': {'specialty': 'paediatric'}\n    }\nyta_model_by_spec =  ParametricIncomingAdmissionPredictor(filters = specialty_filters, verbose=False)\n\n# calculate the number of days between the start of the training and validation sets; \n# this is used to calculate daily arrival rates\nnum_days = (start_validation_set - start_training_set).days\n\nif 'arrival_datetime' in train_inpatient_arrivals_df.columns:\n    train_inpatient_arrivals_df.set_index('arrival_datetime', inplace=True)\n\nyta_model_by_spec =yta_model_by_spec.fit(train_inpatient_arrivals_df, \n              prediction_window=prediction_window, \n              yta_time_interval=yta_time_interval, \n              prediction_times=ed_visits.prediction_time.unique(), \n              num_days=num_days )\n\n</code></pre>"},{"location":"notebooks/4b_Predict_emergency_demand/#make-predictions-for-patients-yet-to-arrive-to-the-ed-who-will-need-admission","title":"Make predictions for patients yet-to-arrive to the ED who will need admission","text":"<p>The trained yet-to-arrive model generates the same distribution for each prediction time, irrespective of day of week, for each specialty. Passing the randomly chosen prediction time, for each specialty, will return the required distributions.</p> <pre><code>for specialty in [ 'medical', 'surgical', 'haem/onc', 'paediatric']:\n\n    prediction_context = {\n        specialty: {\n            'prediction_time': random_prediction_time\n        }\n    }\n\n    weighted_poisson_prediction = yta_model_by_spec.predict(prediction_context, x1=x1, y1=y1, x2=x2, y2=y2)\n    title = (\n    f'Probability distribution for number of {specialty} beds needed for patients '\n    f'who will arrive after {format_prediction_time((random_prediction_time))} on {random_prediction_date} '\n    f'\\nand need a bed within 8 hours '\n    f'if the ED is meeting the target of {int(x1)} hours for {y1*100}% of patients'\n)\n    plot_prob_dist(weighted_poisson_prediction[specialty], title,  \n        include_titles=True,\n        truncate_at_beds=20,\n        probability_levels=[0.7,0.9],\n        show_probability_thresholds=True,\n        figsize=(6, 4) , bar_colour='green')\n</code></pre> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/4b_Predict_emergency_demand/#combining-the-predictions-into-one-function-for-use-in-real-time-inference","title":"Combining the predictions into one function for use in real-time inference","text":"<p>The function shown below is the one used for real-time prediction at UCLH. It returns the probability distributions with the lower threshold set at the requested level using the <code>cdf_cut_points</code> argument.</p> <p>The function returns a dictionary, which is inserted into cells in a spreadsheet (via a process not shown here, as this is not done by the <code>patientflow</code> repo) to create the output requested by the users.</p> <pre><code>from patientflow.predict.emergency_demand import create_predictions\n\nmodels = (admission_model, spec_model, yta_model_by_spec)\n\n# convert elapsed_los to timedelta to ensure correct calculation of probability of admission within prediction window\nprediction_snapshots['elapsed_los'] = pd.to_timedelta(prediction_snapshots['elapsed_los'], unit='s')\n\ncreate_predictions(\n    models = models,\n    prediction_time = random_prediction_time,\n    prediction_snapshots = prediction_snapshots,\n    specialties = ['medical', 'surgical', 'haem/onc', 'paediatric'],\n    prediction_window = timedelta(hours=8),\n    cdf_cut_points =  [0.7, 0.9], \n    x1 = x1,\n    y1 = y1,\n    x2 = x2, \n    y2 = y2)\n</code></pre> <pre><code>{'medical': {'in_ed': [6, 4], 'yet_to_arrive': [1, 0]},\n 'surgical': {'in_ed': [2, 1], 'yet_to_arrive': [0, 0]},\n 'haem/onc': {'in_ed': [2, 1], 'yet_to_arrive': [0, 0]},\n 'paediatric': {'in_ed': [0, 0], 'yet_to_arrive': [0, 0]}}\n</code></pre>"},{"location":"notebooks/4b_Predict_emergency_demand/#summary","title":"Summary","text":"<p>Here I have shown how <code>patientflow</code> is used at UCLH to generate predictions of emergency demand for beds in the next 8 hours. There are two elements to the predictions. </p> <ul> <li>predictions for patients already in the ED</li> <li>predictions for patients yet-to-arrive to the ED, who will need admission in the next 8 hours</li> </ul> <p>Both sets of predictions assume specified ED targets are met. </p> <p>In the next notebook, I show how to evaluate the predictions against the numbers of patients actually admitted. </p>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/","title":"4c. Evaluate predictions of emergency demand","text":"<p>The previous notebook demonstrated the full implementation in code of training models for use at UCLH using the functions provided in <code>patientflow</code>. I demonstrated how we create predictions for a single snapshot. </p> <p>This notebooks show evaluate the predicted distributions against observed numbers, for the whole test set. I will evaluate the predictions by specialty using the approaches covered in a previous notebook.</p> <ul> <li>Histograms of observed versus expected values</li> <li>Adjusted QQ plots</li> </ul> <p>As the predictions for yet-to-arrive patients are aspirational, these cannot be directed evaluated against observed numbers of admissions in the prediction window. In reality, due to poor ED performance, few may have been admitted within the window. Similarly for the group of patients in the ED, we calculate the predicted number of beds needed within the prediction window, but the observed numbers will not reflect the targets.</p> <p>We can, however, evaluate the predictions in a slightly different way. </p> <ul> <li>For the patients in ED, we can compare the predicted bed counts needed for each specialty against observed numbers admitted to each specialty from among patients comprising each group snapshot in the test set period, without taking into account how long it takes each patient to be admitted.</li> <li>For the yet-to-arrive patients, we can compare the predicted with the observed arrival rates within the prediction window.</li> </ul>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#loading-data-and-parameters","title":"Loading data and parameters","text":""},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#set-up-the-notebook-environment","title":"Set up the notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#set-file-paths-and-load-data","title":"Set file paths and load data","text":"<p>I'm going to use real patient data from UCLH to demonstrate the implementation. </p> <p>As noted previously, you can request the datasets that are used here on Zenodo. Alternatively you can use the synthetic data that has been created from the distributions of real patient data. If you don't have the public data, change the argument in the cell below from <code>data_folder_name='data-public'</code> to <code>data_folder_name='data-synthetic'</code>.</p> <pre><code>from patientflow.load import set_file_paths\n\n# set file paths\ndata_folder_name = 'data-public'\ndata_file_path = project_root / data_folder_name\n\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n    project_root, \n    data_folder_name=data_folder_name,\n    config_file = 'config.yaml', verbose=False)\n</code></pre> <pre><code>import pandas as pd\nfrom patientflow.load import load_data\n\n# load ED snapshots data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\ned_visits.snapshot_date = pd.to_datetime(ed_visits.snapshot_date).dt.date\n\n# load data on inpatient arrivals\ninpatient_arrivals = inpatient_arrivals = load_data(data_file_path, \n                    file_name='inpatient_arrivals.csv')\ninpatient_arrivals['arrival_datetime'] = pd.to_datetime(inpatient_arrivals['arrival_datetime'], utc = True)\n\n</code></pre>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#set-modelling-parameters","title":"Set modelling parameters","text":"<p>The parameters are used in training or inference. They are set in config.json in the root of the repository and loaded by <code>load_config_file()</code></p> <pre><code># load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n\n</code></pre>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#apply-temporal-splits","title":"Apply temporal splits","text":"<pre><code>from patientflow.prepare import create_temporal_splits\n\ntrain_visits_df, valid_visits_df, test_visits_df = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\",\n)\n\ntrain_inpatient_arrivals_df, _, test_inpatient_arrivals_df = create_temporal_splits(\n    inpatient_arrivals,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"arrival_datetime\",\n)\n</code></pre> <pre><code>Split sizes: [62071, 10415, 29134]\nSplit sizes: [7716, 1285, 3898]\n</code></pre>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#evaluating-models-that-predict-demand-for-patients-current-in-the-ed","title":"Evaluating models that predict demand for patients current in the ED","text":"<p>The demand predictions for patients current in the ED bring together the admissions and specialty models. First we train each model, with a separate admissions model for each prediction time, and a single model to predict specialty of admission, if admitted. </p>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#train-admissions-models","title":"Train admissions models","text":"<p>This process has already been shown in previous notebooks. This time I'll use a larger parameter grid, while still limiting the search space to a few hyperparameters for expediency.</p> <pre><code>\nfrom patientflow.train.classifiers import train_classifier\nfrom patientflow.load import get_model_key\n\ngrid = { # Current parameters\n    'n_estimators': [30, 40, 50],  # Number of trees\n    'subsample': [0.7, 0.8, 0.9],  # Sample ratio of training instances\n    'colsample_bytree': [0.7, 0.8, 0.9],  # Sample ratio of columns for each tree\n   } \n\nexclude_from_training_data = [ 'snapshot_date', 'prediction_time','visit_number', 'consultation_sequence', 'specialty', 'final_sequence', ]\n\nordinal_mappings = {\n    \"latest_acvpu\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n    \"latest_obs_manchester_triage_acuity\": [\n        \"Blue\",\n        \"Green\",\n        \"Yellow\",\n        \"Orange\",\n        \"Red\",\n    ],\n    \"latest_obs_objective_pain_score\": [\n        \"Nil\",\n        \"Mild\",\n        \"Moderate\",\n        \"Severe\\\\E\\\\Very Severe\",\n    ],\n    \"latest_obs_level_of_consciousness\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n}\n\n# create a dictionary to store the trained models\nadmissions_models = {}\nmodel_name = 'admissions'\n\n# Loop through each prediction time\nfor prediction_time in ed_visits.prediction_time.unique():\n    print(f\"Training model for {prediction_time}\")\n    model = train_classifier(\n        train_visits=train_visits_df,\n        valid_visits=valid_visits_df,\n        test_visits=test_visits_df,\n        grid=grid,\n        exclude_from_training_data=exclude_from_training_data,\n        ordinal_mappings=ordinal_mappings,\n        prediction_time=prediction_time,\n        visit_col=\"visit_number\",\n        calibrate_probabilities=True,\n        calibration_method=\"isotonic\",\n        use_balanced_training=True,\n    )\n    model_key = get_model_key(model_name, prediction_time)\n\n    admissions_models[model_key] = model\n</code></pre> <pre><code>Training model for (22, 0)\nTraining model for (15, 30)\nTraining model for (6, 0)\nTraining model for (12, 0)\nTraining model for (9, 30)\n</code></pre>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#train-specialty-model","title":"Train specialty model","text":"<pre><code>from patientflow.predictors.sequence_predictor import SequenceToOutcomePredictor\n\nspec_model = SequenceToOutcomePredictor(\n    input_var=\"consultation_sequence\",\n    grouping_var=\"final_sequence\",\n    outcome_var=\"specialty\",\n    apply_special_category_filtering=False,\n)\n\nspec_model = spec_model.fit(train_visits_df)\n</code></pre>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#generate-predicted-distributions-for-each-specialty-and-prediction-time-for-patients-in-ed","title":"Generate predicted distributions for each specialty and prediction time for patients in ED","text":"<p>As we are treating paediatric patients differently from adults, the function below includes logic to identify eligible snapshots when caclculating for paediatric versus adult subgroups. When evaluating the predictions for adult destinations (medical, surgical and haem/onc), patients under 18 will be excluded. When evaluating the predictions for paediatric patients, adults will be excluded.</p> <p>The code has been shown here to demonstrate how in the UCLH implementation, we combine the admissions and specialty models to create predictions using the compound probability of admission after the ED visit, and admission to a given specialty. There is optional parameter to use a baseline probability for admission to specialty, which will be discussed later. </p> <pre><code>spec_model\n</code></pre> <pre>SequenceToOutcomePredictor(\n    input_var='consultation_sequence',\n    grouping_var='final_sequence',\n    outcome_var='specialty',\n    apply_special_category_filtering=False,\n    admit_col='is_admitted'\n)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SequenceToOutcomePredictoriNot fitted<pre>SequenceToOutcomePredictor(\n    input_var='consultation_sequence',\n    grouping_var='final_sequence',\n    outcome_var='specialty',\n    apply_special_category_filtering=False,\n    admit_col='is_admitted'\n)</pre> <pre><code>from patientflow.prepare import prepare_patient_snapshots, prepare_group_snapshot_dict\nfrom patientflow.aggregate import get_prob_dist\nfrom patientflow.load import get_model_key\n\n\ndef get_specialty_probability_distributions(\n    test_visits_df,\n    spec_model,\n    admissions_models,\n    model_name,\n    exclude_from_training_data,\n    specialties=['medical', 'surgical', 'haem/onc', 'paediatric'],\n    baseline_prob_dict=None,\n):\n    \"\"\"\n    Calculate probability distributions for emergency department patients by specialty and prediction time.\n\n    Args:\n        test_visits_df: DataFrame containing test visit data\n        spec_model: Model for specialty predictions (SequencePredictor)\n        admissions_models: Dictionary of admission prediction models\n        model_name: Name of the model to use\n        specialties: List of specialties to consider\n        exclude_from_training_data: List of columns to exclude from training data\n        baseline_prob_dict: Optional dict of baseline probabilities to use instead of spec_model predictions\n\n    Returns:\n        Dictionary containing probability distributions for each specialty and prediction time\n    \"\"\"\n\n    # Get predictions of admission to specialty\n    if baseline_prob_dict is not None:\n        # Use baseline probabilities instead of model predictions\n        test_visits_df.loc[:, \"specialty_prob\"] = test_visits_df.apply(\n            lambda row: baseline_prob_dict,\n            axis=1\n        )\n    else:\n\n        # Function to determine the specialty probabilities\n        def determine_specialty(row):\n            return spec_model.predict(row[\"consultation_sequence\"])\n\n         # Use spec_model to get predictions\n        test_visits_df.loc[:, \"specialty_prob\"] = test_visits_df.apply(determine_specialty, axis=1)\n\n\n    # Initialize dictionary to store probability distributions\n    prob_dist_dict_all = {}\n\n    # Process each time of day\n    for _prediction_time in test_visits_df.prediction_time.unique():\n        prob_dist_dict_for_pats_in_ED = {}\n        print(\"\\nProcessing :\" + str(_prediction_time))\n        model_key = get_model_key(model_name, _prediction_time)\n\n        for specialty in specialties:\n            print(f\"Predicting bed counts for {specialty} specialty, for all snapshots in the test set\")\n\n\n            # Get probability of admission to specialty for eligible patients\n            prob_admission_to_specialty = test_visits_df[\"specialty_prob\"].apply(\n                lambda x: x[specialty]\n            )\n\n            # Prepare patient snapshots\n            X_test, y_test = prepare_patient_snapshots(\n                df=test_visits_df, \n                prediction_time=_prediction_time, \n                single_snapshot_per_visit=False,\n                exclude_columns=exclude_from_training_data, \n                visit_col='visit_number'\n            )\n\n            # Prepare group snapshots\n            group_snapshots_dict = prepare_group_snapshot_dict(\n                test_visits_df[test_visits_df.prediction_time == _prediction_time]\n            )\n\n            admitted_to_specialty = test_visits_df['specialty'] == specialty\n\n            # Get probability distribution for this time and specialty\n            prob_dist_dict_for_pats_in_ED[specialty] = get_prob_dist(\n                group_snapshots_dict, X_test, y_test, admissions_models[model_key], \n                weights=prob_admission_to_specialty,\n                category_filter=admitted_to_specialty, \n                normal_approx_threshold=30\n            )\n\n        prob_dist_dict_all[f'{model_key}'] = prob_dist_dict_for_pats_in_ED\n\n    return prob_dist_dict_all\n</code></pre> <pre><code>prob_dist_dict_all = get_specialty_probability_distributions(\n    test_visits_df,\n    spec_model,\n    admissions_models,\n    model_name,\n    exclude_from_training_data\n)\n</code></pre> <pre><code>Processing :(22, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(6, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(15, 30)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(9, 30)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(12, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n</code></pre>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#visualise-the-performance-of-emergency-demand-prediction-models-for-patients-in-the-ed","title":"Visualise the performance of emergency demand prediction models for patients in the ED","text":"<p>Below I use two approaches to evaluate the predicted distributions.  * Histograms of observed versus expected values * Adjusted QQ plots</p> <p>See a previous notebook for more on these approaches.</p> <pre><code>from patientflow.evaluate import calc_mae_mpe\nfrom patientflow.viz.observed_against_expected import plot_deltas\nspecialties=['medical', 'surgical', 'haem/onc', 'paediatric']\n\nfor specialty in specialties:\n\n    specialty_prob_dist = {time: dist_dict[specialty] for time, dist_dict in prob_dist_dict_all.items()}\n    results = calc_mae_mpe(specialty_prob_dist)\n    plot_deltas(results, \n                                   main_title=f\"Histograms of Observed - Expected Values for {specialty} specialty\",)\n\n</code></pre> <p></p> <p></p> <p></p> <p></p> <pre><code>from patientflow.viz.epudd import plot_epudd\nspecialties=['medical', 'surgical', 'haem/onc', 'paediatric']\n\nfor specialty in specialties:\n\n    specialty_prob_dist = {time: dist_dict[specialty] for time, dist_dict in prob_dist_dict_all.items()}\n\n    plot_epudd(ed_visits.prediction_time.unique(), \n            specialty_prob_dist,\n            model_name=\"admissions\",\n            suptitle=f\"EPUDD plots for {specialty} specialty\")\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p>In medical specialties (which have the highest numbers of admissions, accounting for significant majority) the model performance is similar to that seen when not sub-divided by specialty. (See a previous notebook for more on this.) The model underestimates beds needed for patients in the ED at 22:00 and overestimates at 12:00 and 15:30. </p> <p>The model is well calibrated for surgical specialties. </p> <p>For haematology/oncology the model under-predicts at most times of day. For paediatrics, the observed values track the model predictions very well at 06:00 and 09:30. The model is less well calibrated later in the day.  </p>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#comparing-with-a-baseline-prediction-by-specialty","title":"Comparing with a baseline prediction by specialty","text":"<p>The model predicting specialty of admission was trained on sequences of consults. A baseline would be to give each adult patient the same probability of admission to medical, surgical or haem/onc, based on past averages. To calculate past averages, I'll use the <code>inpatient_arrivals</code> since this includes all arrivals, with one row for each visits. (Note - the <code>ed_visits</code> dataset has multiple rows per visit; I could use this by creating a subset that included only admitted patients with their specialty, and dropping duplicate rows. )</p> <pre><code>baseline_probs = train_inpatient_arrivals_df['specialty'].value_counts(normalize=True).to_dict()\n\nprob_dist_dict_all_baseline = get_specialty_probability_distributions(\n    test_visits_df=test_visits_df,\n    spec_model=spec_model,      \n    admissions_models=admissions_models,\n    model_name=model_name,\n    exclude_from_training_data=exclude_from_training_data,\n    baseline_prob_dict=baseline_probs\n)\n</code></pre> <pre><code>Processing :(22, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(6, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(15, 30)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(9, 30)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(12, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n</code></pre> <p>The output below shows two plots per specialty -  the baseline model using average proportions admitted to each specialty (upper), and a model where specialty of admission is predicted using consult sequences (below). Particularly for specialties with small admission numbers (haem/onc and paediatric) there is an improvement; the extent of over-prediction is reduced. </p> <pre><code>from patientflow.viz.epudd import plot_epudd\n\nfor specialty in ['medical', 'surgical', 'haem/onc', 'paediatric']:\n\n    specialty_prob_dist_baseline = {time: dist_dict[specialty] for time, dist_dict in prob_dist_dict_all_baseline.items()}\n    specialty_prob_dist = {time: dist_dict[specialty] for time, dist_dict in prob_dist_dict_all.items()}\n\n    print(f'\\nEPUDD plots for {specialty} specialty: baseline vs sequence predictor')\n\n    plot_epudd(ed_visits.prediction_time.unique(), \n        specialty_prob_dist_baseline,\n        model_name=\"admissions\",\n        suptitle=f\"Evaluating Predictions for Unique Discrete Distributions (EPUDD) plots for {specialty} specialty using baseline probability\")\n\n    plot_epudd(ed_visits.prediction_time.unique(), \n        specialty_prob_dist,\n        model_name=\"admissions\",\n        suptitle=f\"Evaluating Predictions for Unique Discrete Distributions (EPUDD) plots for {specialty} specialty using sequence predictor\")\n</code></pre> <pre><code>EPUDD plots for medical specialty: baseline vs sequence predictor\n</code></pre> <p></p> <p></p> <pre><code>EPUDD plots for surgical specialty: baseline vs sequence predictor\n</code></pre> <p></p> <p></p> <pre><code>EPUDD plots for haem/onc specialty: baseline vs sequence predictor\n</code></pre> <p></p> <p></p> <pre><code>EPUDD plots for paediatric specialty: baseline vs sequence predictor\n</code></pre> <p></p> <p></p>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#evaluate-predictions-for-patients-yet-to-arrive-to-the-ed","title":"Evaluate predictions for patients yet-to-arrive to the ED","text":"<p>Predictions for patients yet-to-arrive are made up of two components:</p> <ul> <li>Arrival rates calculated from past data, prepared for a series of time intervals within a prediction window after the moment of prediction</li> <li>A probability of admission for any patient arriving within one of these time intervals being admitted within the prediction window. The probability of admission is generated using either an empirical survival curve, or an aspirational approach. </li> </ul> <p>We can evaluate these two components separately. </p>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#evaluating-arrival-rates","title":"Evaluating arrival rates","text":"<p>We can, however, compare the predictions based on arrival rates at the front door of ED, that were learned from the training set, against observed arrival rates at the front door during the test set. </p> <p>To illustrate, I start by plotting the cumulative arrivals of patients later admitted within a prediction window on one date. In the upper chart, the blue line shows the cumulative number of arrivals. The orange lines shows the cumulative mean arrival rate.</p> <p>The lower chart shows the delta between the two lines</p> <pre><code>from patientflow.viz.observed_against_expected import plot_arrival_delta_single_instance\nfrom datetime import timedelta\n\nplot_arrival_delta_single_instance(test_inpatient_arrivals_df, \n                        prediction_time=(22,0), \n                        snapshot_date=start_test_set, \n                        show_delta=True, \n                        prediction_window=timedelta(minutes=params[\"prediction_window\"]), \n                        yta_time_interval = timedelta(minutes=params[\"yta_time_interval\"]),\n                        fig_size=(9, 3)\n                        )\n\n\n# plt.show()\n</code></pre> <p></p> <p>The chart below shows multiple version of the delta for each date in the test set, for each prediction time, with the average delta shown in red. </p> <pre><code>from patientflow.viz.observed_against_expected import plot_arrival_deltas\nfrom datetime import timedelta\n\n\nstart_date = start_test_set\nend_date = end_test_set\nsnapshot_dates = []\n\ncurrent_date = start_date\nwhile current_date &lt; end_date:\n    snapshot_dates.append(current_date)\n    current_date += timedelta(days=1)\n\n        # Sort prediction times by converting to minutes since midnight\nprediction_times_sorted = sorted(\n    ed_visits.prediction_time.unique(),\n    key=lambda x: x[0] * 60 + x[1],  # Convert (hour, minute) to minutes since midnight\n)\n\nfor prediction_time in prediction_times_sorted:\n    plot_arrival_deltas(test_inpatient_arrivals_df, \n                         prediction_time, \n                         snapshot_dates, \n                        prediction_window=timedelta(minutes=params[\"prediction_window\"]), \n                        yta_time_interval = timedelta(minutes=params[\"yta_time_interval\"])\n                         )\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/4c_Evaluate_emergency_demand_predictions/#summary","title":"Summary","text":"<p>In this notebook I have shown how to evaluate predicted bed counts for the patients in ED, by specialty, and for the patients yet-to-arrive. Both approaches required adjustments for the fact that the predicted distributions are aspirational. </p> <p>These models are based on a relatively small dataset (nine months of training data, a one month validation set and a 3 month test set).  In the real-time application at UCLH, we use more training data, and we also have the benefit of some additional features which improve model performance. </p> <p>Nonetheless, the models perform well on the relatively small datasets made available here. </p>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/","title":"4d. Evaluate predictions with special categories","text":"<p>In the previous notebook I demonstrated how we evaluate the models used at UCLH. As a final step, I now show the same implementation in code, but including extra functionality to handle certain sub-groups differently from others. </p> <p>At UCLH, it is standard practice to admit paediatric patients (defined as patients under 18 on the day of arrival at the ED) to paediatric wards, and not to admit adult patients (18 or over) to paediatric wards. </p> <p>The two models that enable prediction by sub-groups (specialty of admission, and yet-to-arrive by specialty) offer parameters that allow you to specify that certain groups are handled differently. In the UCLH example, this means disregarding any consult requests for patients in the ED when predicting which specialty they will be admitted to, and counting all yet-to-arrive patients under 18 as paediatric admissions. </p> <p>Most of the code below is the same as in the previous notebook. I limit the narrative here to pointing out how the special sub-groups are handled. </p>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#set-up-the-notebook-environment","title":"Set up the notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#set-file-paths-and-load-data","title":"Set file paths and load data","text":"<p>I'm going to use real patient data from UCLH to demonstrate the implementation. </p> <p>As noted previously, you can request the datasets that are used here on Zenodo. Alternatively you can use the synthetic data that has been created from the distributions of real patient data. If you don't have the public data, change the argument in the cell below from <code>data_folder_name='data-public'</code> to <code>data_folder_name='data-synthetic'</code>.</p> <pre><code>from patientflow.load import set_file_paths\n\n# set file paths\ndata_folder_name = 'data-public'\ndata_file_path = project_root / data_folder_name\n\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n    project_root, \n    data_folder_name=data_folder_name,\n    config_file = 'config.yaml', verbose=False)\n</code></pre> <pre><code>import pandas as pd\nfrom patientflow.load import load_data\n\n# load ED snapshots data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\ned_visits.snapshot_date = pd.to_datetime(ed_visits.snapshot_date).dt.date\n\n# load data on inpatient arrivals\ninpatient_arrivals = inpatient_arrivals = load_data(data_file_path, \n                    file_name='inpatient_arrivals.csv')\ninpatient_arrivals['arrival_datetime'] = pd.to_datetime(inpatient_arrivals['arrival_datetime'], utc = True)\n\n</code></pre>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#set-modelling-parameters","title":"Set modelling parameters","text":"<p>The parameters are used in training or inference. They are set in config.json in the root of the repository and loaded by <code>load_config_file()</code></p> <pre><code># load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n\n</code></pre>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#apply-temporal-splits","title":"Apply temporal splits","text":"<pre><code>from patientflow.prepare import create_temporal_splits\n\ntrain_visits_df, valid_visits_df, test_visits_df = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\",\n)\n\ntrain_inpatient_arrivals_df, _, test_inpatient_arrivals_df = create_temporal_splits(\n    inpatient_arrivals,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"arrival_datetime\",\n)\n</code></pre> <pre><code>Split sizes: [62071, 10415, 29134]\nSplit sizes: [7716, 1285, 3898]\n</code></pre>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#train-models-to-predict-bed-count-distributions-for-patients-currently-in-the-ed","title":"Train models to predict bed count distributions for patients currently in the ED","text":"<p>This time I'll use a larger parameter grid, while still limiting the search space to a few hyperparameters for expediency.</p> <pre><code>\nfrom patientflow.train.classifiers import train_classifier\nfrom patientflow.load import get_model_key\n\ngrid = { # Current parameters\n    'n_estimators': [30, 40, 50],  # Number of trees\n    'subsample': [0.7, 0.8, 0.9],  # Sample ratio of training instances\n    'colsample_bytree': [0.7, 0.8, 0.9],  # Sample ratio of columns for each tree\n   } \n\nexclude_from_training_data = [ 'snapshot_date', 'prediction_time','visit_number', 'consultation_sequence', 'specialty', 'final_sequence', ]\n\nordinal_mappings = {\n    \"latest_acvpu\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n    \"latest_obs_manchester_triage_acuity\": [\n        \"Blue\",\n        \"Green\",\n        \"Yellow\",\n        \"Orange\",\n        \"Red\",\n    ],\n    \"latest_obs_objective_pain_score\": [\n        \"Nil\",\n        \"Mild\",\n        \"Moderate\",\n        \"Severe\\\\E\\\\Very Severe\",\n    ],\n    \"latest_obs_level_of_consciousness\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n}\n\n# create a dictionary to store the trained models\nadmissions_models = {}\nmodel_name = 'admissions'\n\n# Loop through each prediction time\nfor prediction_time in ed_visits.prediction_time.unique():\n    print(f\"Training model for {prediction_time}\")\n    model = train_classifier(\n        train_visits=train_visits_df,\n        valid_visits=valid_visits_df,\n        test_visits=test_visits_df,\n        grid=grid,\n        exclude_from_training_data=exclude_from_training_data,\n        ordinal_mappings=ordinal_mappings,\n        prediction_time=prediction_time,\n        visit_col=\"visit_number\",\n        calibrate_probabilities=True,\n        calibration_method=\"isotonic\",\n        use_balanced_training=True,\n    )\n    model_key = get_model_key(model_name, prediction_time)\n\n    admissions_models[model_key] = model\n</code></pre> <pre><code>Training model for (22, 0)\nTraining model for (15, 30)\nTraining model for (6, 0)\nTraining model for (12, 0)\nTraining model for (9, 30)\n</code></pre>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#train-specialty-model","title":"Train specialty model","text":"<p>Here, when training the model predicting specialty of admission, the <code>apply_special_category_filtering</code> parameter has been set to True, so it will be assumed that all patients under 18 on arrival will be admitted to a paediatric specialty. </p> <pre><code>from patientflow.predictors.sequence_to_outcome_predictor import SequenceToOutcomePredictor\n\nspec_model = SequenceToOutcomePredictor(\n    input_var=\"consultation_sequence\",\n    grouping_var=\"final_sequence\",\n    outcome_var=\"specialty\",\n    apply_special_category_filtering=True,\n)\n\nspec_model = spec_model.fit(train_visits_df)\n\nspec_model\n</code></pre> <pre>SequenceToOutcomePredictor(\n    input_var='consultation_sequence',\n    grouping_var='final_sequence',\n    outcome_var='specialty',\n    apply_special_category_filtering=True,\n    admit_col='is_admitted'\n)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SequenceToOutcomePredictoriNot fitted<pre>SequenceToOutcomePredictor(\n    input_var='consultation_sequence',\n    grouping_var='final_sequence',\n    outcome_var='specialty',\n    apply_special_category_filtering=True,\n    admit_col='is_admitted'\n)</pre> <p>Under the hood, the <code>SequenceToOutcomePredictor</code> will call a <code>create_special_category_objects()</code> function that returns rules for how to handle each subgroup. The implementation here is primarily designed to handle pediatric patients (under 18) as a special category. A <code>SpecialCategoryParams</code> class generates a dictionary mapping specialties to flags (1.0 for pediatric, 0.0 for others) and functions to identify pediatric patients based on age data. It provides methods to handle both age formats (age_on_arrival or age_group). </p> <p>The <code>SequenceToOutcomePredictor</code> applies these rules during both training and prediction, ensuring consistent handling of special categories across the entire prediction pipeline</p> <p>The <code>SpecialCategoryParams</code> class is designed to be picklable, which is necessary for saving the specialty predictor model to disk.</p> <p>The output from <code>create_special_category_objects</code> is shown below. Note that the output is specific to the UCLH implementation. See below for notes about how to change this for your implementation. </p> <pre><code>from patientflow.prepare import create_special_category_objects\ncreate_special_category_objects(train_visits_df.columns)\n</code></pre> <pre><code>{'special_category_func': &lt;bound method SpecialCategoryParams.special_category_func of &lt;patientflow.prepare.SpecialCategoryParams object at 0x12fcba2c0&gt;&gt;,\n 'special_category_dict': {'medical': 0.0,\n  'surgical': 0.0,\n  'haem/onc': 0.0,\n  'paediatric': 1.0},\n 'special_func_map': {'paediatric': &lt;bound method SpecialCategoryParams.special_category_func of &lt;patientflow.prepare.SpecialCategoryParams object at 0x12fcba2c0&gt;&gt;,\n  'default': &lt;bound method SpecialCategoryParams.opposite_special_category_func of &lt;patientflow.prepare.SpecialCategoryParams object at 0x12fcba2c0&gt;&gt;}}\n</code></pre>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#train-models-for-yet-to-arrive-patients","title":"Train models for yet-to-arrive patients","text":"<p>Predictions for patients who are yet-to-arrive models are based on arrival rates learned from past data. See  3c_Predict_bed_counts_without_using_patient_snapshots.md for more information. When making predictions by specialty, arrival rates are learned for each specialty separately. </p> <p>The <code>create_yta_filters()</code> function generates a dictionary of filters for the <code>ParametricIncomingAdmissionPredictor</code> to enable separate prediction models for each specialty. It uses the same special category configuration (as defined in <code>create_special_category_objects</code>) to create two types of filters:</p> <ul> <li>For pediatric patients: {\"is_child\": True}</li> <li>For other specialties: {\"specialty\": specialty_name, \"is_child\": False}</li> </ul> <p>This allows the predictor to  * Train separate models for each specialty * Handle sub-groups differently * Apply appropriate filtering during both training and prediction</p> <pre><code>from patientflow.predictors.incoming_admission_predictors import ParametricIncomingAdmissionPredictor\nfrom patientflow.prepare import create_yta_filters\nfrom datetime import timedelta\n\nx1, y1, x2, y2 = params[\"x1\"], params[\"y1\"], params[\"x2\"], params[\"y2\"]\n\nspecialty_filters = create_yta_filters(ed_visits)\nyta_model_by_spec =  ParametricIncomingAdmissionPredictor(filters = specialty_filters, verbose=False)\n\n# calculate the number of days between the start of the training and validation sets; used for working out daily arrival rates\nnum_days = (start_validation_set - start_training_set).days\n\nif 'arrival_datetime' in train_inpatient_arrivals_df.columns:\n    train_inpatient_arrivals_df.set_index('arrival_datetime', inplace=True)\n\nyta_model_by_spec =yta_model_by_spec.fit(train_inpatient_arrivals_df, \n              prediction_window=timedelta(hours=params[\"prediction_window\"]), \n              yta_time_interval=timedelta(minutes=params[\"yta_time_interval\"]), \n              prediction_times=ed_visits.prediction_time.unique(), \n              num_days=num_days )\n</code></pre>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#saving-of-special-category-information","title":"Saving of special category information","text":"<p>The <code>ParametricIncomingAdmissionPredictor</code> class uses the special category objects during initialisation to create static filters that map specialties to their configurations (e.g., {'is_child': True} for pediatric cases), but does not need them in the predict method. The filters are saved with the instance. </p> <pre><code>yta_model_by_spec.filters\n</code></pre> <pre><code>{'medical': {'specialty': 'medical', 'is_child': False},\n 'surgical': {'specialty': 'surgical', 'is_child': False},\n 'haem/onc': {'specialty': 'haem/onc', 'is_child': False},\n 'paediatric': {'is_child': True}}\n</code></pre> <p>In contrast, the <code>SequenceToOutcomePredictor</code> save the special parameters as a function, which is used by the predict method to filter and categorise patients based on their characteristics.</p> <pre><code>spec_model.special_params\n</code></pre> <pre><code>{'special_category_func': &lt;bound method SpecialCategoryParams.special_category_func of &lt;patientflow.prepare.SpecialCategoryParams object at 0x12fcba3f0&gt;&gt;,\n 'special_category_dict': {'medical': 0.0,\n  'surgical': 0.0,\n  'haem/onc': 0.0,\n  'paediatric': 1.0},\n 'special_func_map': {'paediatric': &lt;bound method SpecialCategoryParams.special_category_func of &lt;patientflow.prepare.SpecialCategoryParams object at 0x12fcba3f0&gt;&gt;,\n  'default': &lt;bound method SpecialCategoryParams.opposite_special_category_func of &lt;patientflow.prepare.SpecialCategoryParams object at 0x12fcba3f0&gt;&gt;}}\n</code></pre>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#changes-required-in-your-implementation","title":"Changes required in your implementation","text":"<p>Listed below are the functions that relate to this special handling. </p> <ol> <li>SpecialCategoryParams Class (<code>src/patientflow/prepare.py</code>):</li> <li>Specialty names and flags in <code>special_category_dict</code></li> <li>Age detection logic in <code>special_category_func</code></li> <li> <p>Category mapping in <code>special_func_map</code></p> </li> <li> <p>SequenceToOutcomePredictor Class (<code>src/patientflow/predictors/sequence_to_outcome_predictor.py</code>):</p> </li> <li>Uses <code>create_special_category_objects</code> in <code>_preprocess_data</code></li> <li>Filters data based on special categories</li> <li> <p>Handles specialty predictions differently for special categories</p> </li> <li> <p>ValueToOutcomePredictor Class (<code>src/patientflow/predictors/value_to_outcome_predictor.py</code>):</p> </li> <li>Similar to SequenceToOutcomePredictor, uses special category filtering</li> <li> <p>Applies the same filtering logic in <code>_preprocess_data</code></p> </li> <li> <p>create_yta_filters Function (<code>src/patientflow/prepare.py</code>):</p> </li> <li>Creates specialty filters based on special category parameters</li> <li> <p>Generates filter configurations for each specialty</p> </li> <li> <p>get_specialty_probs Function (<code>src/patientflow/predict/emergency_demand.py</code>):</p> </li> <li>Uses special category functions to determine specialty probabilities</li> <li> <p>Applies different probability distributions for special categories</p> </li> <li> <p>create_predictions Function (<code>src/patientflow/predict/emergency_demand.py</code>):</p> </li> <li>Validates that requested specialties match special category dictionary</li> <li>Uses special function map for filtering predictions</li> <li> <p>Applies different prediction logic for special categories</p> </li> <li> <p>WeightedPoissonPredictor Class (<code>src/patientflow/predictors/weighted_poisson_predictor.py</code>):</p> </li> <li>Uses specialty filters for predictions</li> <li> <p>Handles different prediction logic for special categories</p> </li> <li> <p>Tests (<code>tests/test_create_predictions.py</code>):</p> </li> <li>Test cases for special category handling</li> <li>Validation of special category predictions</li> </ol> <p>To modify your implementation for different specialty names and rules, you would need to:</p> <ol> <li>Create a new class that inherits from <code>SpecialCategoryParams</code> with your custom logic</li> <li>Update all the specialty names and flags in the special category dictionary</li> <li>Modify the detection functions for your special categories</li> <li>Update the filter configurations in <code>create_yta_filters</code></li> <li>Ensure all test cases are updated to reflect your new specialty structure</li> <li>Update any documentation or examples that reference the specialty names</li> </ol>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#generate-predicted-distributions-for-each-specialty-and-prediction-time-for-patients-in-ed","title":"Generate predicted distributions for each specialty and prediction time for patients in ED","text":"<p>Now that the models have been trained with the special parameters, we proceed with generating and evaluating predictions. The approach below uses a similar function to the <code>get_specialty_probability_distributions</code> function shown in the previous notebook, with some additional logic to identify sub-groups that need special processing. </p> <p>The function </p> <ul> <li>retrieves the special parameters than were saved with the specialty predictor</li> <li>ensures that only eligible patient snapshots are included in the predictions for each specialty. A temporary version of the test set, called <code>test_df_eligible</code> is created for each iteration through the various specialties using only the eligible visits </li> </ul> <p>Why is this necessary? Imagine an ED that currently has 75 adult patients and 25 children. Tje maximum number of beds that could be needed in the paediatric specialties is 25 and the maximum number of beds that could be needed in the adult specialties is 75. Without filtering a probabilty distribution for 100 beds would be produced. The logic below means that adult patients are excluded from the predicted distribution for the paediatric specialty, and children from the predicted distributions for the adult specialty. </p> <pre><code>from patientflow.prepare import prepare_patient_snapshots, prepare_group_snapshot_dict\nfrom patientflow.aggregate import get_prob_dist\nfrom patientflow.predict.emergency_demand import get_specialty_probs\nfrom patientflow.load import get_model_key\n\n\ndef get_specialty_probability_distributions_with_special_categories(\n    test_visits_df,\n    spec_model,\n    admissions_models,\n    model_name,\n    exclude_from_training_data,\n    specialties=['medical', 'surgical', 'haem/onc', 'paediatric'],\n    baseline_prob_dict=None,\n):\n    \"\"\"\n    Calculate probability distributions for emergency department patients by specialty and prediction time.\n\n    Args:\n        test_visits_df: DataFrame containing test visit data\n        spec_model: Model for specialty predictions (SequenceToOutcomePredictor)\n        admissions_models: Dictionary of admission prediction models\n        model_name: Name of the model to use\n        specialties: List of specialties to consider\n        exclude_from_training_data: List of columns to exclude from training data\n        baseline_prob_dict: Optional dict of baseline probabilities to use instead of spec_model predictions\n\n    Returns:\n        Dictionary containing probability distributions for each specialty and prediction time\n    \"\"\"\n    # Get specialty prediction parameters\n    special_params = spec_model.special_params\n    special_category_func = special_params[\"special_category_func\"]\n    special_category_dict = special_params[\"special_category_dict\"]\n    special_func_map = special_params[\"special_func_map\"]\n\n    # Get predictions of admission to specialty\n    if baseline_prob_dict is not None:\n        # Use baseline probabilities instead of model predictions\n        # Create paediatric dictionary for age group 0-17\n        paediatric_dict = {key: 0 for key in baseline_prob_dict.keys()}\n        paediatric_dict['paediatric'] = 1\n\n        # Apply different dictionaries based specialty category function\n        test_visits_df.loc[:, \"specialty_prob\"] = test_visits_df.apply(\n            lambda row: paediatric_dict if special_category_func(row) else baseline_prob_dict,\n            axis=1\n        )\n    else:\n        # Use spec_model to get predictions\n        test_visits_df.loc[:, \"specialty_prob\"] = get_specialty_probs(\n            specialties,\n            spec_model,\n            test_visits_df,\n            special_category_func=special_category_func,\n            special_category_dict=special_category_dict,\n        )\n\n    # Initialize dictionary to store probability distributions\n    prob_dist_dict_all = {}\n\n    # Process each time of day\n    for _prediction_time in test_visits_df.prediction_time.unique():\n        prob_dist_dict_for_pats_in_ED = {}\n        print(\"\\nProcessing :\" + str(_prediction_time))\n        model_key = get_model_key(model_name, _prediction_time)\n\n        for specialty in specialties:\n            print(f\"Predicting bed counts for {specialty} specialty, for all snapshots in the test set\")\n\n            # Get indices of patients who are eligible for this specialty\n            func = special_func_map.get(specialty, special_func_map[\"default\"])\n            non_zero_indices = test_visits_df[\n                test_visits_df.apply(func, axis=1)\n            ].index\n\n            test_df_eligible = test_visits_df.copy()\n            test_df_eligible = test_df_eligible.loc[non_zero_indices]\n\n            # Get probability of admission to specialty for eligible patients\n            prob_admission_to_specialty = test_df_eligible[\"specialty_prob\"].apply(\n                lambda x: x[specialty]\n            )\n\n            # Prepare patient snapshots\n            X_test, y_test = prepare_patient_snapshots(\n                df=test_df_eligible, \n                prediction_time=_prediction_time, \n                single_snapshot_per_visit=False,\n                exclude_columns=exclude_from_training_data, \n                visit_col='visit_number'\n            )\n\n            # Filter probabilities for eligible patients\n            filtered_prob_admission_to_specialty = prob_admission_to_specialty.loc[\n                non_zero_indices\n            ]\n\n            # Prepare group snapshots\n            group_snapshots_dict = prepare_group_snapshot_dict(\n                test_df_eligible[test_df_eligible.prediction_time == _prediction_time]\n            )\n\n            admitted_to_specialty = test_df_eligible['specialty'] == specialty\n\n            # Get probability distribution for this time and specialty\n            prob_dist_dict_for_pats_in_ED[specialty] = get_prob_dist(\n                group_snapshots_dict, X_test, y_test, admissions_models[model_key], \n                weights=filtered_prob_admission_to_specialty,\n                category_filter=admitted_to_specialty, \n                normal_approx_threshold=30\n            )\n\n        prob_dist_dict_all[f'{model_key}'] = prob_dist_dict_for_pats_in_ED\n\n    return prob_dist_dict_all\n</code></pre> <pre><code>prob_dist_dict_all = get_specialty_probability_distributions_with_special_categories(\n    test_visits_df=test_visits_df,\n    spec_model=spec_model,      \n    admissions_models=admissions_models,\n    model_name=model_name,\n    exclude_from_training_data=exclude_from_training_data,\n)\n</code></pre> <pre><code>Processing :(22, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(6, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(15, 30)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(9, 30)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(12, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n</code></pre>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#visualise-the-performance-of-emergency-demand-prediction-models-for-patients-in-the-ed","title":"Visualise the performance of emergency demand prediction models for patients in the ED","text":"<p>Below I generate Adjusted QQ plots for each specialties, using both the baseline predictions, and the sequence predictor. The plots are very similar to the previous notebook. Using age as a fixed category for identifying patients destined for paediatric or adult wards yields similar results.</p> <pre><code>baseline_probs = train_inpatient_arrivals_df[~(train_inpatient_arrivals_df.is_child) &amp; \n                                             (train_inpatient_arrivals_df.specialty.isin(['medical', 'surgical', 'haem/onc']))]['specialty'].value_counts(normalize=True).to_dict()\nbaseline_probs['paediatric'] = 0\n\nprob_dist_dict_all_baseline = get_specialty_probability_distributions_with_special_categories(\n    test_visits_df=test_visits_df,\n    spec_model=spec_model,      \n    admissions_models=admissions_models,\n    model_name=model_name,\n    exclude_from_training_data=exclude_from_training_data,\n    baseline_prob_dict=baseline_probs\n)\n</code></pre> <pre><code>Processing :(22, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(6, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(15, 30)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(9, 30)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n\nProcessing :(12, 0)\nPredicting bed counts for medical specialty, for all snapshots in the test set\nPredicting bed counts for surgical specialty, for all snapshots in the test set\nPredicting bed counts for haem/onc specialty, for all snapshots in the test set\nPredicting bed counts for paediatric specialty, for all snapshots in the test set\n</code></pre> <pre><code>from patientflow.viz.epudd import plot_epudd\n\nfor specialty in ['medical', 'surgical', 'haem/onc', 'paediatric']:\n\n    print(f'\\nEPUDD plots for {specialty} specialty: baseline vs sequence predictor')\n\n    specialty_prob_dist_baseline = {time: dist_dict[specialty] for time, dist_dict in prob_dist_dict_all_baseline.items()}\n    specialty_prob_dist = {time: dist_dict[specialty] for time, dist_dict in prob_dist_dict_all.items()}\n\n    plot_epudd(ed_visits.prediction_time.unique(), \n        specialty_prob_dist_baseline,\n        model_name=\"admissions\",\n        suptitle=f\"EPUDD plots for {specialty} specialty using baseline probability\")\n\n    plot_epudd(ed_visits.prediction_time.unique(), \n        specialty_prob_dist,\n        model_name=\"admissions\",\n        suptitle=f\"EPUDD plots for {specialty} specialty using sequence predictor\")\n</code></pre> <pre><code>EPUDD plots for medical specialty: baseline vs sequence predictor\n</code></pre> <p></p> <p></p> <pre><code>EPUDD plots for surgical specialty: baseline vs sequence predictor\n</code></pre> <p></p> <p></p> <pre><code>EPUDD plots for haem/onc specialty: baseline vs sequence predictor\n</code></pre> <p></p> <p></p> <pre><code>EPUDD plots for paediatric specialty: baseline vs sequence predictor\n</code></pre> <p></p> <p></p>"},{"location":"notebooks/4d_Predict_emergency_demand_with_special_categories/#summary","title":"Summary","text":"<p>In this notebook I have shown how to specify that certain groups are handled differently. In the UCLH case, we assume that all patients under 18 will be admitted to a paediatric specialty. I have demonstrated how you can use the functions in patientflow to handle such special cases. </p>"},{"location":"src/patientflow/","title":"PatientFlow: A Python package for converting patient-level predictions into output that is useful for bed managers in hospitals","text":"<p>The package will support predictions of bed demand and discharges by providing functions that</p> <ul> <li>predict patient-level probabilities of admission and discharge, by specialty</li> <li>create probability distributions predicting number of beds needed for or vacated by those patients, at different levels of aggregation</li> <li>return a net bed position by combining predictions of demand and supply of beds</li> <li>evaluate and provide visualisation of the performance of these predictions</li> </ul> <p>The package is intended to serve as a wrapper of the functions typically used for such purposes in the <code>sklearn</code> and <code>scipy</code> python packages, with additional context to support their application and evaluation in bed management in healthcare.</p> <p>For the full documentation, see the API reference</p>"},{"location":"src/patientflow/#modules-overview-in-order-of-their-use-in-a-typical-modelling-workflow","title":"Modules Overview (in order of their use in a typical modelling workflow)","text":"<ul> <li><code>load</code>: A module for loading configuration files, saved data and trained models</li> <li><code>prepare</code>: A module for preparing saved data prior to input into model training</li> <li><code>train</code>: A module and submodules for training predictive models</li> <li><code>calculate</code>: A module for calculating time-varying arrival rates, and probability of admission within a prediction window</li> <li><code>predictors</code>: A module and submodules containing custom predictors developed for the <code>patientflow</code> package</li> <li><code>predict</code>: A module using trained models for predicting various aspects of bed demand and discharges</li> <li><code>aggregate</code>: A module that turns patient-level probabilities into aggregate distributions of bed numbers</li> <li><code>evaluate</code>: A module that provides convenient functions for evaluating and comparing prediction models</li> <li><code>viz</code>: A module containing convenient plotting functions to examine the outputs from the above functions</li> </ul> <p>Two modules provide supporting</p> <ul> <li><code>model_artifacts</code>: Defines a set of data classes to organise results from model training processes</li> <li><code>errors</code> : Custom exception classes for model loading and validation</li> </ul> <p>The following module has been used in the preparation of this repository, but are not core to the package:</p> <ul> <li><code>convert</code>: Used for converting data from UCLH into the public dataset that is available from Zenodo</li> <li><code>generate</code> : Functions to generate fake datasets for patient visits to an emergency department (ED); used for illustrative purposes in some of the notebooks</li> </ul> <p>Other modules may follow in future</p>"},{"location":"src/patientflow/#deployment","title":"Deployment","text":"<p>This package is designed for use in hospital data projects analysing patient flow and bed capacity in short time horizons. The modules can be customised to align with specific hospital requirements</p>"}]}