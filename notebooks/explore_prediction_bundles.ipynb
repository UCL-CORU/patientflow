{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore Prediction Bundles\n",
        "\n",
        "This notebook loads pickled hierarchical predictors and allows you to explore the prediction bundles that were created.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from patientflow.predict.hierarchy import (\n",
        "    HierarchicalPredictor,\n",
        "    FlowSelection,\n",
        "    create_hierarchical_predictor,\n",
        ")\n",
        "from patientflow.predict.subspecialty import SubspecialtyPredictionInputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Pickled Data\n",
        "\n",
        "Update the path below to point to your pickle file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pickle file: /Users/zellaking/Downloads/hierarchical_predictors_with_inputs.pkl\n",
            "Keys in pickle: ['all', 'elective', 'emergency']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lr/pm79dxzs0v70y4gz98dl13440000gn/T/ipykernel_12431/3782410358.py:5: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
            "  pickled_data = pickle.load(f)\n"
          ]
        }
      ],
      "source": [
        "# Update this path to your pickle file\n",
        "pickle_path = \"/Users/zellaking/Downloads/hierarchical_predictors_with_inputs.pkl\"\n",
        "\n",
        "with open(pickle_path, 'rb') as f:\n",
        "    pickled_data = pickle.load(f)\n",
        "\n",
        "print(f\"Loaded pickle file: {pickle_path}\")\n",
        "print(f\"Keys in pickle: {list(pickled_data.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract Data from 'all' Entry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of subspecialties: 291\n",
            "Subspecialty IDs: ['Oncology - Gynae - Clinical', 'Neurology - Stroke ASU', 'Neurosurgery - Epilepsy', 'Haematology - BMT - Treatment', 'CYPPS - Psychiatry', 'Neurosurgery - Stereotactic Functional', 'Neurosurgery - Gamma Knife', 'Paediatric - Respiratory Medicine', 'Infectious Diseases - COVID-19 Medicines Delivery', 'Neurosurgery - Vascular']...\n",
            "Top level ID: uclh\n",
            "\n",
            "Hierarchy DataFrame shape: (290, 4)\n",
            "Column mapping: {'sub_specialty': 'subspecialty', 'reporting_unit': 'reporting_unit', 'division': 'division', 'board': 'board'}\n"
          ]
        }
      ],
      "source": [
        "if 'all' not in pickled_data:\n",
        "    raise ValueError(f\"Pickled data must contain 'all' key. Available keys: {list(pickled_data.keys())}\")\n",
        "\n",
        "all_data = pickled_data['all']\n",
        "\n",
        "# Extract all components\n",
        "predictor = all_data['predictor']\n",
        "subspecialty_data = all_data['subspecialty_data']\n",
        "hierarchy_df = all_data['hierarchy_df']\n",
        "column_mapping = all_data['column_mapping']\n",
        "top_level_id = all_data['top_level_id']\n",
        "\n",
        "print(f\"Number of subspecialties: {len(subspecialty_data)}\")\n",
        "print(f\"Subspecialty IDs: {list(subspecialty_data.keys())[:10]}...\" if len(subspecialty_data) > 10 else f\"Subspecialty IDs: {list(subspecialty_data.keys())}\")\n",
        "print(f\"Top level ID: {top_level_id}\")\n",
        "print(f\"\\nHierarchy DataFrame shape: {hierarchy_df.shape}\")\n",
        "print(f\"Column mapping: {column_mapping}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect Hierarchy DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sub_specialty</th>\n",
              "      <th>reporting_unit</th>\n",
              "      <th>division</th>\n",
              "      <th>board</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Neurology - Upper Limb</td>\n",
              "      <td>Rehab &amp; Stroke</td>\n",
              "      <td>Queen Square</td>\n",
              "      <td>Specialist Hospitals Board</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oncology - Head and Neck - Clinical</td>\n",
              "      <td>Oncology</td>\n",
              "      <td>Cancer Services</td>\n",
              "      <td>Cancer &amp; Surgery Board</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Oncology - Radiotherapy</td>\n",
              "      <td>Oncology</td>\n",
              "      <td>Cancer Services</td>\n",
              "      <td>Cancer &amp; Surgery Board</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Neurology - Spasticity</td>\n",
              "      <td>Rehab &amp; Stroke</td>\n",
              "      <td>Queen Square</td>\n",
              "      <td>Specialist Hospitals Board</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Neurology - Inherited Metabolic Diseases</td>\n",
              "      <td>Specialist Services</td>\n",
              "      <td>Queen Square</td>\n",
              "      <td>Specialist Hospitals Board</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Haematology - ITP</td>\n",
              "      <td>Haematology</td>\n",
              "      <td>Cancer Services</td>\n",
              "      <td>Cancer &amp; Surgery Board</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ENT - Ears</td>\n",
              "      <td>Adult ENT</td>\n",
              "      <td>RNENT &amp; EDH</td>\n",
              "      <td>Specialist Hospitals Board</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Paediatric - Proton Beam Therapy</td>\n",
              "      <td>Children &amp; Young Peoples Cancer</td>\n",
              "      <td>Children and Young People</td>\n",
              "      <td>Specialist Hospitals Board</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Paediatric - Surgery</td>\n",
              "      <td>Paediatric Surgery</td>\n",
              "      <td>Children and Young People</td>\n",
              "      <td>Specialist Hospitals Board</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Orthopaedics - Upper Limb</td>\n",
              "      <td>Trauma &amp; Orthopaedics</td>\n",
              "      <td>Surgical Specialties</td>\n",
              "      <td>Cancer &amp; Surgery Board</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               sub_specialty                   reporting_unit  \\\n",
              "0                     Neurology - Upper Limb                   Rehab & Stroke   \n",
              "2        Oncology - Head and Neck - Clinical                         Oncology   \n",
              "3                    Oncology - Radiotherapy                         Oncology   \n",
              "4                     Neurology - Spasticity                   Rehab & Stroke   \n",
              "5   Neurology - Inherited Metabolic Diseases              Specialist Services   \n",
              "6                          Haematology - ITP                      Haematology   \n",
              "7                                 ENT - Ears                        Adult ENT   \n",
              "8           Paediatric - Proton Beam Therapy  Children & Young Peoples Cancer   \n",
              "9                       Paediatric - Surgery               Paediatric Surgery   \n",
              "11                 Orthopaedics - Upper Limb            Trauma & Orthopaedics   \n",
              "\n",
              "                     division                       board  \n",
              "0                Queen Square  Specialist Hospitals Board  \n",
              "2             Cancer Services      Cancer & Surgery Board  \n",
              "3             Cancer Services      Cancer & Surgery Board  \n",
              "4                Queen Square  Specialist Hospitals Board  \n",
              "5                Queen Square  Specialist Hospitals Board  \n",
              "6             Cancer Services      Cancer & Surgery Board  \n",
              "7                 RNENT & EDH  Specialist Hospitals Board  \n",
              "8   Children and Young People  Specialist Hospitals Board  \n",
              "9   Children and Young People  Specialist Hospitals Board  \n",
              "11       Surgical Specialties      Cancer & Surgery Board  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hierarchy_df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hierarchy levels:\n",
            "  sub_specialty: 290 unique values\n",
            "  reporting_unit: 55 unique values\n",
            "  division: 14 unique values\n",
            "  board: 3 unique values\n"
          ]
        }
      ],
      "source": [
        "print(f\"Hierarchy levels:\")\n",
        "for col in hierarchy_df.columns:\n",
        "    unique_count = hierarchy_df[col].nunique()\n",
        "    print(f\"  {col}: {unique_count} unique values\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect Subspecialty Prediction Inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example subspecialty: Oncology - Gynae - Clinical\n",
            "\n",
            "SubspecialtyPredictionInputs(subspecialty='Oncology - Gynae - Clinical')\n",
            "  INFLOWS:\n",
            "    Admissions from current ED               PMF[0:10]: [0.970, 0.030, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000] (E=0.0 of 27 patients in ED)\n",
            "    ED yet-to-arrive admissions              λ = 0.014\n",
            "    Non-ED emergency admissions              λ = 0.000\n",
            "    Elective admissions                      λ = 0.075\n",
            "    Elective transfers from other subspecialties PMF[0:2]: [1.000, 0.000] (E=0.0)\n",
            "    Emergency transfers from other subspecialties PMF[0:7]: [0.957, 0.042, 0.001, 0.000, 0.000, 0.000, 0.000] (E=0.0)\n",
            "  OUTFLOWS:\n",
            "    Emergency inpatient departures           PMF[0:2]: [0.905, 0.095] (E=0.1 of 1 emergency patients in subspec)\n",
            "    Elective inpatient departures            PMF[0:2]: [1.000, 0.000] (E=0.0 of 1 elective patients in subspec)\n"
          ]
        }
      ],
      "source": [
        "# Look at one subspecialty's inputs\n",
        "first_spec_id = list(subspecialty_data.keys())[0]\n",
        "first_spec_inputs = subspecialty_data[first_spec_id]\n",
        "\n",
        "print(f\"Example subspecialty: {first_spec_id}\")\n",
        "print(f\"\\n{first_spec_inputs}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inflows for Oncology - Gynae - Clinical:\n",
            "  ed_current: PMF with 28 elements, sum=1.0000, mean=0.0303\n",
            "  ed_yta: Poisson(λ=0.0141)\n",
            "  non_ed_yta: Poisson(λ=0.0000)\n",
            "  elective_yta: Poisson(λ=0.0755)\n",
            "  elective_transfers: PMF with 2 elements, sum=1.0000, mean=0.0000\n",
            "  emergency_transfers: PMF with 7 elements, sum=1.0000, mean=0.0436\n"
          ]
        }
      ],
      "source": [
        "# Inspect inflows for the first subspecialty\n",
        "print(f\"Inflows for {first_spec_id}:\")\n",
        "for flow_id, flow_input in first_spec_inputs.inflows.items():\n",
        "    if flow_input.flow_type == 'pmf':\n",
        "        pmf = flow_input.distribution\n",
        "        print(f\"  {flow_id}: PMF with {len(pmf)} elements, sum={pmf.sum():.4f}, mean={np.sum(pmf * np.arange(len(pmf))):.4f}\")\n",
        "    elif flow_input.flow_type == 'poisson':\n",
        "        lam = flow_input.distribution\n",
        "        print(f\"  {flow_id}: Poisson(λ={lam:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outflows for Oncology - Gynae - Clinical:\n",
            "  emergency_departures: PMF with 2 elements, sum=1.0000, mean=0.0953\n",
            "  elective_departures: PMF with 2 elements, sum=1.0000, mean=0.0000\n"
          ]
        }
      ],
      "source": [
        "# Inspect outflows for the first subspecialty\n",
        "print(f\"Outflows for {first_spec_id}:\")\n",
        "for flow_id, flow_input in first_spec_inputs.outflows.items():\n",
        "    if flow_input.flow_type == 'pmf':\n",
        "        pmf = flow_input.distribution\n",
        "        print(f\"  {flow_id}: PMF with {len(pmf)} elements, sum={pmf.sum():.4f}, mean={np.sum(pmf * np.arange(len(pmf))):.4f}\")\n",
        "    elif flow_input.flow_type == 'poisson':\n",
        "        lam = flow_input.distribution\n",
        "        print(f\"  {flow_id}: Poisson(λ={lam:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect Existing Prediction Bundles (from Pickled Predictor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flow selection from pickled predictor: all\n",
            "\n",
            "Cached bundles in predictor: 364 entities\n",
            "\n",
            "Entity IDs in cache:\n",
            "  subspecialty:Oncology - Gynae - Clinical\n",
            "  subspecialty:Neurology - Stroke ASU\n",
            "  subspecialty:Neurosurgery - Epilepsy\n",
            "  subspecialty:Haematology - BMT - Treatment\n",
            "  subspecialty:CYPPS - Psychiatry\n",
            "  subspecialty:Neurosurgery - Stereotactic Functional\n",
            "  subspecialty:Neurosurgery - Gamma Knife\n",
            "  subspecialty:Paediatric - Respiratory Medicine\n",
            "  subspecialty:Infectious Diseases - COVID-19 Medicines Delivery\n",
            "  subspecialty:Neurosurgery - Vascular\n",
            "  subspecialty:Gastroenterology - Adolescent\n",
            "  subspecialty:Gynaecology - Endometriosis\n",
            "  subspecialty:Neurology - Neuro Ophthalmology\n",
            "  subspecialty:Respiratory - Lung Cancer\n",
            "  subspecialty:Obstetrics - Still Birth\n",
            "  subspecialty:Neurology - Autonomics\n",
            "  subspecialty:Urology - Stones\n",
            "  subspecialty:Neurosurgery - General Cranial\n",
            "  subspecialty:Gynaecology - Urogynaecology\n",
            "  subspecialty:Oncology - Interventional Oncology Service\n",
            "  ... and 344 more\n"
          ]
        }
      ],
      "source": [
        "# Get flow selection from the pickled predictor\n",
        "if predictor.cache:\n",
        "    first_bundle = next(iter(predictor.cache.values()))\n",
        "    flow_selection = first_bundle.flow_selection\n",
        "    print(f\"Flow selection from pickled predictor: {flow_selection.cohort}\")\n",
        "    print(f\"\\nCached bundles in predictor: {len(predictor.cache)} entities\")\n",
        "    print(f\"\\nEntity IDs in cache:\")\n",
        "    for entity_id in list(predictor.cache.keys())[:20]:\n",
        "        print(f\"  {entity_id}\")\n",
        "    if len(predictor.cache) > 20:\n",
        "        print(f\"  ... and {len(predictor.cache) - 20} more\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction Bundle for: subspecialty:Oncology - Gynae - Clinical\n",
            "Entity ID: Oncology - Gynae - Clinical\n",
            "Entity Type: subspecialty\n",
            "\n",
            "PredictionBundle(subspecialty: Oncology - Gynae - Clinical)\n",
            "  Arrivals:    PMF[0:10]: [0.849, 0.140, 0.011, 0.001, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000] (E=0.2)\n",
            "  Departures:  PMF[0:3]: [0.905, 0.095, 0.000] (E=0.1)\n",
            "  Net flow:    PMF[-2:6]: [0.000, 0.081, 0.781, 0.127, 0.010, 0.001, 0.000, 0.000] (E=0.1)\n",
            "  Flows:       selection cohort=all inflows(ed_current=True, ed_yta=True, non_ed_yta=True, elective_yta=True, transfers_in=True) outflows(departures=True)\n"
          ]
        }
      ],
      "source": [
        "# Inspect a specific prediction bundle from the cache\n",
        "# You can modify this to look at different entities\n",
        "entity_to_inspect = list(predictor.cache.keys())[0] if predictor.cache else None\n",
        "\n",
        "if entity_to_inspect:\n",
        "    bundle = predictor.cache[entity_to_inspect]\n",
        "    print(f\"\\nPrediction Bundle for: {entity_to_inspect}\")\n",
        "    print(f\"Entity ID: {bundle.entity_id}\")\n",
        "    print(f\"Entity Type: {bundle.entity_type}\")\n",
        "    print(f\"\\n{bundle}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create New Predictions with Different k_sigma Values\n",
        "\n",
        "You can create new predictions with different k_sigma values to see how they affect the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created new predictor with k_sigma=8.0\n"
          ]
        }
      ],
      "source": [
        "# Choose a k_sigma value to test\n",
        "k_sigma = 8.0\n",
        "\n",
        "# Create a new predictor with this k_sigma\n",
        "new_predictor = create_hierarchical_predictor(\n",
        "    hierarchy_df,\n",
        "    column_mapping,\n",
        "    top_level_id,\n",
        "    k_sigma=k_sigma,\n",
        ")\n",
        "\n",
        "print(f\"Created new predictor with k_sigma={k_sigma}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 364 prediction bundles\n",
            "\n",
            "Entity IDs in results:\n",
            "  subspecialty:Oncology - Gynae - Clinical\n",
            "  subspecialty:Neurology - Stroke ASU\n",
            "  subspecialty:Neurosurgery - Epilepsy\n",
            "  subspecialty:Haematology - BMT - Treatment\n",
            "  subspecialty:CYPPS - Psychiatry\n",
            "  subspecialty:Neurosurgery - Stereotactic Functional\n",
            "  subspecialty:Neurosurgery - Gamma Knife\n",
            "  subspecialty:Paediatric - Respiratory Medicine\n",
            "  subspecialty:Infectious Diseases - COVID-19 Medicines Delivery\n",
            "  subspecialty:Neurosurgery - Vascular\n",
            "  subspecialty:Gastroenterology - Adolescent\n",
            "  subspecialty:Gynaecology - Endometriosis\n",
            "  subspecialty:Neurology - Neuro Ophthalmology\n",
            "  subspecialty:Respiratory - Lung Cancer\n",
            "  subspecialty:Obstetrics - Still Birth\n",
            "  subspecialty:Neurology - Autonomics\n",
            "  subspecialty:Urology - Stones\n",
            "  subspecialty:Neurosurgery - General Cranial\n",
            "  subspecialty:Gynaecology - Urogynaecology\n",
            "  subspecialty:Oncology - Interventional Oncology Service\n",
            "  ... and 344 more\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions with the new k_sigma\n",
        "# Use the flow_selection from the pickled predictor\n",
        "new_results = new_predictor.predict_all_levels(\n",
        "    subspecialty_data,\n",
        "    flow_selection=flow_selection\n",
        ")\n",
        "\n",
        "print(f\"Generated {len(new_results)} prediction bundles\")\n",
        "print(f\"\\nEntity IDs in results:\")\n",
        "for entity_id in list(new_results.keys())[:20]:\n",
        "    print(f\"  {entity_id}\")\n",
        "if len(new_results) > 20:\n",
        "    print(f\"  ... and {len(new_results) - 20} more\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction Bundle for: subspecialty:Oncology - Gynae - Clinical\n",
            "\n",
            "PredictionBundle(subspecialty: Oncology - Gynae - Clinical)\n",
            "  Arrivals:    PMF[0:10]: [0.849, 0.140, 0.011, 0.001, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000] (E=0.2)\n",
            "  Departures:  PMF[0:3]: [0.905, 0.095, 0.000] (E=0.1)\n",
            "  Net flow:    PMF[-2:8]: [0.000, 0.081, 0.781, 0.128, 0.010, 0.000, 0.000, 0.000, 0.000, 0.000] (E=0.1)\n",
            "  Flows:       selection cohort=all inflows(ed_current=True, ed_yta=True, non_ed_yta=True, elective_yta=True, transfers_in=True) outflows(departures=True)\n"
          ]
        }
      ],
      "source": [
        "# Inspect a specific prediction bundle from the new results\n",
        "# Try different entity IDs to explore\n",
        "entity_to_inspect = list(new_results.keys())[0]\n",
        "\n",
        "bundle = new_results[entity_to_inspect]\n",
        "print(f\"\\nPrediction Bundle for: {entity_to_inspect}\")\n",
        "print(f\"\\n{bundle}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-level bundle: hospital:uclh\n",
            "\n",
            "Arrivals PMF length: 189\n",
            "Arrivals expected value: 106.17\n",
            "\n",
            "Departures PMF length: 144\n",
            "Departures expected value: 86.42\n",
            "\n",
            "Net flow PMF length: 332\n",
            "Net flow expected value: 19.75\n",
            "Net flow offset: -143\n",
            "\n",
            "Arrivals percentiles: {50: 106, 75: 113, 90: 119, 95: 123, 99: 130}\n",
            "Departures percentiles: {50: 86, 75: 91, 90: 95, 95: 98, 99: 103}\n",
            "Net flow percentiles: {50: 20, 75: 28, 90: 36, 95: 40, 99: 49}\n"
          ]
        }
      ],
      "source": [
        "# Compare PMF sizes for top-level entity\n",
        "top_level_key = f\"hospital:{top_level_id}\" if f\"hospital:{top_level_id}\" in new_results else None\n",
        "if not top_level_key:\n",
        "    # Try to find top level by checking entity types\n",
        "    for key, bundle in new_results.items():\n",
        "        if bundle.entity_type == 'hospital':\n",
        "            top_level_key = key\n",
        "            break\n",
        "\n",
        "if top_level_key:\n",
        "    bundle = new_results[top_level_key]\n",
        "    print(f\"Top-level bundle: {top_level_key}\")\n",
        "    print(f\"\\nArrivals PMF length: {len(bundle.arrivals.probabilities)}\")\n",
        "    print(f\"Arrivals expected value: {bundle.arrivals.expected_value:.2f}\")\n",
        "    print(f\"\\nDepartures PMF length: {len(bundle.departures.probabilities)}\")\n",
        "    print(f\"Departures expected value: {bundle.departures.expected_value:.2f}\")\n",
        "    print(f\"\\nNet flow PMF length: {len(bundle.net_flow.probabilities)}\")\n",
        "    print(f\"Net flow expected value: {bundle.net_flow.expected_value:.2f}\")\n",
        "    print(f\"Net flow offset: {bundle.net_flow.offset}\")\n",
        "    \n",
        "    # Show percentiles\n",
        "    print(f\"\\nArrivals percentiles: {bundle.arrivals.percentiles}\")\n",
        "    print(f\"Departures percentiles: {bundle.departures.percentiles}\")\n",
        "    print(f\"Net flow percentiles: {bundle.net_flow.percentiles}\")\n",
        "else:\n",
        "    print(\"Could not find top-level entity\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare Different k_sigma Values\n",
        "\n",
        "Compare how different k_sigma values affect PMF sizes and predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k_sigma    Arr PMF      Dep PMF      Net PMF      Arr E[X]     Dep E[X]     Net E[X]    \n",
            "--------------------------------------------------------------------------------\n",
            "4.0        148          116          263          106.09       86.42        19.67       \n",
            "6.0        169          130          298          106.16       86.42        19.74       \n",
            "8.0        189          144          332          106.17       86.42        19.75       \n",
            "10.0       209          158          366          106.17       86.42        19.75       \n",
            "12.0       230          172          401          106.17       86.42        19.75       \n"
          ]
        }
      ],
      "source": [
        "# Test multiple k_sigma values\n",
        "k_sigma_values = [4.0, 6.0, 8.0, 10.0, 12.0]\n",
        "comparison_results = {}\n",
        "\n",
        "for k_sigma in k_sigma_values:\n",
        "    predictor = create_hierarchical_predictor(\n",
        "        hierarchy_df,\n",
        "        column_mapping,\n",
        "        top_level_id,\n",
        "        k_sigma=k_sigma,\n",
        "    )\n",
        "    \n",
        "    results = predictor.predict_all_levels(\n",
        "        subspecialty_data,\n",
        "        flow_selection=flow_selection\n",
        "    )\n",
        "    \n",
        "    # Find top-level bundle\n",
        "    top_bundle = None\n",
        "    for key, bundle in results.items():\n",
        "        if bundle.entity_type == 'hospital':\n",
        "            top_bundle = bundle\n",
        "            break\n",
        "    \n",
        "    if top_bundle:\n",
        "        comparison_results[k_sigma] = {\n",
        "            'arrivals_pmf_len': len(top_bundle.arrivals.probabilities),\n",
        "            'departures_pmf_len': len(top_bundle.departures.probabilities),\n",
        "            'net_flow_pmf_len': len(top_bundle.net_flow.probabilities),\n",
        "            'arrivals_expected': top_bundle.arrivals.expected_value,\n",
        "            'departures_expected': top_bundle.departures.expected_value,\n",
        "            'net_flow_expected': top_bundle.net_flow.expected_value,\n",
        "        }\n",
        "\n",
        "# Display comparison\n",
        "print(f\"{'k_sigma':<10} {'Arr PMF':<12} {'Dep PMF':<12} {'Net PMF':<12} {'Arr E[X]':<12} {'Dep E[X]':<12} {'Net E[X]':<12}\")\n",
        "print(\"-\" * 80)\n",
        "for k_sigma in sorted(comparison_results.keys()):\n",
        "    r = comparison_results[k_sigma]\n",
        "    print(f\"{k_sigma:<10.1f} {r['arrivals_pmf_len']:<12} {r['departures_pmf_len']:<12} {r['net_flow_pmf_len']:<12} \"\n",
        "          f\"{r['arrivals_expected']:<12.2f} {r['departures_expected']:<12.2f} {r['net_flow_expected']:<12.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explore Specific Subspecialty Predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Net Flow Bounds Based on k_sigma\n",
        "\n",
        "Check that net flow bounds are correct: net flow should range from `[-max_departures, +max_arrivals]` where the max values come from the capped arrivals and departures distributions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verification for: Oncology - Gynae - Clinical (subspecialty)\n",
            "\n",
            "Arrivals:\n",
            "  Offset: 0, Max index: 38, Max value: 38\n",
            "\n",
            "Departures:\n",
            "  Offset: 0, Max index: 2, Max value: 2\n",
            "\n",
            "Net Flow Bounds:\n",
            "  Expected offset: -2, Actual: -2 ✓\n",
            "  Expected min value: -2, Actual: -2 ✓\n",
            "  Expected max value: 38, Actual: 38 ✓\n",
            "  Expected PMF length: 41, Actual: 41 ✓\n",
            "\n",
            "All checks passed!\n"
          ]
        }
      ],
      "source": [
        "def verify_net_flow_bounds(bundle):\n",
        "    \"\"\"Verify that net flow bounds are correct based on arrivals and departures.\n",
        "    \n",
        "    Net flow should have:\n",
        "    - Offset = -(max_departures + departures.offset)\n",
        "    - Support range: [-(max_departures + dep_offset), +(max_arrivals + arr_offset)]\n",
        "    - PMF length = (max_arrivals + arr_offset) + (max_departures + dep_offset) + 1\n",
        "    \n",
        "    Where:\n",
        "    - max_arrivals = len(arrivals.probabilities) - 1\n",
        "    - max_departures = len(departures.probabilities) - 1\n",
        "    - arr_offset = arrivals.offset (typically 0)\n",
        "    - dep_offset = departures.offset (typically 0)\n",
        "    \n",
        "    Returns a dictionary with verification results.\n",
        "    \"\"\"\n",
        "    arrivals = bundle.arrivals\n",
        "    departures = bundle.departures\n",
        "    net_flow = bundle.net_flow\n",
        "    \n",
        "    # Calculate max values (accounting for offsets)\n",
        "    arr_offset = arrivals.offset\n",
        "    dep_offset = departures.offset\n",
        "    max_arrivals_idx = len(arrivals.probabilities) - 1\n",
        "    max_departures_idx = len(departures.probabilities) - 1\n",
        "    \n",
        "    # Maximum actual values (not indices)\n",
        "    max_arrivals_value = arr_offset + max_arrivals_idx\n",
        "    max_departures_value = dep_offset + max_departures_idx\n",
        "    \n",
        "    # Expected net flow bounds\n",
        "    # Net flow = arrivals - departures\n",
        "    # Minimum: min_arrivals - max_departures = arr_offset - max_departures_value\n",
        "    # Maximum: max_arrivals - min_departures = max_arrivals_value - dep_offset\n",
        "    expected_min_value = arr_offset - max_departures_value\n",
        "    expected_max_value = max_arrivals_value - dep_offset\n",
        "    expected_offset = expected_min_value\n",
        "    expected_pmf_length = expected_max_value - expected_min_value + 1\n",
        "    \n",
        "    # Actual values\n",
        "    actual_offset = net_flow.offset\n",
        "    actual_min_value = net_flow.offset\n",
        "    actual_max_value = net_flow.offset + len(net_flow.probabilities) - 1\n",
        "    actual_pmf_length = len(net_flow.probabilities)\n",
        "    \n",
        "    # Verify\n",
        "    offset_correct = actual_offset == expected_offset\n",
        "    min_value_correct = actual_min_value == expected_min_value\n",
        "    max_value_correct = actual_max_value == expected_max_value\n",
        "    pmf_length_correct = actual_pmf_length == expected_pmf_length\n",
        "    \n",
        "    all_correct = offset_correct and min_value_correct and max_value_correct and pmf_length_correct\n",
        "    \n",
        "    return {\n",
        "        'entity_id': bundle.entity_id,\n",
        "        'entity_type': bundle.entity_type,\n",
        "        'arr_offset': arr_offset,\n",
        "        'dep_offset': dep_offset,\n",
        "        'max_arrivals_idx': max_arrivals_idx,\n",
        "        'max_departures_idx': max_departures_idx,\n",
        "        'max_arrivals_value': max_arrivals_value,\n",
        "        'max_departures_value': max_departures_value,\n",
        "        'expected_offset': expected_offset,\n",
        "        'actual_offset': actual_offset,\n",
        "        'offset_correct': offset_correct,\n",
        "        'expected_min_value': expected_min_value,\n",
        "        'actual_min_value': actual_min_value,\n",
        "        'min_value_correct': min_value_correct,\n",
        "        'expected_max_value': expected_max_value,\n",
        "        'actual_max_value': actual_max_value,\n",
        "        'max_value_correct': max_value_correct,\n",
        "        'expected_pmf_length': expected_pmf_length,\n",
        "        'actual_pmf_length': actual_pmf_length,\n",
        "        'pmf_length_correct': pmf_length_correct,\n",
        "        'all_correct': all_correct,\n",
        "    }\n",
        "\n",
        "# Verify bounds for a specific bundle\n",
        "if 'new_results' in locals() and new_results:\n",
        "    bundle_to_check = list(new_results.values())[0]\n",
        "    verification = verify_net_flow_bounds(bundle_to_check)\n",
        "    \n",
        "    print(f\"Verification for: {verification['entity_id']} ({verification['entity_type']})\")\n",
        "    print(f\"\\nArrivals:\")\n",
        "    print(f\"  Offset: {verification['arr_offset']}, Max index: {verification['max_arrivals_idx']}, Max value: {verification['max_arrivals_value']}\")\n",
        "    print(f\"\\nDepartures:\")\n",
        "    print(f\"  Offset: {verification['dep_offset']}, Max index: {verification['max_departures_idx']}, Max value: {verification['max_departures_value']}\")\n",
        "    print(f\"\\nNet Flow Bounds:\")\n",
        "    print(f\"  Expected offset: {verification['expected_offset']}, Actual: {verification['actual_offset']} {'✓' if verification['offset_correct'] else '✗'}\")\n",
        "    print(f\"  Expected min value: {verification['expected_min_value']}, Actual: {verification['actual_min_value']} {'✓' if verification['min_value_correct'] else '✗'}\")\n",
        "    print(f\"  Expected max value: {verification['expected_max_value']}, Actual: {verification['actual_max_value']} {'✓' if verification['max_value_correct'] else '✗'}\")\n",
        "    print(f\"  Expected PMF length: {verification['expected_pmf_length']}, Actual: {verification['actual_pmf_length']} {'✓' if verification['pmf_length_correct'] else '✗'}\")\n",
        "    print(f\"\\n{'All checks passed!' if verification['all_correct'] else 'Some checks failed!'}\")\n",
        "else:\n",
        "    print(\"Run the cells above to generate predictions first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verification Summary:\n",
            "k_sigma    Total Entities  All Correct     Failed         \n",
            "------------------------------------------------------------\n",
            "4.0        364             364             0              \n",
            "6.0        364             364             0              \n",
            "8.0        364             364             0              \n",
            "10.0       364             364             0              \n",
            "12.0       364             364             0              \n",
            "50.0       364             364             0              \n",
            "100.0      364             364             0              \n",
            "\n",
            "============================================================\n",
            "Detailed Failures (if any):\n",
            "============================================================\n",
            "\n",
            "k_sigma = 4.0: All entities passed verification ✓\n",
            "\n",
            "k_sigma = 6.0: All entities passed verification ✓\n",
            "\n",
            "k_sigma = 8.0: All entities passed verification ✓\n",
            "\n",
            "k_sigma = 10.0: All entities passed verification ✓\n",
            "\n",
            "k_sigma = 12.0: All entities passed verification ✓\n",
            "\n",
            "k_sigma = 50.0: All entities passed verification ✓\n",
            "\n",
            "k_sigma = 100.0: All entities passed verification ✓\n"
          ]
        }
      ],
      "source": [
        "# Verify bounds across all entities and different k_sigma values\n",
        "k_sigma_test_values = [4.0, 6.0, 8.0, 10.0, 12.0, 50.0, 100.0]\n",
        "verification_results = {}\n",
        "\n",
        "for k_sigma in k_sigma_test_values:\n",
        "    predictor = create_hierarchical_predictor(\n",
        "        hierarchy_df,\n",
        "        column_mapping,\n",
        "        top_level_id,\n",
        "        k_sigma=k_sigma,\n",
        "    )\n",
        "    \n",
        "    results = predictor.predict_all_levels(\n",
        "        subspecialty_data,\n",
        "        flow_selection=flow_selection\n",
        "    )\n",
        "    \n",
        "    # Verify all bundles\n",
        "    entity_verifications = {}\n",
        "    for entity_id, bundle in results.items():\n",
        "        verification = verify_net_flow_bounds(bundle)\n",
        "        entity_verifications[entity_id] = verification\n",
        "    \n",
        "    verification_results[k_sigma] = entity_verifications\n",
        "\n",
        "# Summary: Check how many entities pass verification for each k_sigma\n",
        "print(\"Verification Summary:\")\n",
        "print(f\"{'k_sigma':<10} {'Total Entities':<15} {'All Correct':<15} {'Failed':<15}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for k_sigma in sorted(verification_results.keys()):\n",
        "    verifications = verification_results[k_sigma]\n",
        "    total = len(verifications)\n",
        "    all_correct = sum(1 for v in verifications.values() if v['all_correct'])\n",
        "    failed = total - all_correct\n",
        "    print(f\"{k_sigma:<10.1f} {total:<15} {all_correct:<15} {failed:<15}\")\n",
        "\n",
        "# Show any failures\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Detailed Failures (if any):\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for k_sigma in sorted(verification_results.keys()):\n",
        "    verifications = verification_results[k_sigma]\n",
        "    failures = [(eid, v) for eid, v in verifications.items() if not v['all_correct']]\n",
        "    if failures:\n",
        "        print(f\"\\nk_sigma = {k_sigma}:\")\n",
        "        for entity_id, v in failures:\n",
        "            print(f\"  {entity_id}:\")\n",
        "            if not v['offset_correct']:\n",
        "                print(f\"    Offset: expected {v['expected_offset']}, got {v['actual_offset']}\")\n",
        "            if not v['min_value_correct']:\n",
        "                print(f\"    Min value: expected {v['expected_min_value']}, got {v['actual_min_value']}\")\n",
        "            if not v['max_value_correct']:\n",
        "                print(f\"    Max value: expected {v['expected_max_value']}, got {v['actual_max_value']}\")\n",
        "            if not v['pmf_length_correct']:\n",
        "                print(f\"    PMF length: expected {v['expected_pmf_length']}, got {v['actual_pmf_length']}\")\n",
        "    else:\n",
        "        print(f\"\\nk_sigma = {k_sigma}: All entities passed verification ✓\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How k_sigma affects net flow bounds (top-level entity):\n",
            "k_sigma    Max Arr Val  Max Dep Val  Net Min    Net Max    Net PMF Len  Status    \n",
            "--------------------------------------------------------------------------------\n",
            "4.0        147          115          -115       147        263          ✓         \n",
            "6.0        168          129          -129       168        298          ✓         \n",
            "8.0        188          143          -143       188        332          ✓         \n",
            "10.0       208          157          -157       208        366          ✓         \n",
            "12.0       229          171          -171       229        401          ✓         \n",
            "50.0       614          436          -436       614        1051         ✓         \n",
            "100.0      1122         563          -563       1122       1686         ✓         \n"
          ]
        }
      ],
      "source": [
        "# Show how k_sigma affects net flow bounds for top-level entity\n",
        "print(\"How k_sigma affects net flow bounds (top-level entity):\")\n",
        "print(f\"{'k_sigma':<10} {'Max Arr Val':<12} {'Max Dep Val':<12} {'Net Min':<10} {'Net Max':<10} {'Net PMF Len':<12} {'Status':<10}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for k_sigma in sorted(verification_results.keys()):\n",
        "    verifications = verification_results[k_sigma]\n",
        "    \n",
        "    # Find top-level entity\n",
        "    top_verification = None\n",
        "    for entity_id, v in verifications.items():\n",
        "        if v['entity_type'] == 'hospital':\n",
        "            top_verification = v\n",
        "            break\n",
        "    \n",
        "    if top_verification:\n",
        "        v = top_verification\n",
        "        status = \"✓\" if v['all_correct'] else \"✗\"\n",
        "        print(f\"{k_sigma:<10.1f} {v['max_arrivals_value']:<12} {v['max_departures_value']:<12} \"\n",
        "              f\"{v['actual_min_value']:<10} {v['actual_max_value']:<10} {v['actual_pmf_length']:<12} {status:<10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detailed view of subspecialty: Oncology - Gynae - Clinical\n",
            "\n",
            "PredictionBundle(subspecialty: Oncology - Gynae - Clinical)\n",
            "  Arrivals:    PMF[0:10]: [0.849, 0.140, 0.011, 0.001, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000] (E=0.2)\n",
            "  Departures:  PMF[0:3]: [0.905, 0.095, 0.000] (E=0.1)\n",
            "  Net flow:    PMF[-2:8]: [0.000, 0.081, 0.781, 0.128, 0.010, 0.000, 0.000, 0.000, 0.000, 0.000] (E=0.1)\n",
            "  Flows:       selection cohort=all inflows(ed_current=True, ed_yta=True, non_ed_yta=True, elective_yta=True, transfers_in=True) outflows(departures=True)\n",
            "\n",
            "\n",
            "Arrivals PMF (first 20 values):\n",
            "[8.48694244e-01 1.39805058e-01 1.09366768e-02 5.45197028e-04\n",
            " 1.83986641e-05 4.18752076e-07 6.35445372e-09 6.36642404e-11\n",
            " 4.18183760e-13 1.80973266e-15 5.31576184e-18 1.09678047e-20\n",
            " 1.63744117e-23 1.81122916e-26 1.51211119e-29 9.66733306e-33\n",
            " 4.78723204e-36 1.85225818e-39 5.63508145e-43 1.35349652e-46]\n",
            "\n",
            "Departures PMF (first 20 values):\n",
            "[0.90469798 0.09530202 0.        ]\n",
            "\n",
            "Net Flow PMF (first 20 values, offset=-2):\n",
            "[0.00000000e+00 8.08822721e-02 7.81135676e-01 1.27523642e-01\n",
            " 9.94634782e-03 4.94992082e-04 1.66851423e-05 3.79449751e-07\n",
            " 5.75492880e-09 5.76367637e-11 3.78502476e-13 1.63776810e-15\n",
            " 4.81020427e-18 9.92411128e-21 1.48156234e-23 1.63875948e-26\n",
            " 1.36809608e-29 8.74647296e-33 4.33117570e-36 1.67578794e-39]\n"
          ]
        }
      ],
      "source": [
        "# Choose a subspecialty to inspect in detail\n",
        "spec_to_inspect = list(subspecialty_data.keys())[0]\n",
        "spec_key = f\"subspecialty:{spec_to_inspect}\"\n",
        "\n",
        "if spec_key in new_results:\n",
        "    spec_bundle = new_results[spec_key]\n",
        "    print(f\"Detailed view of subspecialty: {spec_to_inspect}\")\n",
        "    print(f\"\\n{spec_bundle}\")\n",
        "    \n",
        "    # Show PMF arrays\n",
        "    print(f\"\\n\\nArrivals PMF (first 20 values):\")\n",
        "    print(spec_bundle.arrivals.probabilities[:20])\n",
        "    \n",
        "    print(f\"\\nDepartures PMF (first 20 values):\")\n",
        "    print(spec_bundle.departures.probabilities[:20])\n",
        "    \n",
        "    print(f\"\\nNet Flow PMF (first 20 values, offset={spec_bundle.net_flow.offset}):\")\n",
        "    print(spec_bundle.net_flow.probabilities[:20])\n",
        "else:\n",
        "    print(f\"Could not find {spec_key} in results\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "patientflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
