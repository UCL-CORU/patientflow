{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#patientflow-code-and-training-materials-for-predicting-short-term-hospital-bed-capacity-using-real-time-data","title":"PatientFlow: Code and training materials for predicting short-term hospital bed capacity using real-time data","text":"<p>Welcome to the PatientFlow repo, which is designed to support hospital bed management through predictive modelling. The repository shows methods for forecasting short-term bed capacity, a crucial aspect of hospital operations that impacts patient care and resource allocation.</p> <p>Please note that you are looking at this repo prior to its first release. It is incomplete.</p>"},{"location":"#objectives","title":"Objectives","text":"<ol> <li>Develop code that was originally written for University College London Hospital into a reusable resource following the principles of Reproducible Analytical Pipelines</li> <li>Share the resource with analysts, bed managers and other interested parties in the NHS and other hospital systems</li> <li>Provide training materials to inform and educate anyone who wishes to adopt a similar approach</li> </ol>"},{"location":"#main-features-of-our-modelling-approach","title":"Main Features of our modelling approach","text":"<ul> <li>User led: This work is the result of close collaboration with operations directors and bed managers in the Coordination Centre, University College London Hospital (UCLH), over four years. What is modelled directly reflects how they work and what is most useful to them.</li> <li>Focused on short-term predictions: We demonstrate the creation and evaluation of predictive models. The output from these models is a prediction of how many beds with be needed by patients within a short time horizon of (say) 8 hours. (Later we plan to add modules that also predict supply and net bed position over the same period.)</li> <li>Assumes real-time data is available: Our focus is on how hospitals can make use of real-time data to make informed decisions on the ground. All the modelling here assumes that a hospital has some capacity to run models using real-time (or near to real-time) data in its electronic health record, even if this data is minimal (see next point).</li> <li>Demonstrates prediction with minimal data: Recognising that some hospitals are not set up for real-time data modelling, we also demonstrate how short-term demand forecasting could be done using only the datapoints collected for the Operational Pressures Escalation Levels (OPEL) Framework</li> </ul>"},{"location":"#main-features-of-this-repository","title":"Main Features of this repository","text":"<ul> <li>Reproducible - We follow the principles of Reproducible Analytical Pipelines, with the aim that the code can be easily adopted in other settings</li> <li>Accessible - All the elements are based on simple techniques and methods in Health Data Science and Operational Research. The narrative in the notebooks is intended to be accessible to someone without any knowledge of programming; it should still be possible to follow the approach. We intend that anyone with some knowledge of Python could understand and adapt the code for their use.</li> <li>Modular: The repository is structured into submodules, each intended to predict specific aspects of bed capacity (supply of empty beds, demand for beds and net position in 8 hours' time).</li> <li>Interactive: The repository includes an accompanying set of notebooks with code written on Python, and notebooks that will be runable on Colab and BinderHub.</li> <li>Practical: We hope to include a dataset, derived from the work we did at University College London Hospital, which can be used to step through the modelling process. This means that, even if your hospital is not set up to do real-time prediction yet, you can still follow the same steps we took. We are currently working on a Data Protection Impact Assessment (DPIA) with our colleagues at UCLH.</li> </ul>"},{"location":"#main-features-of-this-repository_1","title":"Main Features of this repository","text":"<ul> <li>Exploration: Start with the notebooks README to get an outline of the training materials we intend to provide for modelling of emergency demand for beds, and read the patientflow README to understand our intentions for the Python package</li> <li>[Coming later] Installation: Follow the instructions in setup.py to set up the environment and install necessary dependencies</li> <li>[Coming later] Configuration: Utilise environment.yml and requirements.txt to configure your environment to run these models</li> </ul>"},{"location":"#about","title":"About","text":"<p>This project was inspired by the excellent py-pi template developed by Tom Monks, and is developed in collaboration with the Centre for Advanced Research Computing, University College London.</p>"},{"location":"#project-team","title":"Project Team","text":"<p>Zella King (zella.king@ucl.ac.uk)</p>"},{"location":"#research-software-engineering-contact","title":"Research Software Engineering Contact","text":"<p>Centre for Advanced Research Computing, University College London (arc.collaborations@ucl.ac.uk)</p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p><code>patientflow</code> requires Python 3.6.</p>"},{"location":"#installation","title":"Installation","text":"<p>We recommend installing in a project specific virtual environment created using a environment management tool such as Conda. To install the latest development version of <code>patientflow</code> using <code>pip</code> in the currently active environment run</p> <pre><code>pip install git+https://github.com/zmek/patientflow.git\n</code></pre> <p>Alternatively create a local clone of the repository with</p> <pre><code>git clone https://github.com/zmek/patientflow.git\n</code></pre> <p>and then install in editable mode by running</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"#running-locally","title":"Running Locally","text":"<p>How to run the application on your local system.</p>"},{"location":"#running-tests","title":"Running Tests","text":"<p>Tests can be run across all compatible Python versions in isolated environments using <code>tox</code> by running</p> <pre><code>tox\n</code></pre> <p>To run tests manually in a Python environment with <code>pytest</code> installed run</p> <pre><code>pytest tests\n</code></pre> <p>again from the root of the repository.</p>"},{"location":"#building-documentation","title":"Building Documentation","text":"<p>The MkDocs HTML documentation can be built locally by running</p> <pre><code>tox -e docs\n</code></pre> <p>from the root of the repository. The built documentation will be written to <code>site</code>.</p> <p>Alternatively to build and preview the documentation locally, in a Python environment with the optional <code>docs</code> dependencies installed, run</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li> Initial Research</li> <li> Minimum viable product &lt;-- You are Here</li> <li> Alpha Release</li> <li> Feature-Complete Release</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This work was funded by a grant from the UCL Impact Funding.</p>"},{"location":"LICENSE/","title":"License","text":""},{"location":"LICENSE/#mit-license","title":"MIT License","text":"<p>Copyright (c) 2024 Zella King</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"api/","title":"API reference","text":"<p>Introductory text here</p> <p>test_package</p> <p>Part of a repo containing boilerplate code for publishing on PyPi.</p>"},{"location":"api/#patientflow.predict","title":"<code>predict</code>","text":""},{"location":"api/#patientflow.predict.emergency_demand","title":"<code>emergency_demand</code>","text":""},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve","title":"<code>admission_in_prediction_window_using_aspirational_curve</code>","text":"<p>This module provides functions to model and analyze a curve consisting of an exponential growth segment followed by an exponential decay segment. It includes functions to create the curve, calculate specific points on it, and evaluate probabilities based on its shape.</p> <p>Its intended use is to derive the probability of a patient being admitted to a hospital within a certain elapsed time after their arrival in the Emergency Department (ED), given the hospital's aspirations for the time it takes patients to be admitted. For this purpose, two points on the curve are required as parameters: (x1,y1) : The target proportion of patients y1 (eg 76%) who have been admitted or discharged by time x1 (eg 4 hours). It is assumed that values of y where x &lt; x1 is a growth curve grow exponentially towards x1 and that (x1,y1) the curve switches to a decay curve (x2, y2) : The time x2 by which all but a small proportion y2 of patients have been admitted.</p> <p>The curve is generated by the following functions:</p> <ul> <li>growth_curve: Calculate exponential growth at a point where x &lt; x1.</li> <li>decay_curve: Calculate exponential decay at a point where x &gt;= x1.</li> <li>create_curve: Generate a full curve with both growth and decay segments.</li> </ul> <p>The curve is applied as follows - get_y_from_aspirational_curve: Read from the curve a value for y, the probability of being admitted, for a given moment x hours after arrival - calculate_probability: Compute the probability of a patient being admitted by the end of a prediction window, given how much time has elapsed since their arrival.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.calculate_probability","title":"<code>calculate_probability(elapsed_los_td_hrs, prediction_window_hrs, x1, y1, x2, y2)</code>","text":"<p>Calculates the probability of an admission occurring within a specified prediction window after the moment of prediction, based on the patient's elapsed time in the ED prior to the moment of prediction and the length of the window</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.calculate_probability--parameters","title":"Parameters","text":"<p>elapsed_los_td_hrs : float     The elapsed time since the patient arrived at the ED. prediction_window_hrs : float     The duration of the prediction window after the point of prediction, for which the probability is calculated. (x1,y1) :     An aspirational target, expressed in the form of a point on a curve, representing a proportion of patients y1 (eg 76%) who - if the ED meets its targets - will be admitted or discharged by time x1 (eg 4 hours). (x2,y2) :     An aspirational target, expressed in the form of a point on a curve, representing a time x2 by which all but a small proportion y2 of patients have been admitted if the ED meets its targets.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.calculate_probability--returns","title":"Returns","text":"<p>float     The probability of the event occurring within the given prediction window.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.calculate_probability--edge-case-handling","title":"Edge Case Handling","text":"<p>When elapsed_los_td_hrs is extremely high, such as values significantly greater than x2, the admission probability prior to the current time (<code>prob_admission_prior_to_now</code>) can reach 1.0 despite the curve being asymptotic. This scenario can cause computational errors when calculating the conditional probability, as it involves a division by zero. In such cases, this function directly returns a probability of 1.0, reflecting certainty of admission.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.calculate_probability--example","title":"Example","text":"<p>Calculate the probability that a patient, who has already been in the ED for 3 hours, will be admitted in the next 2 hours. The ED targets that 76% of patients are admitted or discharged within 4 hours, and 99% within 12 hours.</p> <p>calculate_probability(3, 2, 4, 0.76, 12, 0.99)</p> Source code in <code>src/patientflow/predict/emergency_demand/admission_in_prediction_window_using_aspirational_curve.py</code> <pre><code>def calculate_probability(elapsed_los_td_hrs, prediction_window_hrs, x1, y1, x2, y2):\n    \"\"\"\n    Calculates the probability of an admission occurring within a specified prediction window after the moment of prediction, based on the patient's elapsed time in the ED prior to the moment of prediction and the length of the window\n\n    Parameters\n    ----------\n    elapsed_los_td_hrs : float\n        The elapsed time since the patient arrived at the ED.\n    prediction_window_hrs : float\n        The duration of the prediction window after the point of prediction, for which the probability is calculated.\n    (x1,y1) :\n        An aspirational target, expressed in the form of a point on a curve, representing a proportion of patients y1 (eg 76%) who - if the ED meets its targets - will be admitted or discharged by time x1 (eg 4 hours).\n    (x2,y2) :\n        An aspirational target, expressed in the form of a point on a curve, representing a time x2 by which all but a small proportion y2 of patients have been admitted if the ED meets its targets.\n\n    Returns\n    -------\n    float\n        The probability of the event occurring within the given prediction window.\n\n    Edge Case Handling\n    ------------------\n    When elapsed_los_td_hrs is extremely high, such as values significantly greater than x2, the admission probability prior to the current time (`prob_admission_prior_to_now`) can reach 1.0 despite the curve being asymptotic. This scenario can cause computational errors when calculating the conditional probability, as it involves a division by zero. In such cases, this function directly returns a probability of 1.0, reflecting certainty of admission.\n\n    Example\n    -------\n    Calculate the probability that a patient, who has already been in the ED for 3 hours, will be admitted in the next 2 hours. The ED targets that 76% of patients are admitted or discharged within 4 hours, and 99% within 12 hours.\n\n    &gt;&gt;&gt; calculate_probability(3, 2, 4, 0.76, 12, 0.99)\n\n    \"\"\"\n    # probability of still being in the ED now (a function of elapsed time since arrival)\n    prob_admission_prior_to_now = get_y_from_aspirational_curve(\n        elapsed_los_td_hrs, x1, y1, x2, y2\n    )\n\n    # prob admission when adding the prediction window added to elapsed time since arrival\n    prob_admission_by_end_of_window = get_y_from_aspirational_curve(\n        elapsed_los_td_hrs + prediction_window_hrs, x1, y1, x2, y2\n    )\n\n    # Direct return for edge cases where `prob_admission_prior_to_now` reaches 1.0\n    if prob_admission_prior_to_now == 1:\n        return 1.0\n\n    # Calculate conditional probability within the prediction window\n    return (prob_admission_by_end_of_window - prob_admission_prior_to_now) / (\n        1 - prob_admission_prior_to_now\n    )\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.create_curve","title":"<code>create_curve(x1, y1, x2, y2, a=0.01, generate_values=False)</code>","text":"<p>Generates parameters for an exponential growth and decay curve. Optionally generates x-values and corresponding y-values across a default or specified range.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.create_curve--parameters","title":"Parameters","text":"<p>x1 : float     The x-value where the curve transitions from growth to decay. y1 : float     The y-value at the transition point x1. x2 : float     The x-value defining the end of the decay curve for calculation purposes. y2 : float     The y-value at x2, intended to fine-tune the decay rate. a : float, optional     The initial value coefficient for the growth curve, defaults to 0.01. generate_values : bool, optional     Flag to determine whether to generate x-values and y-values for visualization purposes.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.create_curve--returns","title":"Returns","text":"<p>tuple     If generate_values is False, returns (gamma, lamda, a).     If generate_values is True, returns (gamma, lamda, a, x_values, y_values).</p> Source code in <code>src/patientflow/predict/emergency_demand/admission_in_prediction_window_using_aspirational_curve.py</code> <pre><code>def create_curve(x1, y1, x2, y2, a=0.01, generate_values=False):\n    \"\"\"\n    Generates parameters for an exponential growth and decay curve.\n    Optionally generates x-values and corresponding y-values across a default or specified range.\n\n    Parameters\n    ----------\n    x1 : float\n        The x-value where the curve transitions from growth to decay.\n    y1 : float\n        The y-value at the transition point x1.\n    x2 : float\n        The x-value defining the end of the decay curve for calculation purposes.\n    y2 : float\n        The y-value at x2, intended to fine-tune the decay rate.\n    a : float, optional\n        The initial value coefficient for the growth curve, defaults to 0.01.\n    generate_values : bool, optional\n        Flag to determine whether to generate x-values and y-values for visualization purposes.\n\n    Returns\n    -------\n    tuple\n        If generate_values is False, returns (gamma, lamda, a).\n        If generate_values is True, returns (gamma, lamda, a, x_values, y_values).\n\n    \"\"\"\n    # Validate inputs\n    if not (x1 &lt; x2):\n        raise ValueError(\"x1 must be less than x2\")\n    if not (0 &lt; y1 &lt; y2 &lt; 1):\n        raise ValueError(\"y1 must be less than y2, and both must be between 0 and 1\")\n\n    # Constants for growth and decay\n    gamma = np.log(y1 / a) / x1\n    lamda = np.log((1 - y1) / (1 - y2)) / (x2 - x1)\n\n    if generate_values:\n        x_values = np.linspace(0, 20, 200)\n        y_values = [\n            (growth_curve(x, a, gamma) if x &lt;= x1 else decay_curve(x, x1, y1, lamda))\n            for x in x_values\n        ]\n        return gamma, lamda, a, x_values, y_values\n\n    return gamma, lamda, a\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.decay_curve","title":"<code>decay_curve(x, x1, y1, lamda)</code>","text":"<p>Calculate the exponential decay value at a given x using specified parameters. The function supports both scalar and array inputs for x.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.decay_curve--parameters","title":"Parameters","text":"<p>x : float or np.ndarray     The x-value(s) at which to evaluate the curve. x1 : float     The x-value where the growth curve transitions to the decay curve. y1 : float     The y-value at the transition point, where the decay curve starts. lamda : float     The decay rate coefficient.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.decay_curve--returns","title":"Returns","text":"<p>float or np.ndarray     The y-value(s) of the decay curve at x.</p> Source code in <code>src/patientflow/predict/emergency_demand/admission_in_prediction_window_using_aspirational_curve.py</code> <pre><code>def decay_curve(x, x1, y1, lamda):\n    \"\"\"\n    Calculate the exponential decay value at a given x using specified parameters.\n    The function supports both scalar and array inputs for x.\n\n    Parameters\n    ----------\n    x : float or np.ndarray\n        The x-value(s) at which to evaluate the curve.\n    x1 : float\n        The x-value where the growth curve transitions to the decay curve.\n    y1 : float\n        The y-value at the transition point, where the decay curve starts.\n    lamda : float\n        The decay rate coefficient.\n\n    Returns\n    -------\n    float or np.ndarray\n        The y-value(s) of the decay curve at x.\n\n    \"\"\"\n    return y1 + (1 - y1) * (1 - np.exp(-lamda * (x - x1)))\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.get_y_from_aspirational_curve","title":"<code>get_y_from_aspirational_curve(x, x1, y1, x2, y2)</code>","text":"<p>Calculate the probability y that a patient will have been admitted by a specified x after their arrival, by reading from the aspirational curve that has been constrained to pass through points (x1, y1) and (x2, y2) with an exponential growth curve where x &lt; x1 and an exponential decay where x &lt; x2</p> <p>The function handles scalar or array inputs for x and determines y using either an exponential growth curve (for x &lt; x1) or an exponential decay curve (for x &gt;= x1). The curve parameters are derived to ensure the curve passes through specified points (x1, y1) and (x2, y2).</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.get_y_from_aspirational_curve--parameters","title":"Parameters","text":"<p>x : float or np.ndarray     The x-coordinate(s) at which to calculate the y-value on the curve. Can be a single value or an array of values. x1 : float     The x-coordinate of the first key point on the curve, where the growth phase ends and the decay phase begins. y1 : float     The y-coordinate of the first key point (x1), representing the target proportion of patients admitted by time x1. x2 : float     The x-coordinate of the second key point on the curve, beyond which all but a few patients are expected to be admitted. y2 : float     The y-coordinate of the second key point (x2), representing the target proportion of patients admitted by time x2.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.get_y_from_aspirational_curve--returns","title":"Returns","text":"<p>float or np.ndarray     The calculated y-value(s) (probability of admission) at the given x. The type of the return matches the input type     for x (either scalar or array).</p> Source code in <code>src/patientflow/predict/emergency_demand/admission_in_prediction_window_using_aspirational_curve.py</code> <pre><code>def get_y_from_aspirational_curve(x, x1, y1, x2, y2):\n    \"\"\"\n    Calculate the probability y that a patient will have been admitted by a specified x after their arrival, by reading from the aspirational curve that has been constrained to pass through points (x1, y1) and (x2, y2) with an exponential growth curve where x &lt; x1 and an exponential decay where x &lt; x2\n\n    The function handles scalar or array inputs for x and determines y using either an exponential growth curve (for x &lt; x1)\n    or an exponential decay curve (for x &gt;= x1). The curve parameters are derived to ensure the curve passes through\n    specified points (x1, y1) and (x2, y2).\n\n    Parameters\n    ----------\n    x : float or np.ndarray\n        The x-coordinate(s) at which to calculate the y-value on the curve. Can be a single value or an array of values.\n    x1 : float\n        The x-coordinate of the first key point on the curve, where the growth phase ends and the decay phase begins.\n    y1 : float\n        The y-coordinate of the first key point (x1), representing the target proportion of patients admitted by time x1.\n    x2 : float\n        The x-coordinate of the second key point on the curve, beyond which all but a few patients are expected to be admitted.\n    y2 : float\n        The y-coordinate of the second key point (x2), representing the target proportion of patients admitted by time x2.\n\n    Returns\n    -------\n    float or np.ndarray\n        The calculated y-value(s) (probability of admission) at the given x. The type of the return matches the input type\n        for x (either scalar or array).\n\n    \"\"\"\n    gamma, lamda, a = create_curve(x1, y1, x2, y2)\n    y = np.where(x &lt; x1, growth_curve(x, a, gamma), decay_curve(x, x1, y1, lamda))\n    return y\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.growth_curve","title":"<code>growth_curve(x, a, gamma)</code>","text":"<p>Calculate the exponential growth value at a given x using specified parameters. The function supports both scalar and array inputs for x.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.growth_curve--parameters","title":"Parameters","text":"<p>x : float or np.ndarray     The x-value(s) at which to evaluate the curve. a : float     The coefficient that defines the starting point of the growth curve when x is 0. gamma : float     The growth rate coefficient of the curve.</p>"},{"location":"api/#patientflow.predict.emergency_demand.admission_in_prediction_window_using_aspirational_curve.growth_curve--returns","title":"Returns","text":"<p>float or np.ndarray     The y-value(s) of the growth curve at x.</p> Source code in <code>src/patientflow/predict/emergency_demand/admission_in_prediction_window_using_aspirational_curve.py</code> <pre><code>def growth_curve(x, a, gamma):\n    \"\"\"\n    Calculate the exponential growth value at a given x using specified parameters.\n    The function supports both scalar and array inputs for x.\n\n    Parameters\n    ----------\n    x : float or np.ndarray\n        The x-value(s) at which to evaluate the curve.\n    a : float\n        The coefficient that defines the starting point of the growth curve when x is 0.\n    gamma : float\n        The growth rate coefficient of the curve.\n\n    Returns\n    -------\n    float or np.ndarray\n        The y-value(s) of the growth curve at x.\n\n    \"\"\"\n    return a * np.exp(x * gamma)\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs","title":"<code>from_individual_probs</code>","text":"<p>Emergency Demand Prediction From Patient-Level Probababilities</p> <p>This submodule provides functions to predict demand as a probability distribution, based on inputs that are patient-level probabilities. The module uses symbolic mathematics to build and manipulate expressions dynamically, facilitating the computation of aggregate demand probabilities.</p> Dependencies <ul> <li>numpy: Used for array and numerical operations.</li> <li>pandas: Utilized for handling data structures like DataFrames, enabling data manipulation and analysis.</li> <li>sympy: A Python library for symbolic mathematics, used here to dynamically create and manipulate symbolic expressions, particularly for the calculation of probabilities.</li> </ul> <p>Functions: - create_symbols(n): Generates symbolic variables. - compute_core_expression(ri, s): Computes a symbolic expression involving both symbols and constants. - build_expression(syms, n): Constructs a cumulative product of symbolic expressions. - expression_subs(expression, n, predictions): Substitutes numerical values into a symbolic expression. - return_coeff(expression, i): Extracts coefficients from expanded symbolic expressions. - model_input_to_pred_proba(model_input, model): Converts model input data into predicted probabilities. - pred_proba_to_pred_demand(predictions_proba, weights): Aggregates probability predictions into demand predictions. - get_prob_dist_for_prediction_moment(X_test, model, weights, y_test, inference_time): Calculates predicted and (if not inference time) actual demands for a specific date. - get_prob_dist(snapshots_dict, X_test, y_test, model, weights): Computes probability distributions for multiple snapshot dates.</p> <p>These functions can work with any model object as long as it provides the predict_proba method. This icludes libraries (like scikit-learn, TensorFlow, or PyTorch), which generally offer this method</p> Example Usage Note <p>This module is designed to be generic and can be adapted to various domains where probabilistic demand prediction is applicable. Ensure that the input data and the model adhere to the expected formats and conventions as required by the functions.</p> <p>Author: Zella King Date: 25.03.24 Version: 0.1</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs--assuming-a-predictive-model-and-test-data-are-available","title":"Assuming a predictive model and test data are available","text":"<p>snapshot_dates = ['2023-01-01', '2023-01-02'] predicted_distribution = get_prob_dist(snapshot_dates, dataset, X_test, y_test, model) print(predicted_distribution)</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.build_expression","title":"<code>build_expression(syms, n)</code>","text":"<p>Construct a cumulative product expression by combining individual symbolic expressions.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.build_expression--parameters","title":"Parameters","text":"<p>syms : iterable     Iterable containing symbols to use in the expressions. n : int     The number of terms to include in the cumulative product.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.build_expression--returns","title":"Returns","text":"<p>Expr     The cumulative product of the expressions.</p> Source code in <code>src/patientflow/predict/emergency_demand/from_individual_probs.py</code> <pre><code>def build_expression(syms, n):\n    \"\"\"\n    Construct a cumulative product expression by combining individual symbolic expressions.\n\n    Parameters\n    ----------\n    syms : iterable\n        Iterable containing symbols to use in the expressions.\n    n : int\n        The number of terms to include in the cumulative product.\n\n    Returns\n    -------\n    Expr\n        The cumulative product of the expressions.\n\n    \"\"\"\n    s = sym.Symbol(\"s\")\n    expression = 1\n    for i in range(n):\n        expression *= compute_core_expression(syms[i], s)\n    return expression\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.compute_core_expression","title":"<code>compute_core_expression(ri, s)</code>","text":"<p>Compute a symbolic expression involving a basic mathematical operation with a symbol and a constant.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.compute_core_expression--parameters","title":"Parameters","text":"<p>ri : float     The constant value to substitute into the expression. s : Symbol     The symbolic object used in the expression.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.compute_core_expression--returns","title":"Returns","text":"<p>Expr     The symbolic expression after substitution.</p> Source code in <code>src/patientflow/predict/emergency_demand/from_individual_probs.py</code> <pre><code>def compute_core_expression(ri, s):\n    \"\"\"\n    Compute a symbolic expression involving a basic mathematical operation with a symbol and a constant.\n\n    Parameters\n    ----------\n    ri : float\n        The constant value to substitute into the expression.\n    s : Symbol\n        The symbolic object used in the expression.\n\n    Returns\n    -------\n    Expr\n        The symbolic expression after substitution.\n\n    \"\"\"\n    r = sym.Symbol(\"r\")\n    core_expression = (1 - r) + r * s\n    return core_expression.subs({r: ri})\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.create_symbols","title":"<code>create_symbols(n)</code>","text":"<p>Generate a sequence of symbolic objects intended for use in mathematical expressions.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.create_symbols--parameters","title":"Parameters","text":"<p>n : int     Number of symbols to create.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.create_symbols--returns","title":"Returns","text":"<p>tuple     A tuple containing the generated symbolic objects.</p> Source code in <code>src/patientflow/predict/emergency_demand/from_individual_probs.py</code> <pre><code>def create_symbols(n):\n    \"\"\"\n    Generate a sequence of symbolic objects intended for use in mathematical expressions.\n\n    Parameters\n    ----------\n    n : int\n        Number of symbols to create.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the generated symbolic objects.\n\n    \"\"\"\n    return symbols(f\"r0:{n}\")\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.expression_subs","title":"<code>expression_subs(expression, n, predictions)</code>","text":"<p>Substitute values into a symbolic expression based on a mapping from symbols to predictions.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.expression_subs--parameters","title":"Parameters","text":"<p>expression : Expr     The symbolic expression to perform substitution on. n : int     Number of symbols and corresponding predictions. predictions : list     List of numerical predictions to substitute.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.expression_subs--returns","title":"Returns","text":"<p>Expr     The expression after performing the substitution.</p> Source code in <code>src/patientflow/predict/emergency_demand/from_individual_probs.py</code> <pre><code>def expression_subs(expression, n, predictions):\n    \"\"\"\n    Substitute values into a symbolic expression based on a mapping from symbols to predictions.\n\n    Parameters\n    ----------\n    expression : Expr\n        The symbolic expression to perform substitution on.\n    n : int\n        Number of symbols and corresponding predictions.\n    predictions : list\n        List of numerical predictions to substitute.\n\n    Returns\n    -------\n    Expr\n        The expression after performing the substitution.\n\n    \"\"\"\n    syms = create_symbols(n)\n    substitution = dict(zip(syms, predictions))\n    return expression.subs(substitution)\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.get_prob_dist","title":"<code>get_prob_dist(snapshots_dict, X_test, y_test, model, weights=None)</code>","text":"<p>Calculate probability distributions for each snapshot date based on given model predictions.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.get_prob_dist--parameters","title":"Parameters","text":"<p>snapshots_dict : dict     A dictionary mapping snapshot dates (as datetime objects) to indices in <code>X_test</code> and <code>y_test</code>     that correspond to the snapshots to be tested for each date. X_test : pandas.DataFrame     A DataFrame containing the test features for prediction. y_test : pandas.Series     A Series containing the true outcome values corresponding to the test features in <code>X_test</code>. model : any     A predictive model object with a <code>predict_proba</code> method that takes features from <code>X_test</code> and     optionally weights, and returns a probability distribution over possible outcomes. weights : pandas.Series, optional     A Series containing weights for the test data points, which may influence the prediction,     by default None. If provided, the weights should be indexed similarly to <code>X_test</code> and <code>y_test</code>.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.get_prob_dist--returns","title":"Returns","text":"<p>dict     A dictionary where each key is a snapshot date and each value is the resulting probability     distribution for that date, obtained by applying the model on the corresponding test snapshots.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.get_prob_dist--notes","title":"Notes","text":"<ul> <li>The function asserts that the length of the test features and outcomes are equal for each   snapshot before proceeding with predictions.</li> <li>It notifies the user of progress in processing snapshot dates, especially if there are more   than 10 snapshot dates.</li> </ul> Source code in <code>src/patientflow/predict/emergency_demand/from_individual_probs.py</code> <pre><code>def get_prob_dist(snapshots_dict, X_test, y_test, model, weights=None):\n    \"\"\"\n    Calculate probability distributions for each snapshot date based on given model predictions.\n\n    Parameters\n    ----------\n    snapshots_dict : dict\n        A dictionary mapping snapshot dates (as datetime objects) to indices in `X_test` and `y_test`\n        that correspond to the snapshots to be tested for each date.\n    X_test : pandas.DataFrame\n        A DataFrame containing the test features for prediction.\n    y_test : pandas.Series\n        A Series containing the true outcome values corresponding to the test features in `X_test`.\n    model : any\n        A predictive model object with a `predict_proba` method that takes features from `X_test` and\n        optionally weights, and returns a probability distribution over possible outcomes.\n    weights : pandas.Series, optional\n        A Series containing weights for the test data points, which may influence the prediction,\n        by default None. If provided, the weights should be indexed similarly to `X_test` and `y_test`.\n\n    Returns\n    -------\n    dict\n        A dictionary where each key is a snapshot date and each value is the resulting probability\n        distribution for that date, obtained by applying the model on the corresponding test snapshots.\n\n    Notes\n    -----\n    - The function asserts that the length of the test features and outcomes are equal for each\n      snapshot before proceeding with predictions.\n    - It notifies the user of progress in processing snapshot dates, especially if there are more\n      than 10 snapshot dates.\n\n    \"\"\"\n    prob_dist_dict = {}\n    print(\n        f\"Calculating probability distributions for {len(snapshots_dict)} snapshot dates\"\n    )\n\n    if len(snapshots_dict) &gt; 10:\n        print(\"This may take a minute or more\")\n\n    # Initialize a counter for notifying the user every 10 snapshot dates processed\n    count = 0\n\n    for dt, snapshots_to_include in snapshots_dict.items():\n        # Ensure the lengths of test features and outcomes are equal\n        assert len(X_test.loc[snapshots_to_include]) == len(\n            y_test.loc[snapshots_to_include]\n        ), \"Mismatch in lengths of X_test and y_test snapshots.\"\n\n        if weights is None:\n            prediction_moment_weights = None\n        else:\n            prediction_moment_weights = weights.loc[snapshots_to_include].values\n\n        # Compute the predicted and actual demand for the current snapshot date\n        prob_dist_dict[dt] = get_prob_dist_for_prediction_moment(\n            X_test=X_test.loc[snapshots_to_include],\n            y_test=y_test.loc[snapshots_to_include],\n            model=model,\n            weights=prediction_moment_weights,\n        )\n\n        # Increment the counter and notify the user every 10 snapshot dates processed\n        count += 1\n        if count % 10 == 0 and count != len(snapshots_dict):\n            print(f\"Processed {count} snapshot dates\")\n\n    print(f\"Processed {len(snapshots_dict)} snapshot dates\")\n\n    return prob_dist_dict\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.get_prob_dist_for_prediction_moment","title":"<code>get_prob_dist_for_prediction_moment(X_test, model, weights=None, inference_time=False, y_test=None)</code>","text":"<p>Calculate both predicted and actual demand distributions for a given date using test data.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.get_prob_dist_for_prediction_moment--parameters","title":"Parameters","text":"<p>X_test : array-like     Test features for a specific snapshot date. model : object     A predictive model which should provide a <code>predict_proba</code> method. weights : array-like, optional     Weights to apply to the predictions for demand calculation. inference_time : bool, optional (default=False)     If True, do not calculate or return actual demand. y_test : array-like, optional     Actual outcomes corresponding to the test features. Required if inference_time is False.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.get_prob_dist_for_prediction_moment--returns","title":"Returns","text":"<p>dict     A dictionary with keys 'pred_demand' and, if inference_time is False, 'actual_demand' containing the     predicted and actual demands respectively for the snapshot date. Each is presented as a DataFrame or an integer.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.get_prob_dist_for_prediction_moment--raises","title":"Raises","text":"<p>ValueError     If y_test is not provided when inference_time is False.</p> Source code in <code>src/patientflow/predict/emergency_demand/from_individual_probs.py</code> <pre><code>def get_prob_dist_for_prediction_moment(\n    X_test, model, weights=None, inference_time=False, y_test=None\n):\n    \"\"\"\n    Calculate both predicted and actual demand distributions for a given date using test data.\n\n    Parameters\n    ----------\n    X_test : array-like\n        Test features for a specific snapshot date.\n    model : object\n        A predictive model which should provide a `predict_proba` method.\n    weights : array-like, optional\n        Weights to apply to the predictions for demand calculation.\n    inference_time : bool, optional (default=False)\n        If True, do not calculate or return actual demand.\n    y_test : array-like, optional\n        Actual outcomes corresponding to the test features. Required if inference_time is False.\n\n    Returns\n    -------\n    dict\n        A dictionary with keys 'pred_demand' and, if inference_time is False, 'actual_demand' containing the\n        predicted and actual demands respectively for the snapshot date. Each is presented as a DataFrame or an integer.\n\n    Raises\n    ------\n    ValueError\n        If y_test is not provided when inference_time is False.\n\n    \"\"\"\n    if not inference_time and y_test is None:\n        raise ValueError(\"y_test must be provided if inference_time is False.\")\n\n    prediction_moment_dict = {}\n\n    if len(X_test) &gt; 0:\n        pred_proba = model_input_to_pred_proba(X_test, model)\n        pred_demand = pred_proba_to_pred_demand(pred_proba, weights)\n        prediction_moment_dict[\"pred_demand\"] = pred_demand\n\n        if not inference_time:\n            prediction_moment_dict[\"actual_demand\"] = sum(y_test)\n    else:\n        prediction_moment_dict[\"pred_demand\"] = pd.DataFrame(\n            {\"agg_proba\": [1]}, index=[0]\n        )\n        if not inference_time:\n            prediction_moment_dict[\"actual_demand\"] = 0\n\n    return prediction_moment_dict\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.model_input_to_pred_proba","title":"<code>model_input_to_pred_proba(model_input, model)</code>","text":"<p>Use a predictive model to convert model input data into predicted probabilities.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.model_input_to_pred_proba--parameters","title":"Parameters","text":"<p>model_input : array-like     The input data to the model, typically as features used for predictions. model : object     A model object with a <code>predict_proba</code> method that computes probability estimates.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.model_input_to_pred_proba--returns","title":"Returns","text":"<p>DataFrame     A pandas DataFrame containing the predicted probabilities for the positive class,     with one column labeled 'pred_proba'.</p> Source code in <code>src/patientflow/predict/emergency_demand/from_individual_probs.py</code> <pre><code>def model_input_to_pred_proba(model_input, model):\n    \"\"\"\n    Use a predictive model to convert model input data into predicted probabilities.\n\n    Parameters\n    ----------\n    model_input : array-like\n        The input data to the model, typically as features used for predictions.\n    model : object\n        A model object with a `predict_proba` method that computes probability estimates.\n\n    Returns\n    -------\n    DataFrame\n        A pandas DataFrame containing the predicted probabilities for the positive class,\n        with one column labeled 'pred_proba'.\n\n    \"\"\"\n    if len(model_input) == 0:\n        return pd.DataFrame(columns=[\"pred_proba\"])\n    else:\n        predictions = model.predict_proba(model_input)[:, 1]\n        return pd.DataFrame(\n            predictions, index=model_input.index, columns=[\"pred_proba\"]\n        )\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.pred_proba_to_pred_demand","title":"<code>pred_proba_to_pred_demand(predictions_proba, weights=None)</code>","text":"<p>Aggregate individual probability predictions into predicted demand using optional weights.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.pred_proba_to_pred_demand--parameters","title":"Parameters","text":"<p>predictions_proba : DataFrame     A DataFrame containing the probability predictions; must have a single column named 'pred_proba'. weights : array-like, optional     An array of weights, of the same length as the DataFrame rows, to apply to each prediction.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.pred_proba_to_pred_demand--returns","title":"Returns","text":"<p>DataFrame     A DataFrame with a single column 'agg_proba' showing the aggregated probability demand,     indexed from 0 to n, where n is the number of predictions.</p> Source code in <code>src/patientflow/predict/emergency_demand/from_individual_probs.py</code> <pre><code>def pred_proba_to_pred_demand(predictions_proba, weights=None):\n    \"\"\"\n    Aggregate individual probability predictions into predicted demand using optional weights.\n\n    Parameters\n    ----------\n    predictions_proba : DataFrame\n        A DataFrame containing the probability predictions; must have a single column named 'pred_proba'.\n    weights : array-like, optional\n        An array of weights, of the same length as the DataFrame rows, to apply to each prediction.\n\n    Returns\n    -------\n    DataFrame\n        A DataFrame with a single column 'agg_proba' showing the aggregated probability demand,\n        indexed from 0 to n, where n is the number of predictions.\n\n    \"\"\"\n    n = len(predictions_proba)\n\n    if n == 0:\n        pred_demand_dict = {0: 1}\n    else:\n        local_proba = predictions_proba.copy()\n        if weights is not None:\n            local_proba[\"pred_proba\"] *= weights\n\n        syms = create_symbols(n)\n        expression = build_expression(syms, n)\n        expression = expression_subs(expression, n, local_proba[\"pred_proba\"])\n        pred_demand_dict = {i: return_coeff(expression, i) for i in range(n + 1)}\n\n    pred_demand = pd.DataFrame.from_dict(\n        pred_demand_dict, orient=\"index\", columns=[\"agg_proba\"]\n    )\n    return pred_demand\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.return_coeff","title":"<code>return_coeff(expression, i)</code>","text":"<p>Extract the coefficient of a specified power from an expanded symbolic expression.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.return_coeff--parameters","title":"Parameters","text":"<p>expression : Expr     The expression to expand and extract from. i : int     The power of the term whose coefficient is to be extracted.</p>"},{"location":"api/#patientflow.predict.emergency_demand.from_individual_probs.return_coeff--returns","title":"Returns","text":"<p>number     The coefficient of the specified power in the expression.</p> Source code in <code>src/patientflow/predict/emergency_demand/from_individual_probs.py</code> <pre><code>def return_coeff(expression, i):\n    \"\"\"\n    Extract the coefficient of a specified power from an expanded symbolic expression.\n\n    Parameters\n    ----------\n    expression : Expr\n        The expression to expand and extract from.\n    i : int\n        The power of the term whose coefficient is to be extracted.\n\n    Returns\n    -------\n    number\n        The coefficient of the specified power in the expression.\n\n    \"\"\"\n    s = sym.Symbol(\"s\")\n    return expand(expression).coeff(s, i)\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.poisson_binomial_predictor","title":"<code>poisson_binomial_predictor</code>","text":"<p>Poisson-Binomial Admission Predictor</p> <p>This module implements a Poisson-Binomial admission predictor to estimate the number of hospital admissions within a specified prediction window using historical admission data. It applies Poisson and binomial distributions to forecast future admissions, excluding already arrived patients. The predictor accommodates different data filters for tailored predictions across various hospital settings.</p> Dependencies <ul> <li>pandas: For data manipulation and analysis, essential for handling the dataset used in predictions.</li> <li>datetime: For manipulating date and time objects, crucial for time-based predictions.</li> <li>sklearn: Utilizes BaseEstimator and TransformerMixin from scikit-learn for creating custom, interoperable predictors.</li> <li>Custom modules:<ul> <li>predict.emergency_demand.yet_to_arrive: Includes the Poisson-binomial generating function for prediction calculations.</li> <li>predict.emergency_demand.admission_in_prediction_window: Calculates the probability of admission within a specified prediction window.</li> <li>time_varying_arrival_rates: Computes time-varying arrival rates, a core component of the prediction algorithm.</li> </ul> </li> </ul> <p>Classes:</p> Name Description <code>PoissonBinomialPredictor</code> <p>Predicts the number of admissions within a given prediction window based on historical data and Poisson-binomial distribution.</p> <code>Methods within PoissonBinomialPredictor</code> <ul> <li>init(self, filters=None): Initializes the predictor with optional data filters.</li> <li>filter_dataframe(self, df, filters): Applies filters to the dataset for targeted predictions.</li> <li>fit(self, train_df, prediction_window, time_interval, prediction_times, json_file_path, reference_year, y=None): Trains the predictor using historical data and various parameters.</li> <li>predict(self, prediction_context): Predicts the number of admissions using the trained model.</li> </ul> <p>This module is designed for flexibility and customization to suit different prediction needs in hospital environments.</p>"},{"location":"api/#patientflow.predict.emergency_demand.poisson_binomial_predictor.PoissonBinomialPredictor","title":"<code>PoissonBinomialPredictor</code>","text":"<p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>A class to predict an aspirational number of admissions within a specified prediction window. This prediction does not include patients who have already arrived and is based on historical data. The prediction uses a combination of Poisson and binomial distributions.</p> <p>Attributes     None</p> <p>Methods     init(self, filters=None): Initializes the predictor with optional filters for data categorization.     filter_dataframe(self, df, filters): Filters the dataset based on specified criteria for targeted predictions.     fit(self, train_df, prediction_window, time_interval, prediction_times, json_file_path, reference_year, y=None): Trains the model using historical data and prediction parameters.     predict(self, prediction_context): Predicts the number of admissions for a given context after the model is trained.     get_weights(self): Retrieves the model parameters computed during fitting.</p> Source code in <code>src/patientflow/predict/emergency_demand/poisson_binomial_predictor.py</code> <pre><code>class PoissonBinomialPredictor(BaseEstimator, TransformerMixin):\n    \"\"\"\n    A class to predict an aspirational number of admissions within a specified prediction window.\n    This prediction does not include patients who have already arrived and is based on historical data.\n    The prediction uses a combination of Poisson and binomial distributions.\n\n    Attributes\n        None\n\n    Methods\n        __init__(self, filters=None): Initializes the predictor with optional filters for data categorization.\n        filter_dataframe(self, df, filters): Filters the dataset based on specified criteria for targeted predictions.\n        fit(self, train_df, prediction_window, time_interval, prediction_times, json_file_path, reference_year, y=None): Trains the model using historical data and prediction parameters.\n        predict(self, prediction_context): Predicts the number of admissions for a given context after the model is trained.\n        get_weights(self): Retrieves the model parameters computed during fitting.\n\n    \"\"\"\n\n    def __init__(self, filters=None):\n        \"\"\"\n        Initialize the PoissonBinomialPredictor with optional filters.\n\n        Args:\n            filters (dict, optional): A dictionary defining filters for different categories or specialties.\n                                      If None or empty, no filtering will be applied.\n\n        \"\"\"\n        self.filters = filters if filters else {}\n\n    def filter_dataframe(self, df: pd.DataFrame, filters: Dict) -&gt; pd.DataFrame:\n        \"\"\"\n        Apply a set of filters to a dataframe.\n\n        Args:\n            df (pandas.DataFrame): The DataFrame to filter.\n            filters (dict): A dictionary where keys are column names and values are the criteria or function to filter by.\n\n        Returns:\n            pandas.DataFrame: A filtered DataFrame.\n\n        \"\"\"\n        filtered_df = df\n        for column, criteria in filters.items():\n            if callable(criteria):  # If the criteria is a function, apply it directly\n                filtered_df = filtered_df[filtered_df[column].apply(criteria)]\n            else:  # Otherwise, assume the criteria is a value or list of values for equality check\n                filtered_df = filtered_df[filtered_df[column] == criteria]\n        return filtered_df\n\n    def _calculate_parameters(\n        self, df, prediction_window, time_interval, prediction_times\n    ):\n        \"\"\"\n        Calculate parameters required for the model.\n\n        Args:\n            df (pandas.DataFrame): The data frame to process.\n            prediction_window (int): The total prediction window for prediction.\n            time_interval (int): The interval for splitting the prediction window.\n            prediction_times (list): Times of day at which predictions are made.\n\n        Returns:\n            dict: Calculated lambda_t parameters organized by time of day.\n\n        \"\"\"\n        Ntimes = int(prediction_window / time_interval)\n        arrival_rates_dict = calculate_rates(df, time_interval)\n        prediction_time_dict = {}\n\n        for prediction_time_ in prediction_times:\n            prediction_time_hr, prediction_time_min = (\n                (prediction_time_, 0)\n                if isinstance(prediction_time_, int)\n                else prediction_time_\n            )\n            lambda_t = [\n                arrival_rates_dict[\n                    (\n                        datetime(1970, 1, 1, prediction_time_hr, prediction_time_min)\n                        + i * timedelta(minutes=time_interval)\n                    ).time()\n                ]\n                for i in range(Ntimes)\n            ]\n            prediction_time_dict[(prediction_time_hr, prediction_time_min)] = {\n                \"lambda_t\": lambda_t\n            }\n\n        return prediction_time_dict\n\n    def fit(\n        self,\n        train_df: pd.DataFrame,\n        prediction_window: int,\n        time_interval: int,\n        prediction_times: List[float],\n        epsilon: float = 10**-7,\n        y: Optional[None] = None,\n    ) -&gt; \"PoissonBinomialPredictor\":\n        \"\"\"\n        Fits the model to the training data, computing necessary parameters for future predictions.\n\n        Args:\n            train_df (pandas.DataFrame):\n                The training dataset with historical admission data.\n            prediction_window (int):\n                The prediction prediction window in minutes.\n            time_interval (int):\n                The interval in minutes for splitting the prediction window.\n            prediction_times (list):\n                Times of day at which predictions are made, in hours.\n            epsilon (float, optional):\n                A small value representing acceptable error rate to enable calculation of the maximum value of the random variable representing number of beds.\n            y (None, optional):\n                Ignored, present for compatibility with scikit-learn's fit method.\n\n        Returns:\n            PoissonBinomialPredictor: The instance itself, fitted with the training data.\n\n        \"\"\"\n        # Store prediction_window, time_interval, and any other parameters as instance variables\n        self.prediction_window = prediction_window\n        self.time_interval = time_interval\n        self.epsilon = epsilon\n        self.prediction_times = prediction_times\n\n        # Initialize yet_to_arrive_dict\n        self.weights = {}\n\n        # If there are filters specified, calculate and store the parameters directly with the respective spec keys\n        if self.filters:\n            for spec, filters in self.filters.items():\n                self.weights[spec] = self._calculate_parameters(\n                    self.filter_dataframe(train_df, filters),\n                    prediction_window,\n                    time_interval,\n                    prediction_times,\n                )\n        else:\n            # If there are no filters, store the parameters with a generic key, like 'default' or 'unfiltered'\n            self.weights[\"default\"] = self._calculate_parameters(\n                train_df, prediction_window, time_interval, prediction_times\n            )\n\n        print(f\"Poisson Binomial Predictor trained for these times: {prediction_times}\")\n        print(\n            f\"using prediction window of {prediction_window} minutes after the time of prediction\"\n        )\n        print(\n            f\"and time interval of {time_interval} minutes within the prediction window.\"\n        )\n        print(f\"The error value for prediction will be {epsilon}\")\n        print(\"To see the weights saved by this model, used the get_weights() method\")\n\n        return self\n\n    def get_weights(self):\n        \"\"\"\n        Returns the weights computed by the fit method.\n\n        Returns\n            dict: The weights.\n\n        \"\"\"\n        return self.weights\n\n    def predict(\n        self, prediction_context: Dict, x1: float, y1: float, x2: float, y2: float\n    ) -&gt; Dict:\n        \"\"\"\n        Predicts the number of admissions for the given context based on the fitted model.\n\n        Args:\n            prediction_context (dict): A dictionary defining the context for which predictions are to be made.\n                                       It should specify either a general context or one based on the applied filters.\n            x1 : float\n                The x-coordinate of the first transition point on the aspirational curve, where the growth phase ends and the decay phase begins.\n            y1 : float\n                The y-coordinate of the first transition point (x1), representing the target proportion of patients admitted by time x1.\n            x2 : float\n                The x-coordinate of the second transition point on the curve, beyond which all but a few patients are expected to be admitted.\n            y2 : float\n                The y-coordinate of the second transition point (x2), representing the target proportion of patients admitted by time x2.\n\n        Returns:\n            dict: A dictionary with predictions for each specified context.\n\n        \"\"\"\n        predictions = {}\n\n        # theta = self.weights.get(\"theta\", 1)  # Provide a default value or handle if missing\n        NTimes = int(self.prediction_window / self.time_interval)\n        # Calculate theta, probability of admission in prediction window\n\n        # for each time interval, calculate time remaining before end of window\n        time_remaining_before_end_of_window = self.prediction_window / 60 - np.arange(\n            0, self.prediction_window / 60, self.time_interval / 60\n        )\n\n        # probability of admission in that time\n        theta = get_y_from_aspirational_curve(\n            time_remaining_before_end_of_window, x1, y1, x2, y2\n        )\n\n        for filter_key, filter_values in prediction_context.items():\n            try:\n                if filter_key not in self.weights:\n                    raise ValueError(\n                        f\"Filter key '{filter_key}' is not recognized in the model weights.\"\n                    )\n\n                prediction_time = filter_values.get(\"prediction_time\")\n                if prediction_time is None:\n                    raise ValueError(\n                        f\"No 'prediction_time' provided for filter '{filter_key}'.\"\n                    )\n\n                if prediction_time not in self.prediction_times:\n                    prediction_time = find_nearest_previous_prediction_time(\n                        prediction_time, self.prediction_times\n                    )\n\n                lambda_t = self.weights[filter_key][prediction_time].get(\"lambda_t\")\n                if lambda_t is None:\n                    raise ValueError(\n                        f\"No 'lambda_t' found for the time of day '{prediction_time}' under filter '{filter_key}'.\"\n                    )\n\n                predictions[filter_key] = poisson_binom_generating_function(\n                    NTimes, lambda_t, theta, self.epsilon\n                )\n\n            except KeyError as e:\n                raise KeyError(f\"Key error occurred: {e!s}\")\n\n        return predictions\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.poisson_binomial_predictor.PoissonBinomialPredictor.__init__","title":"<code>__init__(filters=None)</code>","text":"<p>Initialize the PoissonBinomialPredictor with optional filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict</code> <p>A dictionary defining filters for different categories or specialties.                       If None or empty, no filtering will be applied.</p> <code>None</code> Source code in <code>src/patientflow/predict/emergency_demand/poisson_binomial_predictor.py</code> <pre><code>def __init__(self, filters=None):\n    \"\"\"\n    Initialize the PoissonBinomialPredictor with optional filters.\n\n    Args:\n        filters (dict, optional): A dictionary defining filters for different categories or specialties.\n                                  If None or empty, no filtering will be applied.\n\n    \"\"\"\n    self.filters = filters if filters else {}\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.poisson_binomial_predictor.PoissonBinomialPredictor.filter_dataframe","title":"<code>filter_dataframe(df, filters)</code>","text":"<p>Apply a set of filters to a dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to filter.</p> required <code>filters</code> <code>dict</code> <p>A dictionary where keys are column names and values are the criteria or function to filter by.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pandas.DataFrame: A filtered DataFrame.</p> Source code in <code>src/patientflow/predict/emergency_demand/poisson_binomial_predictor.py</code> <pre><code>def filter_dataframe(self, df: pd.DataFrame, filters: Dict) -&gt; pd.DataFrame:\n    \"\"\"\n    Apply a set of filters to a dataframe.\n\n    Args:\n        df (pandas.DataFrame): The DataFrame to filter.\n        filters (dict): A dictionary where keys are column names and values are the criteria or function to filter by.\n\n    Returns:\n        pandas.DataFrame: A filtered DataFrame.\n\n    \"\"\"\n    filtered_df = df\n    for column, criteria in filters.items():\n        if callable(criteria):  # If the criteria is a function, apply it directly\n            filtered_df = filtered_df[filtered_df[column].apply(criteria)]\n        else:  # Otherwise, assume the criteria is a value or list of values for equality check\n            filtered_df = filtered_df[filtered_df[column] == criteria]\n    return filtered_df\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.poisson_binomial_predictor.PoissonBinomialPredictor.fit","title":"<code>fit(train_df, prediction_window, time_interval, prediction_times, epsilon=10 ** -7, y=None)</code>","text":"<p>Fits the model to the training data, computing necessary parameters for future predictions.</p> <p>Parameters:</p> Name Type Description Default <code>train_df</code> <code>DataFrame</code> <p>The training dataset with historical admission data.</p> required <code>prediction_window</code> <code>int</code> <p>The prediction prediction window in minutes.</p> required <code>time_interval</code> <code>int</code> <p>The interval in minutes for splitting the prediction window.</p> required <code>prediction_times</code> <code>list</code> <p>Times of day at which predictions are made, in hours.</p> required <code>epsilon</code> <code>float</code> <p>A small value representing acceptable error rate to enable calculation of the maximum value of the random variable representing number of beds.</p> <code>10 ** -7</code> <code>y</code> <code>None</code> <p>Ignored, present for compatibility with scikit-learn's fit method.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>PoissonBinomialPredictor</code> <code>PoissonBinomialPredictor</code> <p>The instance itself, fitted with the training data.</p> Source code in <code>src/patientflow/predict/emergency_demand/poisson_binomial_predictor.py</code> <pre><code>def fit(\n    self,\n    train_df: pd.DataFrame,\n    prediction_window: int,\n    time_interval: int,\n    prediction_times: List[float],\n    epsilon: float = 10**-7,\n    y: Optional[None] = None,\n) -&gt; \"PoissonBinomialPredictor\":\n    \"\"\"\n    Fits the model to the training data, computing necessary parameters for future predictions.\n\n    Args:\n        train_df (pandas.DataFrame):\n            The training dataset with historical admission data.\n        prediction_window (int):\n            The prediction prediction window in minutes.\n        time_interval (int):\n            The interval in minutes for splitting the prediction window.\n        prediction_times (list):\n            Times of day at which predictions are made, in hours.\n        epsilon (float, optional):\n            A small value representing acceptable error rate to enable calculation of the maximum value of the random variable representing number of beds.\n        y (None, optional):\n            Ignored, present for compatibility with scikit-learn's fit method.\n\n    Returns:\n        PoissonBinomialPredictor: The instance itself, fitted with the training data.\n\n    \"\"\"\n    # Store prediction_window, time_interval, and any other parameters as instance variables\n    self.prediction_window = prediction_window\n    self.time_interval = time_interval\n    self.epsilon = epsilon\n    self.prediction_times = prediction_times\n\n    # Initialize yet_to_arrive_dict\n    self.weights = {}\n\n    # If there are filters specified, calculate and store the parameters directly with the respective spec keys\n    if self.filters:\n        for spec, filters in self.filters.items():\n            self.weights[spec] = self._calculate_parameters(\n                self.filter_dataframe(train_df, filters),\n                prediction_window,\n                time_interval,\n                prediction_times,\n            )\n    else:\n        # If there are no filters, store the parameters with a generic key, like 'default' or 'unfiltered'\n        self.weights[\"default\"] = self._calculate_parameters(\n            train_df, prediction_window, time_interval, prediction_times\n        )\n\n    print(f\"Poisson Binomial Predictor trained for these times: {prediction_times}\")\n    print(\n        f\"using prediction window of {prediction_window} minutes after the time of prediction\"\n    )\n    print(\n        f\"and time interval of {time_interval} minutes within the prediction window.\"\n    )\n    print(f\"The error value for prediction will be {epsilon}\")\n    print(\"To see the weights saved by this model, used the get_weights() method\")\n\n    return self\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.poisson_binomial_predictor.PoissonBinomialPredictor.get_weights","title":"<code>get_weights()</code>","text":"<p>Returns the weights computed by the fit method.</p> <p>Returns     dict: The weights.</p> Source code in <code>src/patientflow/predict/emergency_demand/poisson_binomial_predictor.py</code> <pre><code>def get_weights(self):\n    \"\"\"\n    Returns the weights computed by the fit method.\n\n    Returns\n        dict: The weights.\n\n    \"\"\"\n    return self.weights\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.poisson_binomial_predictor.PoissonBinomialPredictor.predict","title":"<code>predict(prediction_context, x1, y1, x2, y2)</code>","text":"<p>Predicts the number of admissions for the given context based on the fitted model.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_context</code> <code>dict</code> <p>A dictionary defining the context for which predictions are to be made.                        It should specify either a general context or one based on the applied filters.</p> required <code>x1</code> <p>float The x-coordinate of the first transition point on the aspirational curve, where the growth phase ends and the decay phase begins.</p> required <code>y1</code> <p>float The y-coordinate of the first transition point (x1), representing the target proportion of patients admitted by time x1.</p> required <code>x2</code> <p>float The x-coordinate of the second transition point on the curve, beyond which all but a few patients are expected to be admitted.</p> required <code>y2</code> <p>float The y-coordinate of the second transition point (x2), representing the target proportion of patients admitted by time x2.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict</code> <p>A dictionary with predictions for each specified context.</p> Source code in <code>src/patientflow/predict/emergency_demand/poisson_binomial_predictor.py</code> <pre><code>def predict(\n    self, prediction_context: Dict, x1: float, y1: float, x2: float, y2: float\n) -&gt; Dict:\n    \"\"\"\n    Predicts the number of admissions for the given context based on the fitted model.\n\n    Args:\n        prediction_context (dict): A dictionary defining the context for which predictions are to be made.\n                                   It should specify either a general context or one based on the applied filters.\n        x1 : float\n            The x-coordinate of the first transition point on the aspirational curve, where the growth phase ends and the decay phase begins.\n        y1 : float\n            The y-coordinate of the first transition point (x1), representing the target proportion of patients admitted by time x1.\n        x2 : float\n            The x-coordinate of the second transition point on the curve, beyond which all but a few patients are expected to be admitted.\n        y2 : float\n            The y-coordinate of the second transition point (x2), representing the target proportion of patients admitted by time x2.\n\n    Returns:\n        dict: A dictionary with predictions for each specified context.\n\n    \"\"\"\n    predictions = {}\n\n    # theta = self.weights.get(\"theta\", 1)  # Provide a default value or handle if missing\n    NTimes = int(self.prediction_window / self.time_interval)\n    # Calculate theta, probability of admission in prediction window\n\n    # for each time interval, calculate time remaining before end of window\n    time_remaining_before_end_of_window = self.prediction_window / 60 - np.arange(\n        0, self.prediction_window / 60, self.time_interval / 60\n    )\n\n    # probability of admission in that time\n    theta = get_y_from_aspirational_curve(\n        time_remaining_before_end_of_window, x1, y1, x2, y2\n    )\n\n    for filter_key, filter_values in prediction_context.items():\n        try:\n            if filter_key not in self.weights:\n                raise ValueError(\n                    f\"Filter key '{filter_key}' is not recognized in the model weights.\"\n                )\n\n            prediction_time = filter_values.get(\"prediction_time\")\n            if prediction_time is None:\n                raise ValueError(\n                    f\"No 'prediction_time' provided for filter '{filter_key}'.\"\n                )\n\n            if prediction_time not in self.prediction_times:\n                prediction_time = find_nearest_previous_prediction_time(\n                    prediction_time, self.prediction_times\n                )\n\n            lambda_t = self.weights[filter_key][prediction_time].get(\"lambda_t\")\n            if lambda_t is None:\n                raise ValueError(\n                    f\"No 'lambda_t' found for the time of day '{prediction_time}' under filter '{filter_key}'.\"\n                )\n\n            predictions[filter_key] = poisson_binom_generating_function(\n                NTimes, lambda_t, theta, self.epsilon\n            )\n\n        except KeyError as e:\n            raise KeyError(f\"Key error occurred: {e!s}\")\n\n    return predictions\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.poisson_binomial_predictor.find_nearest_previous_prediction_time","title":"<code>find_nearest_previous_prediction_time(requested_time, prediction_times)</code>","text":"<p>Finds the nearest previous time of day in 'prediction_times' relative to the requested time. If the requested time is earlier than all times in 'prediction_times', the function returns the latest time in 'prediction_times'.</p> <p>Parameters:</p> Name Type Description Default <code>requested_time</code> <code>tuple</code> <p>The requested time as (hour, minute).</p> required <code>prediction_times</code> <code>list</code> <p>List of available prediction times.</p> required <p>Returns:</p> Name Type Description <code>closest_prediction_time</code> <code>tuple</code> <p>The closest previous time of day from 'prediction_times'.</p> Source code in <code>src/patientflow/predict/emergency_demand/poisson_binomial_predictor.py</code> <pre><code>def find_nearest_previous_prediction_time(requested_time, prediction_times):\n    \"\"\"\n    Finds the nearest previous time of day in 'prediction_times' relative to the requested time.\n    If the requested time is earlier than all times in 'prediction_times', the function returns\n    the latest time in 'prediction_times'.\n\n    Args:\n        requested_time (tuple): The requested time as (hour, minute).\n        prediction_times (list): List of available prediction times.\n\n    Returns:\n        closest_prediction_time (tuple): The closest previous time of day from 'prediction_times'.\n\n    \"\"\"\n    if requested_time in prediction_times:\n        return requested_time\n\n    original_prediction_time = requested_time\n    requested_datetime = datetime.strptime(\n        f\"{requested_time[0]:02d}:{requested_time[1]:02d}\", \"%H:%M\"\n    )\n    closest_prediction_time = max(\n        prediction_times,\n        key=lambda prediction_time_time: datetime.strptime(\n            f\"{prediction_time_time[0]:02d}:{prediction_time_time[1]:02d}\",\n            \"%H:%M\",\n        ),\n    )\n    min_diff = float(\"inf\")\n\n    for prediction_time_time in prediction_times:\n        prediction_time_datetime = datetime.strptime(\n            f\"{prediction_time_time[0]:02d}:{prediction_time_time[1]:02d}\",\n            \"%H:%M\",\n        )\n        diff = (requested_datetime - prediction_time_datetime).total_seconds()\n\n        # If the difference is negative, it means the prediction_time_time is ahead of the requested_time,\n        # hence we calculate the difference by considering a day's wrap around.\n        if diff &lt; 0:\n            diff += 24 * 60 * 60  # Add 24 hours in seconds\n\n        if 0 &lt;= diff &lt; min_diff:\n            closest_prediction_time = prediction_time_time\n            min_diff = diff\n\n    warnings.warn(\n        f\"Time of day requested of {original_prediction_time} was not in model training. \"\n        f\"Reverting to predictions for {closest_prediction_time}.\"\n    )\n\n    return closest_prediction_time\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.specialty_of_admission","title":"<code>specialty_of_admission</code>","text":""},{"location":"api/#patientflow.predict.emergency_demand.specialty_of_admission.SequencePredictor","title":"<code>SequencePredictor</code>","text":"<p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> Source code in <code>src/patientflow/predict/emergency_demand/specialty_of_admission.py</code> <pre><code>class SequencePredictor(BaseEstimator, TransformerMixin):\n    def __init__(self, input_var, grouping_var, outcome_var):\n        self.input_var = input_var  # Column name for the input sequence\n        self.grouping_var = grouping_var  # Column name for the grouping sequence\n        self.outcome_var = outcome_var  # Column name for the outcome category\n        self.weights = None  # Initialize the weights attribute to store model weights\n\n    def fit(self, X: pd.DataFrame) -&gt; Dict:\n        \"\"\"\n        Fits the predictor based on training data by computing the proportion of each\n        input variable sequence ending in specific outcome variable categories. It also handles null\n        sequences and incorporates a default probability for sequences without explicit data.\n\n        Parameters\n        - X: A pandas DataFrame with at least the columns specified by input_var, grouping_var, and outcome_var.\n        - input_var: The name of the column representing the input sequence.\n        - grouping_var: The name of the column representing the grouping sequence.\n        - outcome_var: The name of the column representing the outcome variable.\n\n        Returns\n        - A dictionary mapping each sequence (including null sequences) to their\n        respective probability distribution across different categories.\n\n        \"\"\"\n        # derive the names of the observed specialties from the data (used later)\n        prop_keys = X[self.outcome_var].unique()\n\n        # For each sequences count the number of observed categories\n        X_grouped = (\n            X.groupby(self.grouping_var)[self.outcome_var]\n            .value_counts()\n            .unstack(fill_value=0)\n        )\n\n        # Handle null sequences by assigning them to a specific key\n        null_counts = (\n            X[X[self.grouping_var].isnull()][self.outcome_var]\n            .value_counts()\n            .to_frame()\n            .T\n        )\n        null_counts.index = [tuple()]\n\n        # Concatenate null sequence handling\n        X_grouped = pd.concat([X_grouped, null_counts])\n\n        # Calculate the total number of times each grouping sequence occurred\n        row_totals = X_grouped.sum(axis=1)\n\n        # Calculate for each grouping sequence, the proportion of ending with each observed specialty\n        proportions = X_grouped.div(row_totals, axis=0)\n\n        # Calculate the probability of each grouping sequence occurring in the original data\n        proportions[\"probability_of_grouping_sequence\"] = row_totals / row_totals.sum()\n\n        # Reweight probabilities of ending with each observed specialty\n        # by the likelihood of each grouping sequence occurring\n        for col in proportions.columns[\n            :-1\n        ]:  # Avoid the last column which is the 'probability_of_grouping_sequence'\n            proportions[col] *= proportions[\"probability_of_grouping_sequence\"]\n\n        # Convert final sequence to a string in order to conduct string searches on it\n        proportions[\"grouping_sequence_to_string\"] = (\n            proportions.reset_index()[\"index\"]\n            .apply(lambda x: \"-\".join(map(str, x)))\n            .values\n        )\n        # Row-wise function to return, for each input sequence,\n        # the proportion that end up in each final sequence and thereby\n        # the probability of it ending in any observed category\n        proportions[\"prob_input_var_ends_in_observed_specialty\"] = proportions[\n            \"grouping_sequence_to_string\"\n        ].apply(lambda x: self._string_match_input_var(x, proportions, prop_keys))\n\n        # save these as weights\n        self.weights = proportions.to_dict()[\n            \"prob_input_var_ends_in_observed_specialty\"\n        ]\n\n        # save the input to grouping probabilities\n        self.input_to_grouping_probs = self._probability_of_input_to_grouping_sequence(\n            X\n        )\n\n        return self\n\n    def _string_match_input_var(self, input_var_string, proportions, prop_keys):\n        \"\"\"\n        Matches a given input sequence string with grouped sequences (expressed as strings) in the dataset and aggregates\n        their probabilities for each outcome category. This function filters the data to\n        match only those rows where the *beginning* of the grouped sequence string\n        matches the given input sequence string, allowing for partial matches.\n        For instance, the sequence 'medical' will match 'medical, elderly' and 'medical, surgical'\n        as well as 'medical' on its own. It computes the total probabilities of any input sequence ending\n        in each outcome category, and normalizes these totals if possible.\n\n        Parameters\n        - input_var_string (str): The sequence of inputs represented as a string,\n        used to match against sequences in the proportions DataFrame.\n        - proportions (pd.DataFrame): DataFrame containing proportions data with an additional\n        column 'grouping_sequence_to_string' which includes string representations of sequences.\n        - prop_keys (np.array): Array of unique outcomes to consider in calculations.\n\n        Returns\n        - dict: A dictionary where keys are outcome names and values are the aggregated\n        and normalized probabilities of an input sequence ending in those outcomes.\n\n        \"\"\"\n        # Filter rows where the grouped sequence string starts with the input sequence string\n        props = proportions[\n            proportions[\"grouping_sequence_to_string\"].str.match(\"^\" + input_var_string)\n        ][prop_keys].sum()\n\n        # Sum of all probabilities to normalize them\n        props_total = props.sum()\n\n        # Handle cases where the total probability is zero to avoid division by zero\n        if props_total &gt; 0:\n            normalized_props = props / props_total\n        else:\n            normalized_props = (\n                props * 0\n            )  # Returns zero probabilities if no matches found\n\n        return dict(zip(prop_keys, normalized_props))\n\n    def _probability_of_input_to_grouping_sequence(self, X):\n        # For each input sequence count the number of grouping sequences\n        X_grouped = (\n            X.groupby(self.input_var)[self.grouping_var]\n            .value_counts()\n            .unstack(fill_value=0)\n        )\n\n        # # Calculate the total number of times each input sequence occurred\n        row_totals = X_grouped.sum(axis=1)\n\n        # # Calculate for each grouping sequence, the proportion of ending with each grouping sequence\n        proportions = X_grouped.div(row_totals, axis=0)\n\n        # # Calculate the probability of each input sequence occurring in the original data\n        proportions[\"probability_of_grouping_sequence\"] = row_totals / row_totals.sum()\n\n        return proportions\n\n    def predict(self, input_sequence: tuple[str, ...]) -&gt; Dict[str, float]:\n        \"\"\"\n        Predicts the probabilities of ending in various outcome categories for a given input sequence.\n        For example, for an input sequence such as (\"cardiology\", \"orthopedics\"), the return\n        value will be a dict of probabilities such as {\"cardiology\": 0.3, \"orthopedics\": 0.2, \"neurology\": 0.1}.\n\n        Parameters\n        - input_sequence: A tuple containing the categories that have been observed for an entity in the order\n        they have been encountered. An empty tuple represents an entity with no observed categories.\n\n        Returns\n        - A dictionary of categories and the probabilities that the input sequence will end in them.\n\n        \"\"\"\n        # Check for no tuple\n        if input_sequence is None or pd.isna(input_sequence):\n            return self.weights.get(tuple(), {})\n\n        # Return a direct lookup of probabilities if possible.\n        if input_sequence in self.weights:\n            return self.weights[input_sequence]\n\n        # Otherwise, if the sequence has multiple elements, work back looking for a match\n        while len(input_sequence) &gt; 1:\n            input_sequence_list = list(input_sequence)\n            input_sequence = tuple(input_sequence_list[:-1])  # remove last element\n\n            if input_sequence in self.weights:\n                return self.weights[input_sequence]\n\n        # If no relevant data is found:\n        return self.weights.get(tuple(), {})\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.specialty_of_admission.SequencePredictor.fit","title":"<code>fit(X)</code>","text":"<p>Fits the predictor based on training data by computing the proportion of each input variable sequence ending in specific outcome variable categories. It also handles null sequences and incorporates a default probability for sequences without explicit data.</p> <p>Parameters - X: A pandas DataFrame with at least the columns specified by input_var, grouping_var, and outcome_var. - input_var: The name of the column representing the input sequence. - grouping_var: The name of the column representing the grouping sequence. - outcome_var: The name of the column representing the outcome variable.</p> <p>Returns - A dictionary mapping each sequence (including null sequences) to their respective probability distribution across different categories.</p> Source code in <code>src/patientflow/predict/emergency_demand/specialty_of_admission.py</code> <pre><code>def fit(self, X: pd.DataFrame) -&gt; Dict:\n    \"\"\"\n    Fits the predictor based on training data by computing the proportion of each\n    input variable sequence ending in specific outcome variable categories. It also handles null\n    sequences and incorporates a default probability for sequences without explicit data.\n\n    Parameters\n    - X: A pandas DataFrame with at least the columns specified by input_var, grouping_var, and outcome_var.\n    - input_var: The name of the column representing the input sequence.\n    - grouping_var: The name of the column representing the grouping sequence.\n    - outcome_var: The name of the column representing the outcome variable.\n\n    Returns\n    - A dictionary mapping each sequence (including null sequences) to their\n    respective probability distribution across different categories.\n\n    \"\"\"\n    # derive the names of the observed specialties from the data (used later)\n    prop_keys = X[self.outcome_var].unique()\n\n    # For each sequences count the number of observed categories\n    X_grouped = (\n        X.groupby(self.grouping_var)[self.outcome_var]\n        .value_counts()\n        .unstack(fill_value=0)\n    )\n\n    # Handle null sequences by assigning them to a specific key\n    null_counts = (\n        X[X[self.grouping_var].isnull()][self.outcome_var]\n        .value_counts()\n        .to_frame()\n        .T\n    )\n    null_counts.index = [tuple()]\n\n    # Concatenate null sequence handling\n    X_grouped = pd.concat([X_grouped, null_counts])\n\n    # Calculate the total number of times each grouping sequence occurred\n    row_totals = X_grouped.sum(axis=1)\n\n    # Calculate for each grouping sequence, the proportion of ending with each observed specialty\n    proportions = X_grouped.div(row_totals, axis=0)\n\n    # Calculate the probability of each grouping sequence occurring in the original data\n    proportions[\"probability_of_grouping_sequence\"] = row_totals / row_totals.sum()\n\n    # Reweight probabilities of ending with each observed specialty\n    # by the likelihood of each grouping sequence occurring\n    for col in proportions.columns[\n        :-1\n    ]:  # Avoid the last column which is the 'probability_of_grouping_sequence'\n        proportions[col] *= proportions[\"probability_of_grouping_sequence\"]\n\n    # Convert final sequence to a string in order to conduct string searches on it\n    proportions[\"grouping_sequence_to_string\"] = (\n        proportions.reset_index()[\"index\"]\n        .apply(lambda x: \"-\".join(map(str, x)))\n        .values\n    )\n    # Row-wise function to return, for each input sequence,\n    # the proportion that end up in each final sequence and thereby\n    # the probability of it ending in any observed category\n    proportions[\"prob_input_var_ends_in_observed_specialty\"] = proportions[\n        \"grouping_sequence_to_string\"\n    ].apply(lambda x: self._string_match_input_var(x, proportions, prop_keys))\n\n    # save these as weights\n    self.weights = proportions.to_dict()[\n        \"prob_input_var_ends_in_observed_specialty\"\n    ]\n\n    # save the input to grouping probabilities\n    self.input_to_grouping_probs = self._probability_of_input_to_grouping_sequence(\n        X\n    )\n\n    return self\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.specialty_of_admission.SequencePredictor.predict","title":"<code>predict(input_sequence)</code>","text":"<p>Predicts the probabilities of ending in various outcome categories for a given input sequence. For example, for an input sequence such as (\"cardiology\", \"orthopedics\"), the return value will be a dict of probabilities such as {\"cardiology\": 0.3, \"orthopedics\": 0.2, \"neurology\": 0.1}.</p> <p>Parameters - input_sequence: A tuple containing the categories that have been observed for an entity in the order they have been encountered. An empty tuple represents an entity with no observed categories.</p> <p>Returns - A dictionary of categories and the probabilities that the input sequence will end in them.</p> Source code in <code>src/patientflow/predict/emergency_demand/specialty_of_admission.py</code> <pre><code>def predict(self, input_sequence: tuple[str, ...]) -&gt; Dict[str, float]:\n    \"\"\"\n    Predicts the probabilities of ending in various outcome categories for a given input sequence.\n    For example, for an input sequence such as (\"cardiology\", \"orthopedics\"), the return\n    value will be a dict of probabilities such as {\"cardiology\": 0.3, \"orthopedics\": 0.2, \"neurology\": 0.1}.\n\n    Parameters\n    - input_sequence: A tuple containing the categories that have been observed for an entity in the order\n    they have been encountered. An empty tuple represents an entity with no observed categories.\n\n    Returns\n    - A dictionary of categories and the probabilities that the input sequence will end in them.\n\n    \"\"\"\n    # Check for no tuple\n    if input_sequence is None or pd.isna(input_sequence):\n        return self.weights.get(tuple(), {})\n\n    # Return a direct lookup of probabilities if possible.\n    if input_sequence in self.weights:\n        return self.weights[input_sequence]\n\n    # Otherwise, if the sequence has multiple elements, work back looking for a match\n    while len(input_sequence) &gt; 1:\n        input_sequence_list = list(input_sequence)\n        input_sequence = tuple(input_sequence_list[:-1])  # remove last element\n\n        if input_sequence in self.weights:\n            return self.weights[input_sequence]\n\n    # If no relevant data is found:\n    return self.weights.get(tuple(), {})\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.time_varying_arrival_rates","title":"<code>time_varying_arrival_rates</code>","text":""},{"location":"api/#patientflow.predict.emergency_demand.time_varying_arrival_rates.calculate_rates","title":"<code>calculate_rates(df, time_interval)</code>","text":"<p>Calculate the time-varying arrival rates for a dataset indexed by datetime.</p> <p>This function computes the arrival rates for each time interval specified, across the entire date range present in the dataframe. The arrival rate is calculated as the number of entries in the dataframe for each time interval, divided by the number of days in the dataset's timespan.</p> <p>Parameters df (pandas.DataFrame): A DataFrame indexed by datetime, representing the data for which arrival rates are to be calculated. The index of the DataFrame should be of datetime type. time_interval (int): The time interval, in minutes, for which the arrival rates are to be calculated. For example, if <code>time_interval=60</code>, the function will calculate hourly arrival rates.</p> <p>Returns dict: A dictionary where the keys are the start times of each interval (as <code>datetime.time</code> objects), and the values are the corresponding arrival rates (as floats).</p> <p>Raises TypeError: If the index of the DataFrame is not a datetime index.</p> Source code in <code>src/patientflow/predict/emergency_demand/time_varying_arrival_rates.py</code> <pre><code>def calculate_rates(df, time_interval):\n    \"\"\"\n    Calculate the time-varying arrival rates for a dataset indexed by datetime.\n\n    This function computes the arrival rates for each time interval specified, across the entire date range present in the dataframe. The arrival rate is calculated as the number of entries in the dataframe for each time interval, divided by the number of days in the dataset's timespan.\n\n    Parameters\n    df (pandas.DataFrame): A DataFrame indexed by datetime, representing the data for which arrival rates are to be calculated. The index of the DataFrame should be of datetime type.\n    time_interval (int): The time interval, in minutes, for which the arrival rates are to be calculated. For example, if `time_interval=60`, the function will calculate hourly arrival rates.\n\n    Returns\n    dict: A dictionary where the keys are the start times of each interval (as `datetime.time` objects), and the values are the corresponding arrival rates (as floats).\n\n    Raises\n    TypeError: If the index of the DataFrame is not a datetime index.\n\n    \"\"\"\n    # Validate that the DataFrame index is a datetime object\n    if not isinstance(df.index, pd.DatetimeIndex):\n        raise TypeError(\"The DataFrame index must be a DatetimeIndex.\")\n\n    # Determine the start and end date of the data\n    start_dt = df.index.min()\n    end_dt = df.index.max()\n\n    # Convert start and end times to datetime if they are not already\n    if not isinstance(start_dt, datetime):\n        start_dt = datetime.strptime(start_dt, \"%Y-%m-%d %H:%M:%S%z\")\n\n    if not isinstance(end_dt, datetime):\n        end_dt = datetime.strptime(end_dt, \"%Y-%m-%d %H:%M:%S%z\")\n\n    # Calculate the total number of days covered by the dataset\n    num_days = pd.Series(df.index.date).nunique()\n    print(\n        f\"Calculating time-varying arrival rates for data provided, which spans {num_days} unique dates\"\n    )\n\n    arrival_rates_dict = {}\n\n    # Initialize a time object to iterate through one day in the specified intervals\n    _start_datetime = datetime(1970, 1, 1, 0, 0, 0, 0)\n    _stop_datetime = _start_datetime + timedelta(days=1)\n\n    # Iterate over each interval in a single day to calculate the arrival rate\n    while _start_datetime != _stop_datetime:\n        _start_time = _start_datetime.time()\n        _end_time = (_start_datetime + timedelta(minutes=time_interval)).time()\n\n        # Filter the dataframe for entries within the current time interval\n        _df = df.between_time(_start_time, _end_time, inclusive=\"left\")\n\n        # Calculate and store the arrival rate for the interval\n        arrival_rates_dict[_start_time] = _df.shape[0] / num_days\n\n        # Move to the next interval\n        _start_datetime = _start_datetime + timedelta(minutes=time_interval)\n\n    return arrival_rates_dict\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.yet_to_arrive","title":"<code>yet_to_arrive</code>","text":""},{"location":"api/#patientflow.predict.emergency_demand.yet_to_arrive.aggregate_probabilities","title":"<code>aggregate_probabilities(lam, kmax, theta, time_index)</code>","text":"<p>Aggregate probabilities for a range of values using the weighted Poisson-Binomial distribution.</p> <p>Parameters lam (numpy.ndarray): An array of lambda values for each time interval. kmax (int): The maximum number of events to consider. theta (numpy.ndarray): An array of theta values for each time interval. time_index (int): The current time index for which to calculate probabilities.</p> <p>Returns numpy.ndarray: Aggregated probabilities for the given time index.</p> Source code in <code>src/patientflow/predict/emergency_demand/yet_to_arrive.py</code> <pre><code>def aggregate_probabilities(lam, kmax, theta, time_index):\n    \"\"\"\n    Aggregate probabilities for a range of values using the weighted Poisson-Binomial distribution.\n\n    Parameters\n    lam (numpy.ndarray): An array of lambda values for each time interval.\n    kmax (int): The maximum number of events to consider.\n    theta (numpy.ndarray): An array of theta values for each time interval.\n    time_index (int): The current time index for which to calculate probabilities.\n\n    Returns\n    numpy.ndarray: Aggregated probabilities for the given time index.\n\n    \"\"\"\n    if kmax &lt; 0 or time_index &lt; 0 or len(lam) &lt;= time_index or len(theta) &lt;= time_index:\n        raise ValueError(\"Invalid kmax, time_index, or array lengths.\")\n\n    probabilities_matrix = np.zeros((kmax + 1, kmax + 1))\n    for i in range(kmax + 1):\n        probabilities_matrix[: i + 1, i] = weighted_poisson_binomial(\n            i, lam[time_index], theta[time_index]\n        )\n    return probabilities_matrix.sum(axis=1)\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.yet_to_arrive.convolute_distributions","title":"<code>convolute_distributions(dist_a, dist_b)</code>","text":"<p>Convolutes two probability distributions represented as dataframes.</p> <p>Parameters dist_a (pd.DataFrame): The first distribution with columns ['sum', 'prob']. dist_b (pd.DataFrame): The second distribution with columns ['sum', 'prob'].</p> <p>Returns pd.DataFrame: The convoluted distribution.</p> Source code in <code>src/patientflow/predict/emergency_demand/yet_to_arrive.py</code> <pre><code>def convolute_distributions(dist_a, dist_b):\n    \"\"\"\n    Convolutes two probability distributions represented as dataframes.\n\n    Parameters\n    dist_a (pd.DataFrame): The first distribution with columns ['sum', 'prob'].\n    dist_b (pd.DataFrame): The second distribution with columns ['sum', 'prob'].\n\n    Returns\n    pd.DataFrame: The convoluted distribution.\n\n    \"\"\"\n    if not {\"sum\", \"prob\"}.issubset(dist_a.columns) or not {\n        \"sum\",\n        \"prob\",\n    }.issubset(dist_b.columns):\n        raise ValueError(\"DataFrames must contain 'sum' and 'prob' columns.\")\n\n    sums = [x + y for x in dist_a[\"sum\"] for y in dist_b[\"sum\"]]\n    probs = [x * y for x in dist_a[\"prob\"] for y in dist_b[\"prob\"]]\n    result = pd.DataFrame(zip(sums, probs), columns=[\"sum\", \"prob\"])\n    return result.groupby(\"sum\")[\"prob\"].sum().reset_index()\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.yet_to_arrive.poisson_binom_generating_function","title":"<code>poisson_binom_generating_function(NTimes, lambda_t, theta, epsilon)</code>","text":"<p>Generate a distribution based on the aggregate of Poisson and Binomial distributions over time intervals.</p> <p>Parameters NTimes (int): The number of time intervals. lambda_t (numpy.ndarray): An array of lambda values for each time interval. theta (numpy.ndarray): An array of theta values for each time interval. epsilon (float): The desired error threshold.</p> <p>Returns pd.DataFrame: The generated distribution.</p> Source code in <code>src/patientflow/predict/emergency_demand/yet_to_arrive.py</code> <pre><code>def poisson_binom_generating_function(NTimes, lambda_t, theta, epsilon):\n    \"\"\"\n    Generate a distribution based on the aggregate of Poisson and Binomial distributions over time intervals.\n\n    Parameters\n    NTimes (int): The number of time intervals.\n    lambda_t (numpy.ndarray): An array of lambda values for each time interval.\n    theta (numpy.ndarray): An array of theta values for each time interval.\n    epsilon (float): The desired error threshold.\n\n    Returns\n    pd.DataFrame: The generated distribution.\n\n    \"\"\"\n    if NTimes &lt;= 0 or epsilon &lt;= 0 or epsilon &gt;= 1:\n        raise ValueError(\"Ensure NTimes &gt; 0 and 0 &lt; epsilon &lt; 1.\")\n\n    maxlam = max(lambda_t)\n    kmax = int(poisson.ppf(1 - epsilon, maxlam))\n    distribution = np.zeros((kmax + 1, NTimes))\n\n    for j in range(NTimes):\n        distribution[:, j] = aggregate_probabilities(lambda_t, kmax, theta, j)\n\n    df_list = [\n        pd.DataFrame({\"sum\": range(kmax + 1), \"prob\": distribution[:, j]})\n        for j in range(NTimes)\n    ]\n    total_distribution = df_list[0]\n\n    for df in df_list[1:]:\n        total_distribution = convolute_distributions(total_distribution, df)\n\n    total_distribution = total_distribution.rename(\n        columns={\"prob\": \"agg_proba\"}\n    ).set_index(\"sum\")\n\n    return total_distribution\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.yet_to_arrive.weighted_poisson_binomial","title":"<code>weighted_poisson_binomial(i, lam, theta)</code>","text":"<p>Calculate weighted probabilities using Poisson and Binomial distributions.</p> <p>Parameters i (int): The upper bound of the range for the binomial distribution. lam (float): The lambda parameter for the Poisson distribution. theta (float): The probability of success for the binomial distribution.</p> <p>Returns numpy.ndarray: An array of weighted probabilities.</p> Source code in <code>src/patientflow/predict/emergency_demand/yet_to_arrive.py</code> <pre><code>def weighted_poisson_binomial(i, lam, theta):\n    \"\"\"\n    Calculate weighted probabilities using Poisson and Binomial distributions.\n\n    Parameters\n    i (int): The upper bound of the range for the binomial distribution.\n    lam (float): The lambda parameter for the Poisson distribution.\n    theta (float): The probability of success for the binomial distribution.\n\n    Returns\n    numpy.ndarray: An array of weighted probabilities.\n\n    \"\"\"\n    if i &lt; 0 or lam &lt; 0 or not 0 &lt;= theta &lt;= 1:\n        raise ValueError(\"Ensure i &gt;= 0, lam &gt;= 0, and 0 &lt;= theta &lt;= 1.\")\n\n    arr_seq = np.arange(i + 1)\n    probabilities = binom.pmf(arr_seq, i, theta)\n    return poisson.pmf(i, lam) * probabilities\n</code></pre>"},{"location":"notebooks/","title":"README","text":""},{"location":"notebooks/#about-the-notebooks","title":"About the notebooks","text":"<p>This folder contains a series of notebooks that demonstrate the process of modeling emergency demand in healthcare through a structured approach. Notebooks are an effective tool for merging explanatory narratives with practical code and the results produced by that code. Here\u2019s how different audiences can benefit from these notebooks:</p> <ul> <li>For non-programmers seeking to understand the approach: If you're not familiar with programming, you can read the narrative sections of the notebooks like a blog post to understand the strategies employed and skip the code snippets.</li> <li>For those new to Python or looking to learn: If you have some coding experience but are new to Python, the code snippets, combined with the narrative, provide insights into how Python is applied in modeling emergency bed demand. This includes tasks such as data exploration, model fitting, and result evaluation. Observing the output will help you see the practical outcomes of the modeling.</li> <li>For users who prefer not to set up their own coding environment: Each notebook is designed to run using a provided dataset, aiming to replicate our results. The dataset will hopefully be based on real data from University College London Hospital.</li> <li>For those interested in using the 'patientflow' package: These notebooks serve as a guide on how to use the 'patientflow' package. Through detailed walkthroughs of the functions and their applications, you can learn how to integrate this package into your own projects.</li> </ul>"},{"location":"notebooks/#outline-of-the-notebooks","title":"Outline of the notebooks","text":"<p>The intention is to create the following notebooks:</p> <ul> <li>1_Introduce_our_users: Talk about the users of emergency demand predictions in acute hospitals.</li> <li>2_Modelling_requirements: Explain design choices that were made to develop a practical model, and show an example of the output that is sent at UCLH.</li> <li>3_Introduce_the_datasets: Introduce the two datasets created to accompany this repository</li> <li>4a_Predict_probability_of_admission_from_ED: Show how to train a machine learning model to forecast admission likelihood based on patient data from the Emergency Department (ED). This includes dividing the data into training, validation, and testing sets, as well as into subsets based on the time of day the predictions are made, applying an XGBoost model for predictions, evaluating and interpreting these predictions, and saving the models for future use.</li> <li>4b_Predict_demand_from_patients_in_ED Illustrate how to convert individual admission probabilities into an overall bed demand forecast. Demonstrate the use of a function that will take ED performance targets into account when predicting the number admitted by the end of the prediction window</li> <li>4c_Predict_probablity_of_admission_to_specialty: Show that a rooted directed tree can be used to represent a sequence of consultation requests, which in turn can be mapped to a probability of being admitted to one of three specialties: medical, surgical, haematology/oncology</li> <li>4d_Predict_demand_from_patients_yet_to_arrive: Show the use of a time-varying Poisson distribution to predict a number of patients yet to arrive with a prediction window (say 8 hours) of the time of prediction, by specialty. Demonstrate the use of a function that will take ED performance targets into account when predicting the number admitted by the end of the prediction window</li> <li>5_Model_evaluation: Discuss the importance of evaluating predictions and talk about what it means to evaluate a model of aspirational predictions</li> <li>6 Bring it all together: Show an example of doing live inference using these models</li> </ul>"},{"location":"src/patientflow/","title":"README","text":""},{"location":"src/patientflow/#patientflow-a-forthcoming-python-package","title":"PatientFlow: A forthcoming Python package","text":"<p>Our intention is to release this folder, and its subfolders, as a Python package that can be installed using common methods like <code>pip install</code></p> <p>The package will support predictions of bed demand by providing functions that</p> <ul> <li>take as input patient-level probabilities of admission and discharge</li> <li>return as output probability distributions predicting number of beds needed for or vacated by those patients, at different levels of aggregation (eg by specialty or sex)</li> <li>return a net bed position by combining predictions of demand and supply of beds</li> <li>provide visualisation of the performance of these predictions using qq plots</li> </ul> <p>The package is intended to serve as a wrapper of the functions typically used for such purposes in the <code>scipy</code> python package, with additional context to support their application and evaluation in bed management in healthcare</p>"},{"location":"src/patientflow/#modules-overview","title":"Modules Overview","text":"<ul> <li><code>predict</code>: The central module containing submodules for predicting various aspects of bed capacity</li> <li><code>emergencydemand</code>: generate predictions of the number of emergency beds required within a short time horizon</li> <li>[Later] <code>emergencysupply</code>: generate predictions of the number of emergency beds that will become free within a short time horizon due to patients being discharged</li> <li>[Later] <code>net bed position</code>: using the above functions, generate predictions of the net bed position (surplus or deficit of beds) within a short time horizon</li> <li><code>viz</code>: A module containing convenient plotting functions to examine the outputs from the above functions</li> </ul> <p>Other modules may follow in future</p>"},{"location":"src/patientflow/#deployment","title":"Deployment","text":"<p>This package is designed for use in hospital data projects analysing patient flow and bed capacity in short time horizons. The modules can be customised to align with specific hospital requirements</p>"}]}