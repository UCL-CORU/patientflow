{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PatientFlow: Predicting demand for hospital beds using real-time data","text":""},{"location":"#summary","title":"Summary","text":"<p><code>patientflow</code>, a Python package, converts patient-level predictions into output that is useful for bed managers in hospitals.</p> <p>We originally developed this code for University College London Hospitals (UCLH) to predict the number of emergency admissions they should expect within the next eight hours. Our method used real-time data from their Electronic Health Record (EHR) system. We wrote code to convert patient-level data, extracted from the EHR at a point in time, into predicted numbers of admissions in the following 4 or 8 hours. We also wrote code to help us evaluate the predictions.</p> <p>We have created the <code>patientflow</code> python package to make it convenient for others to adopt our approach. Its purpose is to predict bed demand for groups of hospital patients at a point in time. The package is organised around the following concepts:</p> <ul> <li>Prediction time: A moment in the day at which predictions are to be made, for example 09:30.</li> <li>Patient snapshot: A summary of data from the EHR capturing is known about a single patient at the prediction time. Each patient snapshot has a date and a prediction time associated with it.</li> <li>Group snaphot: A set of patients snapshots. Each group snapshot has a date and a prediction time associated with it.</li> <li>Prediction window: A period of hours that begins at the prediction time.</li> </ul> <p>The modelling functions in <code>patientflow</code> are designed to receive a group snapshot as an input, and to predict something about that group's demand for beds between the prediction moment and the end of the prediction window. For example, that group could be the patients currently in the Emergency Department (ED), and the predictions could be the number of beds needed by those patients in the next 8 hours. The output is a probability distribution over the number of beds needed. The package includes functions to generate predictions at both patient and group level, to visualise predicted probability distributions, and to evaluate them.</p> <p>This snapshot-based approach to predicting demand generalises to other aspects of patient flow in hospitals, such as predictions of how many patients from a clinical specialty will be discharged. A series of notebooks demonstrates the use of the package. We show how to prepare your data and train models based on a snapshot approach. The repository includes a synthetic dataset, and an anonymised patient dataset, based on real data from UCLH is available on Zenodo. Both the synthetic and the real dataset have been prepared in a snapshot structure.</p>"},{"location":"#what-patientflow-is-for","title":"What <code>patientflow</code> is for:","text":"<ul> <li>Predicting patient flow in hospitals: The package can be used by researchers or analysts who want to predict numbers of emergency admissions, discharges or transfers between units</li> <li>Short-term operational planning: The predictions produced by this package are designed for bed managers who need to make decisions within an 4-16 hour timeframe.</li> <li>Working with real-time data: The design assumes that data from an electronic health record (EHR) is available in real-time, or near to real-time</li> <li>Point-in-time analysis: The package works by taking snapshots of groups of patients who are in the hospital at a particular moment, and making predictions about whether a non-clinical outcome like admission or discharge will occur with a short time horizon.</li> </ul>"},{"location":"#what-patientflow-is-not-for","title":"What <code>patientflow</code> is NOT for:","text":"<ul> <li>Long-term capacity planning: The package focuses on immediate operational demand (hours ahead), not strategic planning over weeks or months.</li> <li>Making decisions about individual patients: The package relies on data entered into the EHR by clinical staff looking after patients, but the patient-level predictions it generates should not be used to influence their decision-making</li> <li>General hospital analytics: The package is designed for short-term bed management, not broader hospital analytics like long-term demand and capacity planning.</li> <li>Predicting what happens after a hospital visit: While historical data might train underlying models, the package itself focuses on patients currently in the hospital or soon to arrive</li> <li>Replacing human judgment: The predictions are meant to augment the information available to bed managers, but not to automate bed management decisions.</li> </ul>"},{"location":"#this-package-will-help-you-if-you-want-to","title":"This package will help you if you want to:","text":"<ul> <li>Make predictions for unfinished patient visits: The package is designed for making predictions when outcomes at the end of the visit are as yet unknown, and evaluating those predictions against what actually happened.</li> <li>Convert individual patient predictions to group-level insights: As bed numbers are the currency used by bed managers, the package generates bed count distributions; you may find this kind of output will help you interest hospital site and operations managers in your predictions.</li> <li>Develop your own predictive models of emergency demand: The repository includes a fully worked example of how to convert historical data from Emergency Department visits into snapshots, and use the snapshots to train models that predict numbers of emergency beds.</li> </ul>"},{"location":"#this-package-will-not-help-you-if","title":"This package will NOT help you if:","text":"<ul> <li>You work with time series data: <code>patientflow</code> works with snapshots of a hospital visit summarising what is in the patient record up to that point in time. It would need modification to accept time series data formats.</li> <li>You want to predict clinical outcomes: the approach is designed for the management of hospital sites, not the management of patient care.</li> </ul>"},{"location":"#mathematical-assumptions-underlying-the-conversion-from-individual-to-group-predictions","title":"Mathematical assumptions underlying the conversion from individual to group predictions:","text":"<ul> <li>Independence of patient requirements: The package assumes that individual patient requirements (eg for admission) are conditionally independent.</li> <li>Bernoulli outcome model: Each patient outcome is modelled as a Bernoulli trial with its own probability, and the package computes a probability distribution for the sum of these independent trials.</li> <li>Different levels of aggregation: The package can calculate probability distributions for compound scenarios (such as the probability of a patient being admitted, assigned to a specific specialty if admitted, and being admitted within the prediction window) and for patient subgroups (like distributions by age or gender). In all cases, the independence assumption between patients is maintained.</li> </ul>"},{"location":"#getting-started","title":"Getting started","text":"<ul> <li>Exploration: Start with the notebooks README to get an outline of what is included in the notebooks, and read the patientflow README for an overview of the Python package</li> <li>Installation: Follow the instructions below to set up the environment and install necessary dependencies in your own environment</li> <li>Configuration: Repurpose config.yaml to configure the package to your own data and user requirements</li> </ul>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p><code>patientflow</code> requires Python 3.10.</p>"},{"location":"#installation","title":"Installation","text":"<p>patientflow is not yet available on PyPI. To install the latest development version, clone it first (so that you have access to the synthetic data and the notebooks) and then install it.</p> <pre><code>git clone https://github.com/zmek/patientflow.git\ncd patientflow\npip install -e \".[test]\" #this will install the code in test mode\n\n</code></pre> <p>Navigate to the patientflow folder and run tests to confirm that the installation worked correctly. This command will only work from the root repository. (To date, this has only been tested on Linux and Mac OS machines. If you are running Windows, there may be errors we don't know about.)</p> <pre><code>pytest\n</code></pre> <p>If you get errors running the pytest command, there may be other installations needed on your local machine.</p>"},{"location":"#using-the-notebooks-in-this-repository","title":"Using the notebooks in this repository","text":"<p>The notebooks in this repository demonstrate the use of some of the functions provided in <code>patientflow</code>. The cell output shows the results of running the notebooks. If you want to run them yourself, you have two options</p> <ul> <li>step through the notebooks using the real patient datasets that were used to prepare them. For this you need to request access on Zenodo to real patient data</li> <li>step through the notebooks using synthetic data. You will need to copy the two csv files from <code>data-synthetic</code>into your <code>data-public</code> folder or change the source in the each notebook. If you use synthetic data, you will not see the same cell output.</li> </ul>"},{"location":"#about-the-uclh-implementation","title":"About the UCLH implementation","text":"<p>This repository includes a set of notebooks (prefixed with 4) that show a fully worked example of the implementation of the patientflow package at University College London Hospitals (UCLH).As noted above, please request access to the UCLH dataset via Zenodo.</p> <p>There is also a Python script that illustrates the training of the models that predict emergency demand at UCLH and saves them in your local environment using following commands (by default this will run with the synthetic data in its current location; change the <code>data_folder_name</code> parameter if you have downloaded the Zenodo dataset in <code>data-public</code>)</p> <pre><code>cd src\npython -m patientflow.train.emergency_demand --data_folder_name=data-synthetic\n</code></pre> <p>The <code>data_folder_name</code>argument specifies the name of the folder containing data. The function expects this folder to be directly below the root of the repository</p>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li> Initial Research</li> <li> Minimum viable product &lt;-- You are Here</li> <li> Alpha Release</li> <li> Feature-Complete Release</li> </ul>"},{"location":"#project-team","title":"Project Team","text":"<ul> <li>Dr Zella King, Clinical Operational Research Unit (CORU), University College London (zella.king@ucl.ac.uk)</li> <li>Jon Gillham, Institute of Health Informatics, UCL</li> <li>Professor Sonya Crowe, CORU</li> <li>Professor Martin Utley, CORU</li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>The py-pi template developed by Tom Monks inspired us to create a Python package. This repository is based on a template developed by the Centre for Advanced Research Computing, University College London. We are grateful to Lawrence Lai for creation of the synthetic dataset. MAPS QR Policy Funding from by University College London contributed to the construction of the repository.</p> <p>The development of this repository/package was funded by UCL's QR Policy Support Fund, which is funded by Research England.</p>"},{"location":"LICENSE/","title":"MIT License","text":"<p>Copyright (c) 2024 Zella King</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"api/","title":"API reference","text":"<p>PatientFlow: A package for predicting short-term hospital bed demand.</p> <p>This package provides tools and models for analysing patient flow data and making predictions about emergency demand, elective demand, and hospital discharges.</p>"},{"location":"api/#patientflow.aggregate","title":"<code>aggregate</code>","text":"<p>Aggregate Prediction From Patient-Level Probabilities</p> <p>This submodule provides functions to aggregate patient-level predicted probabilities into a probability distribution. The module uses symbolic mathematics to generate and manipulate expressions, enabling the computation of aggregate probabilities based on individual patient-level predictions.</p> Dependencies <ul> <li>numpy: For array operations and numerical calculations.</li> <li>pandas: To handle and manipulate tabular data (DataFrames) for analysis.</li> <li>sympy: A symbolic mathematics library for building and manipulating symbolic expressions, particularly for calculating probabilities.</li> </ul>"},{"location":"api/#patientflow.aggregate--functions","title":"Functions","text":"<p>create_symbols(n):     Generates a list of symbolic variables to represent probability terms.</p> <pre><code>Parameters\n----------\nn : int\n    Number of symbolic variables to generate.\n\nReturns\n-------\nlist of sympy.Symbol\n    A list containing n symbolic variables.\n</code></pre> <p>compute_core_expression(ri, s):     Computes a symbolic expression using symbolic variables and constants.</p> <pre><code>Parameters\n----------\nri : float\n    A constant value (often a probability).\ns : sympy.Symbol\n    A symbolic variable.\n\nReturns\n-------\nsympy.Mul\n    A symbolic expression representing the product of `ri` and `s`.\n</code></pre> <p>build_expression(syms, n):     Constructs a cumulative product of symbolic expressions using symbolic variables.</p> <pre><code>Parameters\n----------\nsyms : list of sympy.Symbol\n    A list of symbolic variables.\nn : int\n    The number of terms to include in the cumulative product.\n\nReturns\n-------\nsympy.Expr\n    A symbolic expression representing the cumulative product of `syms`.\n</code></pre> <p>expression_subs(expression, n, predictions):     Substitutes numeric values into a symbolic expression.</p> <pre><code>Parameters\n----------\nexpression : sympy.Expr\n    A symbolic expression to perform substitution on.\nn : int\n    The number of variables to substitute.\npredictions : array-like\n    Numeric values (e.g., predicted probabilities) to substitute into the expression.\n\nReturns\n-------\nsympy.Expr\n    The symbolic expression after substitution.\n</code></pre> <p>return_coeff(expression, i):     Extracts the coefficient corresponding to a specific term in an expanded symbolic expression.</p> <pre><code>Parameters\n----------\nexpression : sympy.Expr\n    A symbolic expression that has been expanded.\ni : int\n    The index of the term for which the coefficient is to be extracted.\n\nReturns\n-------\nfloat\n    The coefficient for the i-th term.\n</code></pre> <p>model_input_to_pred_proba(model_input, model):     Converts input data into predicted probabilities using the provided model.</p> <pre><code>Parameters\n----------\nmodel_input : array-like\n    The input data to feed into the model.\nmodel : object\n    A predictive model object that implements a `predict_proba` method.\n\nReturns\n-------\narray-like\n    The predicted probabilities output by the model.\n</code></pre> <p>pred_proba_to_agg_predicted(predictions_proba, weights):     Aggregates individual predicted probabilities into an overall prediction using provided weights.</p> <pre><code>Parameters\n----------\npredictions_proba : array-like\n    Predicted probabilities for individual patients.\nweights : array-like\n    Weights corresponding to each patient's probability prediction.\n\nReturns\n-------\nfloat\n    The aggregate predicted probability.\n</code></pre> <p>get_prob_dist_for_prediction_moment(X_test, model, weights, y_test, inference_time):     Computes predicted and observed probabilities for a specific prediction date.</p> <pre><code>Parameters\n----------\nX_test : DataFrame or array-like\n    Input test data to be passed to the model for prediction.\nmodel : object or TrainedClassifier\n    Either a predictive model which provides a `predict_proba` method,\n    or a TrainedClassifier object containing a pipeline.\nweights : array-like, optional\n    Weights for aggregating the predicted probabilities.\ny_test : array-like\n    Observed target values corresponding to the test data (optional for inference).\ninference_time : bool\n    Indicates whether the function is used in inference mode (i.e., whether observed data is available).\n\nReturns\n-------\ndict\n    A dictionary containing the predicted and, if applicable, observed probability distributions.\n</code></pre> <p>get_prob_dist(snapshots_dict, X_test, y_test, model, weights):     Computes probability distributions for multiple snapshot dates.</p> <pre><code>Parameters\n----------\nsnapshots_dict : dict\n    A dictionary where keys are snapshot dates and values are associated metadata (e.g., test data).\nX_test : DataFrame or array-like\n    Input test data to be passed to the model.\ny_test : array-like\n    Observed target values.\nmodel : object or TrainedClassifier\n    Either a predictive model which provides a `predict_proba` method,\n    or a TrainedClassifier object containing a pipeline.\nweights : pandas.Series, optional\n    A Series containing weights for the test data points, which may influence the prediction,\n    by default None. If provided, the weights should be indexed similarly to `X_test` and `y_test`.\n\nReturns\n-------\ndict\n    A dictionary where each key is a snapshot date and the value is the corresponding probability distribution.\n\nRaises\n------\nValueError\n    If snapshots_dict is not properly formatted or empty.\n    If model has no predict_proba method and is not a TrainedClassifier.\n\nExample Usage\n-------------\n# Assuming a predictive model and test data are available\nsnapshot_dates = ['2023-01-01', '2023-01-02']\npredicted_distribution = get_prob_dist(snapshot_dates, dataset, X_test, y_test, model)\nprint(predicted_distribution)\n</code></pre>"},{"location":"api/#patientflow.aggregate.build_expression","title":"<code>build_expression(syms, n)</code>","text":"<p>Construct a cumulative product expression by combining individual symbolic expressions.</p>"},{"location":"api/#patientflow.aggregate.build_expression--parameters","title":"Parameters","text":"<p>syms : iterable     Iterable containing symbols to use in the expressions. n : int     The number of terms to include in the cumulative product.</p>"},{"location":"api/#patientflow.aggregate.build_expression--returns","title":"Returns","text":"<p>Expr     The cumulative product of the expressions.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def build_expression(syms, n):\n    \"\"\"\n    Construct a cumulative product expression by combining individual symbolic expressions.\n\n    Parameters\n    ----------\n    syms : iterable\n        Iterable containing symbols to use in the expressions.\n    n : int\n        The number of terms to include in the cumulative product.\n\n    Returns\n    -------\n    Expr\n        The cumulative product of the expressions.\n\n    \"\"\"\n    s = sym.Symbol(\"s\")\n    expression = 1\n    for i in range(n):\n        expression *= compute_core_expression(syms[i], s)\n    return expression\n</code></pre>"},{"location":"api/#patientflow.aggregate.compute_core_expression","title":"<code>compute_core_expression(ri, s)</code>","text":"<p>Compute a symbolic expression involving a basic mathematical operation with a symbol and a constant.</p>"},{"location":"api/#patientflow.aggregate.compute_core_expression--parameters","title":"Parameters","text":"<p>ri : float     The constant value to substitute into the expression. s : Symbol     The symbolic object used in the expression.</p>"},{"location":"api/#patientflow.aggregate.compute_core_expression--returns","title":"Returns","text":"<p>Expr     The symbolic expression after substitution.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def compute_core_expression(ri, s):\n    \"\"\"\n    Compute a symbolic expression involving a basic mathematical operation with a symbol and a constant.\n\n    Parameters\n    ----------\n    ri : float\n        The constant value to substitute into the expression.\n    s : Symbol\n        The symbolic object used in the expression.\n\n    Returns\n    -------\n    Expr\n        The symbolic expression after substitution.\n\n    \"\"\"\n    r = sym.Symbol(\"r\")\n    core_expression = (1 - r) + r * s\n    return core_expression.subs({r: ri})\n</code></pre>"},{"location":"api/#patientflow.aggregate.create_symbols","title":"<code>create_symbols(n)</code>","text":"<p>Generate a sequence of symbolic objects intended for use in mathematical expressions.</p>"},{"location":"api/#patientflow.aggregate.create_symbols--parameters","title":"Parameters","text":"<p>n : int     Number of symbols to create.</p>"},{"location":"api/#patientflow.aggregate.create_symbols--returns","title":"Returns","text":"<p>tuple     A tuple containing the generated symbolic objects.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def create_symbols(n):\n    \"\"\"\n    Generate a sequence of symbolic objects intended for use in mathematical expressions.\n\n    Parameters\n    ----------\n    n : int\n        Number of symbols to create.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the generated symbolic objects.\n\n    \"\"\"\n    return symbols(f\"r0:{n}\")\n</code></pre>"},{"location":"api/#patientflow.aggregate.expression_subs","title":"<code>expression_subs(expression, n, predictions)</code>","text":"<p>Substitute values into a symbolic expression based on a mapping from symbols to predictions.</p>"},{"location":"api/#patientflow.aggregate.expression_subs--parameters","title":"Parameters","text":"<p>expression : Expr     The symbolic expression to perform substitution on. n : int     Number of symbols and corresponding predictions. predictions : list     List of numerical predictions to substitute.</p>"},{"location":"api/#patientflow.aggregate.expression_subs--returns","title":"Returns","text":"<p>Expr     The expression after performing the substitution.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def expression_subs(expression, n, predictions):\n    \"\"\"\n    Substitute values into a symbolic expression based on a mapping from symbols to predictions.\n\n    Parameters\n    ----------\n    expression : Expr\n        The symbolic expression to perform substitution on.\n    n : int\n        Number of symbols and corresponding predictions.\n    predictions : list\n        List of numerical predictions to substitute.\n\n    Returns\n    -------\n    Expr\n        The expression after performing the substitution.\n\n    \"\"\"\n    syms = create_symbols(n)\n    substitution = dict(zip(syms, predictions))\n    return expression.subs(substitution)\n</code></pre>"},{"location":"api/#patientflow.aggregate.get_prob_dist","title":"<code>get_prob_dist(snapshots_dict, X_test, y_test, model, weights=None)</code>","text":"<p>Calculate probability distributions for each snapshot date based on given model predictions.</p>"},{"location":"api/#patientflow.aggregate.get_prob_dist--parameters","title":"Parameters","text":"<p>snapshots_dict : dict     A dictionary mapping snapshot dates to indices in <code>X_test</code> and <code>y_test</code>.     Must have datetime.date objects as keys and lists of indices as values. X_test : DataFrame or array-like     Input test data to be passed to the model. y_test : array-like     Observed target values. model : object or TrainedClassifier     Either a predictive model which provides a <code>predict_proba</code> method,     or a TrainedClassifier object containing a pipeline. weights : pandas.Series, optional     A Series containing weights for the test data points.</p>"},{"location":"api/#patientflow.aggregate.get_prob_dist--returns","title":"Returns","text":"<p>dict     A dictionary mapping snapshot dates to probability distributions.</p>"},{"location":"api/#patientflow.aggregate.get_prob_dist--raises","title":"Raises","text":"<p>ValueError     If snapshots_dict is not properly formatted or empty.     If model has no predict_proba method and is not a TrainedClassifier.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def get_prob_dist(snapshots_dict, X_test, y_test, model, weights=None):\n    \"\"\"\n    Calculate probability distributions for each snapshot date based on given model predictions.\n\n    Parameters\n    ----------\n    snapshots_dict : dict\n        A dictionary mapping snapshot dates to indices in `X_test` and `y_test`.\n        Must have datetime.date objects as keys and lists of indices as values.\n    X_test : DataFrame or array-like\n        Input test data to be passed to the model.\n    y_test : array-like\n        Observed target values.\n    model : object or TrainedClassifier\n        Either a predictive model which provides a `predict_proba` method,\n        or a TrainedClassifier object containing a pipeline.\n    weights : pandas.Series, optional\n        A Series containing weights for the test data points.\n\n    Returns\n    -------\n    dict\n        A dictionary mapping snapshot dates to probability distributions.\n\n    Raises\n    ------\n    ValueError\n        If snapshots_dict is not properly formatted or empty.\n        If model has no predict_proba method and is not a TrainedClassifier.\n    \"\"\"\n    # Validate snapshots_dict format\n    if not snapshots_dict:\n        raise ValueError(\"snapshots_dict cannot be empty\")\n\n    for dt, indices in snapshots_dict.items():\n        if not isinstance(dt, date):\n            raise ValueError(\n                f\"snapshots_dict keys must be datetime.date objects, got {type(dt)}\"\n            )\n        if not isinstance(indices, list):\n            raise ValueError(\n                f\"snapshots_dict values must be lists, got {type(indices)}\"\n            )\n        if indices and not all(isinstance(idx, int) for idx in indices):\n            raise ValueError(\"All indices in snapshots_dict must be integers\")\n\n    # Extract pipeline if model is a TrainedClassifier\n    if hasattr(model, \"calibrated_pipeline\") and model.calibrated_pipeline is not None:\n        model = model.calibrated_pipeline\n    elif hasattr(model, \"pipeline\"):\n        model = model.pipeline\n    # Validate that model has predict_proba method\n    elif not hasattr(model, \"predict_proba\"):\n        raise ValueError(\n            \"Model must either be a TrainedClassifier or have a predict_proba method\"\n        )\n\n    prob_dist_dict = {}\n    print(\n        f\"Calculating probability distributions for {len(snapshots_dict)} snapshot dates\"\n    )\n\n    if len(snapshots_dict) &gt; 10:\n        print(\"This may take a minute or more\")\n\n    # Initialize a counter for notifying the user every 10 snapshot dates processed\n    count = 0\n\n    for dt, snapshots_to_include in snapshots_dict.items():\n        if len(snapshots_to_include) == 0:\n            # Create an empty dictionary for the current snapshot date\n            prob_dist_dict[dt] = {\n                \"agg_predicted\": pd.DataFrame({\"agg_proba\": [1]}, index=[0]),\n                \"agg_observed\": 0,\n            }\n        else:\n            # Ensure the lengths of test features and outcomes are equal\n            assert len(X_test.loc[snapshots_to_include]) == len(\n                y_test.loc[snapshots_to_include]\n            ), \"Mismatch in lengths of X_test and y_test snapshots.\"\n\n            if weights is None:\n                prediction_moment_weights = None\n            else:\n                prediction_moment_weights = weights.loc[snapshots_to_include].values\n\n            # Compute the predicted and observed valuesfor the current snapshot date\n            prob_dist_dict[dt] = get_prob_dist_for_prediction_moment(\n                X_test=X_test.loc[snapshots_to_include],\n                y_test=y_test.loc[snapshots_to_include],\n                model=model,\n                weights=prediction_moment_weights,\n            )\n\n        # Increment the counter and notify the user every 10 snapshot dates processed\n        count += 1\n        if count % 10 == 0 and count != len(snapshots_dict):\n            print(f\"Processed {count} snapshot dates\")\n\n    print(f\"Processed {len(snapshots_dict)} snapshot dates\")\n\n    return prob_dist_dict\n</code></pre>"},{"location":"api/#patientflow.aggregate.get_prob_dist_for_prediction_moment","title":"<code>get_prob_dist_for_prediction_moment(X_test, model, weights=None, inference_time=False, y_test=None)</code>","text":"<p>Calculate both predicted distributions and observed values for a given date using test data.</p>"},{"location":"api/#patientflow.aggregate.get_prob_dist_for_prediction_moment--parameters","title":"Parameters","text":"<p>X_test : array-like     Test features for a specific snapshot date. model : object or TrainedClassifier     Either a predictive model which provides a <code>predict_proba</code> method,     or a TrainedClassifier object containing a pipeline. weights : array-like, optional     Weights to apply to the predictions for aggregate calculation. inference_time : bool, optional (default=False)     If True, do not calculate or return actual aggregate. y_test : array-like, optional     Actual outcomes corresponding to the test features. Required if inference_time is False.</p>"},{"location":"api/#patientflow.aggregate.get_prob_dist_for_prediction_moment--returns","title":"Returns","text":"<p>dict     A dictionary with keys 'agg_predicted' and, if inference_time is False, 'agg_observed'.</p>"},{"location":"api/#patientflow.aggregate.get_prob_dist_for_prediction_moment--raises","title":"Raises","text":"<p>ValueError     If y_test is not provided when inference_time is False.     If model has no predict_proba method and is not a TrainedClassifier.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def get_prob_dist_for_prediction_moment(\n    X_test, model, weights=None, inference_time=False, y_test=None\n):\n    \"\"\"\n    Calculate both predicted distributions and observed values for a given date using test data.\n\n    Parameters\n    ----------\n    X_test : array-like\n        Test features for a specific snapshot date.\n    model : object or TrainedClassifier\n        Either a predictive model which provides a `predict_proba` method,\n        or a TrainedClassifier object containing a pipeline.\n    weights : array-like, optional\n        Weights to apply to the predictions for aggregate calculation.\n    inference_time : bool, optional (default=False)\n        If True, do not calculate or return actual aggregate.\n    y_test : array-like, optional\n        Actual outcomes corresponding to the test features. Required if inference_time is False.\n\n    Returns\n    -------\n    dict\n        A dictionary with keys 'agg_predicted' and, if inference_time is False, 'agg_observed'.\n\n    Raises\n    ------\n    ValueError\n        If y_test is not provided when inference_time is False.\n        If model has no predict_proba method and is not a TrainedClassifier.\n    \"\"\"\n    if not inference_time and y_test is None:\n        raise ValueError(\"y_test must be provided if inference_time is False.\")\n\n    # Extract pipeline if model is a TrainedClassifier\n    if hasattr(model, \"calibrated_pipeline\") and model.calibrated_pipeline is not None:\n        model = model.calibrated_pipeline\n    elif hasattr(model, \"pipeline\"):\n        model = model.pipeline\n    # Validate that model has predict_proba method\n    elif not hasattr(model, \"predict_proba\"):\n        raise ValueError(\n            \"Model must either be a TrainedClassifier or have a predict_proba method\"\n        )\n\n    prediction_moment_dict = {}\n\n    if len(X_test) &gt; 0:\n        pred_proba = model_input_to_pred_proba(X_test, model)\n        agg_predicted = pred_proba_to_agg_predicted(pred_proba, weights)\n        prediction_moment_dict[\"agg_predicted\"] = agg_predicted\n\n        if not inference_time:\n            prediction_moment_dict[\"agg_observed\"] = sum(y_test)\n    else:\n        prediction_moment_dict[\"agg_predicted\"] = pd.DataFrame(\n            {\"agg_proba\": [1]}, index=[0]\n        )\n        if not inference_time:\n            prediction_moment_dict[\"agg_observed\"] = 0\n\n    return prediction_moment_dict\n</code></pre>"},{"location":"api/#patientflow.aggregate.model_input_to_pred_proba","title":"<code>model_input_to_pred_proba(model_input, model)</code>","text":"<p>Use a predictive model to convert model input data into predicted probabilities.</p>"},{"location":"api/#patientflow.aggregate.model_input_to_pred_proba--parameters","title":"Parameters","text":"<p>model_input : array-like     The input data to the model, typically as features used for predictions. model : object     A model object with a <code>predict_proba</code> method that computes probability estimates.</p>"},{"location":"api/#patientflow.aggregate.model_input_to_pred_proba--returns","title":"Returns","text":"<p>DataFrame     A pandas DataFrame containing the predicted probabilities for the positive class,     with one column labeled 'pred_proba'.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def model_input_to_pred_proba(model_input, model):\n    \"\"\"\n    Use a predictive model to convert model input data into predicted probabilities.\n\n    Parameters\n    ----------\n    model_input : array-like\n        The input data to the model, typically as features used for predictions.\n    model : object\n        A model object with a `predict_proba` method that computes probability estimates.\n\n    Returns\n    -------\n    DataFrame\n        A pandas DataFrame containing the predicted probabilities for the positive class,\n        with one column labeled 'pred_proba'.\n\n    \"\"\"\n    if len(model_input) == 0:\n        return pd.DataFrame(columns=[\"pred_proba\"])\n    else:\n        predictions = model.predict_proba(model_input)[:, 1]\n        return pd.DataFrame(\n            predictions, index=model_input.index, columns=[\"pred_proba\"]\n        )\n</code></pre>"},{"location":"api/#patientflow.aggregate.pred_proba_to_agg_predicted","title":"<code>pred_proba_to_agg_predicted(predictions_proba, weights=None)</code>","text":"<p>Convert individual probability predictions into aggregate predicted probability distribution using optional weights.</p>"},{"location":"api/#patientflow.aggregate.pred_proba_to_agg_predicted--parameters","title":"Parameters","text":"<p>predictions_proba : DataFrame     A DataFrame containing the probability predictions; must have a single column named 'pred_proba'. weights : array-like, optional     An array of weights, of the same length as the DataFrame rows, to apply to each prediction.</p>"},{"location":"api/#patientflow.aggregate.pred_proba_to_agg_predicted--returns","title":"Returns","text":"<p>DataFrame     A DataFrame with a single column 'agg_proba' showing the aggregated probability,     indexed from 0 to n, where n is the number of predictions.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def pred_proba_to_agg_predicted(predictions_proba, weights=None):\n    \"\"\"\n    Convert individual probability predictions into aggregate predicted probability distribution using optional weights.\n\n    Parameters\n    ----------\n    predictions_proba : DataFrame\n        A DataFrame containing the probability predictions; must have a single column named 'pred_proba'.\n    weights : array-like, optional\n        An array of weights, of the same length as the DataFrame rows, to apply to each prediction.\n\n    Returns\n    -------\n    DataFrame\n        A DataFrame with a single column 'agg_proba' showing the aggregated probability,\n        indexed from 0 to n, where n is the number of predictions.\n\n    \"\"\"\n    n = len(predictions_proba)\n\n    if n == 0:\n        agg_predicted_dict = {0: 1}\n    else:\n        local_proba = predictions_proba.copy()\n        if weights is not None:\n            local_proba[\"pred_proba\"] *= weights\n\n        syms = create_symbols(n)\n        expression = build_expression(syms, n)\n        expression = expression_subs(expression, n, local_proba[\"pred_proba\"])\n        agg_predicted_dict = {i: return_coeff(expression, i) for i in range(n + 1)}\n\n    agg_predicted = pd.DataFrame.from_dict(\n        agg_predicted_dict, orient=\"index\", columns=[\"agg_proba\"]\n    )\n    return agg_predicted\n</code></pre>"},{"location":"api/#patientflow.aggregate.return_coeff","title":"<code>return_coeff(expression, i)</code>","text":"<p>Extract the coefficient of a specified power from an expanded symbolic expression.</p>"},{"location":"api/#patientflow.aggregate.return_coeff--parameters","title":"Parameters","text":"<p>expression : Expr     The expression to expand and extract from. i : int     The power of the term whose coefficient is to be extracted.</p>"},{"location":"api/#patientflow.aggregate.return_coeff--returns","title":"Returns","text":"<p>number     The coefficient of the specified power in the expression.</p> Source code in <code>src/patientflow/aggregate.py</code> <pre><code>def return_coeff(expression, i):\n    \"\"\"\n    Extract the coefficient of a specified power from an expanded symbolic expression.\n\n    Parameters\n    ----------\n    expression : Expr\n        The expression to expand and extract from.\n    i : int\n        The power of the term whose coefficient is to be extracted.\n\n    Returns\n    -------\n    number\n        The coefficient of the specified power in the expression.\n\n    \"\"\"\n    s = sym.Symbol(\"s\")\n    return expand(expression).coeff(s, i)\n</code></pre>"},{"location":"api/#patientflow.convert","title":"<code>convert</code>","text":"<p>Data Processing and Anonymization for Hospital Visit Records.</p> <p>This script provides functions to preprocess hospital visit data, including: - Calculating patient age on arrival and grouping by age ranges. - Shifting dates forward to anonymize visit data. - Mapping consultation codes to predefined consultation types. - Resampling arrival hours in a target dataset based on source data.</p> <p>The script can be run as a standalone program to adjust arrival hours in a target dataset using a source dataset's time distribution.</p>"},{"location":"api/#patientflow.convert--functions","title":"Functions","text":"<ul> <li>prepare_age_and_dates(df) : Calculates patient age on arrival and categorizes into age groups.</li> <li>shift_dates_into_future(df, yta, seed_path) : Shifts all date-related fields into the future for anonymization.</li> <li>map_consultations_to_types(df, name_mapping) : Maps consultation codes to their respective consultation types.</li> <li>resample_hours(df_source, df_target) : Resamples arrival hours in the target dataset based on the source dataset.</li> <li>main() : Command-line interface for resampling hours using input CSV files.</li> </ul>"},{"location":"api/#patientflow.convert--usage","title":"Usage","text":"<p>To run the script from the command line:     python3 convert.py --source  --target  --output"},{"location":"api/#patientflow.convert.main","title":"<code>main()</code>","text":"<p>Main function to resample hours from a source dataset to a target dataset.</p> <p>This function reads input CSV files, resamples arrival times in the target dataset based on the probability distribution from the source dataset, and saves the modified target dataset to an output file.</p> Source code in <code>src/patientflow/convert.py</code> <pre><code>def main():\n    \"\"\"\n    Main function to resample hours from a source dataset to a target dataset.\n\n    This function reads input CSV files, resamples arrival times in the target\n    dataset based on the probability distribution from the source dataset, and\n    saves the modified target dataset to an output file.\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Resample hours from source arrivals data to target data\"\n    )\n    parser.add_argument(\n        \"--source\",\n        default=\"data-public/inpatient_arrivals.csv\",\n        help=\"Source CSV file with original hour distribution\",\n    )\n    parser.add_argument(\n        \"--target\",\n        default=\"data-synthetic/inpatient_arrivals.csv\",\n        help=\"Target CSV file to modify\",\n    )\n    parser.add_argument(\n        \"--output\",\n        default=\"data-synthetic/inpatient_arrivals_modified.csv\",\n        help=\"Output file path\",\n    )\n\n    args = parser.parse_args()\n\n    df_source = pd.read_csv(args.source, parse_dates=[\"arrival_datetime\"])\n    df_target = pd.read_csv(args.target, parse_dates=[\"arrival_datetime\"])\n\n    df_new = resample_hours(df_source, df_target)\n\n    df_new.to_csv(args.output, index=False)\n    print(f\"Modified {len(df_new)} arrival times and saved to {args.output}\")\n</code></pre>"},{"location":"api/#patientflow.convert.map_consultations_to_types","title":"<code>map_consultations_to_types(df, name_mapping)</code>","text":"<p>Map consultation codes to their respective types using a predefined mapping.</p>"},{"location":"api/#patientflow.convert.map_consultations_to_types--parameters","title":"Parameters","text":"<p>df : pandas.DataFrame     The dataframe containing columns 'consultation_sequence' and 'final_sequence',     which store lists of consultation codes. name_mapping : pandas.DataFrame     A dataframe with 'code' and 'type' columns mapping consultation codes     to their respective types.</p>"},{"location":"api/#patientflow.convert.map_consultations_to_types--returns","title":"Returns","text":"<p>pandas.DataFrame     The modified dataframe with mapped consultation types.</p> Source code in <code>src/patientflow/convert.py</code> <pre><code>def map_consultations_to_types(df, name_mapping):\n    \"\"\"\n    Map consultation codes to their respective types using a predefined mapping.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        The dataframe containing columns 'consultation_sequence' and 'final_sequence',\n        which store lists of consultation codes.\n    name_mapping : pandas.DataFrame\n        A dataframe with 'code' and 'type' columns mapping consultation codes\n        to their respective types.\n\n    Returns\n    -------\n    pandas.DataFrame\n        The modified dataframe with mapped consultation types.\n    \"\"\"\n    code_to_type = dict(zip(name_mapping[\"code\"], name_mapping[\"type\"]))\n\n    def map_codes_to_types(codes):\n        return [code_to_type.get(code, \"unknown\") for code in codes]\n\n    df[\"consultation_sequence\"] = df[\"consultation_sequence\"].apply(map_codes_to_types)\n    df[\"final_sequence\"] = df[\"final_sequence\"].apply(map_codes_to_types)\n\n    return df\n</code></pre>"},{"location":"api/#patientflow.convert.prepare_age_and_dates","title":"<code>prepare_age_and_dates(df)</code>","text":"<p>Prepare age and date-related features in the dataset.</p> <p>This function calculates the age of individuals on arrival based on their date of birth and arrival datetime. It also categorizes them into age groups. If <code>snapshot_datetime</code> exists in the dataframe, it computes the prediction time, snapshot date, and elapsed length of stay (LOS).</p>"},{"location":"api/#patientflow.convert.prepare_age_and_dates--parameters","title":"Parameters","text":"<p>df : pandas.DataFrame     A dataframe containing at least the columns 'date_of_birth' and     'arrival_datetime'. If 'snapshot_datetime' exists, additional     computations are performed.</p>"},{"location":"api/#patientflow.convert.prepare_age_and_dates--returns","title":"Returns","text":"<p>pandas.DataFrame     The modified dataframe with additional columns:     - 'age_on_arrival': Numeric representation of age at arrival.     - 'age_group': Categorical age group.     - 'prediction_time': Tuple representing the hour and minute of the snapshot.     - 'snapshot_date': Date extracted from 'snapshot_datetime'.     - 'elapsed_los': Time in seconds since arrival (if snapshot is available).</p> Source code in <code>src/patientflow/convert.py</code> <pre><code>def prepare_age_and_dates(df):\n    \"\"\"\n    Prepare age and date-related features in the dataset.\n\n    This function calculates the age of individuals on arrival based on their\n    date of birth and arrival datetime. It also categorizes them into age groups.\n    If `snapshot_datetime` exists in the dataframe, it computes the prediction\n    time, snapshot date, and elapsed length of stay (LOS).\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A dataframe containing at least the columns 'date_of_birth' and\n        'arrival_datetime'. If 'snapshot_datetime' exists, additional\n        computations are performed.\n\n    Returns\n    -------\n    pandas.DataFrame\n        The modified dataframe with additional columns:\n        - 'age_on_arrival': Numeric representation of age at arrival.\n        - 'age_group': Categorical age group.\n        - 'prediction_time': Tuple representing the hour and minute of the snapshot.\n        - 'snapshot_date': Date extracted from 'snapshot_datetime'.\n        - 'elapsed_los': Time in seconds since arrival (if snapshot is available).\n    \"\"\"\n    df[\"age_on_arrival\"] = (\n        pd.to_timedelta(\n            (\n                pd.to_datetime(df[\"arrival_datetime\"]).dt.date\n                - pd.to_datetime(df[\"date_of_birth\"]).dt.date\n            )\n        ).dt.days\n        / 365.2425\n    ).apply(lambda x: np.floor(x) if pd.notna(x) else x)\n\n    bins = [-1, 18, 25, 35, 45, 55, 65, 75, 102]\n    labels = [\"0-17\", \"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65-74\", \"75-102\"]\n    df[\"age_group\"] = pd.cut(df[\"age_on_arrival\"], bins=bins, labels=labels, right=True)\n\n    if \"snapshot_datetime\" in df.columns:\n        df[\"prediction_time\"] = (\n            df[\"snapshot_datetime\"]\n            .dt.strftime(\"%H,%M\")\n            .apply(lambda x: tuple(map(int, x.split(\",\"))))\n        )\n        df[\"snapshot_date\"] = pd.to_datetime(df[\"snapshot_datetime\"]).dt.date\n        df[\"elapsed_los\"] = (\n            df[\"snapshot_datetime\"] - df[\"arrival_datetime\"]\n        ).dt.total_seconds()\n\n    return df\n</code></pre>"},{"location":"api/#patientflow.convert.resample_hours","title":"<code>resample_hours(df_source, df_target)</code>","text":"<p>Resample arrival hours in <code>df_target</code> based on the probability distribution of arrival hours from <code>df_source</code>.</p>"},{"location":"api/#patientflow.convert.resample_hours--parameters","title":"Parameters","text":"<p>df_source : pandas.DataFrame     Source dataframe with 'arrival_datetime' column to derive the hour distribution. df_target : pandas.DataFrame     Target dataframe where arrival hours will be modified.</p>"},{"location":"api/#patientflow.convert.resample_hours--returns","title":"Returns","text":"<p>pandas.DataFrame     Modified target dataframe with new arrival hours.</p> Source code in <code>src/patientflow/convert.py</code> <pre><code>def resample_hours(df_source, df_target):\n    \"\"\"\n    Resample arrival hours in `df_target` based on the probability distribution\n    of arrival hours from `df_source`.\n\n    Parameters\n    ----------\n    df_source : pandas.DataFrame\n        Source dataframe with 'arrival_datetime' column to derive the hour distribution.\n    df_target : pandas.DataFrame\n        Target dataframe where arrival hours will be modified.\n\n    Returns\n    -------\n    pandas.DataFrame\n        Modified target dataframe with new arrival hours.\n    \"\"\"\n    arrival_hours = df_source[\"arrival_datetime\"].dt.hour\n    hour_counts = arrival_hours.value_counts()\n    total_arrivals = len(arrival_hours)\n    hour_probabilities = hour_counts / total_arrivals\n\n    hours = np.array(hour_probabilities.index)\n    probabilities = np.array(hour_probabilities.values)\n\n    new_hours = np.random.choice(hours, size=len(df_target), p=probabilities)\n    new_datetimes = pd.Series(\n        [x.replace(hour=h) for x, h in zip(df_target[\"arrival_datetime\"], new_hours)]\n    )\n    df_target[\"arrival_datetime\"] = new_datetimes\n\n    return df_target\n</code></pre>"},{"location":"api/#patientflow.convert.shift_dates_into_future","title":"<code>shift_dates_into_future(df, yta, seed_path)</code>","text":"<p>Shift all date-related columns into the future to anonymize visit data.</p> <p>This function reads a random seed from a file, generates a random number of weeks to shift all date-related columns, and applies this shift.</p>"},{"location":"api/#patientflow.convert.shift_dates_into_future--parameters","title":"Parameters","text":"<p>df : pandas.DataFrame     The main dataset containing visit records with date columns. yta : pandas.DataFrame     Additional dataset with arrival and departure datetime fields to be shifted. seed_path : str     Path to the file containing the seed value.</p>"},{"location":"api/#patientflow.convert.shift_dates_into_future--returns","title":"Returns","text":"<p>tuple     A tuple containing the modified <code>df</code> and <code>yta</code> dataframes.</p> Source code in <code>src/patientflow/convert.py</code> <pre><code>def shift_dates_into_future(df, yta, seed_path):\n    \"\"\"\n    Shift all date-related columns into the future to anonymize visit data.\n\n    This function reads a random seed from a file, generates a random number\n    of weeks to shift all date-related columns, and applies this shift.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        The main dataset containing visit records with date columns.\n    yta : pandas.DataFrame\n        Additional dataset with arrival and departure datetime fields to be shifted.\n    seed_path : str\n        Path to the file containing the seed value.\n\n    Returns\n    -------\n    tuple\n        A tuple containing the modified `df` and `yta` dataframes.\n    \"\"\"\n    print(\"\\nConverting dates to anonymise visits. Current min and max snapshot dates:\")\n    print(df.snapshot_date.min())\n    print(df.snapshot_date.max())\n\n    with open(seed_path, \"r\") as file:\n        seed = int(file.read().strip())\n\n    np.random.seed(seed)\n    n = np.random.randint(1, 10 * 52)  # Random shift in weeks\n\n    df.loc[:, \"snapshot_date\"] += pd.Timedelta(days=n * 7)\n    df.loc[:, \"snapshot_datetime\"] += pd.Timedelta(days=n * 7)\n    df.loc[:, \"arrival_datetime\"] += pd.Timedelta(days=n * 7)\n    df.loc[:, \"departure_datetime\"] += pd.Timedelta(days=n * 7)\n\n    print(\"New min and max snapshot dates:\")\n    print(df.snapshot_date.min())\n    print(df.snapshot_date.max())\n\n    yta[\"arrival_datetime\"] += pd.Timedelta(days=n * 7)\n    yta[\"departure_datetime\"] += pd.Timedelta(days=n * 7)\n\n    return df, yta\n</code></pre>"},{"location":"api/#patientflow.evaluate","title":"<code>evaluate</code>","text":"<p>Patient Flow Evaluation Module</p> <p>This module provides functions for evaluating and comparing different prediction models for patient admissions in a healthcare setting. It includes utilities for calculating metrics such as Mean Absolute Error (MAE) and Mean Percentage Error (MPE), as well as functions for predicting admissions based on historical data and combining different prediction models.</p> <p>Key Features: - Evaluation of probability distribution-based prediction models - Calculation of observed admissions based on ED targets - Prediction using historical data from previous weeks - Combination and evaluation of multiple prediction models</p> <p>Main Functions: - calc_mae_mpe: Calculate MAE and MPE for probability distribution predictions - calculate_weighted_observed: Calculate actual admissions assuming ED targets are met - predict_using_previous_weeks: Predict admissions using average from previous weeks - evaluate_six_week_average: Evaluate the six-week average prediction model - evaluate_combined_model: Evaluate a combined prediction model</p>"},{"location":"api/#patientflow.evaluate.calc_mae_mpe","title":"<code>calc_mae_mpe(prob_dist_dict_all, use_most_probable=True)</code>","text":"<p>Calculate MAE and MPE for all prediction times in the given probability distribution dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>prob_dist_dict_all</code> <code>Dict[Any, Dict[Any, Dict[str, Any]]]</code> <p>Nested dictionary containing probability distributions.</p> required <code>use_most_probable</code> <code>bool</code> <p>Whether to use the most probable value or expected value. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]</code> <p>Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]: Dictionary of results for each prediction time.</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def calc_mae_mpe(\n    prob_dist_dict_all: Dict[Any, Dict[Any, Dict[str, Any]]],\n    use_most_probable: bool = True,\n) -&gt; Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]:\n    \"\"\"\n    Calculate MAE and MPE for all prediction times in the given probability distribution dictionary.\n\n    Args:\n        prob_dist_dict_all (Dict[Any, Dict[Any, Dict[str, Any]]]): Nested dictionary containing probability distributions.\n        use_most_probable (bool, optional): Whether to use the most probable value or expected value. Defaults to True.\n\n    Returns:\n        Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]: Dictionary of results for each prediction time.\n    \"\"\"\n    results: Dict[Any, Dict[str, Union[List[Union[int, float]], float]]] = {}\n\n    for _prediction_time in prob_dist_dict_all.keys():\n        expected_values: List[Union[int, float]] = []\n        observed_values: List[float] = []\n\n        for dt in prob_dist_dict_all[_prediction_time].keys():\n            preds: Dict[str, Any] = prob_dist_dict_all[_prediction_time][dt]\n\n            expected_value: Union[int, float] = (\n                int(preds[\"agg_predicted\"].idxmax().values[0])\n                if use_most_probable\n                else float(\n                    np.dot(\n                        preds[\"agg_predicted\"].index,\n                        preds[\"agg_predicted\"].values.flatten(),\n                    )\n                )\n            )\n\n            observed_value: float = float(preds[\"agg_observed\"])\n\n            expected_values.append(expected_value)\n            observed_values.append(observed_value)\n\n        results[_prediction_time] = calculate_results(expected_values, observed_values)\n\n    return results\n</code></pre>"},{"location":"api/#patientflow.evaluate.calculate_admission_probs_relative_to_prediction","title":"<code>calculate_admission_probs_relative_to_prediction(df, prediction_datetime, prediction_window, x1, y1, x2, y2, is_before=True)</code>","text":"<p>Calculate admission probabilities for arrivals relative to a prediction time window</p> <p>Parameters: df: DataFrame containing arrival_datetime column prediction_datetime: datetime for prediction window start prediction_window: window length in minutes x1, y1, x2, y2: parameters for aspirational curve is_before: boolean indicating if arrivals are before prediction time</p> <p>Returns: DataFrame with added probability columns</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def calculate_admission_probs_relative_to_prediction(\n    df, prediction_datetime, prediction_window, x1, y1, x2, y2, is_before=True\n):\n    \"\"\"\n    Calculate admission probabilities for arrivals relative to a prediction time window\n\n    Parameters:\n    df: DataFrame containing arrival_datetime column\n    prediction_datetime: datetime for prediction window start\n    prediction_window: window length in minutes\n    x1, y1, x2, y2: parameters for aspirational curve\n    is_before: boolean indicating if arrivals are before prediction time\n\n    Returns:\n    DataFrame with added probability columns\n    \"\"\"\n    result = df.copy()\n\n    if is_before:\n        result[\"hours_before_pred_window\"] = result[\"arrival_datetime\"].apply(\n            lambda x: (prediction_datetime - x).seconds / 3600\n        )\n        result[\"prob_admission_before_pred_window\"] = result[\n            \"hours_before_pred_window\"\n        ].apply(lambda x: get_y_from_aspirational_curve(x, x1, y1, x2, y2))\n        result[\"prob_admission_in_pred_window\"] = result[\n            \"hours_before_pred_window\"\n        ].apply(\n            lambda x: get_y_from_aspirational_curve(\n                x + prediction_window / 60, x1, y1, x2, y2\n            )\n            - get_y_from_aspirational_curve(x, x1, y1, x2, y2)\n        )\n    else:\n        result[\"hours_after_pred_window\"] = result[\"arrival_datetime\"].apply(\n            lambda x: (x - prediction_datetime).seconds / 3600\n        )\n        result[\"prob_admission_in_pred_window\"] = result[\n            \"hours_after_pred_window\"\n        ].apply(\n            lambda x: get_y_from_aspirational_curve(\n                (prediction_window / 60) - x, x1, y1, x2, y2\n            )\n        )\n\n    return result\n</code></pre>"},{"location":"api/#patientflow.evaluate.calculate_results","title":"<code>calculate_results(expected_values, observed_values)</code>","text":"<p>Calculate evaluation metrics based on expected and observed values.</p> <p>Parameters:</p> Name Type Description Default <code>expected_values</code> <code>List[Union[int, float]]</code> <p>List of expected values.</p> required <code>observed_values</code> <code>List[float]</code> <p>List of observed values.</p> required <p>Returns:</p> Type Description <code>Dict[str, Union[List[Union[int, float]], float]]</code> <p>Dict[str, Union[List[Union[int, float]], float]]: Dictionary containing expected values, observed values, MAE, and MPE.</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def calculate_results(\n    expected_values: List[Union[int, float]], observed_values: List[float]\n) -&gt; Dict[str, Union[List[Union[int, float]], float]]:\n    \"\"\"\n    Calculate evaluation metrics based on expected and observed values.\n\n    Args:\n        expected_values (List[Union[int, float]]): List of expected values.\n        observed_values (List[float]): List of observed values.\n\n    Returns:\n        Dict[str, Union[List[Union[int, float]], float]]: Dictionary containing expected values, observed values, MAE, and MPE.\n    \"\"\"\n    expected_array: np.ndarray = np.array(expected_values)\n    observed_array: np.ndarray = np.array(observed_values)\n\n    absolute_errors: np.ndarray = np.abs(expected_array - observed_array)\n    mae: float = float(np.mean(absolute_errors))\n\n    non_zero_mask: np.ndarray = observed_array != 0\n    filtered_absolute_errors: np.ndarray = absolute_errors[non_zero_mask]\n    filtered_observed_array: np.ndarray = observed_array[non_zero_mask]\n\n    percentage_errors: np.ndarray = (\n        filtered_absolute_errors / filtered_observed_array * 100\n    )\n    mpe: float = float(np.mean(percentage_errors))\n\n    return {\n        \"expected\": expected_values,\n        \"observed\": observed_values,\n        \"mae\": mae,\n        \"mpe\": mpe,\n    }\n</code></pre>"},{"location":"api/#patientflow.evaluate.calculate_weighted_observed","title":"<code>calculate_weighted_observed(df, dt, prediction_window, x1, y1, x2, y2, prediction_time)</code>","text":"<p>Calculate weighted observed admissions for a specific date and prediction window</p> <p>Parameters: df: DataFrame with arrival_datetime column dt: target date prediction_window: window length in minutes x1, y1, x2, y2: parameters for aspirational curve prediction_time: tuple of (hour, minute)</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def calculate_weighted_observed(\n    df, dt, prediction_window, x1, y1, x2, y2, prediction_time\n):\n    \"\"\"\n    Calculate weighted observed admissions for a specific date and prediction window\n\n    Parameters:\n    df: DataFrame with arrival_datetime column\n    dt: target date\n    prediction_window: window length in minutes\n    x1, y1, x2, y2: parameters for aspirational curve\n    prediction_time: tuple of (hour, minute)\n    \"\"\"\n    # Create prediction datetime\n    prediction_datetime = pd.to_datetime(dt).replace(\n        hour=prediction_time[0], minute=prediction_time[1]\n    )\n\n    # Filter for target date and get arrivals with probabilities\n    filtered_df = df[df[\"arrival_datetime\"].dt.date == dt]\n    arrived_before, arrived_after = get_arrivals_with_admission_probs(\n        filtered_df,\n        prediction_datetime,\n        prediction_window,\n        prediction_time,\n        x1,\n        y1,\n        x2,\n        y2,\n        target_date=dt,\n    )\n\n    # Calculate weighted sum\n    weighted_observed = (\n        arrived_before[\"prob_admission_in_pred_window\"].sum()\n        + arrived_after[\"prob_admission_in_pred_window\"].sum()\n    )\n\n    return weighted_observed\n</code></pre>"},{"location":"api/#patientflow.evaluate.combine_distributions","title":"<code>combine_distributions(dist1, dist2)</code>","text":"<p>Combine two probability distributions using convolution.</p> <p>Parameters:</p> Name Type Description Default <code>dist1</code> <code>DataFrame</code> <p>First probability distribution.</p> required <code>dist2</code> <code>DataFrame</code> <p>Second probability distribution.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Combined probability distribution.</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def combine_distributions(dist1: pd.DataFrame, dist2: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Combine two probability distributions using convolution.\n\n    Args:\n        dist1 (pd.DataFrame): First probability distribution.\n        dist2 (pd.DataFrame): Second probability distribution.\n\n    Returns:\n        pd.DataFrame: Combined probability distribution.\n    \"\"\"\n    arr1 = dist1.values\n    arr2 = dist2.values\n\n    combined = signal.convolve(arr1, arr2)\n    new_index = range(len(combined))\n\n    combined_df = pd.DataFrame(combined, index=new_index, columns=[\"agg_predicted\"])\n    combined_df[\"agg_predicted\"] = (\n        combined_df[\"agg_predicted\"] / combined_df[\"agg_predicted\"].sum()\n    )\n\n    return combined_df\n</code></pre>"},{"location":"api/#patientflow.evaluate.create_time_mask","title":"<code>create_time_mask(df, hour, minute)</code>","text":"<p>Create a mask for times before/after a specific hour:minute</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def create_time_mask(df, hour, minute):\n    \"\"\"Create a mask for times before/after a specific hour:minute\"\"\"\n    return (df[\"arrival_datetime\"].dt.hour &gt; hour) | (\n        (df[\"arrival_datetime\"].dt.hour == hour)\n        &amp; (df[\"arrival_datetime\"].dt.minute &gt; minute)\n    )\n</code></pre>"},{"location":"api/#patientflow.evaluate.evaluate_combined_model","title":"<code>evaluate_combined_model(prob_dist_dict_all, df, yta_preds, prediction_window, x1, y1, x2, y2, prediction_time, num_weeks, model_name, use_most_probable=True)</code>","text":"<p>Evaluate the combined prediction model.</p> <p>Parameters:</p> Name Type Description Default <code>prob_dist_dict_all</code> <code>Dict[Any, Dict[Any, Dict[str, Any]]]</code> <p>Nested dictionary containing probability distributions.</p> required <code>df</code> <code>DataFrame</code> <p>DataFrame containing patient data.</p> required <code>yta_preds</code> <code>DataFrame</code> <p>Yet-to-arrive predictions.</p> required <code>prediction_window</code> <code>int</code> <p>Prediction window in minutes.</p> required <code>x1</code> <code>float), y1 (float), x2 (float), y2 (float</code> <p>Parameters for aspirational curve.</p> required <code>prediction_time</code> <code>Tuple[int, int]</code> <p>Hour and minute of prediction.</p> required <code>num_weeks</code> <code>int</code> <p>Number of previous weeks to consider.</p> required <code>model_name</code> <code>str</code> <p>Name of the model.</p> required <code>use_most_probable</code> <code>bool</code> <p>Whether to use the most probable value or expected value. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]</code> <p>Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]: Evaluation results.</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def evaluate_combined_model(\n    prob_dist_dict_all: Dict[Any, Dict[Any, Dict[str, Any]]],\n    df: pd.DataFrame,\n    yta_preds: pd.DataFrame,\n    prediction_window: int,\n    x1: float,\n    y1: float,\n    x2: float,\n    y2: float,\n    prediction_time: Tuple[int, int],\n    num_weeks: int,\n    model_name: str,\n    use_most_probable: bool = True,\n) -&gt; Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]:\n    \"\"\"\n    Evaluate the combined prediction model.\n\n    Args:\n        prob_dist_dict_all (Dict[Any, Dict[Any, Dict[str, Any]]]): Nested dictionary containing probability distributions.\n        df (pd.DataFrame): DataFrame containing patient data.\n        yta_preds (pd.DataFrame): Yet-to-arrive predictions.\n        prediction_window (int): Prediction window in minutes.\n        x1 (float), y1 (float), x2 (float), y2 (float): Parameters for aspirational curve.\n        prediction_time (Tuple[int, int]): Hour and minute of prediction.\n        num_weeks (int): Number of previous weeks to consider.\n        model_name (str): Name of the model.\n        use_most_probable (bool, optional): Whether to use the most probable value or expected value. Defaults to True.\n\n    Returns:\n        Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]: Evaluation results.\n    \"\"\"\n    expected_values: List[Union[int, float]] = []\n    observed_values: List[float] = []\n\n    model_name = get_model_key(model_name, prediction_time)\n\n    for dt in prob_dist_dict_all[model_name].keys():\n        in_ed_preds: Dict[str, Any] = prob_dist_dict_all[model_name][dt]\n        combined = combine_distributions(yta_preds, in_ed_preds[\"agg_predicted\"])\n\n        expected_value: Union[int, float] = (\n            int(combined[\"agg_predicted\"].idxmax())\n            if use_most_probable\n            else float(\n                np.dot(\n                    combined[\"agg_predicted\"].index,\n                    combined[\"agg_predicted\"].values.flatten(),\n                )\n            )\n        )\n\n        observed_value: float = float(\n            calculate_weighted_observed(\n                df, dt, prediction_window, x1, y1, x2, y2, prediction_time\n            )\n        )\n\n        expected_values.append(expected_value)\n        observed_values.append(observed_value)\n\n    results = {model_name: calculate_results(expected_values, observed_values)}\n    return results\n</code></pre>"},{"location":"api/#patientflow.evaluate.evaluate_six_week_average","title":"<code>evaluate_six_week_average(prob_dist_dict_all, df, prediction_window, x1, y1, x2, y2, prediction_time, num_weeks, model_name)</code>","text":"<p>Evaluate the six-week average prediction model.</p> <p>Parameters:</p> Name Type Description Default <code>prob_dist_dict_all</code> <code>Dict[Any, Dict[Any, Dict[str, Any]]]</code> <p>Nested dictionary containing probability distributions.</p> required <code>df</code> <code>DataFrame</code> <p>DataFrame containing patient data.</p> required <code>prediction_window</code> <code>int</code> <p>Prediction window in minutes.</p> required <code>x1</code> <code>float), y1 (float), x2 (float), y2 (float</code> <p>Parameters for aspirational curve.</p> required <code>prediction_time</code> <code>Tuple[int, int]</code> <p>Hour and minute of prediction.</p> required <code>num_weeks</code> <code>int</code> <p>Number of previous weeks to consider.</p> required <code>model_name</code> <code>str</code> <p>Name of the model.</p> required <p>Returns:</p> Type Description <code>Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]</code> <p>Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]: Evaluation results.</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def evaluate_six_week_average(\n    prob_dist_dict_all: Dict[Any, Dict[Any, Dict[str, Any]]],\n    df: pd.DataFrame,\n    prediction_window: int,\n    x1: float,\n    y1: float,\n    x2: float,\n    y2: float,\n    prediction_time: Tuple[int, int],\n    num_weeks: int,\n    model_name: str,\n) -&gt; Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]:\n    \"\"\"\n    Evaluate the six-week average prediction model.\n\n    Args:\n        prob_dist_dict_all (Dict[Any, Dict[Any, Dict[str, Any]]]): Nested dictionary containing probability distributions.\n        df (pd.DataFrame): DataFrame containing patient data.\n        prediction_window (int): Prediction window in minutes.\n        x1 (float), y1 (float), x2 (float), y2 (float): Parameters for aspirational curve.\n        prediction_time (Tuple[int, int]): Hour and minute of prediction.\n        num_weeks (int): Number of previous weeks to consider.\n        model_name (str): Name of the model.\n\n    Returns:\n        Dict[Any, Dict[str, Union[List[Union[int, float]], float]]]: Evaluation results.\n    \"\"\"\n    expected_values: List[Union[int, float]] = []\n    observed_values: List[float] = []\n\n    model_name = get_model_key(model_name, prediction_time)\n\n    for dt in prob_dist_dict_all[model_name].keys():\n        expected_value: float = float(\n            predict_using_previous_weeks(\n                df, dt, prediction_window, x1, y1, x2, y2, prediction_time, num_weeks\n            )\n        )\n        observed_value: float = float(\n            calculate_weighted_observed(\n                df, dt, prediction_window, x1, y1, x2, y2, prediction_time\n            )\n        )\n\n        expected_values.append(expected_value)\n        observed_values.append(observed_value)\n\n    results = {model_name: calculate_results(expected_values, observed_values)}\n    return results\n</code></pre>"},{"location":"api/#patientflow.evaluate.get_arrivals_with_admission_probs","title":"<code>get_arrivals_with_admission_probs(df, prediction_datetime, prediction_window, prediction_time, x1, y1, x2, y2, date_range=None, target_date=None, target_weekday=None)</code>","text":"<p>Get arrivals before and after prediction time with their admission probabilities</p> <p>Parameters: df: DataFrame with arrival_datetime column prediction_datetime: datetime for prediction window start prediction_window: window length in minutes prediction_time: tuple of (hour, minute) x1, y1, x2, y2: parameters for aspirational curve date_range: optional tuple of (start_date, end_date) target_date: optional specific date to analyze target_weekday: optional specific weekday to filter for</p> <p>Returns: tuple of (arrived_before, arrived_after) DataFrames for specified time period</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def get_arrivals_with_admission_probs(\n    df,\n    prediction_datetime,\n    prediction_window,\n    prediction_time,\n    x1,\n    y1,\n    x2,\n    y2,\n    date_range=None,\n    target_date=None,\n    target_weekday=None,\n):\n    \"\"\"\n    Get arrivals before and after prediction time with their admission probabilities\n\n    Parameters:\n    df: DataFrame with arrival_datetime column\n    prediction_datetime: datetime for prediction window start\n    prediction_window: window length in minutes\n    prediction_time: tuple of (hour, minute)\n    x1, y1, x2, y2: parameters for aspirational curve\n    date_range: optional tuple of (start_date, end_date)\n    target_date: optional specific date to analyze\n    target_weekday: optional specific weekday to filter for\n\n    Returns:\n    tuple of (arrived_before, arrived_after) DataFrames for specified time period\n    \"\"\"\n    hour, minute = prediction_time\n\n    # Create base time masks\n    after_mask = create_time_mask(df, hour, minute)\n    before_mask = ~after_mask\n\n    # Add date and weekday conditions if specified\n    if date_range:\n        start_date, end_date = date_range\n        date_mask = (df[\"arrival_datetime\"].dt.date &gt;= start_date) &amp; (\n            df[\"arrival_datetime\"].dt.date &lt; end_date\n        )\n        if target_weekday is not None:\n            date_mask &amp;= df[\"arrival_datetime\"].dt.weekday == target_weekday\n\n        after_mask &amp;= date_mask\n        before_mask &amp;= date_mask\n\n    if target_date:\n        target_mask = df[\"arrival_datetime\"].dt.date == target_date\n        after_mask &amp;= target_mask\n        before_mask &amp;= target_mask\n\n    # Calculate probabilities for filtered groups\n    arrived_before = calculate_admission_probs_relative_to_prediction(\n        df[before_mask],\n        prediction_datetime,\n        prediction_window,\n        x1,\n        y1,\n        x2,\n        y2,\n        is_before=True,\n    )\n\n    arrived_after = calculate_admission_probs_relative_to_prediction(\n        df[after_mask],\n        prediction_datetime,\n        prediction_window,\n        x1,\n        y1,\n        x2,\n        y2,\n        is_before=False,\n    )\n\n    return arrived_before, arrived_after\n</code></pre>"},{"location":"api/#patientflow.evaluate.predict_using_previous_weeks","title":"<code>predict_using_previous_weeks(df, dt, prediction_window, x1, y1, x2, y2, prediction_time, num_weeks, weighted=True)</code>","text":"<p>Calculate predicted admissions remaining until midnight. Args:     df (pd.DataFrame): DataFrame containing patient data.     dt (datetime): Date for prediction.     prediction_time (Tuple[int, int]): Hour and minute of prediction.     num_weeks (int): Number of previous weeks to consider.     weighted(bool): Whether to weight the numbers according to aspirational ED targets Returns:     float: Predicted number of admissions remaining until midnight.</p> Source code in <code>src/patientflow/evaluate.py</code> <pre><code>def predict_using_previous_weeks(\n    df: pd.DataFrame,\n    dt: datetime,\n    prediction_window: int,\n    x1: float,\n    y1: float,\n    x2: float,\n    y2: float,\n    prediction_time: Tuple[int, int],\n    num_weeks: int,\n    weighted=True,\n) -&gt; float:\n    \"\"\"\n    Calculate predicted admissions remaining until midnight.\n    Args:\n        df (pd.DataFrame): DataFrame containing patient data.\n        dt (datetime): Date for prediction.\n        prediction_time (Tuple[int, int]): Hour and minute of prediction.\n        num_weeks (int): Number of previous weeks to consider.\n        weighted(bool): Whether to weight the numbers according to aspirational ED targets\n    Returns:\n        float: Predicted number of admissions remaining until midnight.\n    \"\"\"\n    prediction_datetime = pd.to_datetime(dt).replace(\n        hour=prediction_time[0], minute=prediction_time[1]\n    )\n    target_day_of_week = dt.weekday()\n\n    end_date = dt - timedelta(days=1)\n    start_date = end_date - timedelta(weeks=num_weeks)\n\n    if weighted:\n        # Create mask for historical data\n        historical_mask = (\n            (df[\"arrival_datetime\"].dt.date &gt;= start_date)\n            &amp; (df[\"arrival_datetime\"].dt.date &lt;= end_date)\n            &amp; (df[\"arrival_datetime\"].dt.weekday == target_day_of_week)\n        )\n\n        # Create explicit copy of filtered data\n        historical_data = df[historical_mask].copy()\n\n        # Calculate minutes until midnight\n        midnight_times = (\n            historical_data[\"arrival_datetime\"].dt.normalize()\n            + pd.Timedelta(days=1)\n            - pd.Timedelta(minutes=1)\n        )\n        historical_data.loc[:, \"minutes_to_midnight\"] = (\n            midnight_times - historical_data[\"arrival_datetime\"]\n        ).dt.total_seconds() / 60\n\n        # Calculate admission probabilities\n        historical_data.loc[:, \"admission_probability\"] = historical_data[\n            \"minutes_to_midnight\"\n        ].apply(lambda x: get_y_from_aspirational_curve(x / 60, x1, y1, x2, y2))\n\n        # Group by date and calculate average\n        historical_daily_sums = historical_data.groupby(\n            historical_data[\"arrival_datetime\"].dt.date\n        )[\"admission_probability\"].sum()\n        historical_average = historical_daily_sums.mean()\n\n        # Create mask for today's data\n        today_mask = (df[\"arrival_datetime\"].dt.date == dt) &amp; (\n            df[\"arrival_datetime\"] &lt; prediction_datetime\n        )\n\n        # Create explicit copy of today's filtered data\n        today_data = df[today_mask].copy()\n\n        # Calculate minutes until midnight for today's data\n        midnight_today = (\n            pd.to_datetime(dt).normalize()\n            + pd.Timedelta(days=1)\n            - pd.Timedelta(minutes=1)\n        )\n        today_data.loc[:, \"minutes_to_midnight\"] = (\n            midnight_today - today_data[\"arrival_datetime\"]\n        ).dt.total_seconds() / 60\n\n        # Calculate admission probabilities for today\n        today_data.loc[:, \"admission_probability\"] = today_data[\n            \"minutes_to_midnight\"\n        ].apply(lambda x: get_y_from_aspirational_curve(x / 60, x1, y1, x2, y2))\n\n        today_sum = today_data[\"admission_probability\"].sum()\n\n        still_to_admit = max(historical_average - today_sum, 0)\n\n    else:\n        # Original unweighted logic with explicit copies\n        historical_mask = (\n            (df[\"arrival_datetime\"].dt.date &gt;= start_date)\n            &amp; (df[\"arrival_datetime\"].dt.date &lt; end_date)\n            &amp; (df[\"arrival_datetime\"].dt.weekday == target_day_of_week)\n        )\n        historical_df = df[historical_mask].copy()\n        average_count = len(historical_df) / num_weeks\n\n        target_mask = (df[\"arrival_datetime\"].dt.date == dt) &amp; (\n            df[\"arrival_datetime\"] &lt; prediction_datetime\n        )\n        target_date_count = len(df[target_mask])\n\n        still_to_admit = max(average_count - target_date_count, 0)\n\n    return still_to_admit\n</code></pre>"},{"location":"api/#patientflow.generate","title":"<code>generate</code>","text":""},{"location":"api/#patientflow.generate.create_fake_finished_visits","title":"<code>create_fake_finished_visits(start_date, end_date, mean_patients_per_day)</code>","text":"<p>Generate fake patient visit data with random arrival and departure times.</p>"},{"location":"api/#patientflow.generate.create_fake_finished_visits--parameters","title":"Parameters:","text":"<p>start_date : str or datetime     The minimum date to sample from (format: 'YYYY-MM-DD' if string) end_date : str or datetime     The maximum date to sample from (exclusive) (format: 'YYYY-MM-DD' if string) mean_patients_per_day : float     The average number of patients to generate per day</p>"},{"location":"api/#patientflow.generate.create_fake_finished_visits--returns","title":"Returns:","text":"<p>tuple (pandas.DataFrame, pandas.DataFrame, pandas.DataFrame)     First DataFrame: visits with columns: visit_number, patient_id, arrival_datetime, departure_datetime,     is_admitted, age     Second DataFrame: observations with columns: visit_number, observation_datetime, triage_score     Third DataFrame: lab_orders with columns: visit_number, order_datetime, lab_name</p> Source code in <code>src/patientflow/generate.py</code> <pre><code>def create_fake_finished_visits(start_date, end_date, mean_patients_per_day):\n    \"\"\"\n    Generate fake patient visit data with random arrival and departure times.\n\n    Parameters:\n    -----------\n    start_date : str or datetime\n        The minimum date to sample from (format: 'YYYY-MM-DD' if string)\n    end_date : str or datetime\n        The maximum date to sample from (exclusive) (format: 'YYYY-MM-DD' if string)\n    mean_patients_per_day : float\n        The average number of patients to generate per day\n\n    Returns:\n    --------\n    tuple (pandas.DataFrame, pandas.DataFrame, pandas.DataFrame)\n        First DataFrame: visits with columns: visit_number, patient_id, arrival_datetime, departure_datetime,\n        is_admitted, age\n        Second DataFrame: observations with columns: visit_number, observation_datetime, triage_score\n        Third DataFrame: lab_orders with columns: visit_number, order_datetime, lab_name\n    \"\"\"\n    # Convert string dates to datetime if needed\n    if isinstance(start_date, str):\n        start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n    if isinstance(end_date, str):\n        end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n\n    # Set random seed for reproducibility\n    np.random.seed(42)  # You can change this seed value as needed\n\n    # Calculate total days in range (changed to exclusive end date)\n    days_range = (end_date - start_date).days\n\n    # Generate random number of patients for each day using Poisson distribution\n    daily_patients = np.random.poisson(mean_patients_per_day, days_range)\n\n    # Calculate the total number of visits\n    total_visits = sum(daily_patients)\n\n    # Calculate approximately how many unique patients we need\n    # If 20% of patients have more than one visit (let's assume they have exactly 2),\n    # then for N total visits, we need approximately N * 0.8 + (N * 0.2) / 2 unique patients\n    # Simplifying: N * (0.8 + 0.1) = N * 0.9 unique patients\n    num_unique_patients = int(total_visits * 0.9)\n\n    # Create patient ids\n    patient_ids = list(range(1, num_unique_patients + 1))\n\n    # Define admission probabilities based on triage score\n    # Triage 1: 80% admission, Triage 2: 60%, Triage 3: 30%, Triage 4: 10%, Triage 5: 2%\n    admission_probabilities = {\n        1: 0.80,  # Highest severity - highest admission probability\n        2: 0.60,\n        3: 0.30,\n        4: 0.10,\n        5: 0.02,  # Lowest severity - lowest admission probability\n    }\n\n    # Define triage score distribution\n    # Most common is 3-4, less common are 2 and 5, least common is 1 (most severe)\n    triage_probabilities = [0.05, 0.15, 0.35, 0.35, 0.10]  # For scores 1-5\n\n    # Define common ED lab tests and their ordering probabilities based on triage score\n    lab_tests = [\"CBC\", \"BMP\", \"Troponin\", \"D-dimer\", \"Urinalysis\"]\n    lab_probabilities = {\n        # Higher severity -&gt; more likely to get labs\n        1: {\n            \"CBC\": 0.95,\n            \"BMP\": 0.95,\n            \"Troponin\": 0.90,\n            \"D-dimer\": 0.70,\n            \"Urinalysis\": 0.60,\n        },\n        2: {\n            \"CBC\": 0.90,\n            \"BMP\": 0.90,\n            \"Troponin\": 0.80,\n            \"D-dimer\": 0.60,\n            \"Urinalysis\": 0.50,\n        },\n        3: {\n            \"CBC\": 0.80,\n            \"BMP\": 0.80,\n            \"Troponin\": 0.60,\n            \"D-dimer\": 0.40,\n            \"Urinalysis\": 0.40,\n        },\n        4: {\n            \"CBC\": 0.60,\n            \"BMP\": 0.60,\n            \"Troponin\": 0.30,\n            \"D-dimer\": 0.20,\n            \"Urinalysis\": 0.30,\n        },\n        5: {\n            \"CBC\": 0.40,\n            \"BMP\": 0.40,\n            \"Troponin\": 0.15,\n            \"D-dimer\": 0.10,\n            \"Urinalysis\": 0.20,\n        },\n    }\n\n    visits = []\n    observations = []\n    lab_orders = []\n    visit_number = 1\n\n    # Create a dictionary to track number of visits per patient\n    patient_visit_count = {patient_id: 0 for patient_id in patient_ids}\n\n    # Create a pool of patients who will have multiple visits (20% of patients)\n    multi_visit_patients = set(\n        np.random.choice(\n            patient_ids, size=int(num_unique_patients * 0.2), replace=False\n        )\n    )\n\n    for day_idx, num_patients in enumerate(daily_patients):\n        current_date = start_date + timedelta(days=day_idx)\n\n        # Generate patients for this day\n        for _ in range(num_patients):\n            # Select a patient ID based on our requirements\n            # If we haven't assigned all patients yet, use a new one\n            # Otherwise, pick from multi-visit patients\n            available_new_patients = [\n                pid for pid in patient_ids if patient_visit_count[pid] == 0\n            ]\n\n            if available_new_patients:\n                # Use a new patient\n                patient_id = np.random.choice(available_new_patients)\n            else:\n                # All patients have at least one visit, now use multi-visit patients\n                patient_id = np.random.choice(list(multi_visit_patients))\n\n            # Increment the visit count for this patient\n            patient_visit_count[patient_id] += 1\n\n            # Random hour for arrival (more likely during daytime)\n            arrival_hour = np.random.normal(13, 4)  # Mean at 1 PM, std dev of 4 hours\n            arrival_hour = max(0, min(23, int(arrival_hour)))  # Clamp between 0-23\n\n            # Random minutes\n            arrival_minute = np.random.randint(0, 60)\n\n            # Create arrival datetime\n            arrival_datetime = current_date.replace(\n                hour=arrival_hour,\n                minute=arrival_minute,\n                second=np.random.randint(0, 60),\n            )\n\n            # Generate triage score (1-5)\n            triage_score = np.random.choice([1, 2, 3, 4, 5], p=triage_probabilities)\n\n            # Generate length of stay (in minutes) - log-normal distribution\n            # Most visits are 2 to 6 hours, but some can be shorter or longer\n            length_of_stay = np.random.lognormal(mean=5.2, sigma=0.4)\n            length_of_stay = max(\n                30, min(1440, length_of_stay)\n            )  # Between 30 min and 24 hours\n\n            # Make higher triage scores (more severe) stay longer on average\n            if triage_score &lt;= 2:\n                length_of_stay *= 1.5  # 50% longer stays for more severe cases\n\n            # Calculate departure time\n            departure_datetime = arrival_datetime + timedelta(\n                minutes=int(length_of_stay)\n            )\n\n            # Generate admission status based on triage score\n            admission_prob = admission_probabilities[triage_score]\n            is_admitted = np.random.choice(\n                [0, 1], p=[1 - admission_prob, admission_prob]\n            )\n\n            # For returning patients, use the same age as their first visit\n            if patient_id in [v[\"patient_id\"] for v in visits]:\n                # Find the age from a previous visit\n                age = next(v[\"age\"] for v in visits if v[\"patient_id\"] == patient_id)\n            else:\n                # Generate age with a distribution skewed towards older adults\n                age = int(\n                    np.random.lognormal(mean=3.8, sigma=0.5)\n                )  # Centers around 45 years\n                age = max(0, min(100, age))  # Clamp between 0-100 years\n\n            # Add visit record (without triage score, but with patient_id)\n            visits.append(\n                {\n                    \"patient_id\": patient_id,\n                    \"visit_number\": visit_number,\n                    \"arrival_datetime\": arrival_datetime,\n                    \"departure_datetime\": departure_datetime,\n                    \"is_admitted\": is_admitted,\n                    \"age\": age,\n                }\n            )\n\n            # Generate triage observation within first 10 minutes\n            minutes_after_arrival = np.random.uniform(0, 10)\n            observation_datetime = arrival_datetime + timedelta(\n                minutes=minutes_after_arrival\n            )\n\n            observations.append(\n                {\n                    \"visit_number\": visit_number,\n                    \"observation_datetime\": observation_datetime,\n                    \"triage_score\": triage_score,\n                }\n            )\n\n            # Generate lab orders if visit is longer than 2 hours\n            if length_of_stay &gt; 120:\n                # For each lab test, decide if it should be ordered based on triage score\n                for lab_test in lab_tests:\n                    if np.random.random() &lt; lab_probabilities[triage_score][lab_test]:\n                        # Order time is after triage but within first 90 minutes\n                        minutes_after_triage = np.random.uniform(\n                            0, 90 - minutes_after_arrival\n                        )\n                        order_datetime = observation_datetime + timedelta(\n                            minutes=minutes_after_triage\n                        )\n\n                        lab_orders.append(\n                            {\n                                \"visit_number\": visit_number,\n                                \"order_datetime\": order_datetime,\n                                \"lab_name\": lab_test,\n                            }\n                        )\n\n            visit_number += 1\n\n    # Create DataFrames and sort by time\n    visits_df = pd.DataFrame(visits)\n    visits_df = visits_df.sort_values(\"arrival_datetime\").reset_index(drop=True)\n\n    observations_df = pd.DataFrame(observations)\n    observations_df = observations_df.sort_values(\"observation_datetime\").reset_index(\n        drop=True\n    )\n\n    lab_orders_df = pd.DataFrame(lab_orders)\n    if not lab_orders_df.empty:\n        lab_orders_df = lab_orders_df.sort_values(\"order_datetime\").reset_index(\n            drop=True\n        )\n\n    return visits_df, observations_df, lab_orders_df\n</code></pre>"},{"location":"api/#patientflow.generate.create_fake_snapshots","title":"<code>create_fake_snapshots(prediction_times, start_date, end_date, df=None, observations_df=None, lab_orders_df=None, mean_patients_per_day=50)</code>","text":"<p>Create snapshots of patients present at specific times between start_date and end_date.</p>"},{"location":"api/#patientflow.generate.create_fake_snapshots--parameters","title":"Parameters:","text":"<p>prediction_times : list of tuples     List of (hour, minute) tuples representing times to take snapshots start_date : str or datetime     First date to take snapshots (format: 'YYYY-MM-DD' if string) end_date : str or datetime     Last date to take snapshots (exclusive) (format: 'YYYY-MM-DD' if string) df : pandas.DataFrame, optional     DataFrame with patient visit data, must have 'arrival_datetime' and 'departure_datetime' columns.     If not provided, will be generated using create_fake_finished_visits() observations_df : pandas.DataFrame, optional     DataFrame with triage observations, must have 'visit_number', 'observation_datetime', 'triage_score' columns.     If not provided, will be generated using create_fake_finished_visits() lab_orders_df : pandas.DataFrame, optional     DataFrame with lab orders, must have 'visit_number', 'order_datetime', 'lab_name' columns.     If not provided, will be generated using create_fake_finished_visits() mean_patients_per_day : float, optional     The average number of patients to generate per day if generating fake data.     Only used if df, observations_df, and lab_orders_df are not provided.</p>"},{"location":"api/#patientflow.generate.create_fake_snapshots--returns","title":"Returns:","text":"<p>pandas.DataFrame     DataFrame with snapshot information and patient data, including lab order counts</p> Source code in <code>src/patientflow/generate.py</code> <pre><code>def create_fake_snapshots(\n    prediction_times,\n    start_date,\n    end_date,\n    df=None,\n    observations_df=None,\n    lab_orders_df=None,\n    mean_patients_per_day=50,\n):\n    \"\"\"\n    Create snapshots of patients present at specific times between start_date and end_date.\n\n    Parameters:\n    -----------\n    prediction_times : list of tuples\n        List of (hour, minute) tuples representing times to take snapshots\n    start_date : str or datetime\n        First date to take snapshots (format: 'YYYY-MM-DD' if string)\n    end_date : str or datetime\n        Last date to take snapshots (exclusive) (format: 'YYYY-MM-DD' if string)\n    df : pandas.DataFrame, optional\n        DataFrame with patient visit data, must have 'arrival_datetime' and 'departure_datetime' columns.\n        If not provided, will be generated using create_fake_finished_visits()\n    observations_df : pandas.DataFrame, optional\n        DataFrame with triage observations, must have 'visit_number', 'observation_datetime', 'triage_score' columns.\n        If not provided, will be generated using create_fake_finished_visits()\n    lab_orders_df : pandas.DataFrame, optional\n        DataFrame with lab orders, must have 'visit_number', 'order_datetime', 'lab_name' columns.\n        If not provided, will be generated using create_fake_finished_visits()\n    mean_patients_per_day : float, optional\n        The average number of patients to generate per day if generating fake data.\n        Only used if df, observations_df, and lab_orders_df are not provided.\n\n    Returns:\n    --------\n    pandas.DataFrame\n        DataFrame with snapshot information and patient data, including lab order counts\n    \"\"\"\n    # Generate fake data if not provided\n    if df is None or observations_df is None or lab_orders_df is None:\n        df, observations_df, lab_orders_df = create_fake_finished_visits(\n            start_date, end_date, mean_patients_per_day\n        )\n\n    # Add date conversion at the start\n    if isinstance(start_date, str):\n        start_date = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n    elif isinstance(start_date, datetime):\n        start_date = start_date.date()\n\n    if isinstance(end_date, str):\n        end_date = datetime.strptime(end_date, \"%Y-%m-%d\").date()\n    elif isinstance(end_date, datetime):\n        end_date = end_date.date()\n\n    # Create date range (changed to exclusive end date)\n    snapshot_dates = []\n    current_date = start_date\n    while current_date &lt; end_date:  # Changed from &lt;= to &lt;\n        snapshot_dates.append(current_date)\n        current_date += timedelta(days=1)\n\n    # Get unique lab test names\n    lab_tests = lab_orders_df[\"lab_name\"].unique() if not lab_orders_df.empty else []\n\n    # Create empty list to store all results\n    all_results = []\n\n    # For each combination of date and time\n    for date in snapshot_dates:\n        for hour, minute in prediction_times:\n            snapshot_datetime = datetime.combine(date, time(hour=hour, minute=minute))\n\n            # Filter dataframe for this snapshot\n            mask = (df[\"arrival_datetime\"] &lt;= snapshot_datetime) &amp; (\n                df[\"departure_datetime\"] &gt; snapshot_datetime\n            )\n            snapshot_df = df[mask].copy()  # Create copy to avoid SettingWithCopyWarning\n\n            # Skip if no patients at this time\n            if len(snapshot_df) == 0:\n                continue\n\n            # Get triage scores recorded before the snapshot time\n            valid_observations = observations_df[\n                (observations_df[\"visit_number\"].isin(snapshot_df[\"visit_number\"]))\n                &amp; (observations_df[\"observation_datetime\"] &lt;= snapshot_datetime)\n            ].copy()\n\n            # Keep only the most recent triage score for each visit\n            if not valid_observations.empty:\n                valid_observations = valid_observations.sort_values(\n                    \"observation_datetime\"\n                )\n                valid_observations = (\n                    valid_observations.groupby(\"visit_number\").last().reset_index()\n                )\n                valid_observations = valid_observations.rename(\n                    columns={\"triage_score\": \"latest_triage_score\"}\n                )\n\n            # Get lab orders placed before the snapshot time\n            valid_orders = lab_orders_df[\n                (lab_orders_df[\"visit_number\"].isin(snapshot_df[\"visit_number\"]))\n                &amp; (lab_orders_df[\"order_datetime\"] &lt;= snapshot_datetime)\n            ].copy()\n\n            # Initialize lab_counts with zeros for all visits in snapshot_df\n            lab_counts = pd.DataFrame(\n                0,\n                index=pd.Index(\n                    snapshot_df[\"visit_number\"].unique(), name=\"visit_number\"\n                ),\n                columns=[f\"num_{test.lower()}_orders\" for test in lab_tests],\n            )\n\n            # Update counts if there are any valid orders\n            if not valid_orders.empty:\n                order_counts = (\n                    valid_orders.groupby([\"visit_number\", \"lab_name\"])\n                    .size()\n                    .unstack(fill_value=0)\n                )\n                order_counts.columns = [\n                    f\"num_{test.lower()}_orders\" for test in order_counts.columns\n                ]\n                # Update the counts in lab_counts where we have orders\n                lab_counts.update(order_counts)\n\n            lab_counts = lab_counts.reset_index()\n\n            # Add snapshot information columns\n            snapshot_df[\"snapshot_date\"] = date\n            snapshot_df[\"prediction_time\"] = [(hour, minute)] * len(snapshot_df)\n\n            # Merge with valid observations to get triage scores, handling empty case\n            if not valid_observations.empty:\n                snapshot_df = pd.merge(\n                    snapshot_df,\n                    valid_observations[[\"visit_number\", \"latest_triage_score\"]],\n                    on=\"visit_number\",\n                    how=\"left\",\n                )\n            else:\n                snapshot_df[\"latest_triage_score\"] = pd.Series(\n                    [np.nan] * len(snapshot_df),\n                    dtype=\"float64\",\n                    index=snapshot_df.index,\n                )\n            # Merge with lab counts\n            snapshot_df = pd.merge(\n                snapshot_df, lab_counts, on=\"visit_number\", how=\"left\"\n            )\n\n            # Fill NA values in lab count columns with 0\n            for col in snapshot_df.columns:\n                if col.endswith(\"_orders\"):\n                    snapshot_df[col] = snapshot_df[col].fillna(0)\n            if not snapshot_df.empty:\n                # Optionally check for all-NA in key columns\n                snapshot_cols = [\n                    \"snapshot_date\",\n                    \"prediction_time\",\n                    \"snapshot_datetime\",\n                ]\n                # Only check columns that exist in the DataFrame\n                check_cols = [\n                    col for col in snapshot_cols if col in snapshot_df.columns\n                ]\n\n                if not check_cols or not snapshot_df[check_cols].isna().all().any():\n                    all_results.append(snapshot_df)\n                else:\n                    print(\n                        f\"Skipping DataFrame with all-NA values in key columns: {check_cols}\"\n                    )\n            else:\n                print(\"Skipping empty DataFrame\")\n\n    # Combine all results into single dataframe\n    if all_results:\n        final_df = pd.concat(all_results, ignore_index=True)\n\n        # Define column order\n        snapshot_cols = [\"snapshot_date\", \"prediction_time\"]\n        visit_cols = [\n            \"patient_id\",\n            \"visit_number\",\n            \"is_admitted\",\n            \"age\",\n            \"latest_triage_score\",\n        ]\n        lab_cols = [col for col in final_df.columns if col.endswith(\"_orders\")]\n\n        # Ensure all required columns exist\n        for col in visit_cols:\n            if col not in final_df.columns:\n                if col == \"latest_triage_score\":\n                    final_df[col] = pd.NA\n                else:\n                    final_df[col] = None\n\n        # Reorder columns\n        final_df = final_df[snapshot_cols + visit_cols + lab_cols]\n    else:\n        # Create empty dataframe with correct columns if no results found\n        lab_cols = [f\"num_{test.lower()}_orders\" for test in lab_tests]\n        columns = [\n            \"snapshot_date\",\n            \"prediction_time\",\n            \"visit_number\",\n            \"is_admitted\",\n            \"age\",\n            \"latest_triage_score\",\n        ] + lab_cols\n        final_df = pd.DataFrame(columns=columns)\n\n    # Name the index snapshot_id before returning\n    final_df.index.name = \"snapshot_id\"\n    return final_df\n</code></pre>"},{"location":"api/#patientflow.load","title":"<code>load</code>","text":"<p>This module provides functionality for loading configuration files, data from CSV files, and trained machine learning models.</p> <p>It includes the following features:</p> <ul> <li>Loading Configurations: Parse YAML configuration files and extract necessary parameters for data processing and modeling.</li> <li>Data Handling: Load and preprocess data from CSV files, including optional operations like setting an index, sorting, and applying literal evaluation on columns.</li> <li>Model Management: Load saved machine learning models, customize model filenames based on time, and categorize DataFrame columns into predefined groups for analysis.</li> </ul> <p>The module handles common file and parsing errors, returning appropriate error messages or exceptions.</p>"},{"location":"api/#patientflow.load--functions","title":"Functions","text":"<p>parse_args:     Parses command-line arguments for training models. set_project_root:     Validates project root path from specified environment variable. load_config_file:     Load a YAML configuration file and extract key parameters. set_file_paths:     Sets up the file paths based on UCLH-specific or default parameters. set_data_file_names:     Set file locations based on UCLH-specific or default data sources. safe_literal_eval:     Safely evaluate string literals into Python objects when loading from csv. load_data:     Load and preprocess data from a CSV or pickle file. get_model_key:     Generate a model name based on the time of day. load_saved_model:     Load a machine learning model saved in a joblib file. get_dict_cols:     Categorize columns from a DataFrame into predefined groups for analysis.</p>"},{"location":"api/#patientflow.load.data_from_csv","title":"<code>data_from_csv(csv_path, index_column=None, sort_columns=None, eval_columns=None)</code>","text":"<p>Loads data from a CSV file, with optional transformations. LEGACY!</p> <p>This function loads a CSV file into a pandas DataFrame and provides the following optional features: - Setting a specified column as the index. - Sorting the DataFrame by one or more specified columns. - Applying safe literal evaluation to specified columns to handle string representations of Python objects.</p>"},{"location":"api/#patientflow.load.data_from_csv--parameters","title":"Parameters","text":"<p>csv_path : str     The relative or absolute path to the CSV file. index_column : str, optional     The column to set as the index of the DataFrame. If not provided, no index column is set. sort_columns : list of str, optional     A list of columns by which to sort the DataFrame. If not provided, the DataFrame is not sorted. eval_columns : list of str, optional     A list of columns to which <code>safe_literal_eval</code> should be applied. This is useful for columns containing     string representations of Python data structures (e.g., lists, dictionaries).</p>"},{"location":"api/#patientflow.load.data_from_csv--returns","title":"Returns","text":"<p>pd.DataFrame     A pandas DataFrame containing the loaded data with any specified transformations applied.</p>"},{"location":"api/#patientflow.load.data_from_csv--raises","title":"Raises","text":"<p>SystemExit     If the file cannot be found or another error occurs during loading or processing.</p>"},{"location":"api/#patientflow.load.data_from_csv--notes","title":"Notes","text":"<p>The function will terminate the program with a message if the file is not found or if any errors occur while loading the data. If sorting columns or applying <code>safe_literal_eval</code> fails, a warning message is printed, but execution continues.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def data_from_csv(csv_path, index_column=None, sort_columns=None, eval_columns=None):\n    \"\"\"\n    Loads data from a CSV file, with optional transformations. LEGACY!\n\n    This function loads a CSV file into a pandas DataFrame and provides the following optional features:\n    - Setting a specified column as the index.\n    - Sorting the DataFrame by one or more specified columns.\n    - Applying safe literal evaluation to specified columns to handle string representations of Python objects.\n\n    Parameters\n    ----------\n    csv_path : str\n        The relative or absolute path to the CSV file.\n    index_column : str, optional\n        The column to set as the index of the DataFrame. If not provided, no index column is set.\n    sort_columns : list of str, optional\n        A list of columns by which to sort the DataFrame. If not provided, the DataFrame is not sorted.\n    eval_columns : list of str, optional\n        A list of columns to which `safe_literal_eval` should be applied. This is useful for columns containing\n        string representations of Python data structures (e.g., lists, dictionaries).\n\n    Returns\n    -------\n    pd.DataFrame\n        A pandas DataFrame containing the loaded data with any specified transformations applied.\n\n    Raises\n    ------\n    SystemExit\n        If the file cannot be found or another error occurs during loading or processing.\n\n    Notes\n    -----\n    The function will terminate the program with a message if the file is not found or if any errors\n    occur while loading the data. If sorting columns or applying `safe_literal_eval` fails,\n    a warning message is printed, but execution continues.\n\n    \"\"\"\n    path = os.path.join(Path().home(), csv_path)\n\n    if not os.path.exists(path):\n        print(f\"Data file not found at path: {path}\")\n        sys.exit(1)\n\n    try:\n        df = pd.read_csv(path, parse_dates=True)\n    except FileNotFoundError:\n        print(f\"Data file not found at path: {path}\")\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        sys.exit(1)\n\n    if index_column:\n        try:\n            if df.index.name != index_column:\n                df = df.set_index(index_column)\n        except KeyError:\n            print(f\"Index column '{index_column}' not found in dataframe\")\n\n    if sort_columns:\n        try:\n            df.sort_values(sort_columns, inplace=True)\n        except KeyError:\n            print(\"One or more sort columns not found in dataframe\")\n\n    if eval_columns:\n        for column in eval_columns:\n            if column in df.columns:\n                try:\n                    df[column] = df[column].apply(safe_literal_eval)\n                except Exception as e:\n                    print(f\"Error applying safe_literal_eval to column '{column}': {e}\")\n\n    return df\n</code></pre>"},{"location":"api/#patientflow.load.get_dict_cols","title":"<code>get_dict_cols(df)</code>","text":"<p>Categorize DataFrame columns into predefined groups.</p>"},{"location":"api/#patientflow.load.get_dict_cols--parameters","title":"Parameters","text":"<p>df : pd.DataFrame     The DataFrame to categorize.</p>"},{"location":"api/#patientflow.load.get_dict_cols--returns","title":"Returns","text":"<p>dict     A dictionary where keys are column group names and values are lists of column names in each group.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def get_dict_cols(df):\n    \"\"\"\n    Categorize DataFrame columns into predefined groups.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame to categorize.\n\n    Returns\n    -------\n    dict\n        A dictionary where keys are column group names and values are lists of column names in each group.\n    \"\"\"\n    not_used_in_training_vars = [\n        \"snapshot_id\",\n        \"snapshot_date\",\n        \"prediction_time\",\n        \"visit_number\",\n        \"training_validation_test\",\n        \"random_number\",\n    ]\n    arrival_and_demographic_vars = [\n        \"elapsed_los\",\n        \"sex\",\n        \"age_group\",\n        \"age_on_arrival\",\n        \"arrival_method\",\n    ]\n    summary_vars = [\n        \"num_obs\",\n        \"num_obs_events\",\n        \"num_obs_types\",\n        \"num_lab_batteries_ordered\",\n    ]\n\n    location_vars = []\n    observations_vars = []\n    labs_vars = []\n    consults_vars = [\n        \"has_consultation\",\n        \"consultation_sequence\",\n        \"final_sequence\",\n        \"specialty\",\n    ]\n    outcome_vars = [\"is_admitted\"]\n\n    for col in df.columns:\n        if (\n            col in not_used_in_training_vars\n            or col in arrival_and_demographic_vars\n            or col in summary_vars\n        ):\n            continue\n        elif \"visited\" in col or \"location\" in col:\n            location_vars.append(col)\n        elif \"num_obs\" in col or \"latest_obs\" in col:\n            observations_vars.append(col)\n        elif \"lab_orders\" in col or \"latest_lab_results\" in col:\n            labs_vars.append(col)\n        elif col in consults_vars or col in outcome_vars:\n            continue  # Already categorized\n        else:\n            print(f\"Column '{col}' did not match any predefined group\")\n\n    # Create a list of column groups\n    col_group_names = [\n        \"not used in training\",\n        \"arrival and demographic\",\n        \"summary\",\n        \"location\",\n        \"observations\",\n        \"lab orders and results\",\n        \"consults\",\n        \"outcome\",\n    ]\n\n    # Create a list of the column names within those groups\n    col_groups = [\n        not_used_in_training_vars,\n        arrival_and_demographic_vars,\n        summary_vars,\n        location_vars,\n        observations_vars,\n        labs_vars,\n        consults_vars,\n        outcome_vars,\n    ]\n\n    # Use dictionary to combine them\n    dict_col_groups = {\n        category: var_list for category, var_list in zip(col_group_names, col_groups)\n    }\n\n    return dict_col_groups\n</code></pre>"},{"location":"api/#patientflow.load.get_model_key","title":"<code>get_model_key(model_name, prediction_time)</code>","text":"<p>Create a model name based on the time of day.</p>"},{"location":"api/#patientflow.load.get_model_key--parameters","title":"Parameters","text":"<p>model_name : str     The base name of the model. prediction_time_ : tuple of int     A tuple representing the time of day (hour, minute).</p>"},{"location":"api/#patientflow.load.get_model_key--returns","title":"Returns","text":"<p>str     A string representing the model name based on the time of day.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def get_model_key(model_name, prediction_time):\n    \"\"\"\n    Create a model name based on the time of day.\n\n    Parameters\n    ----------\n    model_name : str\n        The base name of the model.\n    prediction_time_ : tuple of int\n        A tuple representing the time of day (hour, minute).\n\n    Returns\n    -------\n    str\n        A string representing the model name based on the time of day.\n    \"\"\"\n\n    hour_, min_ = prediction_time\n    min_ = f\"{min_}0\" if min_ % 60 == 0 else str(min_)\n    model_name = model_name + \"_\" + f\"{hour_:02}\" + min_\n    return model_name\n</code></pre>"},{"location":"api/#patientflow.load.load_config_file","title":"<code>load_config_file(config_file_path, return_start_end_dates=False)</code>","text":"<p>Load configuration from a YAML file.</p>"},{"location":"api/#patientflow.load.load_config_file--parameters","title":"Parameters","text":"<p>config_file_path : str     The path to the configuration file. return_start_end_dates : bool, optional     If True, return only the start and end dates from the file (default is False).</p>"},{"location":"api/#patientflow.load.load_config_file--returns","title":"Returns","text":"<p>dict or tuple or None     If <code>return_start_end_dates</code> is True, returns a tuple of start and end dates (str).     Otherwise, returns a dictionary containing the configuration parameters.     Returns None if an error occurs during file reading or parsing.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def load_config_file(\n    config_file_path: str, return_start_end_dates: bool = False\n) -&gt; Optional[Union[Dict[str, Any], Tuple[str, str]]]:\n    \"\"\"\n    Load configuration from a YAML file.\n\n    Parameters\n    ----------\n    config_file_path : str\n        The path to the configuration file.\n    return_start_end_dates : bool, optional\n        If True, return only the start and end dates from the file (default is False).\n\n    Returns\n    -------\n    dict or tuple or None\n        If `return_start_end_dates` is True, returns a tuple of start and end dates (str).\n        Otherwise, returns a dictionary containing the configuration parameters.\n        Returns None if an error occurs during file reading or parsing.\n    \"\"\"\n    try:\n        with open(config_file_path, \"r\") as file:\n            config = yaml.safe_load(file)\n    except FileNotFoundError:\n        print(f\"Error: The file '{config_file_path}' was not found.\")\n        return None\n    except yaml.YAMLError as e:\n        print(f\"Error parsing YAML file: {e}\")\n        return None\n\n    try:\n        if return_start_end_dates:\n            # load the dates used in saved data for uclh versions\n            if \"file_dates\" in config and config[\"file_dates\"]:\n                start_date, end_date = [str(item) for item in config[\"file_dates\"]]\n                return (start_date, end_date)\n            else:\n                print(\n                    \"Error: 'file_dates' key not found or empty in the configuration file.\"\n                )\n                return None\n\n        params: Dict[str, Any] = {}\n\n        if \"prediction_times\" in config:\n            params[\"prediction_times\"] = [\n                tuple(item) for item in config[\"prediction_times\"]\n            ]\n        else:\n            print(\"Error: 'prediction_times' key not found in the configuration file.\")\n            sys.exit(1)\n\n        if \"modelling_dates\" in config and len(config[\"modelling_dates\"]) == 4:\n            (\n                params[\"start_training_set\"],\n                params[\"start_validation_set\"],\n                params[\"start_test_set\"],\n                params[\"end_test_set\"],\n            ) = [item for item in config[\"modelling_dates\"]]\n        else:\n            print(\n                f\"Error: expecting 4 modelling dates and only got {len(config.get('modelling_dates', []))}\"\n            )\n            return None\n\n        params[\"x1\"] = float(config.get(\"x1\", 4))\n        params[\"y1\"] = float(config.get(\"y1\", 0.76))\n        params[\"x2\"] = float(config.get(\"x2\", 12))\n        params[\"y2\"] = float(config.get(\"y2\", 0.99))\n        params[\"prediction_window\"] = config.get(\"prediction_window\", 480)\n        params[\"epsilon\"] = config.get(\"epsilon\", 10**-7)\n        params[\"yta_time_interval\"] = config.get(\"yta_time_interval\", 15)\n\n        return params\n\n    except KeyError as e:\n        print(f\"Error: Missing key in the configuration file: {e}\")\n        return None\n    except ValueError as e:\n        print(f\"Error: Invalid value found in the configuration file: {e}\")\n        return None\n</code></pre>"},{"location":"api/#patientflow.load.load_data","title":"<code>load_data(data_file_path, file_name, index_column=None, sort_columns=None, eval_columns=None, home_path=None)</code>","text":"<p>Loads data from CSV or pickle file with optional transformations.</p>"},{"location":"api/#patientflow.load.load_data--parameters","title":"Parameters","text":"<p>data_file_path : str     Directory path containing the data file file_name : str     Name of the CSV or pickle file to load index_column : str, optional     Column to set as DataFrame index sort_columns : list of str, optional     Columns to sort DataFrame by eval_columns : list of str, optional     Columns to apply safe_literal_eval to home_path : str or Path, optional     Base path to use instead of user's home directory</p>"},{"location":"api/#patientflow.load.load_data--returns","title":"Returns","text":"<p>pd.DataFrame     Loaded and transformed DataFrame</p>"},{"location":"api/#patientflow.load.load_data--raises","title":"Raises","text":"<p>FileNotFoundError     If the specified file does not exist ValueError     If the file format is not supported or other processing errors occur</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def load_data(\n    data_file_path,\n    file_name,\n    index_column=None,\n    sort_columns=None,\n    eval_columns=None,\n    home_path=None,\n):\n    \"\"\"\n    Loads data from CSV or pickle file with optional transformations.\n\n    Parameters\n    ----------\n    data_file_path : str\n        Directory path containing the data file\n    file_name : str\n        Name of the CSV or pickle file to load\n    index_column : str, optional\n        Column to set as DataFrame index\n    sort_columns : list of str, optional\n        Columns to sort DataFrame by\n    eval_columns : list of str, optional\n        Columns to apply safe_literal_eval to\n    home_path : str or Path, optional\n        Base path to use instead of user's home directory\n\n    Returns\n    -------\n    pd.DataFrame\n        Loaded and transformed DataFrame\n\n    Raises\n    ------\n    FileNotFoundError\n        If the specified file does not exist\n    ValueError\n        If the file format is not supported or other processing errors occur\n    \"\"\"\n    from pathlib import Path\n\n    # Use provided home_path if available, otherwise default to user's home directory\n    base_path = Path(home_path) if home_path else Path.home()\n    path = base_path / data_file_path / file_name\n\n    if not path.exists():\n        raise FileNotFoundError(f\"Data file not found at path: {path}\")\n\n    try:\n        if path.suffix.lower() == \".csv\":\n            df = pd.read_csv(path, parse_dates=True)\n        elif path.suffix.lower() == \".pkl\":\n            df = pd.read_pickle(path)\n        else:\n            raise ValueError(\n                f\"Unsupported file format: {path.suffix}. Must be .csv or .pkl\"\n            )\n    except Exception as e:\n        raise ValueError(f\"Error loading data: {str(e)}\")\n\n    if index_column and df.index.name != index_column:\n        try:\n            df = df.set_index(index_column)\n        except KeyError:\n            print(f\"Warning: Index column '{index_column}' not found in dataframe\")\n\n    if sort_columns:\n        try:\n            df.sort_values(sort_columns, inplace=True)\n        except KeyError:\n            print(\"Warning: One or more sort columns not found in dataframe\")\n\n    if eval_columns:\n        for column in eval_columns:\n            if column in df.columns:\n                try:\n                    df[column] = df[column].apply(safe_literal_eval)\n                except Exception as e:\n                    print(\n                        f\"Warning: Error applying safe_literal_eval to column '{column}': {str(e)}\"\n                    )\n\n    return df\n</code></pre>"},{"location":"api/#patientflow.load.load_saved_model","title":"<code>load_saved_model(model_file_path, model_name, prediction_time=None)</code>","text":"<p>Load a saved model from a file.</p>"},{"location":"api/#patientflow.load.load_saved_model--parameters","title":"Parameters","text":"<p>model_file_path : Path     The path to the directory where the model is saved. model_name : str     The base name of the model. prediction_time : tuple of int, optional     The time of day the model was trained for.</p>"},{"location":"api/#patientflow.load.load_saved_model--returns","title":"Returns","text":"<p>Any     The loaded model.</p>"},{"location":"api/#patientflow.load.load_saved_model--raises","title":"Raises","text":"<p>ModelLoadError     If the model file cannot be found or loaded.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def load_saved_model(model_file_path, model_name, prediction_time=None):\n    \"\"\"\n    Load a saved model from a file.\n\n    Parameters\n    ----------\n    model_file_path : Path\n        The path to the directory where the model is saved.\n    model_name : str\n        The base name of the model.\n    prediction_time : tuple of int, optional\n        The time of day the model was trained for.\n\n    Returns\n    -------\n    Any\n        The loaded model.\n\n    Raises\n    ------\n    ModelLoadError\n        If the model file cannot be found or loaded.\n    \"\"\"\n    if prediction_time:\n        # retrieve model based on the time of day it is trained for\n        model_name = get_model_key(model_name, prediction_time)\n\n    full_path = model_file_path / model_name\n    full_path = full_path.with_suffix(\".joblib\")\n\n    try:\n        model = load(full_path)\n        return model\n    except FileNotFoundError:\n        # print(f\"Model named {model_name} not found at path: {model_file_path}\")\n        raise ModelLoadError(\n            f\"Model named {model_name} not found at path: {model_file_path}\"\n        )\n    except Exception as e:\n        # print(f\"Error loading model: {e}\")\n        raise ModelLoadError(f\"Error loading model called {model_name}: {e}\")\n</code></pre>"},{"location":"api/#patientflow.load.parse_args","title":"<code>parse_args()</code>","text":"<p>Parse command-line arguments for the training script.</p> <p>Returns:</p> Type Description <code>Namespace</code> <p>argparse.Namespace: The parsed arguments containing 'data_folder_name' and 'uclh' keys.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def parse_args() -&gt; argparse.Namespace:\n    \"\"\"\n    Parse command-line arguments for the training script.\n\n    Returns:\n        argparse.Namespace: The parsed arguments containing 'data_folder_name' and 'uclh' keys.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"Train emergency demand models\")\n    parser.add_argument(\n        \"--data_folder_name\",\n        type=str,\n        default=\"data-synthetic\",\n        help=\"Location of data for training\",\n    )\n    parser.add_argument(\n        \"--uclh\",\n        type=lambda x: x.lower() in [\"true\", \"1\", \"yes\", \"y\"],\n        default=False,\n        help=\"Train using UCLH data (True) or Public data (False)\",\n    )\n    args = parser.parse_args()\n    return args\n</code></pre>"},{"location":"api/#patientflow.load.safe_literal_eval","title":"<code>safe_literal_eval(s)</code>","text":"<p>Safely evaluate a string literal into a Python object. Handles list-like strings by converting them to lists.</p>"},{"location":"api/#patientflow.load.safe_literal_eval--parameters","title":"Parameters","text":"<p>s : str     The string to evaluate.</p>"},{"location":"api/#patientflow.load.safe_literal_eval--returns","title":"Returns","text":"<p>Any, list, or None     The evaluated Python object if successful, a list if the input is list-like,     or None for empty/null values.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def safe_literal_eval(s):\n    \"\"\"\n    Safely evaluate a string literal into a Python object.\n    Handles list-like strings by converting them to lists.\n\n    Parameters\n    ----------\n    s : str\n        The string to evaluate.\n\n    Returns\n    -------\n    Any, list, or None\n        The evaluated Python object if successful, a list if the input is list-like,\n        or None for empty/null values.\n    \"\"\"\n    if pd.isna(s) or str(s).strip().lower() in [\"nan\", \"none\", \"\"]:\n        return None\n\n    if isinstance(s, str):\n        s = s.strip()\n        if s.startswith(\"[\") and s.endswith(\"]\"):\n            try:\n                # Remove square brackets and split by comma\n                items = s[1:-1].split(\",\")\n                # Strip whitespace from each item and remove empty strings\n                return [item.strip() for item in items if item.strip()]\n            except Exception:\n                # If the above fails, fall back to ast.literal_eval\n                pass\n\n    try:\n        return ast.literal_eval(s)\n    except (ValueError, SyntaxError):\n        # If ast.literal_eval fails, return the original string\n        return s\n</code></pre>"},{"location":"api/#patientflow.load.set_data_file_names","title":"<code>set_data_file_names(uclh, data_file_path, config_file_path=None)</code>","text":"<p>Set file locations based on UCLH or default data source.</p>"},{"location":"api/#patientflow.load.set_data_file_names--parameters","title":"Parameters","text":"<p>uclh : bool     If True, use UCLH-specific file locations. If False, use default file locations. data_file_path : Path     The base path to the data directory. config_file_path : str, optional     The path to the configuration file, required if <code>uclh</code> is True.</p>"},{"location":"api/#patientflow.load.set_data_file_names--returns","title":"Returns","text":"<p>tuple     Paths to the required files (visits, arrivals) based on the configuration.</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def set_data_file_names(uclh, data_file_path, config_file_path=None):\n    \"\"\"\n    Set file locations based on UCLH or default data source.\n\n    Parameters\n    ----------\n    uclh : bool\n        If True, use UCLH-specific file locations. If False, use default file locations.\n    data_file_path : Path\n        The base path to the data directory.\n    config_file_path : str, optional\n        The path to the configuration file, required if `uclh` is True.\n\n    Returns\n    -------\n    tuple\n        Paths to the required files (visits, arrivals) based on the configuration.\n    \"\"\"\n    if not isinstance(data_file_path, Path):\n        data_file_path = Path(data_file_path)\n\n    if not uclh:\n        csv_filename = \"ed_visits.csv\"\n        yta_csv_filename = \"inpatient_arrivals.csv\"\n\n        visits_csv_path = data_file_path / csv_filename\n        yta_csv_path = data_file_path / yta_csv_filename\n\n        return visits_csv_path, yta_csv_path\n\n    else:\n        start_date, end_date = load_config_file(\n            config_file_path, return_start_end_dates=True\n        )\n        data_filename = (\n            \"uclh_visits_exc_beds_inc_minority_\"\n            + str(start_date)\n            + \"_\"\n            + str(end_date)\n            + \".pickle\"\n        )\n        csv_filename = \"uclh_ed_visits.csv\"\n        yta_filename = (\n            \"uclh_yet_to_arrive_\" + str(start_date) + \"_\" + str(end_date) + \".pickle\"\n        )\n        yta_csv_filename = \"uclh_inpatient_arrivals.csv\"\n\n        visits_path = data_file_path / data_filename\n        yta_path = data_file_path / yta_filename\n\n        visits_csv_path = data_file_path / csv_filename\n        yta_csv_path = data_file_path / yta_csv_filename\n\n    return visits_path, visits_csv_path, yta_path, yta_csv_path\n</code></pre>"},{"location":"api/#patientflow.load.set_file_paths","title":"<code>set_file_paths(project_root, data_folder_name, train_dttm=None, inference_time=False, config_file='config.yaml', prefix=None, verbose=True)</code>","text":"<p>Sets up the file paths</p> <p>Parameters:</p> Name Type Description Default <code>project_root</code> <code>Path</code> <p>Root path of the project</p> required <code>data_folder_name</code> <code>str</code> <p>Name of the folder where data files are located</p> required <code>train_dttm</code> <code>Optional[str]</code> <p>A string representation of the datetime at which training commenced. Defaults to None</p> <code>None</code> <code>inference_time</code> <code>bool</code> <p>A flag indicating whether it is inference time or not. Defaults to False</p> <code>False</code> <code>config_file</code> <code>str</code> <p>Name of config file. Defaults to \"config.yaml\"</p> <code>'config.yaml'</code> <code>prefix</code> <code>Optional[str]</code> <p>String to prefix model folder names. Defaults to None</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to print path information. Defaults to True</p> <code>True</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[Path, Path, Path, Path]</code> <p>Contains (data_file_path, media_file_path, model_file_path, config_path)</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def set_file_paths(\n    project_root: Path,\n    data_folder_name: str,\n    train_dttm: Optional[str] = None,\n    inference_time: bool = False,\n    config_file: str = \"config.yaml\",\n    prefix: Optional[str] = None,\n    verbose: bool = True,\n) -&gt; Tuple[Path, Path, Path, Path]:\n    \"\"\"\n    Sets up the file paths\n\n    Args:\n        project_root (Path): Root path of the project\n        data_folder_name (str): Name of the folder where data files are located\n        train_dttm (Optional[str], optional): A string representation of the datetime at which training commenced. Defaults to None\n        inference_time (bool, optional): A flag indicating whether it is inference time or not. Defaults to False\n        config_file (str, optional): Name of config file. Defaults to \"config.yaml\"\n        prefix (Optional[str], optional): String to prefix model folder names. Defaults to None\n        verbose (bool, optional): Whether to print path information. Defaults to True\n\n    Returns:\n        tuple: Contains (data_file_path, media_file_path, model_file_path, config_path)\n    \"\"\"\n\n    config_path = Path(project_root) / config_file\n    if verbose:\n        print(f\"Configuration will be loaded from: {config_path}\")\n\n    data_file_path = Path(project_root) / data_folder_name\n    if verbose:\n        print(f\"Data files will be loaded from: {data_file_path}\")\n\n    model_id = data_folder_name.lstrip(\"data-\")\n    if prefix:\n        model_id = f\"{prefix}_{model_id}\"\n    if train_dttm:\n        model_id = f\"{model_id}_{train_dttm}\"\n\n    model_file_path = Path(project_root) / \"trained-models\" / model_id\n    media_file_path = model_file_path / \"media\"\n\n    if not inference_time:\n        if verbose:\n            print(f\"Trained models will be saved to: {model_file_path}\")\n        model_file_path.mkdir(parents=True, exist_ok=True)\n        (model_file_path / \"model-output\").mkdir(parents=False, exist_ok=True)\n        media_file_path.mkdir(parents=False, exist_ok=True)\n        if verbose:\n            print(f\"Images will be saved to: {media_file_path}\")\n\n    return data_file_path, media_file_path, model_file_path, config_path\n</code></pre>"},{"location":"api/#patientflow.load.set_project_root","title":"<code>set_project_root(env_var=None)</code>","text":"<p>Sets project root path from environment variable or infers it from current path.</p> <p>First checks specified environment variable for project root path. If not found, searches current path hierarchy for highest-level 'patientflow' directory.</p> <p>Parameters:</p> Name Type Description Default <code>env_var</code> <code>Optional[str]</code> <p>Name of environment variable containing project root path</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Validated project root path</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If environment variable not set and 'patientflow' not found in path</p> <code>NotADirectoryError</code> <p>If path doesn't exist</p> <code>TypeError</code> <p>If env_var is not None and not a string</p> Source code in <code>src/patientflow/load.py</code> <pre><code>def set_project_root(env_var: Optional[str] = None) -&gt; Path:\n    \"\"\"\n    Sets project root path from environment variable or infers it from current path.\n\n    First checks specified environment variable for project root path.\n    If not found, searches current path hierarchy for highest-level 'patientflow' directory.\n\n    Args:\n        env_var (Optional[str]): Name of environment variable containing project root path\n\n    Returns:\n        Path: Validated project root path\n\n    Raises:\n        ValueError: If environment variable not set and 'patientflow' not found in path\n        NotADirectoryError: If path doesn't exist\n        TypeError: If env_var is not None and not a string\n    \"\"\"\n    # Only try to get env path if env_var is provided\n    env_path: Optional[str] = os.getenv(env_var) if env_var is not None else None\n    project_root: Optional[Path] = None\n\n    # Try getting from environment variable first\n    if env_path is not None:\n        try:\n            project_root = Path(env_path)\n            if not project_root.is_dir():\n                raise NotADirectoryError(f\"Path does not exist: {project_root}\")\n            print(f\"Project root from environment: {project_root}\")\n            return project_root\n        except (TypeError, ValueError) as e:\n            print(f\"Error converting {env_path} to Path: {e}\")\n            raise\n    else:\n        # If not in env var, try to infer from current path\n        current: Path = Path().absolute()\n\n        # Search through parents to find highest-level 'patientflow' directory\n        for parent in [current, *current.parents]:\n            if parent.name == \"patientflow\" and parent.is_dir():\n                project_root = parent\n                # Continue searching to find highest level\n\n        if project_root:\n            print(f\"Inferred project root: {project_root}\")\n            return project_root\n\n        print(\n            f\"Could not find project root - {env_var} not set and 'patientflow' not found in path\"\n        )\n        print(f\"\\nCurrent directory: {Path().absolute()}\")\n        if env_var:\n            print(f\"\\nRun one of these commands in a new cell to set {env_var}:\")\n            print(\"# Linux/Mac:\")\n            print(f\"%env {env_var}=/path/to/project\")\n            print(\"\\n# Windows:\")\n            print(f\"%env {env_var}=C:\\\\path\\\\to\\\\project\")\n        raise ValueError(\"Project root not found\")\n</code></pre>"},{"location":"api/#patientflow.mask","title":"<code>mask</code>","text":""},{"location":"api/#patientflow.mask.calculate_shift_delta","title":"<code>calculate_shift_delta(seed, min_weeks=520, max_weeks=520 * 2)</code>","text":"<p>Calculate a consistent time delta based on the provided seed.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>Random seed for consistent shifts</p> required <code>min_weeks</code> <code>int</code> <p>Minimum number of weeks to shift</p> <code>520</code> <code>max_weeks</code> <code>int</code> <p>Maximum number of weeks to shift</p> <code>520 * 2</code> <p>Returns:</p> Name Type Description <code>timedelta</code> <code>timedelta</code> <p>The time shift to apply</p> Source code in <code>src/patientflow/mask.py</code> <pre><code>def calculate_shift_delta(\n    seed: int, min_weeks: int = 520, max_weeks: int = 520 * 2\n) -&gt; timedelta:\n    \"\"\"\n    Calculate a consistent time delta based on the provided seed.\n\n    Args:\n        seed (int): Random seed for consistent shifts\n        min_weeks (int): Minimum number of weeks to shift\n        max_weeks (int): Maximum number of weeks to shift\n\n    Returns:\n        timedelta: The time shift to apply\n    \"\"\"\n    random.seed(seed)\n    weeks_to_add = random.randint(min_weeks, max_weeks)\n    return timedelta(weeks=weeks_to_add)\n</code></pre>"},{"location":"api/#patientflow.mask.hash_csn","title":"<code>hash_csn(df, salt)</code>","text":"<p>Consistently hash CSN values in a dataframe Returns a new dataframe with hashed CSN column</p> Source code in <code>src/patientflow/mask.py</code> <pre><code>def hash_csn(df, salt):\n    \"\"\"\n    Consistently hash CSN values in a dataframe\n    Returns a new dataframe with hashed CSN column\n    \"\"\"\n    # Create a copy to avoid modifying original\n    df_hashed = df.copy()\n\n    def hash_value(value):\n        if pd.isna(value):\n            return None\n        salted = f\"{str(value)}{salt}\".encode()\n        return hashlib.sha256(salted).hexdigest()[:12]\n\n    # Apply the hash function to the CSN column\n    df_hashed[\"csn\"] = df_hashed[\"csn\"].apply(hash_value)\n\n    return df_hashed\n</code></pre>"},{"location":"api/#patientflow.mask.shift_dates","title":"<code>shift_dates(data, seed, min_weeks=520, max_weeks=520 * 2, start_date=None, end_date=None)</code>","text":"<p>Shift dates either in a DataFrame or create shifted dates from a date range.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[DataFrame, List[Timestamp], DatetimeIndex]</code> <p>Either a DataFrame with datetime columns to shift, or None if using start/end dates</p> required <code>seed</code> <code>int</code> <p>Random seed for consistent shifts</p> required <code>min_weeks</code> <code>int</code> <p>Minimum number of weeks to shift</p> <code>520</code> <code>max_weeks</code> <code>int</code> <p>Maximum number of weeks to shift</p> <code>520 * 2</code> <code>start_date</code> <code>Optional[Union[str, Timestamp]]</code> <p>Start date if generating a date range (only used if data is None)</p> <code>None</code> <code>end_date</code> <code>Optional[Union[str, Timestamp]]</code> <p>End date if generating a date range (only used if data is None)</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[DataFrame, List[Timestamp]]</code> <p>Union[pd.DataFrame, List[pd.Timestamp]]: Either the shifted DataFrame or list of shifted dates</p> Source code in <code>src/patientflow/mask.py</code> <pre><code>def shift_dates(\n    data: Union[pd.DataFrame, List[pd.Timestamp], pd.DatetimeIndex],\n    seed: int,\n    min_weeks: int = 520,\n    max_weeks: int = 520 * 2,\n    start_date: Optional[Union[str, pd.Timestamp]] = None,\n    end_date: Optional[Union[str, pd.Timestamp]] = None,\n) -&gt; Union[pd.DataFrame, List[pd.Timestamp]]:\n    \"\"\"\n    Shift dates either in a DataFrame or create shifted dates from a date range.\n\n    Args:\n        data: Either a DataFrame with datetime columns to shift, or None if using start/end dates\n        seed: Random seed for consistent shifts\n        min_weeks: Minimum number of weeks to shift\n        max_weeks: Maximum number of weeks to shift\n        start_date: Start date if generating a date range (only used if data is None)\n        end_date: End date if generating a date range (only used if data is None)\n\n    Returns:\n        Union[pd.DataFrame, List[pd.Timestamp]]: Either the shifted DataFrame or list of shifted dates\n    \"\"\"\n    shift_delta = calculate_shift_delta(seed, min_weeks, max_weeks)\n\n    # Case 1: Shifting DataFrame columns\n    if isinstance(data, pd.DataFrame):\n        df_copy = data.copy()\n        datetime_cols = df_copy.select_dtypes(\n            include=[\"datetime64[ns]\", \"datetime64\"]\n        ).columns\n        for col in datetime_cols:\n            df_copy[col] = df_copy[col].apply(\n                lambda x: x + shift_delta if pd.notna(x) else x\n            )\n        return df_copy\n\n    # Case 2: Generating shifted date range\n    elif start_date is not None and end_date is not None:\n        original_dates = pd.date_range(\n            start=start_date, end=end_date, freq=\"D\"\n        ).date.tolist()[:-1]\n        return [date + shift_delta for date in original_dates]\n\n    # Case 3: Shifting list of dates or DatetimeIndex\n    elif isinstance(data, (list, pd.DatetimeIndex)):\n        return [date + shift_delta for date in data]\n\n    else:\n        raise ValueError(\n            \"Must provide either a DataFrame, date range parameters, or list of dates\"\n        )\n</code></pre>"},{"location":"api/#patientflow.model_artifacts","title":"<code>model_artifacts</code>","text":""},{"location":"api/#patientflow.model_artifacts.FoldResults","title":"<code>FoldResults</code>  <code>dataclass</code>","text":"<p>Store evaluation metrics for a single fold.</p> Source code in <code>src/patientflow/model_artifacts.py</code> <pre><code>@dataclass\nclass FoldResults:\n    \"\"\"Store evaluation metrics for a single fold.\"\"\"\n\n    auc: float\n    logloss: float\n    auprc: float\n</code></pre>"},{"location":"api/#patientflow.model_artifacts.HyperParameterTrial","title":"<code>HyperParameterTrial</code>  <code>dataclass</code>","text":"<p>Container for a single hyperparameter tuning trial.</p> Source code in <code>src/patientflow/model_artifacts.py</code> <pre><code>@dataclass\nclass HyperParameterTrial:\n    \"\"\"Container for a single hyperparameter tuning trial.\"\"\"\n\n    parameters: Dict[str, Any]\n    cv_results: Dict[str, float]\n</code></pre>"},{"location":"api/#patientflow.model_artifacts.TrainedClassifier","title":"<code>TrainedClassifier</code>  <code>dataclass</code>","text":"<p>Container for trained model artifacts and their associated information.</p> Source code in <code>src/patientflow/model_artifacts.py</code> <pre><code>@dataclass\nclass TrainedClassifier:\n    \"\"\"Container for trained model artifacts and their associated information.\"\"\"\n\n    training_results: TrainingResults\n    pipeline: Optional[Pipeline] = None\n    calibrated_pipeline: Optional[Pipeline] = None\n</code></pre>"},{"location":"api/#patientflow.model_artifacts.TrainingResults","title":"<code>TrainingResults</code>  <code>dataclass</code>","text":"<p>Store comprehensive evaluation metrics and metadata from model training.</p> Source code in <code>src/patientflow/model_artifacts.py</code> <pre><code>@dataclass\nclass TrainingResults:\n    \"\"\"Store comprehensive evaluation metrics and metadata from model training.\"\"\"\n\n    prediction_time: Tuple[int, int]\n    training_info: Dict[str, Any] = field(default_factory=dict)\n    calibration_info: Dict[str, Any] = field(default_factory=dict)\n    test_results: Dict[str, float] = field(default_factory=dict)\n    balance_info: Dict[str, Union[bool, int, float]] = field(default_factory=dict)\n</code></pre>"},{"location":"api/#patientflow.predict","title":"<code>predict</code>","text":""},{"location":"api/#patientflow.predict.emergency_demand","title":"<code>emergency_demand</code>","text":""},{"location":"api/#patientflow.predict.emergency_demand.create_predictions","title":"<code>create_predictions(models, prediction_time, prediction_snapshots, specialties, prediction_window_hrs, x1, y1, x2, y2, cdf_cut_points)</code>","text":"<p>Create predictions for emergency demand for a single prediction moment.</p>"},{"location":"api/#patientflow.predict.emergency_demand.create_predictions--parameters","title":"Parameters","text":"<p>models : Tuple[TrainedClassifier, SequencePredictor, WeightedPoissonPredictor]     Tuple containing:     - classifier: TrainedClassifier containing admission predictions     - spec_model: SequencePredictor for specialty predictions     - yet_to_arrive_model: WeightedPoissonPredictor for yet-to-arrive predictions prediction_time : Tuple     Hour and minute of time for model inference prediction_snapshots : pd.DataFrame     DataFrame containing prediction snapshots specialties : List[str]     List of specialty names for predictions (e.g., ['surgical', 'medical']) prediction_window_hrs : float     Prediction window in hours x1 : float     X-coordinate of first point for probability curve y1 : float     Y-coordinate of first point for probability curve x2 : float     X-coordinate of second point for probability curve y2 : float     Y-coordinate of second point for probability curve cdf_cut_points : List[float]     List of cumulative distribution function cut points (e.g., [0.9, 0.7]) special_params : Optional[Dict[str, Any]], optional     Special handling parameters for categories, by default None</p>"},{"location":"api/#patientflow.predict.emergency_demand.create_predictions--returns","title":"Returns","text":"<p>Dict[str, Dict[str, List[int]]]     Nested dictionary containing predictions for each specialty:     {         'specialty_name': {             'in_ed': [pred1, pred2, ...],             'yet_to_arrive': [pred1, pred2, ...]         }     }</p>"},{"location":"api/#patientflow.predict.emergency_demand.create_predictions--notes","title":"Notes","text":"<p>The admissions models in the models dictionary must be ModelResults objects that contain either a 'pipeline' or 'calibrated_pipeline' attribute. The pipeline will be used for making predictions, with calibrated_pipeline taking precedence if both exist.</p> Source code in <code>src/patientflow/predict/emergency_demand.py</code> <pre><code>def create_predictions(\n    models: Tuple[TrainedClassifier, SequencePredictor, WeightedPoissonPredictor],\n    prediction_time: Tuple,\n    prediction_snapshots: pd.DataFrame,\n    specialties: List[str],\n    prediction_window_hrs: float,\n    x1: float,\n    y1: float,\n    x2: float,\n    y2: float,\n    cdf_cut_points: List[float],\n) -&gt; Dict[str, Dict[str, List[int]]]:\n    \"\"\"\n    Create predictions for emergency demand for a single prediction moment.\n\n    Parameters\n    ----------\n    models : Tuple[TrainedClassifier, SequencePredictor, WeightedPoissonPredictor]\n        Tuple containing:\n        - classifier: TrainedClassifier containing admission predictions\n        - spec_model: SequencePredictor for specialty predictions\n        - yet_to_arrive_model: WeightedPoissonPredictor for yet-to-arrive predictions\n    prediction_time : Tuple\n        Hour and minute of time for model inference\n    prediction_snapshots : pd.DataFrame\n        DataFrame containing prediction snapshots\n    specialties : List[str]\n        List of specialty names for predictions (e.g., ['surgical', 'medical'])\n    prediction_window_hrs : float\n        Prediction window in hours\n    x1 : float\n        X-coordinate of first point for probability curve\n    y1 : float\n        Y-coordinate of first point for probability curve\n    x2 : float\n        X-coordinate of second point for probability curve\n    y2 : float\n        Y-coordinate of second point for probability curve\n    cdf_cut_points : List[float]\n        List of cumulative distribution function cut points (e.g., [0.9, 0.7])\n    special_params : Optional[Dict[str, Any]], optional\n        Special handling parameters for categories, by default None\n\n    Returns\n    -------\n    Dict[str, Dict[str, List[int]]]\n        Nested dictionary containing predictions for each specialty:\n        {\n            'specialty_name': {\n                'in_ed': [pred1, pred2, ...],\n                'yet_to_arrive': [pred1, pred2, ...]\n            }\n        }\n\n    Notes\n    -----\n    The admissions models in the models dictionary must be ModelResults objects\n    that contain either a 'pipeline' or 'calibrated_pipeline' attribute. The pipeline\n    will be used for making predictions, with calibrated_pipeline taking precedence\n    if both exist.\n    \"\"\"\n    # Validate model types\n    classifier, spec_model, yet_to_arrive_model = models\n\n    if not isinstance(classifier, TrainedClassifier):\n        raise TypeError(\"First model must be of type TrainedClassifier\")\n    if not isinstance(spec_model, SequencePredictor):\n        raise TypeError(\"Second model must be of type SequencePredictor\")\n    if not isinstance(yet_to_arrive_model, WeightedPoissonPredictor):\n        raise TypeError(\"Third model must be of type WeightedPoissonPredictor\")\n\n    # Check that all models have been fit\n    if not hasattr(classifier, \"pipeline\") or classifier.pipeline is None:\n        raise ValueError(\"Classifier model has not been fit\")\n    if not hasattr(spec_model, \"weights\") or spec_model.weights is None:\n        raise ValueError(\"Specialty model has not been fit\")\n    if (\n        not hasattr(yet_to_arrive_model, \"prediction_window\")\n        or yet_to_arrive_model.prediction_window is None\n    ):\n        raise ValueError(\"Yet-to-arrive model has not been fit\")\n\n    # Validate that the correct models have been passed for the requested prediction time and prediction window\n    if not classifier.training_results.prediction_time == prediction_time:\n        raise ValueError(\n            \"Requested prediction time does not match the prediction time of the trained classifier\"\n        )\n    if not yet_to_arrive_model.prediction_window / 60 == prediction_window_hrs:\n        raise ValueError(\n            \"Requested prediction window does not match the prediction window of the trained yet-to-arrive model\"\n        )\n    if not set(yet_to_arrive_model.filters.keys()) == set(specialties):\n        raise ValueError(\n            \"Requested specialties do not match the specialties of the trained yet-to-arrive model\"\n        )\n\n    special_params = spec_model.special_params\n\n    if special_params:\n        special_category_func = special_params[\"special_category_func\"]\n        special_category_dict = special_params[\"special_category_dict\"]\n        special_func_map = special_params[\"special_func_map\"]\n    else:\n        special_category_func = special_category_dict = special_func_map = None\n\n    if special_category_dict is not None and not set(specialties) == set(\n        special_category_dict.keys()\n    ):\n        raise ValueError(\n            \"Requested specialties do not match the specialty dictionary defined in special_params\"\n        )\n\n    predictions: Dict[str, Dict[str, List[int]]] = {\n        specialty: {\"in_ed\": [], \"yet_to_arrive\": []} for specialty in specialties\n    }\n\n    # Use calibrated pipeline if available, otherwise use regular pipeline\n    if (\n        hasattr(classifier, \"calibrated_pipeline\")\n        and classifier.calibrated_pipeline is not None\n    ):\n        pipeline = classifier.calibrated_pipeline\n    else:\n        pipeline = classifier.pipeline\n\n    # Add missing columns expected by the model\n    prediction_snapshots = add_missing_columns(pipeline, prediction_snapshots)\n\n    # Get predictions of admissions for ED patients\n    prob_admission_after_ed = model_input_to_pred_proba(prediction_snapshots, pipeline)\n\n    # Get predictions of admission to specialty\n    prediction_snapshots.loc[:, \"specialty_prob\"] = get_specialty_probs(\n        specialties,\n        spec_model,\n        prediction_snapshots,\n        special_category_func=special_category_func,\n        special_category_dict=special_category_dict,\n    )\n\n    prediction_snapshots.loc[:, \"elapsed_los_hrs\"] = prediction_snapshots[\n        \"elapsed_los\"\n    ].apply(lambda x: x / 3600)\n\n    # Get probability of admission within prediction window\n    prob_admission_in_window = prediction_snapshots.apply(\n        lambda row: calculate_probability(\n            row[\"elapsed_los_hrs\"], prediction_window_hrs, x1, y1, x2, y2\n        ),\n        axis=1,\n    )\n\n    if special_func_map is None:\n        special_func_map = {\"default\": lambda row: True}\n\n    for specialty in specialties:\n        func = special_func_map.get(specialty, special_func_map[\"default\"])\n        non_zero_indices = prediction_snapshots[\n            prediction_snapshots.apply(func, axis=1)\n        ].index\n\n        filtered_prob_admission_after_ed = prob_admission_after_ed.loc[non_zero_indices]\n        prob_admission_to_specialty = prediction_snapshots[\"specialty_prob\"].apply(\n            lambda x: x[specialty]\n        )\n\n        filtered_prob_admission_to_specialty = prob_admission_to_specialty.loc[\n            non_zero_indices\n        ]\n        filtered_prob_admission_in_window = prob_admission_in_window.loc[\n            non_zero_indices\n        ]\n\n        filtered_weights = (\n            filtered_prob_admission_to_specialty * filtered_prob_admission_in_window\n        )\n\n        agg_predicted_in_ed = pred_proba_to_agg_predicted(\n            filtered_prob_admission_after_ed, weights=filtered_weights\n        )\n\n        prediction_context = {specialty: {\"prediction_time\": prediction_time}}\n        agg_predicted_yta = yet_to_arrive_model.predict(\n            prediction_context, x1, y1, x2, y2\n        )\n\n        predictions[specialty][\"in_ed\"] = [\n            index_of_sum(agg_predicted_in_ed[\"agg_proba\"].values.cumsum(), cut_point)\n            for cut_point in cdf_cut_points\n        ]\n        predictions[specialty][\"yet_to_arrive\"] = [\n            index_of_sum(\n                agg_predicted_yta[specialty][\"agg_proba\"].values.cumsum(), cut_point\n            )\n            for cut_point in cdf_cut_points\n        ]\n\n    return predictions\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.get_specialty_probs","title":"<code>get_specialty_probs(specialties, specialty_model, snapshots_df, special_category_func=None, special_category_dict=None)</code>","text":"<p>Calculate specialty probability distributions for patient visits based on their data.</p> <p>This function applies a predictive model to each row of the input DataFrame to compute specialty probability distributions. Optionally, it can classify certain rows as belonging to a special category (like pediatric cases) based on a user-defined function, applying a fixed probability distribution for these cases.</p>"},{"location":"api/#patientflow.predict.emergency_demand.get_specialty_probs--parameters","title":"Parameters","text":"str <p>List of specialty names for which predictions are required.</p> <p>specialty_model : object     Trained model for making specialty predictions. snapshots_df : pandas.DataFrame     DataFrame containing the data on which predictions are to be made. Must include     a 'consultation_sequence' column if no special_category_func is applied. special_category_func : callable, optional     A function that takes a DataFrame row (Series) as input and returns True if the row     belongs to a special category that requires a fixed probability distribution.     If not provided, no special categorization is applied. special_category_dict : dict, optional     A dictionary containing the fixed probability distribution for special category cases.     This dictionary is applied to rows identified by <code>special_category_func</code>. If     <code>special_category_func</code> is provided, this parameter must also be provided.</p>"},{"location":"api/#patientflow.predict.emergency_demand.get_specialty_probs--returns","title":"Returns","text":"<p>pandas.Series     A Series containing dictionaries as values. Each dictionary represents the probability     distribution of specialties for each patient visit.</p>"},{"location":"api/#patientflow.predict.emergency_demand.get_specialty_probs--raises","title":"Raises","text":"<p>ValueError     If <code>special_category_func</code> is provided but <code>special_category_dict</code> is None.</p>"},{"location":"api/#patientflow.predict.emergency_demand.get_specialty_probs--examples","title":"Examples","text":"<p>snapshots_df = pd.DataFrame({ ...     'consultation_sequence': [[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]], ...     'age': [5, 40, 70] ... }) def pediatric_case(row): ...     return row['age'] &lt; 18 special_dist = {'pediatrics': 0.9, 'general': 0.1} get_specialty_probs('model.pkl', snapshots_df, pediatric_case, special_dist) 0    {'pediatrics': 0.9, 'general': 0.1} 1    {'cardiology': 0.7, 'general': 0.3} 2    {'neurology': 0.8, 'general': 0.2} dtype: object</p> Source code in <code>src/patientflow/predict/emergency_demand.py</code> <pre><code>def get_specialty_probs(\n    specialties,\n    specialty_model,\n    snapshots_df,\n    special_category_func=None,\n    special_category_dict=None,\n):\n    \"\"\"\n    Calculate specialty probability distributions for patient visits based on their data.\n\n    This function applies a predictive model to each row of the input DataFrame to compute\n    specialty probability distributions. Optionally, it can classify certain rows as\n    belonging to a special category (like pediatric cases) based on a user-defined function,\n    applying a fixed probability distribution for these cases.\n\n    Parameters\n    ----------\n\n    specialties : str\n        List of specialty names for which predictions are required.\n    specialty_model : object\n        Trained model for making specialty predictions.\n    snapshots_df : pandas.DataFrame\n        DataFrame containing the data on which predictions are to be made. Must include\n        a 'consultation_sequence' column if no special_category_func is applied.\n    special_category_func : callable, optional\n        A function that takes a DataFrame row (Series) as input and returns True if the row\n        belongs to a special category that requires a fixed probability distribution.\n        If not provided, no special categorization is applied.\n    special_category_dict : dict, optional\n        A dictionary containing the fixed probability distribution for special category cases.\n        This dictionary is applied to rows identified by `special_category_func`. If\n        `special_category_func` is provided, this parameter must also be provided.\n\n    Returns\n    -------\n    pandas.Series\n        A Series containing dictionaries as values. Each dictionary represents the probability\n        distribution of specialties for each patient visit.\n\n    Raises\n    ------\n    ValueError\n        If `special_category_func` is provided but `special_category_dict` is None.\n\n    Examples\n    --------\n    &gt;&gt;&gt; snapshots_df = pd.DataFrame({\n    ...     'consultation_sequence': [[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]],\n    ...     'age': [5, 40, 70]\n    ... })\n    &gt;&gt;&gt; def pediatric_case(row):\n    ...     return row['age'] &lt; 18\n    &gt;&gt;&gt; special_dist = {'pediatrics': 0.9, 'general': 0.1}\n    &gt;&gt;&gt; get_specialty_probs('model.pkl', snapshots_df, pediatric_case, special_dist)\n    0    {'pediatrics': 0.9, 'general': 0.1}\n    1    {'cardiology': 0.7, 'general': 0.3}\n    2    {'neurology': 0.8, 'general': 0.2}\n    dtype: object\n    \"\"\"\n\n    # Convert consultation_sequence to tuple if not already a tuple\n    if len(snapshots_df[\"consultation_sequence\"]) &gt; 0 and not isinstance(\n        snapshots_df[\"consultation_sequence\"].iloc[0], tuple\n    ):\n        snapshots_df.loc[:, \"consultation_sequence\"] = snapshots_df[\n            \"consultation_sequence\"\n        ].apply(lambda x: tuple(x) if x else ())\n\n    if special_category_func and not special_category_dict:\n        raise ValueError(\n            \"special_category_dict must be provided if special_category_func is specified.\"\n        )\n\n    # Function to determine the specialty probabilities\n    def determine_specialty(row):\n        if special_category_func and special_category_func(row):\n            return special_category_dict\n        else:\n            return specialty_model.predict(row[\"consultation_sequence\"])\n\n    # Apply the determine_specialty function to each row\n    specialty_prob_series = snapshots_df.apply(determine_specialty, axis=1)\n\n    # Find all unique keys used in any dictionary within the series\n    all_keys = set().union(\n        *(d.keys() for d in specialty_prob_series if isinstance(d, dict))\n    )\n\n    # Combine all_keys with the specialties requested\n    all_keys = set(all_keys).union(set(specialties))\n\n    # Ensure each dictionary contains all keys found, with default values of 0 for missing keys\n    specialty_prob_series = specialty_prob_series.apply(\n        lambda d: (\n            {key: d.get(key, 0) for key in all_keys} if isinstance(d, dict) else d\n        )\n    )\n\n    return specialty_prob_series\n</code></pre>"},{"location":"api/#patientflow.predict.emergency_demand.index_of_sum","title":"<code>index_of_sum(sequence, max_sum)</code>","text":"<p>Returns the index where the cumulative sum of a sequence of probabilities exceeds max_sum.</p> Source code in <code>src/patientflow/predict/emergency_demand.py</code> <pre><code>def index_of_sum(sequence: List[float], max_sum: float) -&gt; int:\n    \"\"\"Returns the index where the cumulative sum of a sequence of probabilities exceeds max_sum.\"\"\"\n    cumulative_sum = 0.0\n    for i, value in enumerate(sequence):\n        cumulative_sum += value\n        if cumulative_sum &gt;= 1 - max_sum:\n            return i\n    return len(sequence) - 1  # Return the last index if the sum doesn't exceed max_sum\n</code></pre>"},{"location":"api/#patientflow.predictors","title":"<code>predictors</code>","text":""},{"location":"api/#patientflow.predictors.sequence_predictor","title":"<code>sequence_predictor</code>","text":"<p>This module implements a <code>SequencePredictor</code> class that models and predicts the probability distribution of sequences in categorical data. The class builds a model based on training data, where input sequences are mapped to specific outcome categories. It provides methods to fit the model, compute sequence-based probabilities, and make predictions on an unseen datatset of input sequences.</p>"},{"location":"api/#patientflow.predictors.sequence_predictor--classes","title":"Classes","text":"<p>SequencePredictor : sklearn.base.BaseEstimator, sklearn.base.TransformerMixin     A model that predicts the probability of ending in different outcome categories based on input sequences.</p>"},{"location":"api/#patientflow.predictors.sequence_predictor.SequencePredictor","title":"<code>SequencePredictor</code>","text":"<p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>A class to model sequence-based predictions for categorical data using input and grouping sequences. This class implements both the <code>fit</code> and <code>predict</code> methods from the parent sklearn classes.</p>"},{"location":"api/#patientflow.predictors.sequence_predictor.SequencePredictor--parameters","title":"Parameters","text":"<p>input_var : str     Name of the column representing the input sequence in the DataFrame. grouping_var : str     Name of the column representing the grouping sequence in the DataFrame. outcome_var : str     Name of the column representing the outcome category in the DataFrame. apply_special_category_filtering : bool, default=True     Whether to filter out special categories of patients before fitting the model. admit_col : str, default='is_admitted'     Name of the column indicating whether a patient was admitted.</p>"},{"location":"api/#patientflow.predictors.sequence_predictor.SequencePredictor--attributes","title":"Attributes","text":"<p>weights : dict     A dictionary storing the probabilities of different input sequences leading to specific outcome categories. input_to_grouping_probs : pd.DataFrame     A DataFrame that stores the computed probabilities of input sequences being associated with different grouping sequences. special_params : dict, optional     The special category parameters used for filtering, only populated if apply_special_category_filtering=True. metrics : dict     A dictionary to store metrics related to the training process.</p> Source code in <code>src/patientflow/predictors/sequence_predictor.py</code> <pre><code>class SequencePredictor(BaseEstimator, TransformerMixin):\n    \"\"\"\n    A class to model sequence-based predictions for categorical data using input and grouping sequences.\n    This class implements both the `fit` and `predict` methods from the parent sklearn classes.\n\n    Parameters\n    ----------\n    input_var : str\n        Name of the column representing the input sequence in the DataFrame.\n    grouping_var : str\n        Name of the column representing the grouping sequence in the DataFrame.\n    outcome_var : str\n        Name of the column representing the outcome category in the DataFrame.\n    apply_special_category_filtering : bool, default=True\n        Whether to filter out special categories of patients before fitting the model.\n    admit_col : str, default='is_admitted'\n        Name of the column indicating whether a patient was admitted.\n\n    Attributes\n    ----------\n    weights : dict\n        A dictionary storing the probabilities of different input sequences leading to specific outcome categories.\n    input_to_grouping_probs : pd.DataFrame\n        A DataFrame that stores the computed probabilities of input sequences being associated with different grouping sequences.\n    special_params : dict, optional\n        The special category parameters used for filtering, only populated if apply_special_category_filtering=True.\n    metrics : dict\n        A dictionary to store metrics related to the training process.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_var,\n        grouping_var,\n        outcome_var,\n        apply_special_category_filtering=True,\n        admit_col=\"is_admitted\",\n    ):\n        self.input_var = input_var\n        self.grouping_var = grouping_var\n        self.outcome_var = outcome_var\n        self.apply_special_category_filtering = apply_special_category_filtering\n        self.admit_col = admit_col\n        self.weights = None\n        self.special_params = None\n        self.metrics = {}\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the estimator.\"\"\"\n        class_name = self.__class__.__name__\n        return (\n            f\"{class_name}(\\n\"\n            f\"    input_var='{self.input_var}',\\n\"\n            f\"    grouping_var='{self.grouping_var}',\\n\"\n            f\"    outcome_var='{self.outcome_var}',\\n\"\n            f\"    apply_special_category_filtering={self.apply_special_category_filtering},\\n\"\n            f\"    admit_col='{self.admit_col}'\\n\"\n            f\")\"\n        )\n\n    def _preprocess_data(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Preprocesses the input data before fitting the model.\n\n        Steps include:\n        1. Selecting only admitted patients with a non-null specialty\n        2. Optionally filtering out special categories\n        3. Converting sequence columns to tuple format if they aren't already\n\n        Parameters\n        ----------\n        X : pd.DataFrame\n            DataFrame containing patient data.\n\n        Returns\n        -------\n        pd.DataFrame\n            Preprocessed DataFrame ready for model fitting.\n        \"\"\"\n        # Make a copy to avoid modifying the original\n        df = X.copy()\n\n        # Step 1: Select only admitted patients with a non-null specialty\n        if self.admit_col in df.columns:\n            df = df[df[self.admit_col] &amp; ~df[self.outcome_var].isnull()]\n\n        # Step 2: Optionally apply filtering for special categories\n        if self.apply_special_category_filtering:\n            # Get configuration for categorizing patients based on columns\n            self.special_params = create_special_category_objects(df.columns)\n\n            # Extract function that identifies non-special category patients\n            opposite_special_category_func = self.special_params[\"special_func_map\"][\n                \"default\"\n            ]\n\n            # Determine which category is the special category\n            special_category_key = next(\n                key\n                for key, value in self.special_params[\"special_category_dict\"].items()\n                if value == 1.0\n            )\n\n            # Filter out special category patients\n            df = df[\n                df.apply(opposite_special_category_func, axis=1)\n                &amp; (df[self.outcome_var] != special_category_key)\n            ]\n\n        # Step 3: Convert sequence columns to tuple format if not already tuples\n        # Process input variable\n        if self.input_var in df.columns:\n            df[self.input_var] = df[self.input_var].apply(\n                lambda x: tuple(x)\n                if (x is not None and not isinstance(x, tuple))\n                else ()\n                if x is None\n                else x\n            )\n\n        # Process grouping variable\n        if self.grouping_var in df.columns:\n            df[self.grouping_var] = df[self.grouping_var].apply(\n                lambda x: tuple(x)\n                if (x is not None and not isinstance(x, tuple))\n                else ()\n                if x is None\n                else x\n            )\n\n        return df\n\n    def fit(self, X: pd.DataFrame) -&gt; \"SequencePredictor\":\n        \"\"\"\n        Fits the predictor based on training data by computing the proportion of each input variable sequence\n        ending in specific outcome variable categories.\n\n        Automatically preprocesses the data before fitting.\n\n        Parameters\n        ----------\n        X : pd.DataFrame\n            A pandas DataFrame containing at least the columns specified by `input_var`, `grouping_var`, and `outcome_var`.\n\n        Returns\n        -------\n        self : SequencePredictor\n            The fitted SequencePredictor model with calculated probabilities for each sequence.\n        \"\"\"\n        # Store metrics about the training data\n        self.metrics[\"train_dttm\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n        self.metrics[\"train_set_no\"] = len(X)\n        if not X.empty:\n            self.metrics[\"start_date\"] = X[\"snapshot_date\"].min()\n            self.metrics[\"end_date\"] = X[\"snapshot_date\"].max()\n\n        # Preprocess the data\n        X = self._preprocess_data(X)\n\n        # derive the names of the observed outcome variables from the data\n        prop_keys = X[self.outcome_var].unique()\n\n        # For each sequence count the number of observed categories\n        X_grouped = (\n            X.groupby(self.grouping_var)[self.outcome_var]\n            .value_counts()\n            .unstack(fill_value=0)\n        )\n\n        # Handle null sequences by assigning them to a specific key\n        null_counts = (\n            X[X[self.grouping_var].isnull()][self.outcome_var]\n            .value_counts()\n            .to_frame()\n            .T\n        )\n        null_counts.index = [tuple()]\n\n        # Concatenate null sequence handling\n        X_grouped = pd.concat([X_grouped, null_counts])\n\n        # Calculate the total number of times each grouping sequence occurred\n        row_totals = X_grouped.sum(axis=1)\n\n        # Calculate for each grouping sequence, the proportion of ending with each observed specialty\n        proportions = X_grouped.div(row_totals, axis=0)\n\n        # Calculate the probability of each grouping sequence occurring in the original data\n        proportions[\"probability_of_grouping_sequence\"] = row_totals / row_totals.sum()\n\n        # Reweight probabilities of ending with each observed specialty\n        # by the likelihood of each grouping sequence occurring\n        for col in proportions.columns[\n            :-1\n        ]:  # Avoid the last column which is the 'probability_of_grouping_sequence'\n            proportions[col] *= proportions[\"probability_of_grouping_sequence\"]\n\n        # Convert final sequence to a string in order to conduct string searches on it\n        proportions[\"grouping_sequence_to_string\"] = (\n            proportions.reset_index()[\"index\"]\n            .apply(lambda x: \"-\".join(map(str, x)))\n            .values\n        )\n        # Row-wise function to return, for each input sequence,\n        # the proportion that end up in each final sequence and thereby\n        # the probability of it ending in any observed category\n        proportions[\"prob_input_var_ends_in_observed_specialty\"] = proportions[\n            \"grouping_sequence_to_string\"\n        ].apply(lambda x: self._string_match_input_var(x, proportions, prop_keys))\n\n        # Convert the prob_input_var_ends_in_observed_specialty column to a dictionary\n        result_dict = proportions[\"prob_input_var_ends_in_observed_specialty\"].to_dict()\n\n        # Clean the key to remove excess strint quotes\n        def clean_tuple_key(key):\n            if isinstance(key, tuple):\n                return tuple(\n                    ast.literal_eval(item)\n                    if item.startswith(\"'\") and item.endswith(\"'\")\n                    else item\n                    for item in key\n                )\n            return key\n\n        cleaned_dict = {clean_tuple_key(k): v for k, v in result_dict.items()}\n\n        # save prob_input_var_ends_in_observed_specialty as weights within the model\n        self.weights = cleaned_dict\n\n        # save the input to grouping probabilities for use as a reference\n        self.input_to_grouping_probs = self._probability_of_input_to_grouping_sequence(\n            X\n        )\n\n        return self\n\n    def _string_match_input_var(self, input_var_string, proportions, prop_keys):\n        \"\"\"\n        Matches a given input sequence string with grouped sequences (expressed as strings) in the dataset and aggregates\n        their probabilities for each outcome category. This function filters the data to\n        match only those rows where the *beginning* of the grouped sequence string\n        matches the given input sequence string, allowing for partial matches.\n        For instance, the sequence 'medical' will match 'medical, elderly' and 'medical, surgical'\n        as well as 'medical' on its own. It computes the total probabilities of any input sequence ending\n        in each outcome category, and normalizes these totals if possible.\n\n        Parameters\n        ----------\n        input_var_string : str\n            The sequence of inputs represented as a string, used to match against sequences in the proportions DataFrame.\n        proportions : pd.DataFrame\n            DataFrame containing proportions data with an additional column 'grouping_sequence_to_string'\n            which includes string representations of sequences.\n        prop_keys : np.array\n            Array of unique outcomes to consider in calculations.\n\n        Returns\n        -------\n        dict\n            A dictionary where keys are outcome names and values are the aggregated and normalized probabilities\n            of an input sequence ending in those outcomes.\n\n        \"\"\"\n        # Filter rows where the grouped sequence string starts with the input sequence string\n        props = proportions[\n            proportions[\"grouping_sequence_to_string\"].str.match(\"^\" + input_var_string)\n        ][prop_keys].sum()\n\n        # Sum of all probabilities to normalize them\n        props_total = props.sum()\n\n        # Handle cases where the total probability is zero to avoid division by zero\n        if props_total &gt; 0:\n            normalized_props = props / props_total\n        else:\n            normalized_props = (\n                props * 0\n            )  # Returns zero probabilities if no matches found\n\n        return dict(zip(prop_keys, normalized_props))\n\n    def _probability_of_input_to_grouping_sequence(self, X):\n        \"\"\"\n        Computes the probabilities of different input sequences leading to specific grouping sequences.\n\n        Parameters\n        ----------\n        X : pd.DataFrame\n            A pandas DataFrame containing at least the columns specified by `input_var` and `grouping_var`.\n\n        Returns\n        -------\n        pd.DataFrame\n            A DataFrame containing the probabilities of input sequences leading to grouping sequences.\n        \"\"\"\n        # For each input sequence count the number of grouping sequences\n        X_grouped = (\n            X.groupby(self.input_var)[self.grouping_var]\n            .value_counts()\n            .unstack(fill_value=0)\n        )\n\n        # # Calculate the total number of times each input sequence occurred\n        row_totals = X_grouped.sum(axis=1)\n\n        # # Calculate for each grouping sequence, the proportion of ending with each grouping sequence\n        proportions = X_grouped.div(row_totals, axis=0)\n\n        # # Calculate the probability of each input sequence occurring in the original data\n        proportions[\"probability_of_grouping_sequence\"] = row_totals / row_totals.sum()\n\n        return proportions\n\n    def predict(self, input_sequence: tuple[str, ...]) -&gt; Dict[str, float]:\n        \"\"\"\n        Predicts the probabilities of ending in various outcome categories for a given input sequence.\n\n        Parameters\n        ----------\n        input_sequence : tuple[str, ...]\n            A tuple containing the categories that have been observed for an entity in the order they\n            have been encountered. An empty tuple represents an entity with no observed categories.\n\n        Returns\n        -------\n        dict\n            A dictionary of categories and the probabilities that the input sequence will end in them.\n        \"\"\"\n        # Check for no tuple\n        if input_sequence is None or pd.isna(input_sequence):\n            return self.weights.get(tuple(), {})\n\n        # Return a direct lookup of probabilities if possible.\n        if input_sequence in self.weights:\n            return self.weights[input_sequence]\n\n        # Otherwise, if the sequence has multiple elements, work back looking for a match\n        while len(input_sequence) &gt; 1:\n            input_sequence_list = list(input_sequence)\n            input_sequence = tuple(input_sequence_list[:-1])  # remove last element\n\n            if input_sequence in self.weights:\n                return self.weights[input_sequence]\n\n        # If no relevant data is found:\n        return self.weights.get(tuple(), {})\n</code></pre>"},{"location":"api/#patientflow.predictors.sequence_predictor.SequencePredictor.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the estimator.</p> Source code in <code>src/patientflow/predictors/sequence_predictor.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a string representation of the estimator.\"\"\"\n    class_name = self.__class__.__name__\n    return (\n        f\"{class_name}(\\n\"\n        f\"    input_var='{self.input_var}',\\n\"\n        f\"    grouping_var='{self.grouping_var}',\\n\"\n        f\"    outcome_var='{self.outcome_var}',\\n\"\n        f\"    apply_special_category_filtering={self.apply_special_category_filtering},\\n\"\n        f\"    admit_col='{self.admit_col}'\\n\"\n        f\")\"\n    )\n</code></pre>"},{"location":"api/#patientflow.predictors.sequence_predictor.SequencePredictor.fit","title":"<code>fit(X)</code>","text":"<p>Fits the predictor based on training data by computing the proportion of each input variable sequence ending in specific outcome variable categories.</p> <p>Automatically preprocesses the data before fitting.</p>"},{"location":"api/#patientflow.predictors.sequence_predictor.SequencePredictor.fit--parameters","title":"Parameters","text":"<p>X : pd.DataFrame     A pandas DataFrame containing at least the columns specified by <code>input_var</code>, <code>grouping_var</code>, and <code>outcome_var</code>.</p>"},{"location":"api/#patientflow.predictors.sequence_predictor.SequencePredictor.fit--returns","title":"Returns","text":"<p>self : SequencePredictor     The fitted SequencePredictor model with calculated probabilities for each sequence.</p> Source code in <code>src/patientflow/predictors/sequence_predictor.py</code> <pre><code>def fit(self, X: pd.DataFrame) -&gt; \"SequencePredictor\":\n    \"\"\"\n    Fits the predictor based on training data by computing the proportion of each input variable sequence\n    ending in specific outcome variable categories.\n\n    Automatically preprocesses the data before fitting.\n\n    Parameters\n    ----------\n    X : pd.DataFrame\n        A pandas DataFrame containing at least the columns specified by `input_var`, `grouping_var`, and `outcome_var`.\n\n    Returns\n    -------\n    self : SequencePredictor\n        The fitted SequencePredictor model with calculated probabilities for each sequence.\n    \"\"\"\n    # Store metrics about the training data\n    self.metrics[\"train_dttm\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n    self.metrics[\"train_set_no\"] = len(X)\n    if not X.empty:\n        self.metrics[\"start_date\"] = X[\"snapshot_date\"].min()\n        self.metrics[\"end_date\"] = X[\"snapshot_date\"].max()\n\n    # Preprocess the data\n    X = self._preprocess_data(X)\n\n    # derive the names of the observed outcome variables from the data\n    prop_keys = X[self.outcome_var].unique()\n\n    # For each sequence count the number of observed categories\n    X_grouped = (\n        X.groupby(self.grouping_var)[self.outcome_var]\n        .value_counts()\n        .unstack(fill_value=0)\n    )\n\n    # Handle null sequences by assigning them to a specific key\n    null_counts = (\n        X[X[self.grouping_var].isnull()][self.outcome_var]\n        .value_counts()\n        .to_frame()\n        .T\n    )\n    null_counts.index = [tuple()]\n\n    # Concatenate null sequence handling\n    X_grouped = pd.concat([X_grouped, null_counts])\n\n    # Calculate the total number of times each grouping sequence occurred\n    row_totals = X_grouped.sum(axis=1)\n\n    # Calculate for each grouping sequence, the proportion of ending with each observed specialty\n    proportions = X_grouped.div(row_totals, axis=0)\n\n    # Calculate the probability of each grouping sequence occurring in the original data\n    proportions[\"probability_of_grouping_sequence\"] = row_totals / row_totals.sum()\n\n    # Reweight probabilities of ending with each observed specialty\n    # by the likelihood of each grouping sequence occurring\n    for col in proportions.columns[\n        :-1\n    ]:  # Avoid the last column which is the 'probability_of_grouping_sequence'\n        proportions[col] *= proportions[\"probability_of_grouping_sequence\"]\n\n    # Convert final sequence to a string in order to conduct string searches on it\n    proportions[\"grouping_sequence_to_string\"] = (\n        proportions.reset_index()[\"index\"]\n        .apply(lambda x: \"-\".join(map(str, x)))\n        .values\n    )\n    # Row-wise function to return, for each input sequence,\n    # the proportion that end up in each final sequence and thereby\n    # the probability of it ending in any observed category\n    proportions[\"prob_input_var_ends_in_observed_specialty\"] = proportions[\n        \"grouping_sequence_to_string\"\n    ].apply(lambda x: self._string_match_input_var(x, proportions, prop_keys))\n\n    # Convert the prob_input_var_ends_in_observed_specialty column to a dictionary\n    result_dict = proportions[\"prob_input_var_ends_in_observed_specialty\"].to_dict()\n\n    # Clean the key to remove excess strint quotes\n    def clean_tuple_key(key):\n        if isinstance(key, tuple):\n            return tuple(\n                ast.literal_eval(item)\n                if item.startswith(\"'\") and item.endswith(\"'\")\n                else item\n                for item in key\n            )\n        return key\n\n    cleaned_dict = {clean_tuple_key(k): v for k, v in result_dict.items()}\n\n    # save prob_input_var_ends_in_observed_specialty as weights within the model\n    self.weights = cleaned_dict\n\n    # save the input to grouping probabilities for use as a reference\n    self.input_to_grouping_probs = self._probability_of_input_to_grouping_sequence(\n        X\n    )\n\n    return self\n</code></pre>"},{"location":"api/#patientflow.predictors.sequence_predictor.SequencePredictor.predict","title":"<code>predict(input_sequence)</code>","text":"<p>Predicts the probabilities of ending in various outcome categories for a given input sequence.</p>"},{"location":"api/#patientflow.predictors.sequence_predictor.SequencePredictor.predict--parameters","title":"Parameters","text":"<p>input_sequence : tuple[str, ...]     A tuple containing the categories that have been observed for an entity in the order they     have been encountered. An empty tuple represents an entity with no observed categories.</p>"},{"location":"api/#patientflow.predictors.sequence_predictor.SequencePredictor.predict--returns","title":"Returns","text":"<p>dict     A dictionary of categories and the probabilities that the input sequence will end in them.</p> Source code in <code>src/patientflow/predictors/sequence_predictor.py</code> <pre><code>def predict(self, input_sequence: tuple[str, ...]) -&gt; Dict[str, float]:\n    \"\"\"\n    Predicts the probabilities of ending in various outcome categories for a given input sequence.\n\n    Parameters\n    ----------\n    input_sequence : tuple[str, ...]\n        A tuple containing the categories that have been observed for an entity in the order they\n        have been encountered. An empty tuple represents an entity with no observed categories.\n\n    Returns\n    -------\n    dict\n        A dictionary of categories and the probabilities that the input sequence will end in them.\n    \"\"\"\n    # Check for no tuple\n    if input_sequence is None or pd.isna(input_sequence):\n        return self.weights.get(tuple(), {})\n\n    # Return a direct lookup of probabilities if possible.\n    if input_sequence in self.weights:\n        return self.weights[input_sequence]\n\n    # Otherwise, if the sequence has multiple elements, work back looking for a match\n    while len(input_sequence) &gt; 1:\n        input_sequence_list = list(input_sequence)\n        input_sequence = tuple(input_sequence_list[:-1])  # remove last element\n\n        if input_sequence in self.weights:\n            return self.weights[input_sequence]\n\n    # If no relevant data is found:\n    return self.weights.get(tuple(), {})\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor","title":"<code>weighted_poisson_predictor</code>","text":"<p>Weighted Poisson Predictor</p> <p>This module implements a custom predictor to estimate the number of hospital admissions within a specified prediction window using historical admission data. It applies Poisson and binomial distributions to forecast future admissions, excluding already arrived patients. The predictor accommodates different data filters for tailored predictions across various hospital settings.</p> Dependencies <ul> <li>pandas: For data manipulation and analysis, essential for handling the dataset used in predictions.</li> <li>datetime: For manipulating date and time objects, crucial for time-based predictions.</li> <li>sklearn: Utilizes BaseEstimator and TransformerMixin from scikit-learn for creating custom, interoperable predictors.</li> <li>Custom modules:<ul> <li>calculate.time_varying_arrival_rates: Computes time-varying arrival rates, for each specified interval within the prediction window.</li> <li>predict.admission_in_prediction_window: Calculates the probability of admission within a specified prediction window.</li> </ul> </li> </ul> <p>Classes:</p> Name Description <code>WeightedPoissonPredictor</code> <p>Predicts the number of admissions within a given prediction window based on historical data and Poisson-binomial distribution.</p> <code>Methods within WeightedPoissonPredictor</code> <ul> <li>init(self, filters=None): Initializes the predictor with optional data filters.</li> <li>filter_dataframe(self, df, filters): Applies filters to the dataset for targeted predictions.</li> <li>fit(self, train_df, prediction_window, yta_time_interval, prediction_times, json_file_path, reference_year, y=None): Trains the predictor using historical data and various parameters.</li> <li>predict(self, prediction_context): Predicts the number of admissions using the trained model.</li> </ul>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.WeightedPoissonPredictor","title":"<code>WeightedPoissonPredictor</code>","text":"<p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>A class to predict an aspirational number of admissions within a specified prediction window. This prediction does not include patients who have already arrived and is based on historical data. The prediction uses a combination of Poisson and binomial distributions.</p> <p>Attributes:</p> Name Type Description <code>filters</code> <code>dict</code> <p>Optional filters for data categorization</p> <code>verbose</code> <code>bool</code> <p>Whether to enable verbose logging</p> <code>metrics</code> <code>dict</code> <p>Stores metadata about the model and training data</p> <p>Methods     init(self, filters=None): Initializes the predictor with optional filters for data categorization.     filter_dataframe(self, df, filters): Filters the dataset based on specified criteria for targeted predictions.     fit(self, train_df, prediction_window, yta_time_interval, prediction_times, y=None): Trains the model using historical data and prediction parameters.     predict(self, prediction_context): Predicts the number of admissions for a given context after the model is trained.     get_weights(self): Retrieves the model parameters computed during fitting.</p> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>class WeightedPoissonPredictor(BaseEstimator, TransformerMixin):\n    \"\"\"\n    A class to predict an aspirational number of admissions within a specified prediction window.\n    This prediction does not include patients who have already arrived and is based on historical data.\n    The prediction uses a combination of Poisson and binomial distributions.\n\n    Attributes:\n        filters (dict): Optional filters for data categorization\n        verbose (bool): Whether to enable verbose logging\n        metrics (dict): Stores metadata about the model and training data\n\n    Methods\n        __init__(self, filters=None): Initializes the predictor with optional filters for data categorization.\n        filter_dataframe(self, df, filters): Filters the dataset based on specified criteria for targeted predictions.\n        fit(self, train_df, prediction_window, yta_time_interval, prediction_times, y=None): Trains the model using historical data and prediction parameters.\n        predict(self, prediction_context): Predicts the number of admissions for a given context after the model is trained.\n        get_weights(self): Retrieves the model parameters computed during fitting.\n\n    \"\"\"\n\n    def __init__(self, filters=None, verbose=False):\n        \"\"\"\n        Initialize the WeightedPoissonPredictor with optional filters.\n\n        Args:\n            filters (dict, optional): A dictionary defining filters for different categories or specialties.\n                                    If None or empty, no filtering will be applied.\n            verbose (bool, optional): If True, enable info-level logging. Defaults to False.\n        \"\"\"\n        self.filters = filters if filters else {}\n        self.verbose = verbose\n        self.metrics = {}  # Add metrics dictionary to store metadata\n\n        if verbose:\n            # Configure logging for Jupyter notebook compatibility\n            import logging\n            import sys\n\n            # Create logger\n            self.logger = logging.getLogger(f\"{__name__}.WeightedPoissonPredictor\")\n\n            # Only set up handlers if they don't exist\n            if not self.logger.handlers:\n                self.logger.setLevel(logging.INFO if verbose else logging.WARNING)\n\n                # Create handler that writes to sys.stdout\n                handler = logging.StreamHandler(sys.stdout)\n                handler.setLevel(logging.INFO if verbose else logging.WARNING)\n\n                # Create a formatting configuration\n                formatter = logging.Formatter(\"%(message)s\")\n                handler.setFormatter(formatter)\n\n                # Add the handler to the logger\n                self.logger.addHandler(handler)\n\n                # Prevent propagation to root logger\n                self.logger.propagate = False\n\n        # Apply filters\n        self.filters = filters if filters else {}\n\n    def filter_dataframe(self, df: pd.DataFrame, filters: Dict) -&gt; pd.DataFrame:\n        \"\"\"\n        Apply a set of filters to a dataframe.\n\n        Args:\n            df (pandas.DataFrame): The DataFrame to filter.\n            filters (dict): A dictionary where keys are column names and values are the criteria or function to filter by.\n\n        Returns:\n            pandas.DataFrame: A filtered DataFrame.\n\n        \"\"\"\n        filtered_df = df\n        for column, criteria in filters.items():\n            if callable(criteria):  # If the criteria is a function, apply it directly\n                filtered_df = filtered_df[filtered_df[column].apply(criteria)]\n            else:  # Otherwise, assume the criteria is a value or list of values for equality check\n                filtered_df = filtered_df[filtered_df[column] == criteria]\n        return filtered_df\n\n    def _calculate_parameters(\n        self, df, prediction_window, yta_time_interval, prediction_times, num_days\n    ):\n        \"\"\"\n        Calculate parameters required for the model.\n\n        Args:\n            df (pandas.DataFrame): The data frame to process.\n            prediction_window (int): The total prediction window for prediction.\n            yta_time_interval (int): The interval for splitting the prediction window.\n            prediction_times (list): Times of day at which predictions are made.\n            num_days (int): Number of days over which to calculate time-varying arrival rates\n\n        Returns:\n            dict: Calculated lambda_t parameters organized by time of day.\n\n        \"\"\"\n        Ntimes = int(prediction_window / yta_time_interval)\n        arrival_rates_dict = time_varying_arrival_rates(\n            df, yta_time_interval, num_days, verbose=self.verbose\n        )\n        prediction_time_dict = {}\n\n        for prediction_time_ in prediction_times:\n            prediction_time_hr, prediction_time_min = (\n                (prediction_time_, 0)\n                if isinstance(prediction_time_, int)\n                else prediction_time_\n            )\n            lambda_t = [\n                arrival_rates_dict[\n                    (\n                        datetime(1970, 1, 1, prediction_time_hr, prediction_time_min)\n                        + i * timedelta(minutes=yta_time_interval)\n                    ).time()\n                ]\n                for i in range(Ntimes)\n            ]\n            prediction_time_dict[(prediction_time_hr, prediction_time_min)] = {\n                \"lambda_t\": lambda_t\n            }\n\n        return prediction_time_dict\n\n    def fit(\n        self,\n        train_df: pd.DataFrame,\n        prediction_window: int,\n        yta_time_interval: int,\n        prediction_times: List[float],\n        num_days: int,\n        epsilon: float = 10**-7,\n        y: Optional[None] = None,\n    ) -&gt; \"WeightedPoissonPredictor\":\n        \"\"\"\n        Fits the model to the training data, computing necessary parameters for future predictions.\n\n        Args:\n            train_df (pandas.DataFrame):\n                The training dataset with historical admission data.\n            prediction_window (int):\n                The prediction prediction window in minutes.\n            yta_time_interval (int):\n                The interval in minutes for splitting the prediction window.\n            prediction_times (list):\n                Times of day at which predictions are made, in hours.\n            num_days (int):\n                 The number of days that the train_df spans\n            epsilon (float, optional):\n                A small value representing acceptable error rate to enable calculation of the maximum value of the random variable representing number of beds.\n            y (None, optional):\n                Ignored, present for compatibility with scikit-learn's fit method.\n\n        Returns:\n            WeightedPoissonPredictor: The instance itself, fitted with the training data.\n\n        \"\"\"\n        # Add error checking at the start of fit\n        if int(prediction_window / yta_time_interval) == 0:\n            raise ValueError(\n                f\"prediction_window ({prediction_window}) divided by yta_time_interval ({yta_time_interval}) must be greater than 1 to generate meaningful predictions\"\n            )\n\n        # Store prediction_window, yta_time_interval, and any other parameters as instance variables\n        self.prediction_window = prediction_window\n        self.yta_time_interval = yta_time_interval\n        self.epsilon = epsilon\n        self.prediction_times = [\n            tuple(x)\n            if isinstance(x, (list, np.ndarray))\n            else (x, 0)\n            if isinstance(x, (int, float))\n            else x\n            for x in prediction_times\n        ]\n\n        # Initialize yet_to_arrive_dict\n        self.weights = {}\n\n        # If there are filters specified, calculate and store the parameters directly with the respective spec keys\n        if self.filters:\n            for spec, filters in self.filters.items():\n                self.weights[spec] = self._calculate_parameters(\n                    self.filter_dataframe(train_df, filters),\n                    prediction_window,\n                    yta_time_interval,\n                    prediction_times,\n                    num_days,\n                )\n        else:\n            # If there are no filters, store the parameters with a generic key, like 'default' or 'unfiltered'\n            self.weights[\"default\"] = self._calculate_parameters(\n                train_df,\n                prediction_window,\n                yta_time_interval,\n                prediction_times,\n                num_days,\n            )\n\n        if self.verbose:\n            self.logger.info(\n                f\"Poisson Binomial Predictor trained for these times: {prediction_times}\"\n            )\n            self.logger.info(\n                f\"using prediction window of {prediction_window} minutes after the time of prediction\"\n            )\n            self.logger.info(\n                f\"and time interval of {yta_time_interval} minutes within the prediction window.\"\n            )\n            self.logger.info(f\"The error value for prediction will be {epsilon}\")\n            self.logger.info(\n                \"To see the weights saved by this model, used the get_weights() method\"\n            )\n\n        # Store metrics about the training data\n        self.metrics[\"train_dttm\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n        self.metrics[\"train_set_no\"] = len(train_df)\n        self.metrics[\"start_date\"] = train_df.index.min().date()\n        self.metrics[\"end_date\"] = train_df.index.max().date()\n        self.metrics[\"num_days\"] = num_days\n\n        return self\n\n    def get_weights(self):\n        \"\"\"\n        Returns the weights computed by the fit method.\n\n        Returns\n            dict: The weights.\n\n        \"\"\"\n        return self.weights\n\n    def predict(\n        self, prediction_context: Dict, x1: float, y1: float, x2: float, y2: float\n    ) -&gt; Dict:\n        \"\"\"\n        Predicts the number of admissions for the given context based on the fitted model.\n\n        Args:\n            prediction_context (dict): A dictionary defining the context for which predictions are to be made.\n                                       It should specify either a general context or one based on the applied filters.\n            x1 : float\n                The x-coordinate of the first transition point on the aspirational curve, where the growth phase ends and the decay phase begins.\n            y1 : float\n                The y-coordinate of the first transition point (x1), representing the target proportion of patients admitted by time x1.\n            x2 : float\n                The x-coordinate of the second transition point on the curve, beyond which all but a few patients are expected to be admitted.\n            y2 : float\n                The y-coordinate of the second transition point (x2), representing the target proportion of patients admitted by time x2.\n\n        Returns:\n            dict: A dictionary with predictions for each specified context.\n\n        \"\"\"\n        predictions = {}\n\n        NTimes = int(self.prediction_window / self.yta_time_interval)\n        # Calculate theta, probability of admission in prediction window\n\n        # for each time interval, calculate time remaining before end of window\n        time_remaining_before_end_of_window = self.prediction_window / 60 - np.arange(\n            0, self.prediction_window / 60, self.yta_time_interval / 60\n        )\n\n        # probability of admission in that time\n        theta = get_y_from_aspirational_curve(\n            time_remaining_before_end_of_window, x1, y1, x2, y2\n        )\n\n        for filter_key, filter_values in prediction_context.items():\n            try:\n                if filter_key not in self.weights:\n                    raise ValueError(\n                        f\"Filter key '{filter_key}' is not recognized in the model weights.\"\n                    )\n\n                prediction_time = filter_values.get(\"prediction_time\")\n                if prediction_time is None:\n                    raise ValueError(\n                        f\"No 'prediction_time' provided for filter '{filter_key}'.\"\n                    )\n\n                if prediction_time not in self.prediction_times:\n                    prediction_time = find_nearest_previous_prediction_time(\n                        prediction_time, self.prediction_times\n                    )\n\n                lambda_t = self.weights[filter_key][prediction_time].get(\"lambda_t\")\n                if lambda_t is None:\n                    raise ValueError(\n                        f\"No 'lambda_t' found for the time of day '{prediction_time}' under filter '{filter_key}'.\"\n                    )\n\n                predictions[filter_key] = poisson_binom_generating_function(\n                    NTimes, lambda_t, theta, self.epsilon\n                )\n\n            except KeyError as e:\n                raise KeyError(f\"Key error occurred: {e!s}\")\n\n        return predictions\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.WeightedPoissonPredictor.__init__","title":"<code>__init__(filters=None, verbose=False)</code>","text":"<p>Initialize the WeightedPoissonPredictor with optional filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict</code> <p>A dictionary defining filters for different categories or specialties.                     If None or empty, no filtering will be applied.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, enable info-level logging. Defaults to False.</p> <code>False</code> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>def __init__(self, filters=None, verbose=False):\n    \"\"\"\n    Initialize the WeightedPoissonPredictor with optional filters.\n\n    Args:\n        filters (dict, optional): A dictionary defining filters for different categories or specialties.\n                                If None or empty, no filtering will be applied.\n        verbose (bool, optional): If True, enable info-level logging. Defaults to False.\n    \"\"\"\n    self.filters = filters if filters else {}\n    self.verbose = verbose\n    self.metrics = {}  # Add metrics dictionary to store metadata\n\n    if verbose:\n        # Configure logging for Jupyter notebook compatibility\n        import logging\n        import sys\n\n        # Create logger\n        self.logger = logging.getLogger(f\"{__name__}.WeightedPoissonPredictor\")\n\n        # Only set up handlers if they don't exist\n        if not self.logger.handlers:\n            self.logger.setLevel(logging.INFO if verbose else logging.WARNING)\n\n            # Create handler that writes to sys.stdout\n            handler = logging.StreamHandler(sys.stdout)\n            handler.setLevel(logging.INFO if verbose else logging.WARNING)\n\n            # Create a formatting configuration\n            formatter = logging.Formatter(\"%(message)s\")\n            handler.setFormatter(formatter)\n\n            # Add the handler to the logger\n            self.logger.addHandler(handler)\n\n            # Prevent propagation to root logger\n            self.logger.propagate = False\n\n    # Apply filters\n    self.filters = filters if filters else {}\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.WeightedPoissonPredictor.filter_dataframe","title":"<code>filter_dataframe(df, filters)</code>","text":"<p>Apply a set of filters to a dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame to filter.</p> required <code>filters</code> <code>dict</code> <p>A dictionary where keys are column names and values are the criteria or function to filter by.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pandas.DataFrame: A filtered DataFrame.</p> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>def filter_dataframe(self, df: pd.DataFrame, filters: Dict) -&gt; pd.DataFrame:\n    \"\"\"\n    Apply a set of filters to a dataframe.\n\n    Args:\n        df (pandas.DataFrame): The DataFrame to filter.\n        filters (dict): A dictionary where keys are column names and values are the criteria or function to filter by.\n\n    Returns:\n        pandas.DataFrame: A filtered DataFrame.\n\n    \"\"\"\n    filtered_df = df\n    for column, criteria in filters.items():\n        if callable(criteria):  # If the criteria is a function, apply it directly\n            filtered_df = filtered_df[filtered_df[column].apply(criteria)]\n        else:  # Otherwise, assume the criteria is a value or list of values for equality check\n            filtered_df = filtered_df[filtered_df[column] == criteria]\n    return filtered_df\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.WeightedPoissonPredictor.fit","title":"<code>fit(train_df, prediction_window, yta_time_interval, prediction_times, num_days, epsilon=10 ** -7, y=None)</code>","text":"<p>Fits the model to the training data, computing necessary parameters for future predictions.</p> <p>Parameters:</p> Name Type Description Default <code>train_df</code> <code>DataFrame</code> <p>The training dataset with historical admission data.</p> required <code>prediction_window</code> <code>int</code> <p>The prediction prediction window in minutes.</p> required <code>yta_time_interval</code> <code>int</code> <p>The interval in minutes for splitting the prediction window.</p> required <code>prediction_times</code> <code>list</code> <p>Times of day at which predictions are made, in hours.</p> required <code>num_days</code> <code>int</code> <p>The number of days that the train_df spans</p> required <code>epsilon</code> <code>float</code> <p>A small value representing acceptable error rate to enable calculation of the maximum value of the random variable representing number of beds.</p> <code>10 ** -7</code> <code>y</code> <code>None</code> <p>Ignored, present for compatibility with scikit-learn's fit method.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>WeightedPoissonPredictor</code> <code>WeightedPoissonPredictor</code> <p>The instance itself, fitted with the training data.</p> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>def fit(\n    self,\n    train_df: pd.DataFrame,\n    prediction_window: int,\n    yta_time_interval: int,\n    prediction_times: List[float],\n    num_days: int,\n    epsilon: float = 10**-7,\n    y: Optional[None] = None,\n) -&gt; \"WeightedPoissonPredictor\":\n    \"\"\"\n    Fits the model to the training data, computing necessary parameters for future predictions.\n\n    Args:\n        train_df (pandas.DataFrame):\n            The training dataset with historical admission data.\n        prediction_window (int):\n            The prediction prediction window in minutes.\n        yta_time_interval (int):\n            The interval in minutes for splitting the prediction window.\n        prediction_times (list):\n            Times of day at which predictions are made, in hours.\n        num_days (int):\n             The number of days that the train_df spans\n        epsilon (float, optional):\n            A small value representing acceptable error rate to enable calculation of the maximum value of the random variable representing number of beds.\n        y (None, optional):\n            Ignored, present for compatibility with scikit-learn's fit method.\n\n    Returns:\n        WeightedPoissonPredictor: The instance itself, fitted with the training data.\n\n    \"\"\"\n    # Add error checking at the start of fit\n    if int(prediction_window / yta_time_interval) == 0:\n        raise ValueError(\n            f\"prediction_window ({prediction_window}) divided by yta_time_interval ({yta_time_interval}) must be greater than 1 to generate meaningful predictions\"\n        )\n\n    # Store prediction_window, yta_time_interval, and any other parameters as instance variables\n    self.prediction_window = prediction_window\n    self.yta_time_interval = yta_time_interval\n    self.epsilon = epsilon\n    self.prediction_times = [\n        tuple(x)\n        if isinstance(x, (list, np.ndarray))\n        else (x, 0)\n        if isinstance(x, (int, float))\n        else x\n        for x in prediction_times\n    ]\n\n    # Initialize yet_to_arrive_dict\n    self.weights = {}\n\n    # If there are filters specified, calculate and store the parameters directly with the respective spec keys\n    if self.filters:\n        for spec, filters in self.filters.items():\n            self.weights[spec] = self._calculate_parameters(\n                self.filter_dataframe(train_df, filters),\n                prediction_window,\n                yta_time_interval,\n                prediction_times,\n                num_days,\n            )\n    else:\n        # If there are no filters, store the parameters with a generic key, like 'default' or 'unfiltered'\n        self.weights[\"default\"] = self._calculate_parameters(\n            train_df,\n            prediction_window,\n            yta_time_interval,\n            prediction_times,\n            num_days,\n        )\n\n    if self.verbose:\n        self.logger.info(\n            f\"Poisson Binomial Predictor trained for these times: {prediction_times}\"\n        )\n        self.logger.info(\n            f\"using prediction window of {prediction_window} minutes after the time of prediction\"\n        )\n        self.logger.info(\n            f\"and time interval of {yta_time_interval} minutes within the prediction window.\"\n        )\n        self.logger.info(f\"The error value for prediction will be {epsilon}\")\n        self.logger.info(\n            \"To see the weights saved by this model, used the get_weights() method\"\n        )\n\n    # Store metrics about the training data\n    self.metrics[\"train_dttm\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n    self.metrics[\"train_set_no\"] = len(train_df)\n    self.metrics[\"start_date\"] = train_df.index.min().date()\n    self.metrics[\"end_date\"] = train_df.index.max().date()\n    self.metrics[\"num_days\"] = num_days\n\n    return self\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.WeightedPoissonPredictor.get_weights","title":"<code>get_weights()</code>","text":"<p>Returns the weights computed by the fit method.</p> <p>Returns     dict: The weights.</p> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>def get_weights(self):\n    \"\"\"\n    Returns the weights computed by the fit method.\n\n    Returns\n        dict: The weights.\n\n    \"\"\"\n    return self.weights\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.WeightedPoissonPredictor.predict","title":"<code>predict(prediction_context, x1, y1, x2, y2)</code>","text":"<p>Predicts the number of admissions for the given context based on the fitted model.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_context</code> <code>dict</code> <p>A dictionary defining the context for which predictions are to be made.                        It should specify either a general context or one based on the applied filters.</p> required <code>x1</code> <p>float The x-coordinate of the first transition point on the aspirational curve, where the growth phase ends and the decay phase begins.</p> required <code>y1</code> <p>float The y-coordinate of the first transition point (x1), representing the target proportion of patients admitted by time x1.</p> required <code>x2</code> <p>float The x-coordinate of the second transition point on the curve, beyond which all but a few patients are expected to be admitted.</p> required <code>y2</code> <p>float The y-coordinate of the second transition point (x2), representing the target proportion of patients admitted by time x2.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict</code> <p>A dictionary with predictions for each specified context.</p> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>def predict(\n    self, prediction_context: Dict, x1: float, y1: float, x2: float, y2: float\n) -&gt; Dict:\n    \"\"\"\n    Predicts the number of admissions for the given context based on the fitted model.\n\n    Args:\n        prediction_context (dict): A dictionary defining the context for which predictions are to be made.\n                                   It should specify either a general context or one based on the applied filters.\n        x1 : float\n            The x-coordinate of the first transition point on the aspirational curve, where the growth phase ends and the decay phase begins.\n        y1 : float\n            The y-coordinate of the first transition point (x1), representing the target proportion of patients admitted by time x1.\n        x2 : float\n            The x-coordinate of the second transition point on the curve, beyond which all but a few patients are expected to be admitted.\n        y2 : float\n            The y-coordinate of the second transition point (x2), representing the target proportion of patients admitted by time x2.\n\n    Returns:\n        dict: A dictionary with predictions for each specified context.\n\n    \"\"\"\n    predictions = {}\n\n    NTimes = int(self.prediction_window / self.yta_time_interval)\n    # Calculate theta, probability of admission in prediction window\n\n    # for each time interval, calculate time remaining before end of window\n    time_remaining_before_end_of_window = self.prediction_window / 60 - np.arange(\n        0, self.prediction_window / 60, self.yta_time_interval / 60\n    )\n\n    # probability of admission in that time\n    theta = get_y_from_aspirational_curve(\n        time_remaining_before_end_of_window, x1, y1, x2, y2\n    )\n\n    for filter_key, filter_values in prediction_context.items():\n        try:\n            if filter_key not in self.weights:\n                raise ValueError(\n                    f\"Filter key '{filter_key}' is not recognized in the model weights.\"\n                )\n\n            prediction_time = filter_values.get(\"prediction_time\")\n            if prediction_time is None:\n                raise ValueError(\n                    f\"No 'prediction_time' provided for filter '{filter_key}'.\"\n                )\n\n            if prediction_time not in self.prediction_times:\n                prediction_time = find_nearest_previous_prediction_time(\n                    prediction_time, self.prediction_times\n                )\n\n            lambda_t = self.weights[filter_key][prediction_time].get(\"lambda_t\")\n            if lambda_t is None:\n                raise ValueError(\n                    f\"No 'lambda_t' found for the time of day '{prediction_time}' under filter '{filter_key}'.\"\n                )\n\n            predictions[filter_key] = poisson_binom_generating_function(\n                NTimes, lambda_t, theta, self.epsilon\n            )\n\n        except KeyError as e:\n            raise KeyError(f\"Key error occurred: {e!s}\")\n\n    return predictions\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.aggregate_probabilities","title":"<code>aggregate_probabilities(lam, kmax, theta, time_index)</code>","text":"<p>Aggregate probabilities for a range of values using the weighted Poisson-Binomial distribution.</p> <p>Parameters lam (numpy.ndarray): An array of lambda values for each time interval. kmax (int): The maximum number of events to consider. theta (numpy.ndarray): An array of theta values for each time interval. time_index (int): The current time index for which to calculate probabilities.</p> <p>Returns numpy.ndarray: Aggregated probabilities for the given time index.</p> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>def aggregate_probabilities(lam, kmax, theta, time_index):\n    \"\"\"\n    Aggregate probabilities for a range of values using the weighted Poisson-Binomial distribution.\n\n    Parameters\n    lam (numpy.ndarray): An array of lambda values for each time interval.\n    kmax (int): The maximum number of events to consider.\n    theta (numpy.ndarray): An array of theta values for each time interval.\n    time_index (int): The current time index for which to calculate probabilities.\n\n    Returns\n    numpy.ndarray: Aggregated probabilities for the given time index.\n\n    \"\"\"\n    if kmax &lt; 0 or time_index &lt; 0 or len(lam) &lt;= time_index or len(theta) &lt;= time_index:\n        raise ValueError(\"Invalid kmax, time_index, or array lengths.\")\n\n    probabilities_matrix = np.zeros((kmax + 1, kmax + 1))\n    for i in range(kmax + 1):\n        probabilities_matrix[: i + 1, i] = weighted_poisson_binomial(\n            i, lam[time_index], theta[time_index]\n        )\n    return probabilities_matrix.sum(axis=1)\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.convolute_distributions","title":"<code>convolute_distributions(dist_a, dist_b)</code>","text":"<p>Convolutes two probability distributions represented as dataframes.</p> <p>Parameters dist_a (pd.DataFrame): The first distribution with columns ['sum', 'prob']. dist_b (pd.DataFrame): The second distribution with columns ['sum', 'prob'].</p> <p>Returns pd.DataFrame: The convoluted distribution.</p> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>def convolute_distributions(dist_a, dist_b):\n    \"\"\"\n    Convolutes two probability distributions represented as dataframes.\n\n    Parameters\n    dist_a (pd.DataFrame): The first distribution with columns ['sum', 'prob'].\n    dist_b (pd.DataFrame): The second distribution with columns ['sum', 'prob'].\n\n    Returns\n    pd.DataFrame: The convoluted distribution.\n\n    \"\"\"\n    if not {\"sum\", \"prob\"}.issubset(dist_a.columns) or not {\n        \"sum\",\n        \"prob\",\n    }.issubset(dist_b.columns):\n        raise ValueError(\"DataFrames must contain 'sum' and 'prob' columns.\")\n\n    sums = [x + y for x in dist_a[\"sum\"] for y in dist_b[\"sum\"]]\n    probs = [x * y for x in dist_a[\"prob\"] for y in dist_b[\"prob\"]]\n    result = pd.DataFrame(zip(sums, probs), columns=[\"sum\", \"prob\"])\n    return result.groupby(\"sum\")[\"prob\"].sum().reset_index()\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.find_nearest_previous_prediction_time","title":"<code>find_nearest_previous_prediction_time(requested_time, prediction_times)</code>","text":"<p>Finds the nearest previous time of day in 'prediction_times' relative to the requested time. If the requested time is earlier than all times in 'prediction_times', the function returns the latest time in 'prediction_times'.</p> <p>Parameters:</p> Name Type Description Default <code>requested_time</code> <code>tuple</code> <p>The requested time as (hour, minute).</p> required <code>prediction_times</code> <code>list</code> <p>List of available prediction times.</p> required <p>Returns:</p> Name Type Description <code>closest_prediction_time</code> <code>tuple</code> <p>The closest previous time of day from 'prediction_times'.</p> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>def find_nearest_previous_prediction_time(requested_time, prediction_times):\n    \"\"\"\n    Finds the nearest previous time of day in 'prediction_times' relative to the requested time.\n    If the requested time is earlier than all times in 'prediction_times', the function returns\n    the latest time in 'prediction_times'.\n\n    Args:\n        requested_time (tuple): The requested time as (hour, minute).\n        prediction_times (list): List of available prediction times.\n\n    Returns:\n        closest_prediction_time (tuple): The closest previous time of day from 'prediction_times'.\n\n    \"\"\"\n    if requested_time in prediction_times:\n        return requested_time\n\n    original_prediction_time = requested_time\n    requested_datetime = datetime.strptime(\n        f\"{requested_time[0]:02d}:{requested_time[1]:02d}\", \"%H:%M\"\n    )\n    closest_prediction_time = max(\n        prediction_times,\n        key=lambda prediction_time_time: datetime.strptime(\n            f\"{prediction_time_time[0]:02d}:{prediction_time_time[1]:02d}\",\n            \"%H:%M\",\n        ),\n    )\n    min_diff = float(\"inf\")\n\n    for prediction_time_time in prediction_times:\n        prediction_time_datetime = datetime.strptime(\n            f\"{prediction_time_time[0]:02d}:{prediction_time_time[1]:02d}\",\n            \"%H:%M\",\n        )\n        diff = (requested_datetime - prediction_time_datetime).total_seconds()\n\n        # If the difference is negative, it means the prediction_time_time is ahead of the requested_time,\n        # hence we calculate the difference by considering a day's wrap around.\n        if diff &lt; 0:\n            diff += 24 * 60 * 60  # Add 24 hours in seconds\n\n        if 0 &lt;= diff &lt; min_diff:\n            closest_prediction_time = prediction_time_time\n            min_diff = diff\n\n    warnings.warn(\n        f\"Time of day requested of {original_prediction_time} was not in model training. \"\n        f\"Reverting to predictions for {closest_prediction_time}.\"\n    )\n\n    return closest_prediction_time\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.poisson_binom_generating_function","title":"<code>poisson_binom_generating_function(NTimes, lambda_t, theta, epsilon)</code>","text":"<p>Generate a distribution based on the aggregate of Poisson and Binomial distributions over time intervals.</p> <p>Parameters NTimes (int): The number of time intervals. lambda_t (numpy.ndarray): An array of lambda values for each time interval. theta (numpy.ndarray): An array of theta values for each time interval. epsilon (float): The desired error threshold.</p> <p>Returns pd.DataFrame: The generated distribution.</p> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>def poisson_binom_generating_function(NTimes, lambda_t, theta, epsilon):\n    \"\"\"\n    Generate a distribution based on the aggregate of Poisson and Binomial distributions over time intervals.\n\n    Parameters\n    NTimes (int): The number of time intervals.\n    lambda_t (numpy.ndarray): An array of lambda values for each time interval.\n    theta (numpy.ndarray): An array of theta values for each time interval.\n    epsilon (float): The desired error threshold.\n\n    Returns\n    pd.DataFrame: The generated distribution.\n\n    \"\"\"\n\n    if NTimes &lt;= 0 or epsilon &lt;= 0 or epsilon &gt;= 1:\n        raise ValueError(\"Ensure NTimes &gt; 0 and 0 &lt; epsilon &lt; 1.\")\n\n    maxlam = max(lambda_t)\n    kmax = int(poisson.ppf(1 - epsilon, maxlam))\n    distribution = np.zeros((kmax + 1, NTimes))\n\n    for j in range(NTimes):\n        distribution[:, j] = aggregate_probabilities(lambda_t, kmax, theta, j)\n\n    df_list = [\n        pd.DataFrame({\"sum\": range(kmax + 1), \"prob\": distribution[:, j]})\n        for j in range(NTimes)\n    ]\n    total_distribution = df_list[0]\n\n    for df in df_list[1:]:\n        total_distribution = convolute_distributions(total_distribution, df)\n\n    total_distribution = total_distribution.rename(\n        columns={\"prob\": \"agg_proba\"}\n    ).set_index(\"sum\")\n\n    return total_distribution\n</code></pre>"},{"location":"api/#patientflow.predictors.weighted_poisson_predictor.weighted_poisson_binomial","title":"<code>weighted_poisson_binomial(i, lam, theta)</code>","text":"<p>Calculate weighted probabilities using Poisson and Binomial distributions.</p> <p>Parameters i (int): The upper bound of the range for the binomial distribution. lam (float): The lambda parameter for the Poisson distribution. theta (float): The probability of success for the binomial distribution.</p> <p>Returns numpy.ndarray: An array of weighted probabilities.</p> Source code in <code>src/patientflow/predictors/weighted_poisson_predictor.py</code> <pre><code>def weighted_poisson_binomial(i, lam, theta):\n    \"\"\"\n    Calculate weighted probabilities using Poisson and Binomial distributions.\n\n    Parameters\n    i (int): The upper bound of the range for the binomial distribution.\n    lam (float): The lambda parameter for the Poisson distribution.\n    theta (float): The probability of success for the binomial distribution.\n\n    Returns\n    numpy.ndarray: An array of weighted probabilities.\n\n    \"\"\"\n    if i &lt; 0 or lam &lt; 0 or not 0 &lt;= theta &lt;= 1:\n        raise ValueError(\"Ensure i &gt;= 0, lam &gt;= 0, and 0 &lt;= theta &lt;= 1.\")\n\n    arr_seq = np.arange(i + 1)\n    probabilities = binom.pmf(arr_seq, i, theta)\n    return poisson.pmf(i, lam) * probabilities\n</code></pre>"},{"location":"api/#patientflow.prepare","title":"<code>prepare</code>","text":"<p>Module for preparing data, loading models, and organizing snapshots for inference.</p> <p>This module provides functionality to load a trained model, prepare data for making predictions, calculate arrival rates, and organize snapshot data. It allows for selecting one snapshot per visit, filtering snapshots by prediction time, and mapping snapshot dates to corresponding indices.</p>"},{"location":"api/#patientflow.prepare--functions","title":"Functions","text":"<p>prepare_for_inference(model_file_path, model_name, prediction_time=None,                       model_only=False, df=None, data_path=None,                       single_snapshot_per_visit=True, index_column='snapshot_id',                       sort_columns=None, eval_columns=None,                       exclude_from_training_data=None)     Loads a model and prepares data for inference.</p> <p>select_one_snapshot_per_visit(df, visit_col, seed=42)     Selects one snapshot per visit based on a random number and returns the filtered DataFrame.</p> <p>prepare_patient_snapshots(df, prediction_time, exclude_columns, single_snapshot_per_visit=True)     Filters the DataFrame by prediction time and optionally selects one snapshot per visit.</p> <p>prepare_group_snapshot_dict(df, start_dt=None, end_dt=None)     Prepares a dictionary mapping snapshot dates to their corresponding snapshot indices.</p> <p>calculate_time_varying_arrival_rates(df, yta_time_interval)     Calculates the time-varying arrival rates for a dataset indexed by datetime.</p>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams","title":"<code>SpecialCategoryParams</code>","text":"<p>A picklable implementation of special category parameters for patient classification.</p> <p>This class identifies pediatric patients based on available age-related columns in the dataset and provides functions to categorize patients accordingly. It's designed to be serializable with pickle by implementing the reduce method.</p> <p>Attributes:</p> Name Type Description <code>columns</code> <code>list</code> <p>List of column names from the dataset</p> <code>method_type</code> <code>str</code> <p>The method used for age detection ('age_on_arrival' or 'age_group')</p> <code>special_category_dict</code> <code>dict</code> <p>Default category values mapping</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>class SpecialCategoryParams:\n    \"\"\"\n    A picklable implementation of special category parameters for patient classification.\n\n    This class identifies pediatric patients based on available age-related columns\n    in the dataset and provides functions to categorize patients accordingly.\n    It's designed to be serializable with pickle by implementing the __reduce__ method.\n\n    Attributes:\n        columns (list): List of column names from the dataset\n        method_type (str): The method used for age detection ('age_on_arrival' or 'age_group')\n        special_category_dict (dict): Default category values mapping\n    \"\"\"\n\n    def __init__(self, columns):\n        \"\"\"\n        Initialize the SpecialCategoryParams object.\n\n        Parameters:\n            columns (list or pandas.Index): Column names from the dataset\n                used to determine the appropriate age identification method\n\n        Raises:\n            ValueError: If neither 'age_on_arrival' nor 'age_group' columns are found\n        \"\"\"\n        self.columns = columns\n        self.special_category_dict = {\n            \"medical\": 0.0,\n            \"surgical\": 0.0,\n            \"haem/onc\": 0.0,\n            \"paediatric\": 1.0,\n        }\n\n        if \"age_on_arrival\" in columns:\n            self.method_type = \"age_on_arrival\"\n        elif \"age_group\" in columns:\n            self.method_type = \"age_group\"\n        else:\n            raise ValueError(\"Unknown data format: could not find expected age columns\")\n\n    def special_category_func(self, row: Union[dict, pd.Series]) -&gt; bool:\n        \"\"\"\n        Identify if a patient is pediatric based on age data.\n\n        Parameters:\n            row (Union[dict, pd.Series]): A row of patient data containing either\n                'age_on_arrival' or 'age_group'\n\n        Returns:\n            bool: True if the patient is pediatric (age &lt; 18 or age_group is '0-17'),\n                 False otherwise\n        \"\"\"\n        if self.method_type == \"age_on_arrival\":\n            return row[\"age_on_arrival\"] &lt; 18\n        else:  # age_group\n            return row[\"age_group\"] == \"0-17\"\n\n    def opposite_special_category_func(self, row: Union[dict, pd.Series]) -&gt; bool:\n        \"\"\"\n        Identify if a patient is NOT pediatric.\n\n        Parameters:\n            row (Union[dict, pd.Series]): A row of patient data\n\n        Returns:\n            bool: True if the patient is NOT pediatric, False if they are pediatric\n        \"\"\"\n        return not self.special_category_func(row)\n\n    def get_params_dict(\n        self,\n    ) -&gt; Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]:\n        \"\"\"\n        Get the special parameter dictionary in the format expected by the application.\n\n        Returns:\n            Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]: A dictionary containing:\n                - 'special_category_func': Function to identify pediatric patients\n                - 'special_category_dict': Default category values (float)\n                - 'special_func_map': Mapping of category names to detection functions\n        \"\"\"\n        return {\n            \"special_category_func\": self.special_category_func,\n            \"special_category_dict\": self.special_category_dict,\n            \"special_func_map\": {\n                \"paediatric\": self.special_category_func,\n                \"default\": self.opposite_special_category_func,\n            },\n        }\n\n    def __reduce__(self) -&gt; Tuple[Type[\"SpecialCategoryParams\"], Tuple[list]]:\n        \"\"\"\n        Support for pickle serialization.\n\n        Returns:\n            Tuple[Type['SpecialCategoryParams'], Tuple[list]]: A tuple containing:\n                - The class itself (to be called as a function)\n                - A tuple of arguments to pass to the class constructor\n        \"\"\"\n        return (self.__class__, (self.columns,))\n</code></pre>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams.__init__","title":"<code>__init__(columns)</code>","text":"<p>Initialize the SpecialCategoryParams object.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>list or Index</code> <p>Column names from the dataset used to determine the appropriate age identification method</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither 'age_on_arrival' nor 'age_group' columns are found</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def __init__(self, columns):\n    \"\"\"\n    Initialize the SpecialCategoryParams object.\n\n    Parameters:\n        columns (list or pandas.Index): Column names from the dataset\n            used to determine the appropriate age identification method\n\n    Raises:\n        ValueError: If neither 'age_on_arrival' nor 'age_group' columns are found\n    \"\"\"\n    self.columns = columns\n    self.special_category_dict = {\n        \"medical\": 0.0,\n        \"surgical\": 0.0,\n        \"haem/onc\": 0.0,\n        \"paediatric\": 1.0,\n    }\n\n    if \"age_on_arrival\" in columns:\n        self.method_type = \"age_on_arrival\"\n    elif \"age_group\" in columns:\n        self.method_type = \"age_group\"\n    else:\n        raise ValueError(\"Unknown data format: could not find expected age columns\")\n</code></pre>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams.__reduce__","title":"<code>__reduce__()</code>","text":"<p>Support for pickle serialization.</p> <p>Returns:</p> Type Description <code>Tuple[Type[SpecialCategoryParams], Tuple[list]]</code> <p>Tuple[Type['SpecialCategoryParams'], Tuple[list]]: A tuple containing: - The class itself (to be called as a function) - A tuple of arguments to pass to the class constructor</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def __reduce__(self) -&gt; Tuple[Type[\"SpecialCategoryParams\"], Tuple[list]]:\n    \"\"\"\n    Support for pickle serialization.\n\n    Returns:\n        Tuple[Type['SpecialCategoryParams'], Tuple[list]]: A tuple containing:\n            - The class itself (to be called as a function)\n            - A tuple of arguments to pass to the class constructor\n    \"\"\"\n    return (self.__class__, (self.columns,))\n</code></pre>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams.get_params_dict","title":"<code>get_params_dict()</code>","text":"<p>Get the special parameter dictionary in the format expected by the application.</p> <p>Returns:</p> Type Description <code>Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]</code> <p>Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]: A dictionary containing: - 'special_category_func': Function to identify pediatric patients - 'special_category_dict': Default category values (float) - 'special_func_map': Mapping of category names to detection functions</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def get_params_dict(\n    self,\n) -&gt; Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]:\n    \"\"\"\n    Get the special parameter dictionary in the format expected by the application.\n\n    Returns:\n        Dict[str, Union[Callable, Dict[str, float], Dict[str, Callable]]]: A dictionary containing:\n            - 'special_category_func': Function to identify pediatric patients\n            - 'special_category_dict': Default category values (float)\n            - 'special_func_map': Mapping of category names to detection functions\n    \"\"\"\n    return {\n        \"special_category_func\": self.special_category_func,\n        \"special_category_dict\": self.special_category_dict,\n        \"special_func_map\": {\n            \"paediatric\": self.special_category_func,\n            \"default\": self.opposite_special_category_func,\n        },\n    }\n</code></pre>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams.opposite_special_category_func","title":"<code>opposite_special_category_func(row)</code>","text":"<p>Identify if a patient is NOT pediatric.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Union[dict, Series]</code> <p>A row of patient data</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the patient is NOT pediatric, False if they are pediatric</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def opposite_special_category_func(self, row: Union[dict, pd.Series]) -&gt; bool:\n    \"\"\"\n    Identify if a patient is NOT pediatric.\n\n    Parameters:\n        row (Union[dict, pd.Series]): A row of patient data\n\n    Returns:\n        bool: True if the patient is NOT pediatric, False if they are pediatric\n    \"\"\"\n    return not self.special_category_func(row)\n</code></pre>"},{"location":"api/#patientflow.prepare.SpecialCategoryParams.special_category_func","title":"<code>special_category_func(row)</code>","text":"<p>Identify if a patient is pediatric based on age data.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>Union[dict, Series]</code> <p>A row of patient data containing either 'age_on_arrival' or 'age_group'</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the patient is pediatric (age &lt; 18 or age_group is '0-17'),  False otherwise</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def special_category_func(self, row: Union[dict, pd.Series]) -&gt; bool:\n    \"\"\"\n    Identify if a patient is pediatric based on age data.\n\n    Parameters:\n        row (Union[dict, pd.Series]): A row of patient data containing either\n            'age_on_arrival' or 'age_group'\n\n    Returns:\n        bool: True if the patient is pediatric (age &lt; 18 or age_group is '0-17'),\n             False otherwise\n    \"\"\"\n    if self.method_type == \"age_on_arrival\":\n        return row[\"age_on_arrival\"] &lt; 18\n    else:  # age_group\n        return row[\"age_group\"] == \"0-17\"\n</code></pre>"},{"location":"api/#patientflow.prepare.assign_patient_ids","title":"<code>assign_patient_ids(df, start_training_set, start_validation_set, start_test_set, end_test_set, date_col='arrival_datetime', patient_id='mrn', visit_col='encounter')</code>","text":"<p>Probabilistically assign patient IDs to train/validation/test sets.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with patient_id, encounter, and temporal columns</p> required <code>start_training_set</code> <code>date</code> <p>Start date for training period</p> required <code>start_validation_set</code> <code>date</code> <p>Start date for validation period</p> required <code>start_test_set</code> <code>date</code> <p>Start date for test period</p> required <code>end_test_set</code> <code>date</code> <p>End date for test period</p> required <code>date_col</code> <code>str</code> <p>Column name for temporal splitting</p> <code>'arrival_datetime'</code> <code>patient_id</code> <code>str</code> <p>Column name for patient identifier (default: 'mrn')</p> <code>'mrn'</code> <code>visit_col</code> <code>str</code> <p>Column name for visit identifier (default: 'encounter')</p> <code>'encounter'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with patient ID assignments based on weighted random sampling</p> Notes <ul> <li>Counts encounters in each time period per patient ID</li> <li>Randomly assigns each patient ID to one set, weighted by their temporal distribution</li> <li>Patient with 70% encounters in training, 30% in validation has 70% chance of training assignment</li> </ul> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def assign_patient_ids(\n    df: pd.DataFrame,\n    start_training_set: date,\n    start_validation_set: date,\n    start_test_set: date,\n    end_test_set: date,\n    date_col: str = \"arrival_datetime\",\n    patient_id: str = \"mrn\",\n    visit_col: str = \"encounter\",\n) -&gt; pd.DataFrame:\n    \"\"\"Probabilistically assign patient IDs to train/validation/test sets.\n\n    Args:\n        df: DataFrame with patient_id, encounter, and temporal columns\n        start_training_set: Start date for training period\n        start_validation_set: Start date for validation period\n        start_test_set: Start date for test period\n        end_test_set: End date for test period\n        date_col: Column name for temporal splitting\n        patient_id: Column name for patient identifier (default: 'mrn')\n        visit_col: Column name for visit identifier (default: 'encounter')\n\n    Returns:\n        DataFrame with patient ID assignments based on weighted random sampling\n\n    Notes:\n        - Counts encounters in each time period per patient ID\n        - Randomly assigns each patient ID to one set, weighted by their temporal distribution\n        - Patient with 70% encounters in training, 30% in validation has 70% chance of training assignment\n    \"\"\"\n    patients: pd.DataFrame = (\n        df.groupby([patient_id, visit_col])[date_col].max().reset_index()\n    )\n\n    # Handle date_col as string, datetime, or date type\n    if pd.api.types.is_datetime64_any_dtype(patients[date_col]):\n        # Already datetime, extract date if needed\n        if hasattr(patients[date_col].iloc[0], \"date\"):\n            date_series = patients[date_col].dt.date\n        else:\n            # Already date type\n            date_series = patients[date_col]\n    else:\n        # Try to convert string to datetime\n        try:\n            patients[date_col] = pd.to_datetime(patients[date_col])\n            date_series = patients[date_col].dt.date\n        except (TypeError, ValueError) as e:\n            raise ValueError(\n                f\"Could not convert column '{date_col}' to datetime format: {str(e)}\"\n            )\n\n    # Filter out patient IDs outside temporal bounds\n    pre_training_patients = patients[date_series &lt; start_training_set]\n    post_test_patients = patients[date_series &gt;= end_test_set]\n\n    if len(pre_training_patients) &gt; 0:\n        print(\n            f\"Filtered out {len(pre_training_patients)} patients with only pre-training visits\"\n        )\n    if len(post_test_patients) &gt; 0:\n        print(\n            f\"Filtered out {len(post_test_patients)} patients with only post-test visits\"\n        )\n\n    valid_patients = patients[\n        (date_series &gt;= start_training_set) &amp; (date_series &lt; end_test_set)\n    ]\n    patients = valid_patients\n\n    # Use the date_series for set assignment\n    patients[\"training_set\"] = (date_series &gt;= start_training_set) &amp; (\n        date_series &lt; start_validation_set\n    )\n    patients[\"validation_set\"] = (date_series &gt;= start_validation_set) &amp; (\n        date_series &lt; start_test_set\n    )\n    patients[\"test_set\"] = (date_series &gt;= start_test_set) &amp; (\n        date_series &lt; end_test_set\n    )\n\n    patients = patients.groupby(patient_id)[\n        [\"training_set\", \"validation_set\", \"test_set\"]\n    ].sum()\n    patients[\"training_validation_test\"] = patients.apply(apply_set, axis=1)\n\n    print(\n        f\"\\nPatient Set Overlaps (before random assignment):\"\n        f\"\\nTrain-Valid: {patients[patients.training_set * patients.validation_set != 0].shape[0]} of {patients[patients.training_set + patients.validation_set &gt; 0].shape[0]}\"\n        f\"\\nValid-Test: {patients[patients.validation_set * patients.test_set != 0].shape[0]} of {patients[patients.validation_set + patients.test_set &gt; 0].shape[0]}\"\n        f\"\\nTrain-Test: {patients[patients.training_set * patients.test_set != 0].shape[0]} of {patients[patients.training_set + patients.test_set &gt; 0].shape[0]}\"\n        f\"\\nAll Sets: {patients[patients.training_set * patients.validation_set * patients.test_set != 0].shape[0]} of {patients.shape[0]} total patients\"\n    )\n\n    return patients\n</code></pre>"},{"location":"api/#patientflow.prepare.create_special_category_objects","title":"<code>create_special_category_objects(columns)</code>","text":"<p>Creates a configuration for categorizing patients with special handling for pediatric cases.</p>"},{"location":"api/#patientflow.prepare.create_special_category_objects--parameters","title":"Parameters:","text":"<p>columns : list or pandas.Index     The column names available in the dataset. Used to determine which age format is present.</p>"},{"location":"api/#patientflow.prepare.create_special_category_objects--returns","title":"Returns:","text":"<p>dict     A dictionary containing special category configuration.</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def create_special_category_objects(columns):\n    \"\"\"\n    Creates a configuration for categorizing patients with special handling for pediatric cases.\n\n    Parameters:\n    -----------\n    columns : list or pandas.Index\n        The column names available in the dataset. Used to determine which age format is present.\n\n    Returns:\n    --------\n    dict\n        A dictionary containing special category configuration.\n    \"\"\"\n    # Create the class instance and return its parameter dictionary\n    params_obj = SpecialCategoryParams(columns)\n    return params_obj.get_params_dict()\n</code></pre>"},{"location":"api/#patientflow.prepare.create_temporal_splits","title":"<code>create_temporal_splits(df, start_train, start_valid, start_test, end_test, col_name='arrival_datetime', patient_id='mrn', visit_col='encounter')</code>","text":"<p>Split dataset into temporal train/validation/test sets.</p> <p>Creates temporal data splits using primary datetime column and optional snapshot dates. Handles patient ID grouping if present to prevent data leakage.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input dataframe</p> required <code>start_train</code> <code>date</code> <p>Training start (inclusive)</p> required <code>start_valid</code> <code>date</code> <p>Validation start (inclusive)</p> required <code>start_test</code> <code>date</code> <p>Test start (inclusive)</p> required <code>end_test</code> <code>date</code> <p>Test end (exclusive)</p> required <code>col_name</code> <code>str</code> <p>Primary datetime column for splitting</p> <code>'arrival_datetime'</code> <code>patient_id</code> <code>str</code> <p>Column name for patient identifier (default: 'mrn')</p> <code>'mrn'</code> <code>visit_col</code> <code>str</code> <p>Column name for visit identifier (default: 'encounter')</p> <code>'encounter'</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>Tuple[DataFrame, DataFrame, DataFrame]</code> <p>(train_df, valid_df, test_df) Split dataframes</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def create_temporal_splits(\n    df: pd.DataFrame,\n    start_train: date,\n    start_valid: date,\n    start_test: date,\n    end_test: date,\n    col_name: str = \"arrival_datetime\",\n    patient_id: str = \"mrn\",\n    visit_col: str = \"encounter\",\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n    \"\"\"Split dataset into temporal train/validation/test sets.\n\n    Creates temporal data splits using primary datetime column and optional snapshot dates.\n    Handles patient ID grouping if present to prevent data leakage.\n\n    Args:\n        df: Input dataframe\n        start_train: Training start (inclusive)\n        start_valid: Validation start (inclusive)\n        start_test: Test start (inclusive)\n        end_test: Test end (exclusive)\n        col_name: Primary datetime column for splitting\n        patient_id: Column name for patient identifier (default: 'mrn')\n        visit_col: Column name for visit identifier (default: 'encounter')\n\n    Returns:\n        tuple: (train_df, valid_df, test_df) Split dataframes\n    \"\"\"\n\n    def get_date_value(series: pd.Series) -&gt; pd.Series:\n        \"\"\"Convert timestamp or date column to date, handling both types\"\"\"\n        try:\n            return pd.to_datetime(series).dt.date\n        except (AttributeError, TypeError):\n            return series\n\n    if patient_id in df.columns:\n        set_assignment: pd.DataFrame = assign_patient_ids(\n            df,\n            start_train,\n            start_valid,\n            start_test,\n            end_test,\n            col_name,\n            patient_id,\n            visit_col,\n        )\n        patient_sets: Dict[str, Set] = {\n            k: set(set_assignment[set_assignment.training_validation_test == v].index)\n            for k, v in {\"train\": \"train\", \"valid\": \"valid\", \"test\": \"test\"}.items()\n        }\n\n    splits: List[pd.DataFrame] = []\n    for start, end, set_key in [\n        (start_train, start_valid, \"train\"),\n        (start_valid, start_test, \"valid\"),\n        (start_test, end_test, \"test\"),\n    ]:\n        mask = (get_date_value(df[col_name]) &gt;= start) &amp; (\n            get_date_value(df[col_name]) &lt; end\n        )\n\n        if \"snapshot_date\" in df.columns:\n            mask &amp;= (get_date_value(df.snapshot_date) &gt;= start) &amp; (\n                get_date_value(df.snapshot_date) &lt; end\n            )\n\n        if patient_id in df.columns:\n            mask &amp;= df[patient_id].isin(patient_sets[set_key])\n\n        splits.append(df[mask].copy())\n\n    print(f\"Split sizes: {[len(split) for split in splits]}\")\n    return tuple(splits)\n</code></pre>"},{"location":"api/#patientflow.prepare.create_yta_filters","title":"<code>create_yta_filters(df)</code>","text":"<p>Create specialty filters for categorizing patients by specialty and age group.</p> <p>This function generates a dictionary of filters based on specialty categories, with special handling for pediatric patients. It uses the SpecialCategoryParams class to determine which specialties correspond to pediatric care.</p>"},{"location":"api/#patientflow.prepare.create_yta_filters--parameters","title":"Parameters:","text":"<p>df : pandas.DataFrame     DataFrame containing patient data with columns that include either     'age_on_arrival' or 'age_group' for pediatric classification</p>"},{"location":"api/#patientflow.prepare.create_yta_filters--returns","title":"Returns:","text":"<p>dict     A dictionary mapping specialty names to filter configurations.     Each configuration contains:     - For pediatric specialty: {\"is_child\": True}     - For other specialties: {\"specialty\": specialty_name, \"is_child\": False}</p>"},{"location":"api/#patientflow.prepare.create_yta_filters--examples","title":"Examples:","text":"<p>df = pd.DataFrame({'patient_id': [1, 2], 'age_on_arrival': [10, 40]}) filters = create_yta_filters(df) print(filters['paediatric']) {'is_child': True} print(filters['medical']) {'specialty': 'medical', 'is_child': False}</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def create_yta_filters(df):\n    \"\"\"\n    Create specialty filters for categorizing patients by specialty and age group.\n\n    This function generates a dictionary of filters based on specialty categories,\n    with special handling for pediatric patients. It uses the SpecialCategoryParams\n    class to determine which specialties correspond to pediatric care.\n\n    Parameters:\n    -----------\n    df : pandas.DataFrame\n        DataFrame containing patient data with columns that include either\n        'age_on_arrival' or 'age_group' for pediatric classification\n\n    Returns:\n    --------\n    dict\n        A dictionary mapping specialty names to filter configurations.\n        Each configuration contains:\n        - For pediatric specialty: {\"is_child\": True}\n        - For other specialties: {\"specialty\": specialty_name, \"is_child\": False}\n\n    Examples:\n    ---------\n    &gt;&gt;&gt; df = pd.DataFrame({'patient_id': [1, 2], 'age_on_arrival': [10, 40]})\n    &gt;&gt;&gt; filters = create_yta_filters(df)\n    &gt;&gt;&gt; print(filters['paediatric'])\n    {'is_child': True}\n    &gt;&gt;&gt; print(filters['medical'])\n    {'specialty': 'medical', 'is_child': False}\n    \"\"\"\n    # Get the special category parameters using the picklable implementation\n    special_params = create_special_category_objects(df.columns)\n\n    # Extract necessary data from the special_params\n    special_category_dict = special_params[\"special_category_dict\"]\n\n    # Create the specialty_filters dictionary\n    specialty_filters = {}\n\n    for specialty, is_paediatric_flag in special_category_dict.items():\n        if is_paediatric_flag == 1.0:\n            # For the paediatric specialty, set `is_child` to True\n            specialty_filters[specialty] = {\"is_child\": True}\n        else:\n            # For other specialties, set `is_child` to False\n            specialty_filters[specialty] = {\"specialty\": specialty, \"is_child\": False}\n\n    return specialty_filters\n</code></pre>"},{"location":"api/#patientflow.prepare.prepare_for_inference","title":"<code>prepare_for_inference(model_file_path, model_name, prediction_time=None, model_only=False, df=None, data_path=None, single_snapshot_per_visit=True, index_column='snapshot_id', sort_columns=['visit_number', 'snapshot_date', 'prediction_time'], eval_columns=['prediction_time', 'consultation_sequence', 'final_sequence'], exclude_from_training_data=['visit_number', 'snapshot_date', 'prediction_time'])</code>","text":"<p>Load a trained model and prepare data for making predictions.</p> <p>This function retrieves a trained model from a specified file path and, if requested, prepares the data required for inference. The data can be provided either as a DataFrame or as a file path to a CSV file. The function allows filtering and processing of the data to match the model's requirements. If available, it will use the calibrated pipeline instead of the regular pipeline.</p>"},{"location":"api/#patientflow.prepare.prepare_for_inference--parameters","title":"Parameters","text":"<p>model_file_path : str     The file path where the trained model is saved. model_name : str     The name of the model to be loaded. prediction_time : str, optional     The time at which predictions are to be made. This is used to filter     the data for the relevant time snapshot. model_only : bool, optional     If True, only the model is returned. If False, both the prepared data     and the model are returned. Default is False. df : pandas.DataFrame, optional     The DataFrame containing the data to be used for inference. If not     provided, data_path must be specified. data_path : str, optional     The file path to a CSV file containing the data to be used for inference.     Ignored if <code>df</code> is provided. single_snapshot_per_visit : bool, optional     If True, only a single snapshot per visit is considered. Default is True. index_column : str, optional     The name of the index column in the data. Default is 'snapshot_id'. sort_columns : list of str, optional     The columns to sort the data by. Default is [\"visit_number\", \"snapshot_date\", \"prediction_time\"]. eval_columns : list of str, optional     The columns that require literal evaluation of their content when loading from csv.     Default is [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"]. exclude_from_training_data : list of str, optional     The columns to be excluded from the training data. Default is [\"visit_number\", \"snapshot_date\", \"prediction_time\"].</p>"},{"location":"api/#patientflow.prepare.prepare_for_inference--returns","title":"Returns","text":"<p>model : object     The loaded model (calibrated pipeline if available, otherwise regular pipeline). X_test : pandas.DataFrame, optional     The features prepared for testing, returned only if model_only is False. y_test : pandas.Series, optional     The labels corresponding to X_test, returned only if model_only is False.</p>"},{"location":"api/#patientflow.prepare.prepare_for_inference--raises","title":"Raises","text":"<p>KeyError     If the 'training_validation_test' column is not found in the provided DataFrame.</p>"},{"location":"api/#patientflow.prepare.prepare_for_inference--notes","title":"Notes","text":"<ul> <li>Either <code>df</code> or <code>data_path</code> must be provided. If neither is provided or if <code>df</code>   is empty, the function will print an error message and return None.</li> <li>The function will automatically use a calibrated pipeline if one is available   in the model, otherwise it will fall back to the regular pipeline.</li> </ul> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def prepare_for_inference(\n    model_file_path,\n    model_name,\n    prediction_time=None,\n    model_only=False,\n    df=None,\n    data_path=None,\n    single_snapshot_per_visit=True,\n    index_column=\"snapshot_id\",\n    sort_columns=[\"visit_number\", \"snapshot_date\", \"prediction_time\"],\n    eval_columns=[\"prediction_time\", \"consultation_sequence\", \"final_sequence\"],\n    exclude_from_training_data=[\"visit_number\", \"snapshot_date\", \"prediction_time\"],\n):\n    \"\"\"\n    Load a trained model and prepare data for making predictions.\n\n    This function retrieves a trained model from a specified file path and,\n    if requested, prepares the data required for inference. The data can be\n    provided either as a DataFrame or as a file path to a CSV file. The function\n    allows filtering and processing of the data to match the model's requirements.\n    If available, it will use the calibrated pipeline instead of the regular pipeline.\n\n    Parameters\n    ----------\n    model_file_path : str\n        The file path where the trained model is saved.\n    model_name : str\n        The name of the model to be loaded.\n    prediction_time : str, optional\n        The time at which predictions are to be made. This is used to filter\n        the data for the relevant time snapshot.\n    model_only : bool, optional\n        If True, only the model is returned. If False, both the prepared data\n        and the model are returned. Default is False.\n    df : pandas.DataFrame, optional\n        The DataFrame containing the data to be used for inference. If not\n        provided, data_path must be specified.\n    data_path : str, optional\n        The file path to a CSV file containing the data to be used for inference.\n        Ignored if `df` is provided.\n    single_snapshot_per_visit : bool, optional\n        If True, only a single snapshot per visit is considered. Default is True.\n    index_column : str, optional\n        The name of the index column in the data. Default is 'snapshot_id'.\n    sort_columns : list of str, optional\n        The columns to sort the data by. Default is [\"visit_number\", \"snapshot_date\", \"prediction_time\"].\n    eval_columns : list of str, optional\n        The columns that require literal evaluation of their content when loading from csv.\n        Default is [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"].\n    exclude_from_training_data : list of str, optional\n        The columns to be excluded from the training data. Default is [\"visit_number\", \"snapshot_date\", \"prediction_time\"].\n\n    Returns\n    -------\n    model : object\n        The loaded model (calibrated pipeline if available, otherwise regular pipeline).\n    X_test : pandas.DataFrame, optional\n        The features prepared for testing, returned only if model_only is False.\n    y_test : pandas.Series, optional\n        The labels corresponding to X_test, returned only if model_only is False.\n\n    Raises\n    ------\n    KeyError\n        If the 'training_validation_test' column is not found in the provided DataFrame.\n\n    Notes\n    -----\n    - Either `df` or `data_path` must be provided. If neither is provided or if `df`\n      is empty, the function will print an error message and return None.\n    - The function will automatically use a calibrated pipeline if one is available\n      in the model, otherwise it will fall back to the regular pipeline.\n    \"\"\"\n\n    # retrieve model trained for this time of day\n    model = load_saved_model(model_file_path, model_name, prediction_time)\n\n    # Use calibrated pipeline if available, otherwise use regular pipeline\n    if hasattr(model, \"calibrated_pipeline\") and model.calibrated_pipeline is not None:\n        pipeline = model.calibrated_pipeline\n    else:\n        pipeline = model.pipeline\n\n    if model_only:\n        return pipeline\n\n    if data_path:\n        df = data_from_csv(data_path, index_column, sort_columns, eval_columns)\n    elif df is None or df.empty:\n        print(\"Please supply a dataset if not passing a data path\")\n        return None\n\n    try:\n        test_df = (\n            df[df.training_validation_test == \"test\"]\n            .drop(columns=\"training_validation_test\")\n            .copy()\n        )\n    except KeyError:\n        print(\"Column training_validation_test not found in dataframe\")\n        return None\n\n    X_test, y_test = prepare_patient_snapshots(\n        test_df,\n        prediction_time,\n        exclude_from_training_data,\n        single_snapshot_per_visit,\n    )\n\n    return X_test, y_test, pipeline\n</code></pre>"},{"location":"api/#patientflow.prepare.prepare_group_snapshot_dict","title":"<code>prepare_group_snapshot_dict(df, start_dt=None, end_dt=None)</code>","text":"<p>Prepares a dictionary mapping snapshot dates to their corresponding snapshot indices.</p> <p>Args: df (pd.DataFrame): DataFrame containing at least a 'snapshot_date' column which represents the dates. start_dt (datetime.date): Start date (optional) end_dt (datetime.date): End date (optional)</p> <p>Returns: dict: A dictionary where keys are dates and values are arrays of indices corresponding to each date's snapshots. A array can be empty if there are no snapshots associated with a date</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def prepare_group_snapshot_dict(df, start_dt=None, end_dt=None):\n    \"\"\"\n    Prepares a dictionary mapping snapshot dates to their corresponding snapshot indices.\n\n    Args:\n    df (pd.DataFrame): DataFrame containing at least a 'snapshot_date' column which represents the dates.\n    start_dt (datetime.date): Start date (optional)\n    end_dt (datetime.date): End date (optional)\n\n    Returns:\n    dict: A dictionary where keys are dates and values are arrays of indices corresponding to each date's snapshots.\n    A array can be empty if there are no snapshots associated with a date\n\n    \"\"\"\n    # Ensure 'snapshot_date' is in the DataFrame\n    if \"snapshot_date\" not in df.columns:\n        raise ValueError(\"DataFrame must include a 'snapshot_date' column\")\n\n    # Filter DataFrame to date range if provided\n    filtered_df = df.copy()\n    if start_dt and end_dt:\n        filtered_df = df[\n            (df[\"snapshot_date\"] &gt;= start_dt) &amp; (df[\"snapshot_date\"] &lt; end_dt)\n        ]\n\n    # Group the DataFrame by 'snapshot_date' and collect the indices for each group\n    snapshots_dict = {\n        date: group.index.tolist()\n        for date, group in filtered_df.groupby(\"snapshot_date\")\n    }\n\n    # If start_dt and end_dt are specified, add any missing keys from prediction_dates\n    if start_dt:\n        prediction_dates = pd.date_range(\n            start=start_dt, end=end_dt, freq=\"D\"\n        ).date.tolist()[:-1]\n        for dt in prediction_dates:\n            if dt not in snapshots_dict:\n                snapshots_dict[dt] = []\n\n    return snapshots_dict\n</code></pre>"},{"location":"api/#patientflow.prepare.prepare_patient_snapshots","title":"<code>prepare_patient_snapshots(df, prediction_time, exclude_columns=[], single_snapshot_per_visit=True, visit_col=None, label_col='is_admitted')</code>","text":"<p>Get snapshots of data at a specific prediction time with configurable visit and label columns.</p>"},{"location":"api/#patientflow.prepare.prepare_patient_snapshots--parameters","title":"Parameters:","text":"<p>df : pandas.DataFrame     Input DataFrame containing the data prediction_time : str or datetime     The specific prediction time to filter for exclude_columns : list     List of columns to exclude from the final DataFrame single_snapshot_per_visit : bool, default=True     Whether to select only one snapshot per visit. If True, visit_col must be provided. visit_col : str, optional     Name of the column containing visit identifiers. Required if single_snapshot_per_visit is True. label_col : str, default=\"is_admitted\"     Name of the column containing the target labels</p>"},{"location":"api/#patientflow.prepare.prepare_patient_snapshots--returns","title":"Returns:","text":"<p>Tuple[pandas.DataFrame, pandas.Series]     A tuple containing:     - DataFrame: Processed DataFrame with features     - Series: Corresponding labels</p> Source code in <code>src/patientflow/prepare.py</code> <pre><code>def prepare_patient_snapshots(\n    df,\n    prediction_time,\n    exclude_columns=[],\n    single_snapshot_per_visit=True,\n    visit_col=None,\n    label_col=\"is_admitted\",\n) -&gt; Tuple[pd.DataFrame, pd.Series]:\n    \"\"\"\n    Get snapshots of data at a specific prediction time with configurable visit and label columns.\n\n    Parameters:\n    -----------\n    df : pandas.DataFrame\n        Input DataFrame containing the data\n    prediction_time : str or datetime\n        The specific prediction time to filter for\n    exclude_columns : list\n        List of columns to exclude from the final DataFrame\n    single_snapshot_per_visit : bool, default=True\n        Whether to select only one snapshot per visit. If True, visit_col must be provided.\n    visit_col : str, optional\n        Name of the column containing visit identifiers. Required if single_snapshot_per_visit is True.\n    label_col : str, default=\"is_admitted\"\n        Name of the column containing the target labels\n\n    Returns:\n    --------\n    Tuple[pandas.DataFrame, pandas.Series]\n        A tuple containing:\n        - DataFrame: Processed DataFrame with features\n        - Series: Corresponding labels\n    \"\"\"\n    if single_snapshot_per_visit and visit_col is None:\n        raise ValueError(\n            \"visit_col must be provided when single_snapshot_per_visit is True\"\n        )\n\n    # Filter by the time of day while keeping the original index\n    df_tod = df[df[\"prediction_time\"] == prediction_time].copy()\n\n    if single_snapshot_per_visit:\n        # Select one row for each visit\n        df_single = select_one_snapshot_per_visit(df_tod, visit_col)\n        # Create label array with the same index\n        y = df_single.pop(label_col).astype(int)\n        # Drop specified columns and ensure we do not reset the index\n        df_single.drop(columns=exclude_columns, inplace=True)\n        return df_single, y\n    else:\n        # Directly modify df_tod without resetting the index\n        df_tod.drop(\n            columns=[\"random_number\"] + exclude_columns, inplace=True, errors=\"ignore\"\n        )\n        y = df_tod.pop(label_col).astype(int)\n        return df_tod, y\n</code></pre>"},{"location":"api/#patientflow.train","title":"<code>train</code>","text":""},{"location":"api/#patientflow.train.classifiers","title":"<code>classifiers</code>","text":""},{"location":"api/#patientflow.train.classifiers.chronological_cross_validation","title":"<code>chronological_cross_validation(pipeline, X, y, n_splits=5)</code>","text":"<p>Perform time series cross-validation with multiple metrics.</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def chronological_cross_validation(\n    pipeline: Pipeline, X: DataFrame, y: Series, n_splits: int = 5\n) -&gt; Dict[str, float]:\n    \"\"\"Perform time series cross-validation with multiple metrics.\"\"\"\n    tscv = TimeSeriesSplit(n_splits=n_splits)\n\n    train_metrics: List[FoldResults] = []\n    valid_metrics: List[FoldResults] = []\n\n    for train_idx, valid_idx in tscv.split(X):\n        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\n        pipeline.fit(X_train, y_train)\n        train_preds = pipeline.predict_proba(X_train)[:, 1]\n        valid_preds = pipeline.predict_proba(X_valid)[:, 1]\n\n        train_metrics.append(evaluate_predictions(y_train, train_preds))\n        valid_metrics.append(evaluate_predictions(y_valid, valid_preds))\n\n    def aggregate_metrics(metrics_list: List[FoldResults]) -&gt; Dict[str, float]:\n        return {\n            field: np.mean([getattr(m, field) for m in metrics_list])\n            for field in FoldResults.__dataclass_fields__\n        }\n\n    train_means = aggregate_metrics(train_metrics)\n    valid_means = aggregate_metrics(valid_metrics)\n\n    return {f\"train_{metric}\": value for metric, value in train_means.items()} | {\n        f\"valid_{metric}\": value for metric, value in valid_means.items()\n    }\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.create_balance_info","title":"<code>create_balance_info(is_balanced, original_size, balanced_size, original_positive_rate, balanced_positive_rate, majority_to_minority_ratio)</code>","text":"<p>Create a dictionary with balance information.</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def create_balance_info(\n    is_balanced: bool,\n    original_size: int,\n    balanced_size: int,\n    original_positive_rate: float,\n    balanced_positive_rate: float,\n    majority_to_minority_ratio: float,\n) -&gt; Dict[str, Union[bool, int, float]]:\n    \"\"\"Create a dictionary with balance information.\"\"\"\n    return {\n        \"is_balanced\": is_balanced,\n        \"original_size\": original_size,\n        \"balanced_size\": balanced_size,\n        \"original_positive_rate\": original_positive_rate,\n        \"balanced_positive_rate\": balanced_positive_rate,\n        \"majority_to_minority_ratio\": majority_to_minority_ratio,\n    }\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.create_column_transformer","title":"<code>create_column_transformer(df, ordinal_mappings=None)</code>","text":"<p>Create a column transformer for a dataframe with dynamic column handling.</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def create_column_transformer(\n    df: DataFrame, ordinal_mappings: Optional[Dict[str, List[Any]]] = None\n) -&gt; ColumnTransformer:\n    \"\"\"Create a column transformer for a dataframe with dynamic column handling.\"\"\"\n    transformers: List[\n        Tuple[str, Union[OrdinalEncoder, OneHotEncoder, StandardScaler], List[str]]\n    ] = []\n\n    if ordinal_mappings is None:\n        ordinal_mappings = {}\n\n    for col in df.columns:\n        if col in ordinal_mappings:\n            transformers.append(\n                (\n                    col,\n                    OrdinalEncoder(\n                        categories=[ordinal_mappings[col]],\n                        handle_unknown=\"use_encoded_value\",\n                        unknown_value=np.nan,\n                    ),\n                    [col],\n                )\n            )\n        elif df[col].dtype == \"object\" or (\n            df[col].dtype == \"bool\" or df[col].nunique() == 2\n        ):\n            transformers.append((col, OneHotEncoder(handle_unknown=\"ignore\"), [col]))\n        else:\n            transformers.append((col, StandardScaler(), [col]))\n\n    return ColumnTransformer(transformers)\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.evaluate_model","title":"<code>evaluate_model(pipeline, X_test, y_test)</code>","text":"<p>Evaluate model on test set.</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def evaluate_model(\n    pipeline: Pipeline, X_test: DataFrame, y_test: Series\n) -&gt; Dict[str, float]:\n    \"\"\"Evaluate model on test set.\"\"\"\n    y_test_pred = pipeline.predict_proba(X_test)[:, 1]\n    return {\n        \"test_auc\": float(roc_auc_score(y_test, y_test_pred)),\n        \"test_logloss\": float(log_loss(y_test, y_test_pred)),\n        \"test_auprc\": float(average_precision_score(y_test, y_test_pred)),\n    }\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.evaluate_predictions","title":"<code>evaluate_predictions(y_true, y_pred)</code>","text":"<p>Calculate multiple metrics for given predictions.</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def evaluate_predictions(\n    y_true: npt.NDArray[np.int_], y_pred: npt.NDArray[np.float64]\n) -&gt; FoldResults:\n    \"\"\"Calculate multiple metrics for given predictions.\"\"\"\n    return FoldResults(\n        auc=roc_auc_score(y_true, y_pred),\n        logloss=log_loss(y_true, y_pred),\n        auprc=average_precision_score(y_true, y_pred),\n    )\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.get_dataset_metadata","title":"<code>get_dataset_metadata(X_train, X_valid, X_test, y_train, y_valid, y_test)</code>","text":"<p>Get dataset sizes and class balances.</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def get_dataset_metadata(\n    X_train: DataFrame,\n    X_valid: DataFrame,\n    X_test: DataFrame,\n    y_train: Series,\n    y_valid: Series,\n    y_test: Series,\n) -&gt; Dict[str, Dict[str, Any]]:\n    \"\"\"Get dataset sizes and class balances.\"\"\"\n    return {\n        \"train_valid_test_set_no\": {\n            \"train_set_no\": len(X_train),\n            \"valid_set_no\": len(X_valid),\n            \"test_set_no\": len(X_test),\n        },\n        \"train_valid_test_class_balance\": {\n            \"y_train_class_balance\": calculate_class_balance(y_train),\n            \"y_valid_class_balance\": calculate_class_balance(y_valid),\n            \"y_test_class_balance\": calculate_class_balance(y_test),\n        },\n    }\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.get_feature_metadata","title":"<code>get_feature_metadata(pipeline)</code>","text":"<p>Extract feature names and importances from pipeline.</p>"},{"location":"api/#patientflow.train.classifiers.get_feature_metadata--parameters","title":"Parameters","text":"<p>pipeline : Pipeline     Sklearn pipeline containing feature transformer and classifier</p>"},{"location":"api/#patientflow.train.classifiers.get_feature_metadata--returns","title":"Returns","text":"<p>FeatureMetadata     Dictionary containing feature names and their importance scores (if available)</p>"},{"location":"api/#patientflow.train.classifiers.get_feature_metadata--raises","title":"Raises","text":"<p>AttributeError     If the classifier doesn't support feature importance</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def get_feature_metadata(pipeline: Pipeline) -&gt; FeatureMetadata:\n    \"\"\"\n    Extract feature names and importances from pipeline.\n\n    Parameters\n    ----------\n    pipeline : Pipeline\n        Sklearn pipeline containing feature transformer and classifier\n\n    Returns\n    -------\n    FeatureMetadata\n        Dictionary containing feature names and their importance scores (if available)\n\n    Raises\n    ------\n    AttributeError\n        If the classifier doesn't support feature importance\n    \"\"\"\n    transformed_cols = pipeline.named_steps[\n        \"feature_transformer\"\n    ].get_feature_names_out()\n    classifier = pipeline.named_steps[\"classifier\"]\n\n    # Try different common feature importance attributes\n    if hasattr(classifier, \"feature_importances_\"):\n        importances = classifier.feature_importances_\n    elif hasattr(classifier, \"coef_\"):\n        importances = (\n            np.abs(classifier.coef_[0])\n            if classifier.coef_.ndim &gt; 1\n            else np.abs(classifier.coef_)\n        )\n    else:\n        raise AttributeError(\"Classifier doesn't provide feature importance scores\")\n\n    return {\n        \"feature_names\": [col.split(\"__\")[-1] for col in transformed_cols],\n        \"feature_importances\": importances.tolist(),\n    }\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.initialise_model","title":"<code>initialise_model(model_class, params, xgb_specific_params={'n_jobs': -1, 'eval_metric': 'logloss', 'enable_categorical': True})</code>","text":"<p>Initialize a model with given hyperparameters.</p>"},{"location":"api/#patientflow.train.classifiers.initialise_model--parameters","title":"Parameters","text":"<p>model_class : Type     The classifier class to instantiate params : Dict[str, Any]     Model-specific parameters to set xgb_specific_params : Dict[str, Any], optional     XGBoost-specific default parameters</p>"},{"location":"api/#patientflow.train.classifiers.initialise_model--returns","title":"Returns","text":"<p>Any     Initialized model instance</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def initialise_model(\n    model_class: Type,\n    params: Dict[str, Any],\n    xgb_specific_params: Dict[str, Any] = {\n        \"n_jobs\": -1,\n        \"eval_metric\": \"logloss\",\n        \"enable_categorical\": True,\n    },\n) -&gt; Any:\n    \"\"\"\n    Initialize a model with given hyperparameters.\n\n    Parameters\n    ----------\n    model_class : Type\n        The classifier class to instantiate\n    params : Dict[str, Any]\n        Model-specific parameters to set\n    xgb_specific_params : Dict[str, Any], optional\n        XGBoost-specific default parameters\n\n    Returns\n    -------\n    Any\n        Initialized model instance\n    \"\"\"\n    if model_class == XGBClassifier:\n        model = model_class(**xgb_specific_params)\n        model.set_params(**params)\n    else:\n        model = model_class(**params)\n\n    return model\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.train_classifier","title":"<code>train_classifier(train_visits, valid_visits, test_visits, prediction_time, exclude_from_training_data, grid, ordinal_mappings, visit_col=None, model_class=XGBClassifier, use_balanced_training=True, majority_to_minority_ratio=1.0, calibrate_probabilities=True, calibration_method='sigmoid', single_snapshot_per_visit=True)</code>","text":"<p>Train a single model including data preparation and balancing.</p>"},{"location":"api/#patientflow.train.classifiers.train_classifier--parameters","title":"Parameters:","text":"<p>train_visits : DataFrame     Training visits dataset valid_visits : DataFrame     Validation visits dataset test_visits : DataFrame     Test visits dataset prediction_time : Tuple[int, int]     The prediction time point to use exclude_from_training_data : List[str]     Columns to exclude from training grid : Dict[str, List[Any]]     Parameter grid for hyperparameter tuning ordinal_mappings : Dict[str, List[Any]]     Mappings for ordinal categorical features visit_col : str, optional     Name of the visit column. Required if single_snapshot_per_visit is True. model_class : Type, optional     The classifier class to use. Must be sklearn-compatible with fit() and predict_proba().     Defaults to XGBClassifier. use_balanced_training : bool, default=True     Whether to use balanced training data majority_to_minority_ratio : float, default=1.0     Ratio of majority to minority class samples calibrate_probabilities : bool, default=True     Whether to apply probability calibration to the best model calibration_method : str, default='sigmoid'     Method for probability calibration ('isotonic' or 'sigmoid') single_snapshot_per_visit : bool, default=True     Whether to select only one snapshot per visit. If True, visit_col must be provided.</p>"},{"location":"api/#patientflow.train.classifiers.train_classifier--returns","title":"Returns:","text":"<p>TrainedClassifier     Trained model, including metrics, and feature information</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def train_classifier(\n    train_visits: DataFrame,\n    valid_visits: DataFrame,\n    test_visits: DataFrame,\n    prediction_time: Tuple[int, int],\n    exclude_from_training_data: List[str],\n    grid: Dict[str, List[Any]],\n    ordinal_mappings: Dict[str, List[Any]],\n    visit_col: Optional[str] = None,\n    model_class: Type = XGBClassifier,\n    use_balanced_training: bool = True,\n    majority_to_minority_ratio: float = 1.0,\n    calibrate_probabilities: bool = True,\n    calibration_method: str = \"sigmoid\",\n    single_snapshot_per_visit: bool = True,\n) -&gt; TrainedClassifier:\n    \"\"\"\n    Train a single model including data preparation and balancing.\n\n    Parameters:\n    -----------\n    train_visits : DataFrame\n        Training visits dataset\n    valid_visits : DataFrame\n        Validation visits dataset\n    test_visits : DataFrame\n        Test visits dataset\n    prediction_time : Tuple[int, int]\n        The prediction time point to use\n    exclude_from_training_data : List[str]\n        Columns to exclude from training\n    grid : Dict[str, List[Any]]\n        Parameter grid for hyperparameter tuning\n    ordinal_mappings : Dict[str, List[Any]]\n        Mappings for ordinal categorical features\n    visit_col : str, optional\n        Name of the visit column. Required if single_snapshot_per_visit is True.\n    model_class : Type, optional\n        The classifier class to use. Must be sklearn-compatible with fit() and predict_proba().\n        Defaults to XGBClassifier.\n    use_balanced_training : bool, default=True\n        Whether to use balanced training data\n    majority_to_minority_ratio : float, default=1.0\n        Ratio of majority to minority class samples\n    calibrate_probabilities : bool, default=True\n        Whether to apply probability calibration to the best model\n    calibration_method : str, default='sigmoid'\n        Method for probability calibration ('isotonic' or 'sigmoid')\n    single_snapshot_per_visit : bool, default=True\n        Whether to select only one snapshot per visit. If True, visit_col must be provided.\n\n    Returns:\n    --------\n    TrainedClassifier\n        Trained model, including metrics, and feature information\n    \"\"\"\n    if single_snapshot_per_visit and visit_col is None:\n        raise ValueError(\n            \"visit_col must be provided when single_snapshot_per_visit is True\"\n        )\n\n    # Get snapshots for each set\n    X_train, y_train = prepare_patient_snapshots(\n        train_visits,\n        prediction_time,\n        exclude_from_training_data,\n        visit_col=visit_col,\n        single_snapshot_per_visit=single_snapshot_per_visit,\n    )\n    X_valid, y_valid = prepare_patient_snapshots(\n        valid_visits,\n        prediction_time,\n        exclude_from_training_data,\n        visit_col=visit_col,\n        single_snapshot_per_visit=single_snapshot_per_visit,\n    )\n    X_test, y_test = prepare_patient_snapshots(\n        test_visits,\n        prediction_time,\n        exclude_from_training_data,\n        visit_col=visit_col,\n        single_snapshot_per_visit=single_snapshot_per_visit,\n    )\n\n    # Get dataset metadata before any balancing\n    dataset_metadata = get_dataset_metadata(\n        X_train, X_valid, X_test, y_train, y_valid, y_test\n    )\n\n    # Store original size and positive rate before any balancing\n    original_size = len(X_train)\n    original_positive_rate = y_train.mean()\n\n    if use_balanced_training:\n        pos_indices = y_train[y_train == 1].index\n        neg_indices = y_train[y_train == 0].index\n\n        n_pos = len(pos_indices)\n        n_neg = int(n_pos * majority_to_minority_ratio)\n\n        neg_indices_sampled = np.random.choice(\n            neg_indices, size=min(n_neg, len(neg_indices)), replace=False\n        )\n\n        train_balanced_indices = np.concatenate([pos_indices, neg_indices_sampled])\n        np.random.shuffle(train_balanced_indices)\n\n        X_train = X_train.loc[train_balanced_indices]\n        y_train = y_train.loc[train_balanced_indices]\n\n    # Create balance info after any balancing is done\n    balance_info = create_balance_info(\n        is_balanced=use_balanced_training,\n        original_size=original_size,\n        balanced_size=len(X_train),\n        original_positive_rate=original_positive_rate,\n        balanced_positive_rate=y_train.mean(),\n        majority_to_minority_ratio=majority_to_minority_ratio\n        if use_balanced_training\n        else 1.0,\n    )\n\n    # Initialize best training results with default values\n    best_training = TrainingResults(\n        prediction_time=prediction_time,\n        balance_info=balance_info,\n        # Other fields will use their default empty dictionaries\n    )\n\n    # Initialize best model container\n    best_model = TrainedClassifier(\n        training_results=best_training,\n        pipeline=None,\n        calibrated_pipeline=None,\n    )\n\n    trials_list: List[HyperParameterTrial] = []\n    best_logloss = float(\"inf\")\n\n    for params in ParameterGrid(grid):\n        # Initialize model based on provided class\n        model = initialise_model(model_class, params)\n\n        column_transformer = create_column_transformer(X_train, ordinal_mappings)\n        pipeline = Pipeline(\n            [(\"feature_transformer\", column_transformer), (\"classifier\", model)]\n        )\n\n        cv_results = chronological_cross_validation(\n            pipeline, X_train, y_train, n_splits=5\n        )\n        # Store trial results\n        trials_list.append(\n            HyperParameterTrial(\n                parameters=params.copy(),  # Make a copy to ensure immutability\n                cv_results=cv_results,\n            )\n        )\n\n        if cv_results[\"valid_logloss\"] &lt; best_logloss:\n            best_logloss = cv_results[\"valid_logloss\"]\n            best_model.pipeline = pipeline\n\n            # Get feature metadata if available\n            try:\n                feature_metadata = get_feature_metadata(pipeline)\n                has_feature_importance = True\n            except (AttributeError, NotImplementedError):\n                feature_metadata = {\n                    \"feature_names\": column_transformer.get_feature_names_out().tolist(),\n                    \"feature_importances\": [],\n                }\n                has_feature_importance = False\n\n            # Update training results\n            best_training.training_info = {\n                \"cv_trials\": trials_list,\n                \"features\": {\n                    \"names\": feature_metadata[\"feature_names\"],\n                    \"importances\": feature_metadata[\"feature_importances\"],\n                    \"has_importance_values\": has_feature_importance,\n                },\n                \"dataset_info\": dataset_metadata,\n            }\n\n            if calibrate_probabilities:\n                best_training.calibration_info = {\"method\": calibration_method}\n\n    # Apply probability calibration to the best model if requested\n    if calibrate_probabilities and best_model.pipeline is not None:\n        best_feature_transformer = best_model.pipeline.named_steps[\n            \"feature_transformer\"\n        ]\n        best_classifier = best_model.pipeline.named_steps[\"classifier\"]\n\n        X_valid_transformed = best_feature_transformer.transform(X_valid)\n\n        calibrated_classifier = CalibratedClassifierCV(\n            estimator=best_classifier,\n            method=calibration_method,\n            cv=\"prefit\",\n        )\n        calibrated_classifier.fit(X_valid_transformed, y_valid)\n\n        calibrated_pipeline = Pipeline(\n            [\n                (\"feature_transformer\", best_feature_transformer),\n                (\"classifier\", calibrated_classifier),\n            ]\n        )\n\n        best_model.calibrated_pipeline = calibrated_pipeline\n        best_training.test_results = evaluate_model(calibrated_pipeline, X_test, y_test)\n\n    else:\n        best_training.test_results = evaluate_model(best_model.pipeline, X_test, y_test)\n\n    return best_model\n</code></pre>"},{"location":"api/#patientflow.train.classifiers.train_multiple_classifiers","title":"<code>train_multiple_classifiers(train_visits, valid_visits, test_visits, grid, exclude_from_training_data, ordinal_mappings, prediction_times, model_name='admissions', visit_col='visit_number', calibrate_probabilities=True, calibration_method='isotonic', use_balanced_training=True, majority_to_minority_ratio=1.0)</code>","text":"<p>Train admission prediction models for multiple prediction times.</p> Source code in <code>src/patientflow/train/classifiers.py</code> <pre><code>def train_multiple_classifiers(\n    train_visits: DataFrame,\n    valid_visits: DataFrame,\n    test_visits: DataFrame,\n    grid: Dict[str, List[Any]],\n    exclude_from_training_data: List[str],\n    ordinal_mappings: Dict[str, List[Any]],\n    prediction_times: List[Tuple[int, int]],\n    model_name: str = \"admissions\",\n    visit_col: str = \"visit_number\",\n    calibrate_probabilities: bool = True,\n    calibration_method: str = \"isotonic\",\n    use_balanced_training: bool = True,\n    majority_to_minority_ratio: float = 1.0,\n) -&gt; Dict[str, TrainedClassifier]:\n    \"\"\"Train admission prediction models for multiple prediction times.\"\"\"\n    trained_models: Dict[str, TrainedClassifier] = {}\n\n    for prediction_time in prediction_times:\n        print(f\"\\nProcessing: {prediction_time}\")\n        model_key = get_model_key(model_name, prediction_time)\n\n        # Train model with the new simplified interface\n        best_model = train_classifier(\n            train_visits,\n            valid_visits,\n            test_visits,\n            prediction_time,\n            exclude_from_training_data,\n            grid,\n            ordinal_mappings,\n            visit_col,\n            use_balanced_training=use_balanced_training,\n            majority_to_minority_ratio=majority_to_minority_ratio,\n            calibrate_probabilities=calibrate_probabilities,\n            calibration_method=calibration_method,\n        )\n\n        trained_models[model_key] = best_model\n\n    return trained_models\n</code></pre>"},{"location":"api/#patientflow.train.emergency_demand","title":"<code>emergency_demand</code>","text":""},{"location":"api/#patientflow.train.emergency_demand.main","title":"<code>main(data_folder_name=None)</code>","text":"<p>Main entry point for training patient flow models.</p> <p>Parameters:</p> Name Type Description Default <code>data_folder_name</code> <code>str</code> <p>Name of data folder</p> <code>None</code> Source code in <code>src/patientflow/train/emergency_demand.py</code> <pre><code>def main(data_folder_name=None):\n    \"\"\"\n    Main entry point for training patient flow models.\n\n    Args:\n        data_folder_name (str, optional): Name of data folder\n    \"\"\"\n    # Parse arguments if not provided\n    if data_folder_name is None:\n        args = parse_args()\n        data_folder_name = (\n            data_folder_name if data_folder_name is not None else args.data_folder_name\n        )\n    print(f\"Loading data from folder: {data_folder_name}\")\n\n    project_root = set_project_root()\n\n    # Set file locations\n    data_file_path, _, model_file_path, config_path = set_file_paths(\n        project_root=project_root,\n        inference_time=False,\n        train_dttm=None,\n        data_folder_name=data_folder_name,\n        config_file=\"config.yaml\",\n    )\n\n    # Load parameters\n    config = load_config_file(config_path)\n\n    # Extract parameters\n    prediction_times = config[\"prediction_times\"]\n    start_training_set = config[\"start_training_set\"]\n    start_validation_set = config[\"start_validation_set\"]\n    start_test_set = config[\"start_test_set\"]\n    end_test_set = config[\"end_test_set\"]\n    prediction_window = config[\"prediction_window\"]\n    epsilon = float(config[\"epsilon\"])\n    yta_time_interval = config[\"yta_time_interval\"]\n    x1, y1, x2, y2 = config[\"x1\"], config[\"y1\"], config[\"x2\"], config[\"y2\"]\n\n    # Load data\n    ed_visits = load_data(\n        data_file_path=data_file_path,\n        file_name=\"ed_visits.csv\",\n        index_column=\"snapshot_id\",\n        sort_columns=[\"visit_number\", \"snapshot_date\", \"prediction_time\"],\n        eval_columns=[\"prediction_time\", \"consultation_sequence\", \"final_sequence\"],\n    )\n    inpatient_arrivals = load_data(\n        data_file_path=data_file_path, file_name=\"inpatient_arrivals.csv\"\n    )\n\n    # Create snapshot date\n    ed_visits[\"snapshot_date\"] = pd.to_datetime(ed_visits[\"snapshot_date\"]).dt.date\n\n    # Set up model parameters\n    grid_params = {\"n_estimators\": [30], \"subsample\": [0.7], \"colsample_bytree\": [0.7]}\n\n    exclude_columns = [\n        \"visit_number\",\n        \"snapshot_date\",\n        \"prediction_time\",\n        \"specialty\",\n        \"consultation_sequence\",\n        \"final_sequence\",\n    ]\n\n    ordinal_mappings = {\n        \"age_group\": [\n            \"0-17\",\n            \"18-24\",\n            \"25-34\",\n            \"35-44\",\n            \"45-54\",\n            \"55-64\",\n            \"65-74\",\n            \"75-102\",\n        ],\n        \"latest_acvpu\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n        \"latest_obs_manchester_triage_acuity\": [\n            \"Blue\",\n            \"Green\",\n            \"Yellow\",\n            \"Orange\",\n            \"Red\",\n        ],\n        \"latest_obs_objective_pain_score\": [\n            \"Nil\",\n            \"Mild\",\n            \"Moderate\",\n            \"Severe\\\\E\\\\Very Severe\",\n        ],\n        \"latest_obs_level_of_consciousness\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n    }\n\n    specialties = [\"surgical\", \"haem/onc\", \"medical\", \"paediatric\"]\n    cdf_cut_points = [0.9, 0.7]\n    curve_params = (x1, y1, x2, y2)\n    random_seed = 42\n\n    # Call train_all_models with prepared parameters\n    train_all_models(\n        visits=ed_visits,\n        start_training_set=start_training_set,\n        start_validation_set=start_validation_set,\n        start_test_set=start_test_set,\n        end_test_set=end_test_set,\n        yta=inpatient_arrivals,\n        model_file_path=model_file_path,\n        prediction_times=prediction_times,\n        prediction_window=prediction_window,\n        yta_time_interval=yta_time_interval,\n        epsilon=epsilon,\n        curve_params=curve_params,\n        grid_params=grid_params,\n        exclude_columns=exclude_columns,\n        ordinal_mappings=ordinal_mappings,\n        specialties=specialties,\n        cdf_cut_points=cdf_cut_points,\n        random_seed=random_seed,\n    )\n\n    return\n</code></pre>"},{"location":"api/#patientflow.train.emergency_demand.test_real_time_predictions","title":"<code>test_real_time_predictions(visits, models, prediction_window, specialties, cdf_cut_points, curve_params, random_seed)</code>","text":"<p>Test real-time predictions by selecting a random sample from the visits dataset and generating predictions using the trained models.</p>"},{"location":"api/#patientflow.train.emergency_demand.test_real_time_predictions--parameters","title":"Parameters","text":"<p>visits : pd.DataFrame     DataFrame containing visit data with columns including 'prediction_time',     'snapshot_date', and other required features for predictions. models : Tuple[Dict[str, TrainedClassifier], SequencePredictor, WeightedPoissonPredictor]     Tuple containing:     - trained_classifiers: TrainedClassifier containing admission predictions     - spec_model: SequencePredictor for specialty predictions     - yet_to_arrive_model: WeightedPoissonPredictor for yet-to-arrive predictions prediction_window : int     Size of the prediction window in minutes for which to generate forecasts. specialties : list[str]     List of specialty names to generate predictions for (e.g., ['surgical',     'medical', 'paediatric']). cdf_cut_points : list[float]     List of probability thresholds for cumulative distribution function     cut points (e.g., [0.9, 0.7]). curve_params : tuple[float, float, float, float]     Parameters (x1, y1, x2, y2) defining the curve used for predictions. random_seed : int     Random seed for reproducible sampling of test cases.</p>"},{"location":"api/#patientflow.train.emergency_demand.test_real_time_predictions--returns","title":"Returns","text":"<p>dict     Dictionary containing:     - 'prediction_time': str, The time point for which predictions were made     - 'prediction_date': str, The date for which predictions were made     - 'realtime_preds': dict, The generated predictions for the sample</p>"},{"location":"api/#patientflow.train.emergency_demand.test_real_time_predictions--raises","title":"Raises","text":"<p>Exception     If real-time inference fails, with detailed error message printed before     system exit.</p>"},{"location":"api/#patientflow.train.emergency_demand.test_real_time_predictions--notes","title":"Notes","text":"<p>The function selects a single random row from the visits DataFrame and generates predictions for that specific time point using all provided models. The predictions are made using the create_predictions() function with the specified parameters.</p> Source code in <code>src/patientflow/train/emergency_demand.py</code> <pre><code>def test_real_time_predictions(\n    visits,\n    models: Tuple[\n        Dict[str, TrainedClassifier], SequencePredictor, WeightedPoissonPredictor\n    ],\n    prediction_window,\n    specialties,\n    cdf_cut_points,\n    curve_params,\n    random_seed,\n):\n    \"\"\"\n    Test real-time predictions by selecting a random sample from the visits dataset\n    and generating predictions using the trained models.\n\n    Parameters\n    ----------\n    visits : pd.DataFrame\n        DataFrame containing visit data with columns including 'prediction_time',\n        'snapshot_date', and other required features for predictions.\n    models : Tuple[Dict[str, TrainedClassifier], SequencePredictor, WeightedPoissonPredictor]\n        Tuple containing:\n        - trained_classifiers: TrainedClassifier containing admission predictions\n        - spec_model: SequencePredictor for specialty predictions\n        - yet_to_arrive_model: WeightedPoissonPredictor for yet-to-arrive predictions\n    prediction_window : int\n        Size of the prediction window in minutes for which to generate forecasts.\n    specialties : list[str]\n        List of specialty names to generate predictions for (e.g., ['surgical',\n        'medical', 'paediatric']).\n    cdf_cut_points : list[float]\n        List of probability thresholds for cumulative distribution function\n        cut points (e.g., [0.9, 0.7]).\n    curve_params : tuple[float, float, float, float]\n        Parameters (x1, y1, x2, y2) defining the curve used for predictions.\n    random_seed : int\n        Random seed for reproducible sampling of test cases.\n\n    Returns\n    -------\n    dict\n        Dictionary containing:\n        - 'prediction_time': str, The time point for which predictions were made\n        - 'prediction_date': str, The date for which predictions were made\n        - 'realtime_preds': dict, The generated predictions for the sample\n\n    Raises\n    ------\n    Exception\n        If real-time inference fails, with detailed error message printed before\n        system exit.\n\n    Notes\n    -----\n    The function selects a single random row from the visits DataFrame and\n    generates predictions for that specific time point using all provided models.\n    The predictions are made using the create_predictions() function with the\n    specified parameters.\n    \"\"\"\n    # Select random test set row\n    random_row = visits.sample(n=1, random_state=random_seed)\n    prediction_time = random_row.prediction_time.values[0]\n    prediction_date = random_row.snapshot_date.values[0]\n\n    # Get prediction snapshots\n    prediction_snapshots = visits[\n        (visits.prediction_time == prediction_time)\n        &amp; (visits.snapshot_date == prediction_date)\n    ]\n\n    trained_classifiers, spec_model, yet_to_arrive_model = models\n\n    # Find the model matching the required prediction time\n    classifier = None\n    for model_key, trained_model in trained_classifiers.items():\n        if trained_model.training_results.prediction_time == prediction_time:\n            classifier = trained_model\n            break\n\n    if classifier is None:\n        raise ValueError(f\"No model found for prediction time {prediction_time}\")\n\n    try:\n        x1, y1, x2, y2 = curve_params\n        _ = create_predictions(\n            models=(classifier, spec_model, yet_to_arrive_model),\n            prediction_time=prediction_time,\n            prediction_snapshots=prediction_snapshots,\n            specialties=specialties,\n            prediction_window_hrs=prediction_window / 60,\n            cdf_cut_points=cdf_cut_points,\n            x1=x1,\n            y1=y1,\n            x2=x2,\n            y2=y2,\n        )\n        print(\"Real-time inference ran correctly\")\n    except Exception as e:\n        print(f\"Real-time inference failed due to this error: {str(e)}\")\n        sys.exit(1)\n\n    return\n</code></pre>"},{"location":"api/#patientflow.train.emergency_demand.train_all_models","title":"<code>train_all_models(visits, start_training_set, start_validation_set, start_test_set, end_test_set, yta, prediction_times, prediction_window, yta_time_interval, epsilon, grid_params, exclude_columns, ordinal_mappings, random_seed, visit_col='visit_number', specialties=None, cdf_cut_points=None, curve_params=None, model_file_path=None, save_models=True, test_realtime=True)</code>","text":"<p>Train and evaluate patient flow models.</p>"},{"location":"api/#patientflow.train.emergency_demand.train_all_models--parameters","title":"Parameters","text":"<p>visits : pd.DataFrame     DataFrame containing visit data. yta : pd.DataFrame     DataFrame containing yet-to-arrive data. prediction_times : list     List of times for making predictions. prediction_window : int     Prediction window size in minutes. yta_time_interval : int     Interval size for yet-to-arrive predictions in minutes. epsilon : float     Epsilon parameter for model training. grid_params : dict     Hyperparameter grid for model training. exclude_columns : list     Columns to exclude during training. ordinal_mappings : dict     Ordinal variable mappings for categorical features. random_seed : int     Random seed for reproducibility. visit_col : str, optional     Name of column in dataset that is used to identify a hospital visit (eg visit_number, csn). specialties : list, optional     List of specialties to consider. Required if test_realtime is True. cdf_cut_points : list, optional     CDF cut points for predictions. Required if test_realtime is True. curve_params : tuple, optional     Curve parameters (x1, y1, x2, y2). Required if test_realtime is True. model_file_path : Path, optional     Path to save trained models. Required if save_models is True. save_models : bool, optional     Whether to save the trained models to disk. Defaults to True. test_realtime : bool, optional     Whether to run real-time prediction tests. Defaults to True.</p>"},{"location":"api/#patientflow.train.emergency_demand.train_all_models--returns","title":"Returns","text":"<p>None</p>"},{"location":"api/#patientflow.train.emergency_demand.train_all_models--raises","title":"Raises","text":"<p>ValueError     If save_models is True but model_file_path is not provided,     or if test_realtime is True but any of specialties, cdf_cut_points, or curve_params are not provided.</p>"},{"location":"api/#patientflow.train.emergency_demand.train_all_models--notes","title":"Notes","text":"<p>The function generates model names internally: - \"admissions\": \"admissions\" - \"specialty\": \"ed_specialty\" - \"yet_to_arrive\": f\"yet_to_arrive_{int(prediction_window/60)}_hours\"</p> Source code in <code>src/patientflow/train/emergency_demand.py</code> <pre><code>def train_all_models(\n    visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    yta,\n    prediction_times,\n    prediction_window,\n    yta_time_interval,\n    epsilon,\n    grid_params,\n    exclude_columns,\n    ordinal_mappings,\n    random_seed,\n    visit_col=\"visit_number\",\n    specialties=None,\n    cdf_cut_points=None,\n    curve_params=None,\n    model_file_path=None,\n    save_models=True,\n    test_realtime=True,\n):\n    \"\"\"\n    Train and evaluate patient flow models.\n\n    Parameters\n    ----------\n    visits : pd.DataFrame\n        DataFrame containing visit data.\n    yta : pd.DataFrame\n        DataFrame containing yet-to-arrive data.\n    prediction_times : list\n        List of times for making predictions.\n    prediction_window : int\n        Prediction window size in minutes.\n    yta_time_interval : int\n        Interval size for yet-to-arrive predictions in minutes.\n    epsilon : float\n        Epsilon parameter for model training.\n    grid_params : dict\n        Hyperparameter grid for model training.\n    exclude_columns : list\n        Columns to exclude during training.\n    ordinal_mappings : dict\n        Ordinal variable mappings for categorical features.\n    random_seed : int\n        Random seed for reproducibility.\n    visit_col : str, optional\n        Name of column in dataset that is used to identify a hospital visit (eg visit_number, csn).\n    specialties : list, optional\n        List of specialties to consider. Required if test_realtime is True.\n    cdf_cut_points : list, optional\n        CDF cut points for predictions. Required if test_realtime is True.\n    curve_params : tuple, optional\n        Curve parameters (x1, y1, x2, y2). Required if test_realtime is True.\n    model_file_path : Path, optional\n        Path to save trained models. Required if save_models is True.\n    save_models : bool, optional\n        Whether to save the trained models to disk. Defaults to True.\n    test_realtime : bool, optional\n        Whether to run real-time prediction tests. Defaults to True.\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        If save_models is True but model_file_path is not provided,\n        or if test_realtime is True but any of specialties, cdf_cut_points, or curve_params are not provided.\n\n    Notes\n    -----\n    The function generates model names internally:\n    - \"admissions\": \"admissions\"\n    - \"specialty\": \"ed_specialty\"\n    - \"yet_to_arrive\": f\"yet_to_arrive_{int(prediction_window/60)}_hours\"\n    \"\"\"\n    # Validate parameters\n    if save_models and model_file_path is None:\n        raise ValueError(\"model_file_path must be provided when save_models is True\")\n\n    if test_realtime:\n        if specialties is None:\n            raise ValueError(\"specialties must be provided when test_realtime is True\")\n        if cdf_cut_points is None:\n            raise ValueError(\n                \"cdf_cut_points must be provided when test_realtime is True\"\n            )\n        if curve_params is None:\n            raise ValueError(\"curve_params must be provided when test_realtime is True\")\n\n    # Set random seed\n    np.random.seed(random_seed)\n\n    # Define model names internally\n    model_names = {\n        \"admissions\": \"admissions\",\n        \"specialty\": \"ed_specialty\",\n        \"yet_to_arrive\": f\"yet_to_arrive_{int(prediction_window/60)}_hours\",\n    }\n\n    if \"arrival_datetime\" in visits.columns:\n        col_name = \"arrival_datetime\"\n    else:\n        col_name = \"snapshot_date\"\n\n    train_visits, valid_visits, test_visits = create_temporal_splits(\n        visits,\n        start_training_set,\n        start_validation_set,\n        start_test_set,\n        end_test_set,\n        col_name=col_name,\n    )\n\n    train_yta, _, _ = create_temporal_splits(\n        yta[(~yta.specialty.isnull())],\n        start_training_set,\n        start_validation_set,\n        start_test_set,\n        end_test_set,\n        col_name=\"arrival_datetime\",\n    )\n\n    # Use predicted_times from visits if not explicitly provided\n    if prediction_times is None:\n        prediction_times = visits.prediction_time.unique()\n\n    # Train admission models\n    admission_models = train_multiple_classifiers(\n        train_visits=train_visits,\n        valid_visits=valid_visits,\n        test_visits=test_visits,\n        grid=grid_params,\n        exclude_from_training_data=exclude_columns,\n        ordinal_mappings=ordinal_mappings,\n        prediction_times=prediction_times,\n        model_name=model_names[\"admissions\"],\n        visit_col=visit_col,\n    )\n\n    # Save admission models if requested\n\n    if save_models:\n        save_model(admission_models, model_names[\"admissions\"], model_file_path)\n\n    # Train specialty model\n    specialty_model = train_sequence_predictor(\n        train_visits=train_visits,\n        model_name=model_names[\"specialty\"],\n        input_var=\"consultation_sequence\",\n        grouping_var=\"final_sequence\",\n        outcome_var=\"specialty\",\n        visit_col=visit_col,\n    )\n\n    # Save specialty model if requested\n    if save_models:\n        save_model(specialty_model, model_names[\"specialty\"], model_file_path)\n\n    # Train yet-to-arrive model\n    yta_model_name = model_names[\"yet_to_arrive\"]\n\n    num_days = (start_validation_set - start_training_set).days\n\n    yta_model = train_weighted_poisson_predictor(\n        train_visits=train_visits,\n        train_yta=train_yta,\n        prediction_window=prediction_window,\n        yta_time_interval=yta_time_interval,\n        prediction_times=prediction_times,\n        epsilon=epsilon,\n        num_days=num_days,\n    )\n\n    # Save yet-to-arrive model if requested\n    if save_models:\n        save_model(yta_model, yta_model_name, model_file_path)\n        print(f\"Models have been saved to {model_file_path}\")\n\n    # Test real-time predictions if requested\n    if test_realtime:\n        test_real_time_predictions(\n            visits=visits,\n            models=(admission_models, specialty_model, yta_model),\n            prediction_window=prediction_window,\n            specialties=specialties,\n            cdf_cut_points=cdf_cut_points,\n            curve_params=curve_params,\n            random_seed=random_seed,\n        )\n\n    return\n</code></pre>"},{"location":"api/#patientflow.train.sequence_predictor","title":"<code>sequence_predictor</code>","text":""},{"location":"api/#patientflow.train.sequence_predictor.get_default_visits","title":"<code>get_default_visits(admitted)</code>","text":"<p>Filters a dataframe of patient visits to include only non-pediatric patients.</p> <p>This function identifies and removes pediatric patients from the dataset based on both age criteria and specialty assignment. It automatically detects the appropriate age column format from the provided dataframe.</p>"},{"location":"api/#patientflow.train.sequence_predictor.get_default_visits--parameters","title":"Parameters:","text":"<p>admitted : DataFrame     A pandas DataFrame containing patient visit information. Must include either     'age_on_arrival' or 'age_group' columns, and a 'specialty' column.</p>"},{"location":"api/#patientflow.train.sequence_predictor.get_default_visits--returns","title":"Returns:","text":"<p>DataFrame     A filtered DataFrame containing only non-pediatric patients (adults).</p>"},{"location":"api/#patientflow.train.sequence_predictor.get_default_visits--notes","title":"Notes:","text":"<p>The function automatically detects which age-related columns are present in the dataframe and configures the appropriate filtering logic. It removes patients who are either: 1. Identified as pediatric based on age criteria, or 2. Assigned to a pediatric specialty</p>"},{"location":"api/#patientflow.train.sequence_predictor.get_default_visits--examples","title":"Examples:","text":"<p>adult_visits = get_default_visits(all_patient_visits) print(f\"Reduced from {len(all_patient_visits)} to {len(adult_visits)} adult visits\")</p> Source code in <code>src/patientflow/train/sequence_predictor.py</code> <pre><code>def get_default_visits(admitted: DataFrame) -&gt; DataFrame:\n    \"\"\"\n    Filters a dataframe of patient visits to include only non-pediatric patients.\n\n    This function identifies and removes pediatric patients from the dataset based on\n    both age criteria and specialty assignment. It automatically detects the appropriate\n    age column format from the provided dataframe.\n\n    Parameters:\n    -----------\n    admitted : DataFrame\n        A pandas DataFrame containing patient visit information. Must include either\n        'age_on_arrival' or 'age_group' columns, and a 'specialty' column.\n\n    Returns:\n    --------\n    DataFrame\n        A filtered DataFrame containing only non-pediatric patients (adults).\n\n    Notes:\n    ------\n    The function automatically detects which age-related columns are present in the\n    dataframe and configures the appropriate filtering logic. It removes patients who\n    are either:\n    1. Identified as pediatric based on age criteria, or\n    2. Assigned to a pediatric specialty\n\n    Examples:\n    ---------\n    &gt;&gt;&gt; adult_visits = get_default_visits(all_patient_visits)\n    &gt;&gt;&gt; print(f\"Reduced from {len(all_patient_visits)} to {len(adult_visits)} adult visits\")\n    \"\"\"\n    # Get configuration for categorizing patients based on age columns\n    special_params = create_special_category_objects(admitted.columns)\n\n    # Extract function that identifies non-pediatric patients\n    opposite_special_category_func = special_params[\"special_func_map\"][\"default\"]\n\n    # Determine which category is the special category (should be \"paediatric\")\n    special_category_key = next(\n        key\n        for key, value in special_params[\"special_category_dict\"].items()\n        if value == 1.0\n    )\n\n    # Filter out pediatric patients based on both age criteria and specialty\n    filtered_admitted = admitted[\n        admitted.apply(opposite_special_category_func, axis=1)\n        &amp; (admitted[\"specialty\"] != special_category_key)\n    ]\n\n    return filtered_admitted\n</code></pre>"},{"location":"api/#patientflow.train.sequence_predictor.train_sequence_predictor","title":"<code>train_sequence_predictor(train_visits, model_name, visit_col, input_var, grouping_var, outcome_var)</code>","text":"<p>Train a specialty prediction model.</p> <p>Parameters:</p> Name Type Description Default <code>train_visits</code> <code>DataFrame</code> <p>Training data containing visit information</p> required <code>model_name</code> <code>str</code> <p>Name identifier for the model</p> required <code>visit_col</code> <code>str</code> <p>Column name containing visit identifiers</p> required <code>input_var</code> <code>str</code> <p>Column name for input sequence</p> required <code>grouping_var</code> <code>str</code> <p>Column name for grouping sequence</p> required <code>outcome_var</code> <code>str</code> <p>Column name for target variable</p> required <p>Returns:</p> Type Description <code>SequencePredictor</code> <p>Trained SequencePredictor model</p> Source code in <code>src/patientflow/train/sequence_predictor.py</code> <pre><code>def train_sequence_predictor(\n    train_visits: DataFrame,\n    model_name: str,\n    visit_col: str,\n    input_var: str,\n    grouping_var: str,\n    outcome_var: str,\n) -&gt; SequencePredictor:\n    \"\"\"Train a specialty prediction model.\n\n    Args:\n        train_visits: Training data containing visit information\n        model_name: Name identifier for the model\n        visit_col: Column name containing visit identifiers\n        input_var: Column name for input sequence\n        grouping_var: Column name for grouping sequence\n        outcome_var: Column name for target variable\n\n    Returns:\n        Trained SequencePredictor model\n    \"\"\"\n    visits_single = select_one_snapshot_per_visit(train_visits, visit_col)\n    admitted = visits_single[\n        (visits_single.is_admitted) &amp; ~(visits_single.specialty.isnull())\n    ]\n    filtered_admitted = get_default_visits(admitted)\n\n    filtered_admitted.loc[:, input_var] = filtered_admitted[input_var].apply(\n        lambda x: tuple(x) if x else ()\n    )\n    filtered_admitted.loc[:, grouping_var] = filtered_admitted[grouping_var].apply(\n        lambda x: tuple(x) if x else ()\n    )\n\n    spec_model = SequencePredictor(\n        input_var=input_var,\n        grouping_var=grouping_var,\n        outcome_var=outcome_var,\n    )\n    spec_model.fit(filtered_admitted)\n\n    return spec_model\n</code></pre>"},{"location":"api/#patientflow.train.utils","title":"<code>utils</code>","text":""},{"location":"api/#patientflow.train.utils.save_model","title":"<code>save_model(model, model_name, model_file_path)</code>","text":"<p>Save trained model(s) to disk.</p>"},{"location":"api/#patientflow.train.utils.save_model--parameters","title":"Parameters","text":"<p>model : object or dict     A single model instance or a dictionary of models to save. model_name : str     Base name to use for saving the model(s). model_file_path : Path     Directory path where the model(s) will be saved.</p>"},{"location":"api/#patientflow.train.utils.save_model--returns","title":"Returns","text":"<p>None</p> Source code in <code>src/patientflow/train/utils.py</code> <pre><code>def save_model(model, model_name, model_file_path):\n    \"\"\"\n    Save trained model(s) to disk.\n\n    Parameters\n    ----------\n    model : object or dict\n        A single model instance or a dictionary of models to save.\n    model_name : str\n        Base name to use for saving the model(s).\n    model_file_path : Path\n        Directory path where the model(s) will be saved.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    if isinstance(model, dict):\n        # Handle dictionary of models (e.g., admission models)\n        for name, m in model.items():\n            full_path = model_file_path / name\n            full_path = full_path.with_suffix(\".joblib\")\n            dump(m, full_path)\n    else:\n        # Handle single model (e.g., specialty or yet-to-arrive model)\n        full_path = model_file_path / model_name\n        full_path = full_path.with_suffix(\".joblib\")\n        dump(model, full_path)\n</code></pre>"},{"location":"api/#patientflow.train.weighted_poisson_predictor","title":"<code>weighted_poisson_predictor</code>","text":""},{"location":"api/#patientflow.train.weighted_poisson_predictor.create_yta_filters","title":"<code>create_yta_filters(df)</code>","text":"<p>Create specialty filters for categorizing patients by specialty and age group.</p> <p>This function generates a dictionary of filters based on specialty categories, with special handling for pediatric patients. It uses the SpecialCategoryParams class to determine which specialties correspond to pediatric care.</p>"},{"location":"api/#patientflow.train.weighted_poisson_predictor.create_yta_filters--parameters","title":"Parameters:","text":"<p>df : pandas.DataFrame     DataFrame containing patient data with columns that include either     'age_on_arrival' or 'age_group' for pediatric classification</p>"},{"location":"api/#patientflow.train.weighted_poisson_predictor.create_yta_filters--returns","title":"Returns:","text":"<p>dict     A dictionary mapping specialty names to filter configurations.     Each configuration contains:     - For pediatric specialty: {\"is_child\": True}     - For other specialties: {\"specialty\": specialty_name, \"is_child\": False}</p>"},{"location":"api/#patientflow.train.weighted_poisson_predictor.create_yta_filters--examples","title":"Examples:","text":"<p>df = pd.DataFrame({'patient_id': [1, 2], 'age_on_arrival': [10, 40]}) filters = create_yta_filters(df) print(filters['paediatric']) {'is_child': True} print(filters['medical']) {'specialty': 'medical', 'is_child': False}</p> Source code in <code>src/patientflow/train/weighted_poisson_predictor.py</code> <pre><code>def create_yta_filters(df):\n    \"\"\"\n    Create specialty filters for categorizing patients by specialty and age group.\n\n    This function generates a dictionary of filters based on specialty categories,\n    with special handling for pediatric patients. It uses the SpecialCategoryParams\n    class to determine which specialties correspond to pediatric care.\n\n    Parameters:\n    -----------\n    df : pandas.DataFrame\n        DataFrame containing patient data with columns that include either\n        'age_on_arrival' or 'age_group' for pediatric classification\n\n    Returns:\n    --------\n    dict\n        A dictionary mapping specialty names to filter configurations.\n        Each configuration contains:\n        - For pediatric specialty: {\"is_child\": True}\n        - For other specialties: {\"specialty\": specialty_name, \"is_child\": False}\n\n    Examples:\n    ---------\n    &gt;&gt;&gt; df = pd.DataFrame({'patient_id': [1, 2], 'age_on_arrival': [10, 40]})\n    &gt;&gt;&gt; filters = create_yta_filters(df)\n    &gt;&gt;&gt; print(filters['paediatric'])\n    {'is_child': True}\n    &gt;&gt;&gt; print(filters['medical'])\n    {'specialty': 'medical', 'is_child': False}\n    \"\"\"\n    # Get the special category parameters using the picklable implementation\n    special_params = create_special_category_objects(df.columns)\n\n    # Extract necessary data from the special_params\n    special_category_dict = special_params[\"special_category_dict\"]\n\n    # Create the specialty_filters dictionary\n    specialty_filters = {}\n\n    for specialty, is_paediatric_flag in special_category_dict.items():\n        if is_paediatric_flag == 1.0:\n            # For the paediatric specialty, set `is_child` to True\n            specialty_filters[specialty] = {\"is_child\": True}\n        else:\n            # For other specialties, set `is_child` to False\n            specialty_filters[specialty] = {\"specialty\": specialty, \"is_child\": False}\n\n    return specialty_filters\n</code></pre>"},{"location":"api/#patientflow.train.weighted_poisson_predictor.train_weighted_poisson_predictor","title":"<code>train_weighted_poisson_predictor(train_visits, train_yta, prediction_window, yta_time_interval, prediction_times, num_days, epsilon=1e-06)</code>","text":"<p>Train a yet-to-arrive prediction model.</p> <p>Parameters:</p> Name Type Description Default <code>train_visits</code> <code>DataFrame</code> <p>Visits dataset (used for identifying special categories)</p> required <code>train_yta</code> <code>DataFrame</code> <p>Training data for yet-to-arrive predictions</p> required <code>prediction_window</code> <code>int</code> <p>Time window for predictions</p> required <code>yta_time_interval</code> <code>int</code> <p>Time interval for predictions</p> required <code>prediction_times</code> <code>List[float]</code> <p>List of prediction times</p> required <code>epsilon</code> <code>float</code> <p>Epsilon parameter for model</p> <code>1e-06</code> <code>num_days</code> <code>int</code> <p>Number of days to consider</p> required <p>Returns:</p> Type Description <code>WeightedPoissonPredictor</code> <p>Trained WeightedPoissonPredictor model</p> Source code in <code>src/patientflow/train/weighted_poisson_predictor.py</code> <pre><code>def train_weighted_poisson_predictor(\n    train_visits: DataFrame,\n    train_yta: DataFrame,\n    prediction_window: int,\n    yta_time_interval: int,\n    prediction_times: List[float],\n    num_days: int,\n    epsilon: float = 10e-7,\n) -&gt; WeightedPoissonPredictor:\n    \"\"\"Train a yet-to-arrive prediction model.\n\n    Args:\n        train_visits: Visits dataset (used for identifying special categories)\n        train_yta: Training data for yet-to-arrive predictions\n        prediction_window: Time window for predictions\n        yta_time_interval: Time interval for predictions\n        prediction_times: List of prediction times\n        epsilon: Epsilon parameter for model\n        num_days: Number of days to consider\n\n    Returns:\n        Trained WeightedPoissonPredictor model\n    \"\"\"\n    if train_yta.index.name is None:\n        if \"arrival_datetime\" in train_yta.columns:\n            train_yta.loc[:, \"arrival_datetime\"] = pd.to_datetime(\n                train_yta[\"arrival_datetime\"], utc=True\n            )\n            train_yta.set_index(\"arrival_datetime\", inplace=True)\n\n    elif train_yta.index.name != \"arrival_datetime\":\n        print(\"Dataset needs arrival_datetime column\")\n\n    specialty_filters = create_yta_filters(train_visits)\n\n    yta_model = WeightedPoissonPredictor(filters=specialty_filters)\n    yta_model.fit(\n        train_df=train_yta,\n        prediction_window=prediction_window,\n        yta_time_interval=yta_time_interval,\n        prediction_times=prediction_times,\n        epsilon=epsilon,\n        num_days=num_days,\n    )\n\n    return yta_model\n</code></pre>"},{"location":"notebooks/","title":"About the notebooks","text":""},{"location":"notebooks/#background","title":"Background","text":"<p>The notebooks in this folder demonstrate how you can use the PatientFlow repository. Notebooks combine commentary, code and the results produced by that code. Here's how different audiences can use the notebooks:</p> <ul> <li>As a non-programmer seeking to understand the approach: The narrative sections in each notebook introduce my approach to creating predictive models of emergency demand for a hospital.</li> <li>As a data scientist interested in how to model emergency demand: The code snippets, combined with the narrative, show how I trained, tested and applied my models in Python. The output of each notebook cell shows the results of running the code.</li> <li>As a researcher interested in the patientflow package: The repository contains a Python package that can be installed using an import statement in your code, so that you can use the functions I have developed. The notebooks demonstrate use of the functions in the PatientFlow package.</li> </ul>"},{"location":"notebooks/#outline-of-the-notebooks","title":"Outline of the notebooks","text":"<p>The first notebook explains how to set up your environment to run the notebooks that follow. Instructions are also provided at the bottom of this page.</p> <ul> <li>0_Set_up_your_environment: Shows how to set things up if you want to run these notebooks in a Jupyter environment</li> </ul> <p>I then explain who are the users of predictive models of patient flow.</p> <ul> <li>1_Meet_the_users_of_our_predictions: Talks about the users of patient flow predictions in acute hospitals.</li> </ul> <p>A series of notebooks on patient snapshots.</p> <ul> <li>2a_Create_patient_snapshots: Shows how to convert finished hospital visits into patient snapshots.</li> <li>2b_Predict_using_patient_snapshots: Shows how to make predictions using patient snapshots, handling multiple visits for a single patient, and multiple snapshots in a single visit.</li> <li>2c_Evaluate_patient_snapshot_models: Demonstrates the use of convenient function to help you evaluate predictive models trained on patient snapshots.</li> <li>2d_Explore_the_datasets_provided: Provides exploratory plots of the two datasets that accompany this repository.</li> </ul> <p>Two notebooks on group snapshots.</p> <ul> <li>3a_Prepare_group_snapshots: Show how to create group snapshots from patient snapshots.</li> </ul> <p>A set of notebooks follow, to show how we have used the functions in <code>patientflow</code> at UCLH to predict number of beds needed for emergency demand.</p> <ul> <li>4_Specify_emergency_demand_model: Explains design choices that were made to develop a practical model, and shows an example of the output that is sent five times a day at UCLH.</li> <li>4a_Predict_probability_of_admission_from_ED: Shows how to train a machine learning model to predict a patient's probability of admission using patient data from the Emergency Department (ED). This includes dividing the data into training, validation, and testing sets, as well as into subsets based on the time of day the predictions are made, applying an XGBoost model for predictions, and saving the models for future use.</li> <li>4b_Predict_demand_from_patients_in_ED Shows how to convert patient-level admission probabilities into a predictions of overall bed demand</li> <li>4c_Predict_probability_of_admission_to_specialty: Shows how to train a model predicting specialty of admission; a sequence of consultation requests is mapped to a probability of being admitted to one of three specialties: medical, surgical, and haematology/oncology, with paediatric patients (under 18) handled differently</li> <li>4d_Predict_demand_from_patients_yet_to_arrive: Shows the use of a time-varying weighted Poisson distribution to predict a number of patients yet to arrive to the ED within a prediction window (say 8 hours). Demonstrates the use of a function that will assume ED performance targets are met when predicting the number admitted by the end of the prediction window</li> <li>4e_Predict_probabiity_of_admission_using_minimal_data: Shows an example of doing live inference using the models trained in the previous steps</li> <li>4f_Bring_it_all_together: Shows an example of doing live inference using the models trained in the previous steps</li> </ul>"},{"location":"notebooks/#preparing-your-notebook-environment","title":"Preparing your notebook environment","text":"<p>The <code>PATH_TO_PATIENTFLOW</code> environment variable needs to be set so notebooks know where the patientflow repository resides on your computer. You have various options:</p> <ul> <li>use a virtual environment and set PATH_TO_PATIENTFLOW up within that</li> <li>set PATH_TO_PATIENTFLOW globally on your computer</li> <li>let each notebook infer PATH_TO_PATIENTFLOW from the location of the notebook file, or specify it within the notebook</li> </ul>"},{"location":"notebooks/#to-set-the-path_to_patientflow-environment-variable-within-your-virtual-environment","title":"To set the PATH_TO_PATIENTFLOW environment variable within your virtual environment","text":"<p>Conda environments</p> <p>Add PATH_TO_PATIENTFLOW to the <code>environment.yml</code> file:</p> <pre><code>variables:\n  PATH_TO_PATIENTFLOW: /path/to/patientflow\n</code></pre> <p>venv environment</p> <p>Add path_to_patientflow to the venv activation script:</p> <pre><code>echo 'export PATH_TO_PATIENTFLOW=/path/to/patientflow' &gt;&gt; venv/bin/activate  # Linux/Mac\necho 'set PATH_TO_PATIENTFLOW=/path/to/patientflow' &gt;&gt; venv/Scripts/activate.bat  # Windows\n</code></pre> <p>The environment variable will be set whenever you activate the virtual environment and unset when you deactivate it. Replace /path/to/patientflow with your repository path.</p>"},{"location":"notebooks/#to-set-the-project_root-environment-variable-from-within-each-notebook","title":"To set the project_root environment variable from within each notebook","text":"<p>A function called <code>set_project_root()</code> can be run in each notebook. If you include the name of a environment variable as shown below, the function will look in your global environment for a variable of this name.</p> <p>Alternatively, if you call the function without any arguments, the function will try to infer the location of the patientflow repo from your currently active path.</p> <pre><code># to specify an environment variable that has been set elsewhere\nproject_root = set_project_root(env_var =\"PATH_TO_PATIENTFLOW\")\n\n# to let the notebook infer the path\nproject_root = set_project_root()\n\n</code></pre> <p>You can also set an environment variable from within a notebook cell:</p> <p>Linux/Mac:</p> <pre><code>%env PATH_TO_PATIENTFLOW=/path/to/patientflow\n</code></pre> <p>Windows:</p> <pre><code>%env PATH_TO_PATIENTFLOW=C:\\path\\to\\patientflow\n</code></pre> <p>Replace /path/to/patientflow with the actual path to your cloned repository.</p>"},{"location":"notebooks/#to-set-project_root-environment-variable-permanently-on-your-system","title":"To set project_root environment variable permanently on your system","text":"<p>Linux/Mac:</p> <pre><code># Add to ~/.bashrc or ~/.zshrc:\nexport PATH_TO_PATIENTFLOW=/path/to/patientflow\n</code></pre> <p>Windows:</p> <pre><code>Open System Properties &gt; Advanced &gt; Environment Variables\nUnder User Variables, click New\nVariable name: PATH_TO_PATIENTFLOW\nVariable value: C:\\path\\to\\patientflow\nClick OK\n</code></pre> <p>Replace /path/to/patientflow with your repository path. Restart your terminal/IDE after setting.</p>"},{"location":"notebooks/0_Set_up_your_environment/","title":"Set up your environment","text":"<p>Skip this notebook if you are just browsing. </p> <p>In this notebook I will explain where the code looks for data and saves models and media by default, and suggest how to set up your environment. There are two README files that may be useful:</p> <ul> <li>Repository README in the root of the repository</li> <li>Notebooks README in this folder</li> </ul>"},{"location":"notebooks/0_Set_up_your_environment/#set-notebook-to-reload-functions-every-time-a-cell-is-fun","title":"Set notebook to reload functions every time a cell is fun","text":"<p>This is useful if you make any changes to any underlying code</p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre>"},{"location":"notebooks/0_Set_up_your_environment/#check-that-the-patientflow-package-has-been-installed","title":"Check that the patientflow package has been installed","text":"<pre><code>try:\n   import patientflow\n   print(f\"\u2713 patientflow {patientflow.__version__} imported successfully\")\nexcept ImportError:\n   print(\"\u274c patientflow not found - please check installation instructions in README\")\n   print(\"   pip install -e '.[test]'\")\nexcept Exception as e:\n   print(f\"\u274c Error: {e}\")\n</code></pre> <pre><code>\u2713 patientflow 0.1.0 imported successfully\n</code></pre>"},{"location":"notebooks/0_Set_up_your_environment/#set-project_root-variable","title":"Set project_root variable","text":"<p>The variable called project_root tells the notebooks where the patientflow repository resides on your computer. All paths in the notebooks are set relative to project_root. There are various ways to set it, which are described in the notebooks README. </p> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/0_Set_up_your_environment/#set-file-paths","title":"Set file paths","text":"<p>Now that you have set the project root, you can specify where the data will be loaded from, where images and models are saved, and where to load the config file from. By default, a function called <code>set_file_paths()</code> sets these as shown here. </p> <pre><code># Basic checks\nprint(f\"patientflow version: {patientflow.__version__}\")\nprint(f\"Repository root: {project_root}\")\n\n# Verify data access\ndata_folder_name = 'data-synthetic'\ndata_file_path = project_root / data_folder_name\nif data_file_path.exists():\n    print(\"\u2713 Synthetic data found\")\nelse:\n    print(\"Synthetic data not found - check repository structure\")\n</code></pre> <pre><code>patientflow version: 0.1.0\nRepository root: /Users/zellaking/Repos/patientflow\n\u2713 Synthetic data found\n</code></pre> <p>The function will set file paths to default values, as shown here. You can override these as required. </p> <pre><code>from patientflow.load import set_file_paths\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(project_root, \n               data_folder_name=data_folder_name)\n</code></pre> <pre><code>Configuration will be loaded from: /Users/zellaking/Repos/patientflow/config.yaml\nData files will be loaded from: /Users/zellaking/Repos/patientflow/data-synthetic\nTrained models will be saved to: /Users/zellaking/Repos/patientflow/trained-models/synthetic\nImages will be saved to: /Users/zellaking/Repos/patientflow/trained-models/synthetic/media\n</code></pre>"},{"location":"notebooks/0_Set_up_your_environment/#summary","title":"Summary","text":"<p>In this notebook you have seen </p> <ul> <li>how to configure your environment to run these notebooks</li> <li>where the notebooks expect to find data, and where they will save models and media, by default</li> </ul> <p>Now you are ready to explore the data that has been provided with this repository</p>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/","title":"Introducing our users","text":"<p>This repository offers predictive modelling to support the management of patient flow in hospitals. </p>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/#what-is-patient-flow","title":"What is patient flow?","text":"<p>Hospitals refer to the streams of patients arriving and leaving as \u2018patient flow\u2019. Unplanned admissions create the \u2018emergency\u2019 flow, and the hospital must accommodate that flow alongside a flow of \u2018elective\u2019 or planned admissions. Sometimes outflows are reduced because patients are waiting for care to become available in another setting. \u00a0</p> <p>There are various ways people are admitted to a hospital specialty: </p> <ul> <li>via the Accident &amp; Emergency Department, which is referred to by hospitals as the ED (Emergency Department). Some patients are admitted after visiting Same Day Emergency Care (SDEC). Here, we refer to the combined flows from ED and SDEC as coming via the ED</li> <li>as planned (or elective) admissions </li> <li>as an emergency admission via another route, like a transfer from another hospital</li> <li>as an internal transfer from another specialty in the same hospital</li> </ul> <p>And various ways people leave a hospital specialty: </p> <ul> <li>as a discharge from hospital, to home or another care setting</li> <li>as an internal transfer to another specialty within the same hospital</li> <li>as a death</li> </ul> <p>If patient flow works well, each patient will receive timely and appropriate care from the right specialty team, without undue delays. An example of poor patient flow is when incoming patients experience delays to admission because inpatients are not being discharged.</p> <p>Due to imbalances in admissions and discharges, pressures can build up in certain parts of the hospital, while other parts remain relatively less pressured. When one specialty is under pressure, new patients may be housed in the wrong ward - ie a ward that is not dedicated to the specialty they are under. In this case they are referred to as 'outliers'. Outlying is not ideal; evidence indicates it can lead to worse clinical outcomes and longer stays in hospitals. </p> <p>Hospitals strive to keep patient flow going, across all specialties, so far as they are able to. </p>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/#who-is-responsible-for-managing-patient-flow","title":"Who is responsible for managing patient flow?","text":"<p>All hospital staff share responsibility for patient flow, but a team of bed managers takes primary responsibility for managing it. Bed managers are usually senior nurses with a good understanding of each patient's likely care needs. Their work involves responding to rapidly changing situations caused by delays in patient care, infection outbreaks, excess demand for beds, and other incidents.</p> <p>To keep track of the changing situation, bed managers convene \"flow huddles\" three times a day. In these huddles, staff from the emergency department and from each ward meet with bed managers to discuss patients coming in (as either emergency or planned admissions), and review which inpatients are likely to be discharged. The flow huddles provide a picture of likely areas of pressure on beds.</p> <p>If bed pressures are anticipated, bed managers can take action by trying to accelerate discharges, or opening  up temporary beds and finding staff to cover them, or temporarily divert ambulances to another hospital. These decisions have consequences for patients, staff and other hospitals. </p>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/#what-information-do-bed-managers-use-to-manage-patient-flow","title":"What information do bed managers use to manage patient flow?","text":"<p>Bed managers' decisions depend on having a clear picture of current capacity and imminent pressures.  They like to know how many beds will be needed for new patients by the end of the day or shift, and how many will become available during that time. To predict how many beds will be needed today, they assume the number will be the same as yesterday. To work out how many patients will leave, they apply a simple rule based on patients' expected dates of discharge. </p> <p>These are simple rules of thumb, that are based on static information. Many hospitals have Electronic Health Records (EHRs), into which data are being entered all the time. That up-to-date information could provide a better view; bed managers' understanding of the current situation, and their projection of how it will develop, could be refreshed as new information comes into the EHR. </p>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/#what-modelling-is-useful-to-bed-managers","title":"What modelling is useful to bed managers?","text":"<p>I'm Zella King, a health data scientist in the Clinical Operational Research Unit (CORU) at University College London. I started working with University College London Hospital (UCLH) in 2020 because the hospital wanted to make better use of the data streaming into its EHR. My colleague Prof Sonya Crowe led a small project to create a prototype of a predictive model of emergency demand that used real-time data. Through that project, and over the subsequent years, we have come to understand the needs of bed managers from predictive modelling. </p> <p>What bed managers want from predictive models</p> <ul> <li> <p>Predictions issued at the times of day they need them:   Our users have a routine where they prepare a situation report of hospital capacity five times each day, and have flow huddles three times a day. They wanted predictions of bed demand to be available to them in the preparation of the reports, and at the flow huddles. </p> </li> <li> <p>Predictions over a rolling window:   The current heuristics used widely across the NHS rely on daily averages, which means that a patient flow meeting will focus on projections up to midnight that day. A rolling prediction of 8 to 12 hours is more useful, because it enables conversation about what needs to be done during the current day or night shift, in order to head off pressures later.  </p> </li> <li> <p>Output at aggregate level rather than individual:   It is common for researchers using statistics or Machine Learning to produce models that predict each patient's probability of admission. However, this is not useful for bed managers because, when managing capacity, they are mainly interested in overall numbers of beds needed, rather than whether any particular patient will be admitted.</p> </li> <li> <p>Predictions that are based on real-time data from the Electronic Health Record (EHR):   Predictive models can be trained on historical patterns of admissions and discharges. However, if they can make use of real-time data from the EHR, bed managers will have a better sense of today's demand, rather than that of a typical day.</p> </li> <li> <p>A breakdown of demand by specialty:   Knowing that the whole hospital is going to be short of beds is somewhat useful and does give a sense of the scale of the problem. More precise information - about which specialties are most affected - makes it easier to pinpoint where action is needed. </p> </li> <li> <p>Some sense of the uncertainty of predictions:   Simple heuristics give bed managers a single number to work with. For example, if 50 patients were admitted yesterday, they might plan for 50 today. This doesn't show how likely the number 50 is; could it be 46 or 54? A good model will give a sense of uncertainty around the suggested number of beds.  Ironically, knowing the spread of the uncertainty gives a more certain picture.</p> </li> </ul>"},{"location":"notebooks/1_Meet_the_users_of_our_predictions/#what-are-the-elements-of-patient-flow","title":"What are the elements of patient flow?","text":"<p>Above, I said that bed managers want a breakdown of demand by specialty. Let's break down the sources of that demand. </p> <p>I intend that this repository will show how to model all of these flows eventually. </p>"},{"location":"notebooks/2a_Create_patient_snapshots/","title":"Create patient-level snapshots","text":""},{"location":"notebooks/2a_Create_patient_snapshots/#about-snapshots","title":"About snapshots","text":"<p><code>patientflow</code> is organised around the following concepts:</p> <ul> <li>Prediction time: A moment in the day at which predictions are to be made, for example 09:30.</li> <li>Patient snapshot: A summary of data from the EHR capturing is known about a single patient at the prediction time. Each patient snapshot has a date and a prediction time associated with it.</li> <li>Group snaphot: A set of patients snapshots. Each group snapshot has a date and a prediction time associated with it.</li> <li>Prediction window: A period of hours that begins at the prediction time.</li> </ul> <p>Its intended use is with data on hospital visits that are unfinished, to predict whether some outcome (admission from A&amp;E, discharge from hospital, or transfer to another clinical specialty) will happen within the prediction window. What the outcome is doesn't really matter; the same methods can be used. </p> <p>The utility of our approach - and the thing that makes it very generalisable - is that we then build up from the patient-level predictions into a predictions for a whole cohort of patients at a point in time. That step is what creates useful information for bed managers. I show this in later notebooks.</p> <p>To use <code>patientflow</code> your data should be in snapshot form. Here I suggest how to you might prepare your data, starting from past hospital visits that have already finished. I'm going to use some fake data on Emergency Department visits, and imagine that we want to predict whether a patient will be admitted to a ward after they leave the ED, or discharged from hospital. </p> <p>NOTE: In practice, how to whether a patient was admitted after the ED visit, and when they were ready to be admitted, can be tricky. How do you account for the fact that the patient may wait in the ED for a bed, due to lack of available beds? Likewise, if you are trying to predict discharge at the end of a hospital visit, should that that be the time they were ready to leave, or the time they actually left? Discharge delays are common, due to waiting for medication or transport, or waiting for onward care provision to become available. </p> <p>The outcome that you are aiming for will depend on your setting. You may have to infer when a patient was ready from available data. Suffice to say, think carefully about what it is you are trying to predict, and how you will identify that outcome in data. </p>"},{"location":"notebooks/2a_Create_patient_snapshots/#creating-fake-finished-visits","title":"Creating fake finished visits","text":"<p>I'll start by loading some fake data resembling structure of EHR data on Emergency Department (ED) visits. In my fake data, each visit has one row, with an arrival time at the ED, a discharge time from the ED, the patient's age and an outcome of whether they were admitted after the ED visit. </p> <p>The <code>is_admitted</code> column is our label, indicating the outcome in this imaginary case. </p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</code></pre> <pre><code>from patientflow.generate import create_fake_finished_visits\nvisits_df, _, _ = create_fake_finished_visits('2023-01-01', '2023-04-01', 25)\n\nprint(f'There are {len(visits_df)} visits in the fake dataset, with arrivals between {visits_df.arrival_datetime.min().date()} and {visits_df.arrival_datetime.max().date()} inclusive.')\nvisits_df.head()\n</code></pre> <pre><code>There are 2253 visits in the fake dataset, with arrivals between 2023-01-01 and 2023-03-31 inclusive.\n</code></pre> patient_id visit_number arrival_datetime departure_datetime is_admitted age 0 1658 14 2023-01-01 03:31:47 2023-01-01 08:00:47 0 30 1 238 20 2023-01-01 04:25:57 2023-01-01 07:43:57 1 61 2 354 1 2023-01-01 05:21:43 2023-01-01 08:52:43 1 86 3 114 3 2023-01-01 08:01:26 2023-01-01 09:38:26 0 33 4 497 10 2023-01-01 08:20:52 2023-01-01 11:20:52 0 59"},{"location":"notebooks/2a_Create_patient_snapshots/#create-snapshots-from-fake-data","title":"Create snapshots from fake data","text":"<p>My goal is to create snapshots of these visits. First, I define the times of day I will be issuing predictions at. </p> <pre><code>prediction_times = [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)] # each time is expressed as a tuple of (hour, minute)\n</code></pre> <p>Then using the code below I create an array of all the snapshot dates in some date range that my data covers.</p> <pre><code>from datetime import datetime, time, timedelta, date\n\n# Create date range\nsnapshot_dates = []\nstart_date = date(2023, 1, 1)\nend_date = date(2023, 4, 1)\n\ncurrent_date = start_date\nwhile current_date &lt; end_date:\n    snapshot_dates.append(current_date)\n    current_date += timedelta(days=1)\n\nprint('First ten snapshot dates')\nsnapshot_dates[0:10]\n</code></pre> <pre><code>First ten snapshot dates\n\n\n\n\n\n[datetime.date(2023, 1, 1),\n datetime.date(2023, 1, 2),\n datetime.date(2023, 1, 3),\n datetime.date(2023, 1, 4),\n datetime.date(2023, 1, 5),\n datetime.date(2023, 1, 6),\n datetime.date(2023, 1, 7),\n datetime.date(2023, 1, 8),\n datetime.date(2023, 1, 9),\n datetime.date(2023, 1, 10)]\n</code></pre> <p>Next I iterate through the date array, using the arrival and departure times from the hospital visits table to identify any patients who were in the ED at the prediction time (eg 09:30 or 12.00 on each date). </p> <pre><code>import pandas as pd\n\n\n# Create empty list to store results for each snapshot date\npatient_shapshot_list = []\n\n# For each combination of date and time\nfor date_val in snapshot_dates:\n    for hour, minute in prediction_times:\n        snapshot_datetime = datetime.combine(date_val, time(hour=hour, minute=minute))\n\n        # Filter dataframe for this snapshot\n        mask = (visits_df[\"arrival_datetime\"] &lt;= snapshot_datetime) &amp; (\n            visits_df[\"departure_datetime\"] &gt; snapshot_datetime\n        )\n        snapshot_df = visits_df[mask].copy()\n\n        # Skip if no patients at this time\n        if len(snapshot_df) == 0:\n            continue\n\n        # Add snapshot information columns\n        snapshot_df[\"snapshot_date\"] = date_val\n        snapshot_df[\"prediction_time\"] = [(hour, minute)] * len(snapshot_df)\n\n        patient_shapshot_list.append(snapshot_df)\n\n# Combine all results into single dataframe\nsnapshots_df = pd.concat(patient_shapshot_list, ignore_index=True)\n\n# Name the index snapshot_id\nsnapshots_df.index.name = \"snapshot_id\"\n</code></pre> <p>Note that each record in the snapshots dataframe is indexed by a unique snapshot_id. </p> <pre><code>snapshots_df.head()\n</code></pre> patient_id visit_number arrival_datetime departure_datetime is_admitted age snapshot_date prediction_time snapshot_id 0 1658 14 2023-01-01 03:31:47 2023-01-01 08:00:47 0 30 2023-01-01 (6, 0) 1 238 20 2023-01-01 04:25:57 2023-01-01 07:43:57 1 61 2023-01-01 (6, 0) 2 354 1 2023-01-01 05:21:43 2023-01-01 08:52:43 1 86 2023-01-01 (6, 0) 3 114 3 2023-01-01 08:01:26 2023-01-01 09:38:26 0 33 2023-01-01 (9, 30) 4 497 10 2023-01-01 08:20:52 2023-01-01 11:20:52 0 59 2023-01-01 (9, 30) <p>Some patients are present at more than one of the prediction times, given them more than one entry in snapshots_df</p> <pre><code>snapshots_df.visit_number.value_counts()\n</code></pre> <pre><code>visit_number\n1784    4\n1342    3\n1432    3\n1292    3\n1604    3\n       ..\n777     1\n787     1\n774     1\n770     1\n2238    1\nName: count, Length: 1675, dtype: int64\n</code></pre> <pre><code># Displaying the snapshots for a visit with multiple snapshots\nexample_visit_number = snapshots_df.visit_number.value_counts().index[0]\nsnapshots_df[snapshots_df.visit_number == example_visit_number]\n\n</code></pre> patient_id visit_number arrival_datetime departure_datetime is_admitted age snapshot_date prediction_time snapshot_id 1512 459 1784 2023-03-13 05:47:42 2023-03-13 18:59:42 0 48 2023-03-13 (6, 0) 1513 459 1784 2023-03-13 05:47:42 2023-03-13 18:59:42 0 48 2023-03-13 (9, 30) 1518 459 1784 2023-03-13 05:47:42 2023-03-13 18:59:42 0 48 2023-03-13 (12, 0) 1525 459 1784 2023-03-13 05:47:42 2023-03-13 18:59:42 0 48 2023-03-13 (15, 30)"},{"location":"notebooks/2a_Create_patient_snapshots/#creating-fake-finished-visits-a-more-complicated-example","title":"Creating fake finished visits - a more complicated example","text":"<p>In an EHR, information about the patient accumulates as the ED visit progresses. Patients may visit various locations in the ED, such as triage, where their acuity is recorded, and they have various different things done to them, like measurements of vital signs or lab tests. </p> <p>The function below returns three fake dataframes, meant to resemble EHR data. </p> <ul> <li>hospital visit</li> <li>observations - with a single measurement - a triage score - plus a timestamp for when that was recorded</li> <li>lab orders - with five types of lab orders plus a timestamp for when that test was requested</li> </ul> <p>The function that creates the fake data returns one triage score for each visit, within 10 minutes of arrival</p> <pre><code>visits_df, observations_df, lab_orders_df = create_fake_finished_visits('2023-01-01', '2023-04-01', 25)\n\nprint(f'There are {len(observations_df)} triage scores in the observations_df dataframe, for {len(observations_df.visit_number.unique())} visits')\nobservations_df.head()\n</code></pre> <pre><code>There are 2253 triage scores in the observations_df dataframe, for 2253 visits\n</code></pre> visit_number observation_datetime triage_score 0 14 2023-01-01 03:35:36.163784 5 1 20 2023-01-01 04:29:37.764451 1 2 1 2023-01-01 05:23:25.286763 2 3 3 2023-01-01 08:10:51.432211 3 4 10 2023-01-01 08:26:20.775693 4 <p>The function that creates the fake data returns a random number of lab tests for each patient, for visits over 2 hours </p> <pre><code>print(f'There are {len(lab_orders_df)} lab orders in the dataset, for {len(lab_orders_df.visit_number.unique())} visits')\nlab_orders_df.head()\n</code></pre> <pre><code>There are 5177 lab orders in the dataset, for 1874 visits\n</code></pre> visit_number order_datetime lab_name 0 14 2023-01-01 03:46:03.833071 CBC 1 20 2023-01-01 04:42:28.890734 CBC 2 20 2023-01-01 05:08:21.224579 D-dimer 3 1 2023-01-01 05:23:31.838338 BMP 4 20 2023-01-01 05:45:18.145241 BMP"},{"location":"notebooks/2a_Create_patient_snapshots/#create-snapshots-from-fake-data-a-more-complicated-example","title":"Create snapshots from fake data - a more complicated example","text":"<p>A function called <code>create_fake_snapshots()</code> will pull information from all three tables. Note that this function has been designed to work with the fake data generated above. You would need to create your own version of this function, to handle the data you have. </p> <pre><code>from datetime import date\nstart_date = date(2023, 1, 1)\nend_date = date(2023, 4, 1)\n\nfrom patientflow.generate import create_fake_snapshots\n\n# Create snapshots\nnew_snapshots_df = create_fake_snapshots(df=visits_df, observations_df=observations_df, lab_orders_df=lab_orders_df, prediction_times=prediction_times, start_date=start_date, end_date=end_date)\nnew_snapshots_df.head()\n</code></pre> snapshot_date prediction_time patient_id visit_number is_admitted age latest_triage_score num_cbc_orders num_d-dimer_orders num_bmp_orders num_urinalysis_orders num_troponin_orders snapshot_id 0 2023-01-01 (6, 0) 1658 14 0 30 5.0 1 0 0 0 0 1 2023-01-01 (6, 0) 238 20 1 61 1.0 1 1 1 0 0 2 2023-01-01 (6, 0) 354 1 1 86 2.0 0 1 1 0 0 3 2023-01-01 (9, 30) 114 3 0 33 3.0 0 0 0 0 0 4 2023-01-01 (9, 30) 497 10 0 59 4.0 0 0 1 0 1 <p>Returning to the example visit above, we can see that at 09:30 on 2023-01-10, the first snapshot for this patient, the triage score had not yet been recorded. This, and the lab orders, were placed between 09:30 and 12:00, so they appear first in the 12:00 snapshot.</p> <pre><code>new_snapshots_df[new_snapshots_df.visit_number==example_visit_number]\n</code></pre> snapshot_date prediction_time patient_id visit_number is_admitted age latest_triage_score num_cbc_orders num_d-dimer_orders num_bmp_orders num_urinalysis_orders num_troponin_orders snapshot_id 1512 2023-03-13 (6, 0) 459 1784 0 48 5.0 0 0 0 0 0 1513 2023-03-13 (9, 30) 459 1784 0 48 5.0 1 0 1 1 0 1518 2023-03-13 (12, 0) 459 1784 0 48 5.0 1 0 1 1 0 1525 2023-03-13 (15, 30) 459 1784 0 48 5.0 1 0 1 1 0"},{"location":"notebooks/2a_Create_patient_snapshots/#conclusion","title":"Conclusion","text":"<p>Here I have shown how to create snapshots from finished patient visits. Note that there is a summarisation element going on. Above, there are counts of the number of lab orders, and the latest triage score. In the same vein, you might just take the last recorded heart rate or oxygen saturation level, or the latest value of a lab result. A snapshot loses some of the richness of the full data in an EHR, but with the benefit that you get data that replicates unfinished visits. </p> <p>You might ask why we don't use time series data, to hang on to that richness. The main reason is that hospital visit data can be very patchy, with a lot of missingness. For example, in the ED, a severely ill patient might have enough heart rate values recorded to constitute a time series, while a non-acute patient (say someone with a sprained ankle) might have one or no heart rate measurements. In the case of predicting probability of admission after ED, the absence of data is revealing in itself. By summarising, snapshots allow us to capture that variation in data completeness. </p> <p>In the next notebook I'll show how to make predictions using patient snapshots.</p>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/","title":"Make predictions using patient-level snapshots","text":""},{"location":"notebooks/2b_Predict_using_patient_snapshots/#things-to-consider-when-training-predictive-models-using-snapshots","title":"Things to consider when training predictive models using snapshots","text":"<p>Random versus temporal splits</p> <p>When dividing your data into training, validation and test sets, a random allocation will make your models appear to perform better than they actually would in practice. This is because random splits ignore the temporal nature of healthcare data, where patterns may change over time. A more realistic approach is to use temporal splits, where you train on earlier data and validate/test on later data, mimicking how the model would be deployed in a real-world setting.</p> <p>Multiple snapshots per visit</p> <p>To use <code>patientflow</code> your data should be in snapshot form. I showed how to create this in the last notebook. I defined a series of prediction times, and then sampled finished visit to get snapshots that represent those visits while still in progress. When you follow this method, you may end up with multiple snapshots. Is this OK, for your analysis? You will need to decide whether you include all snapshots from a single visit into a predictive model. These snapshots from the same visit are inherently correlated, which may violate assumptions of many statistical and machine learning methods. </p> <p>Multiple visits per patient</p> <p>The patient identifier is also important, because if the same patient appears in training and test sets, there is the potential for data leakage. We took the decision to probabilistically allocate each patient to training, validation and test sets, where the probability of being allocated to each set is in proportion to the number of visits they made in any of those time periods. </p> <p><code>patientflow</code> includes functions that handle of all these considerations.</p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#create-fake-snapshots","title":"Create fake snapshots","text":"<p>See the previous notebook for more information about how this is done. </p> <pre><code>from patientflow.generate import create_fake_snapshots\nprediction_times = [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)] \nsnapshots_df=create_fake_snapshots(prediction_times=prediction_times, start_date='2023-01-01', end_date='2023-04-01')\nsnapshots_df.head()\n</code></pre> snapshot_date prediction_time patient_id visit_number is_admitted age latest_triage_score num_bmp_orders num_troponin_orders num_cbc_orders num_urinalysis_orders num_d-dimer_orders snapshot_id 0 2023-01-01 (6, 0) 2690 6 0 49 5.0 0 0 0 0 0 1 2023-01-01 (9, 30) 2471 16 0 76 4.0 1 1 0 0 0 2 2023-01-01 (9, 30) 2987 9 0 58 2.0 1 1 1 1 1 3 2023-01-01 (9, 30) 3472 46 0 63 5.0 0 0 1 0 0 4 2023-01-01 (9, 30) 41 35 0 83 4.0 1 0 0 1 0"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#train-a-model-to-predict-the-outcome-of-each-snapshot","title":"Train a model to predict the outcome of each snapshot","text":"<p>Let's train a model to predict admission for the 9:30 prediction time. We will specify that the triage scores are ordinal, to make use of sklearn's OrdinalEncoder to maintain the natural order of categories. </p> <p>We exclude columns that are not relevant to the prediction of probability of admission, including <code>snapshot_date</code> and <code>prediction_time</code>. Note that here we are trying a different model for each prediction time. That was a design decision, which allows the model to pick up different signals of the outcome at different times of day. You'll see the results of this in later notebooks where I show shap plots for models at different times of day. </p> <p>If the same patient appears in training, validation or test sets, there is the potential for data leakage. The <code>create_temporal_splits()</code> function below will randomly allocate each patient_id to training, validation and test sets, where the probability of being allocated to each is in proportion to the number of visits they made in any of those time periods. </p> <pre><code>from datetime import date   \nfrom patientflow.prepare import create_temporal_splits\n\n# set the temporal split\nstart_training_set = date(2023, 1, 1) \nstart_validation_set = date(2023, 2, 15) # 6 week training set \nstart_test_set = date(2023, 3, 1) # 2 week validation set \nend_test_set = date(2023, 4, 1) # 1 month test set\n\n# create the temporal splits\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    snapshots_df,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\", # states which column contains the date to use when making the splits \n    patient_id=\"patient_id\", # states which column contains the patient id to use when making the splits \n    visit_col=\"visit_number\", # states which column contains the visit number to use when making the splits \n\n)\n\n\n\n</code></pre> <pre><code>Patient Set Overlaps (before random assignment):\nTrain-Valid: 0 of 2158\nValid-Test: 29 of 1513\nTrain-Test: 100 of 2500\nAll Sets: 0 of 3021 total patients\nSplit sizes: [1811, 629, 1242]\n</code></pre> <p>You will need to decide whether you include all snapshots from a single visit into a predictive model. If you do, there will be non-independence in the data. </p> <p>Since we train a different model for each prediction time, then it is only visits spanning more than 24 hours that would have multiple rows. If your snapshots are drawn from visits to ED, this should hopefully not happen too often (though sadly it is becoming more common in the UK). If your snapshots are drawn from inpatient visits, then it is very likely that you will have multiple rows per patient. </p> <p>We took the decision to select one visit at random, even for our ED visits. The function below gives you the option. If you specify <code>single_snapshot_per_visit</code> as True, the function will expect a <code>visit_col</code> parameter. </p> <pre><code>from patientflow.train.classifiers import train_classifier\n\n# exclude columns that are not needed for training\nexclude_from_training_data=['patient_id', 'visit_number', 'snapshot_date', 'prediction_time']\n\n# train the patient-level model\nmodel = train_classifier(\n    train_visits,\n    valid_visits,\n    test_visits,\n    grid={\"n_estimators\": [20, 30, 40]},\n    prediction_time=(9, 30),\n    exclude_from_training_data=exclude_from_training_data,\n    ordinal_mappings={'latest_triage_score': [1, 2, 3, 4, 5]},\n    single_snapshot_per_visit=True,\n    visit_col='visit_number', # as we are using a single snapshot per visit, we need to specify which column contains the visit number\n    use_balanced_training=True,\n    calibrate_probabilities=True,\n    calibration_method='sigmoid'\n)\n\n</code></pre> <p>About the parameters in <code>train_classifer()</code></p> <p>There are a few parameters in this function to explain. </p> <ul> <li><code>grid</code>: specifies the grid to use in hyperparameter tuning.</li> <li><code>prediction_time</code>: is used to identify which patient snapshots to use for training.</li> <li><code>single_snapshot_per_visit</code>: if this is True, the function will randomly pick one snapshot for any visit, using <code>visit_col</code> as the column name that identifies the visit identifier. </li> <li><code>exclude_from_training_data</code>: certain columns in the data should not be used for training, including visit numbers and dates.</li> <li><code>ordinal_mappings</code>: the function makes use of SKLearn's Ordinal Mapping encoder.</li> <li><code>use_balanced_training</code>: in healthcare contexts, there are often fewer observations in the positive class. Set this to True for imbalanced samples (common for ED visits, when most patients are discharged, and for predicting inpatient discharge from hospital when most patients remain). It will downsample the negative class. </li> <li><code>calibrate_probabilities</code>: when you downsample the negative class, it is a good idea to calibrate the probabilities to account for this class imbalance. Setting this to True will apply isotonic regression to calibrate the predicted probabilities, ensuring they better reflect the probabilities in the original data distribution.</li> <li><code>calibration_method</code>: options are sigmoid or isotonic; I have found that sigmoid (the default) works better.</li> </ul> <p>About machine learning choices</p> <p>By default, the function will use an XGBoost classifier, initialised with the hyperparamter grid provided with log loss as the evaluation metric. Chronological ross-validation is used, with the best hyperparameters selected based on minimising log loss in the validation set. We chose XGBoost because it is quick to train, generally performs well, and handles missing values. </p> <p>If you wish to use a different classifer, you can use another parameter,  not shown here:</p> <ul> <li><code>model_class</code> (not shown here):  You can pass your own model in an optional model_class argument, which expects classifier class (like XGBClassifier or other scikit-learn compatible classifiers) that can be instantiated and initialised with the parameters provided</li> </ul>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#inspecting-the-object-returned-by-train_classifier","title":"Inspecting the object returned by <code>train_classifier()</code>","text":"<p>The function returns an object of type TrainedClassifer(). Meta data and metrics from the training process are returned with it. </p> <pre><code>print(f'Object returned is of type: {type(model)}')\n\nprint(f'\\nThe metadata from the training process are returned in the `training_results` attribute:')\nmodel.training_results\n</code></pre> <pre><code>Object returned is of type: &lt;class 'patientflow.model_artifacts.TrainedClassifier'&gt;\n\nThe metadata from the training process are returned in the `training_results` attribute:\n\n\n\n\n\nTrainingResults(prediction_time=(9, 30), training_info={'cv_trials': [HyperParameterTrial(parameters={'n_estimators': 20}, cv_results={'train_auc': np.float64(0.9891000722886609), 'train_logloss': np.float64(0.2401767879184195), 'train_auprc': np.float64(0.9915814710451907), 'valid_auc': np.float64(0.6902652943461767), 'valid_logloss': np.float64(0.7612948055228466), 'valid_auprc': np.float64(0.6423223640376016)}), HyperParameterTrial(parameters={'n_estimators': 30}, cv_results={'train_auc': np.float64(0.9964572270616507), 'train_logloss': np.float64(0.2037677992999191), 'train_auprc': np.float64(0.9968371157941393), 'valid_auc': np.float64(0.6828805304172951), 'valid_logloss': np.float64(0.7965992894598218), 'valid_auprc': np.float64(0.6440393638797277)}), HyperParameterTrial(parameters={'n_estimators': 40}, cv_results={'train_auc': np.float64(0.9986821301541798), 'train_logloss': np.float64(0.17958817128501964), 'train_auprc': np.float64(0.9986379247873801), 'valid_auc': np.float64(0.6922204225513049), 'valid_logloss': np.float64(0.8288787785614758), 'valid_auprc': np.float64(0.6543331451114808)})], 'features': {'names': ['age', 'latest_triage_score', 'num_bmp_orders_0', 'num_bmp_orders_1', 'num_troponin_orders_0', 'num_troponin_orders_1', 'num_cbc_orders_0', 'num_cbc_orders_1', 'num_urinalysis_orders_0', 'num_urinalysis_orders_1', 'num_d-dimer_orders_0', 'num_d-dimer_orders_1'], 'importances': [0.11312869191169739, 0.3690102994441986, 0.11062111705541611, 0.0, 0.10884614288806915, 0.0, 0.11563073843717575, 0.0, 0.0881805568933487, 0.0, 0.09458249062299728, 0.0], 'has_importance_values': True}, 'dataset_info': {'train_valid_test_set_no': {'train_set_no': 299, 'valid_set_no': 106, 'test_set_no': 213}, 'train_valid_test_class_balance': {'y_train_class_balance': {0: 0.7123745819397993, 1: 0.28762541806020064}, 'y_valid_class_balance': {0: 0.6698113207547169, 1: 0.330188679245283}, 'y_test_class_balance': {0: 0.6901408450704225, 1: 0.30985915492957744}}}}, calibration_info={'method': 'sigmoid'}, test_results={'test_auc': 0.7148010719439291, 'test_logloss': 0.5654510176351998, 'test_auprc': 0.5559247479672749}, balance_info={'is_balanced': True, 'original_size': 299, 'balanced_size': 172, 'original_positive_rate': np.float64(0.28762541806020064), 'balanced_positive_rate': np.float64(0.5), 'majority_to_minority_ratio': 1.0})\n</code></pre> <p>To get a better view of what is included within the results, here is a list of the fields returned: </p> <pre><code>from dataclasses import fields\nprint(\"\\nDataclass fields in TrainingResults:\")\nfor field in fields(model.training_results):\n    print(field.name)\n</code></pre> <pre><code>Dataclass fields in TrainingResults:\nprediction_time\ntraining_info\ncalibration_info\ntest_results\nbalance_info\n</code></pre> <p>The prediction time has been saved. </p> <pre><code>print(f'The prediction time is: {model.training_results.prediction_time}')\n</code></pre> <pre><code>The prediction time is: (9, 30)\n</code></pre> <p>An object called training_info contains information related to model training. To simplify the code, I'll assign it to a variable called results. It will tell us the size and class balance of each set </p> <pre><code>results = model.training_results.training_info\n\nprint(f\"The training_info object contains the following keys: {results.keys()}\")\n\nprint(f\"\\nNumber in each set{results['dataset_info']['train_valid_test_set_no']}\")\n\ndef print_class_balance(d):\n    for k in d:\n        print(f\"{k.split('_')[1]}: {d[k][0]:.1%} neg, {d[k][1]:.1%} pos\")\n\n\nprint_class_balance(results['dataset_info']['train_valid_test_class_balance'])\n</code></pre> <pre><code>The training_info object contains the following keys: dict_keys(['cv_trials', 'features', 'dataset_info'])\n\nNumber in each set{'train_set_no': 299, 'valid_set_no': 106, 'test_set_no': 213}\ntrain: 71.2% neg, 28.8% pos\nvalid: 67.0% neg, 33.0% pos\ntest: 69.0% neg, 31.0% pos\n</code></pre> <p>Class balance information is also saved in the training_results, which will store information about the differences between the class balance when forcing the training set to be balanced</p> <pre><code>model.training_results.balance_info\n</code></pre> <pre><code>{'is_balanced': True,\n 'original_size': 299,\n 'balanced_size': 172,\n 'original_positive_rate': np.float64(0.28762541806020064),\n 'balanced_positive_rate': np.float64(0.5),\n 'majority_to_minority_ratio': 1.0}\n</code></pre> <p>And the type of calibration done on balanced samples is saved in training_results also</p> <pre><code>model.training_results.calibration_info\n</code></pre> <pre><code>{'method': 'sigmoid'}\n</code></pre> <p>Results of hyperparameter tuning are saved in a HyperParameterTrial object</p> <pre><code># results are stored in a HyperParameterTrial object\nresults['cv_trials']\n</code></pre> <pre><code>[HyperParameterTrial(parameters={'n_estimators': 20}, cv_results={'train_auc': np.float64(0.9891000722886609), 'train_logloss': np.float64(0.2401767879184195), 'train_auprc': np.float64(0.9915814710451907), 'valid_auc': np.float64(0.6902652943461767), 'valid_logloss': np.float64(0.7612948055228466), 'valid_auprc': np.float64(0.6423223640376016)}),\n HyperParameterTrial(parameters={'n_estimators': 30}, cv_results={'train_auc': np.float64(0.9964572270616507), 'train_logloss': np.float64(0.2037677992999191), 'train_auprc': np.float64(0.9968371157941393), 'valid_auc': np.float64(0.6828805304172951), 'valid_logloss': np.float64(0.7965992894598218), 'valid_auprc': np.float64(0.6440393638797277)}),\n HyperParameterTrial(parameters={'n_estimators': 40}, cv_results={'train_auc': np.float64(0.9986821301541798), 'train_logloss': np.float64(0.17958817128501964), 'train_auprc': np.float64(0.9986379247873801), 'valid_auc': np.float64(0.6922204225513049), 'valid_logloss': np.float64(0.8288787785614758), 'valid_auprc': np.float64(0.6543331451114808)})]\n</code></pre> <pre><code>\n# Find the trial with the lowest validation logloss\nbest_trial = min(results[\"cv_trials\"], key=lambda trial: trial.cv_results['valid_logloss'])\n\n# print the best parameters\nprint(f'The best parameters are: {best_trial.parameters}')\n</code></pre> <pre><code>The best parameters are: {'n_estimators': 20}\n</code></pre> <pre><code>print(f'The results on the test set were:')\nmodel.training_results.test_results\n\n</code></pre> <pre><code>The results on the test set were:\n\n\n\n\n\n{'test_auc': 0.7148010719439291,\n 'test_logloss': 0.5654510176351998,\n 'test_auprc': 0.5559247479672749}\n</code></pre> <p>Note that each record in the snapshots dataframe is indexed by a unique snapshot_id. </p>"},{"location":"notebooks/2b_Predict_using_patient_snapshots/#conclusion","title":"Conclusion","text":"<p>Here I have shown how <code>patientflow</code> can help you</p> <ul> <li>handle multiple snapshots per visit and multiple visits per patient</li> <li>impose a temporal split on your training and test sets, allowing for the point above </li> <li>train a model to predict some later outcome using functions that handle class imbalance and calibration</li> </ul> <p>In the next notice, I show how to evaluate models applied to patient snapshots. </p> <p>A process like this creates a predicted probability of admission for each patient, based on what is known about them at the time of the snapshot. However, bed managers really want predictions for the whole cohort of patients in the ED at a point in time. This is where <code>patientflow</code> comes into its own. In the next notebook, I show how to do this. </p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/","title":"Evaluate models trained on patient-level snapshots","text":""},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#things-to-consider","title":"Things to consider","text":"<p>In the last notebook, I showed how to train models on patient snapshots using <code>patientflow</code>. Now, let's think about how to evaluate those models. </p> <p>When evaluating patient snapshots, we focus on:</p> <ul> <li>How well-calibrated the predicted probabilities are</li> <li>The distribution of these probabilities</li> </ul> <p>We don't focus as much on typical classification metrics like Area under the ROC curve, accuracy or precision/recall. </p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#why-dont-we-focus-on-typical-classification-metrics","title":"Why don't we focus on typical classification metrics?","text":"<p>The ultimate goal is to predict bed count distributions for groups of patients. Bed count distributions will be calculated in two steps</p> <ol> <li>First, we predict the probability of the outcome we are interested in (admission or discharge) for each individual patient, as shown in previous notebooks.</li> <li>Then, we use these probabilities in Bernoulli trials to get bed count distributions. The Bernouill trials step will be shown in later notebooks.</li> </ol> <p>Because of this approach, the accuracy of the probability values matters more than correct classification. That is why we use log loss to optimise our classifiers. </p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#about-the-data-used-in-this-notebook","title":"About the data used in this notebook","text":"<p>I'm going to use real patient data from visits to the Emergency Department (ED) and Same Day Emergency Care (SDEC) unit at UCLH to demonstrate the evaluation. The methods shown will work on any data in the same structure. </p> <p>You can request the datasets that are used here on Zenodo. Alternatively you can use the synthetic data that has been created from the distributions of real patient data. If you don't have the public data, change the argument in the cell below from <code>data_folder_name='data-public'</code> to <code>data_folder_name='data-synthetic'</code>.</p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#loading-real-patient-data","title":"Loading real patient data","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <p>The function below identifies the root of the patientflow repository, in order to locate the folders containing data.</p> <pre><code>import pandas as pd\nfrom patientflow.load import set_file_paths, load_data\n\n# set project root\nfrom patientflow.load import set_project_root\nproject_root = set_project_root()\n\n# set file paths\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n        project_root, \n        data_folder_name='data-public', # change this to data-synthetic if you don't have the public dataset\n        verbose=False) \n\n# load the data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n\n\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre> <p>Inspecting the data that has been loaded, we can see that it is similar in structure to the fake data that was generated on the fly in the previous notebooks. The dates have been pushed into the future, to minimise the likelihood of re-identifcation of patients.</p> <pre><code>ed_visits.head()\n</code></pre> snapshot_date prediction_time visit_number elapsed_los sex age_group arrival_method current_location_type total_locations_visited num_obs num_obs_events num_obs_types num_lab_batteries_ordered has_consultation consultation_sequence visited_majors visited_otf visited_paeds visited_rat visited_resus visited_sdec visited_sdec_waiting visited_unknown visited_utc visited_waiting num_obs_blood_pressure num_obs_pulse num_obs_air_or_oxygen num_obs_glasgow_coma_scale_best_motor_response num_obs_level_of_consciousness num_obs_news_score_result num_obs_manchester_triage_acuity num_obs_objective_pain_score num_obs_subjective_pain_score num_obs_temperature num_obs_oxygen_delivery_method num_obs_pupil_reaction_right num_obs_oxygen_flow_rate num_obs_uclh_sskin_areas_observed latest_obs_pulse latest_obs_respirations latest_obs_level_of_consciousness latest_obs_news_score_result latest_obs_manchester_triage_acuity latest_obs_objective_pain_score latest_obs_temperature lab_orders_bc lab_orders_bon lab_orders_crp lab_orders_csnf lab_orders_ddit lab_orders_ncov lab_orders_rflu lab_orders_xcov latest_lab_results_crea latest_lab_results_hctu latest_lab_results_k latest_lab_results_lac latest_lab_results_na latest_lab_results_pco2 latest_lab_results_ph latest_lab_results_wcc latest_lab_results_alb latest_lab_results_htrt training_validation_test final_sequence is_admitted random_number specialty snapshot_id 0 4/17/2031 (12, 0) 30767 1920 F 55-64 Ambulance majors 4 107 34 34 4 False [] True False False True False False False True False True 2 2 3 2 3 2 1 1 1 2 0 0 0 0 71.0 16.0 A 0.0 Yellow Nil 98.2 False False True False False False False True NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN train [] False 15795 medical 1 4/17/2031 (15, 30) 30767 14520 F 55-64 Ambulance majors 5 138 39 34 6 False [] True False False True False False False True False True 4 5 6 3 6 3 1 1 1 3 0 0 0 0 48.0 16.0 A 0.0 Yellow Nil 98.1 False False True False False False False True 57.0 0.422 3.8 1.0 138.0 4.61 7.474 8.77 NaN NaN train [] False 860 medical 2 12/10/2031 (15, 30) 36297 9180 M 75-102 NaN majors 4 127 12 37 8 False [] True False False True True False False True False False 7 6 7 7 7 6 1 1 1 6 0 0 0 0 63.0 22.0 A 2.0 Orange Nil 97.5 False False True True False False False False 97.0 0.483 4.1 1.2 140.0 4.82 7.433 6.59 NaN NaN test [] False 76820 surgical 3 3/28/2031 (6, 0) 53554 2220 F 35-44 Public Trans rat 3 356 101 57 5 False [] False False False True False False False True False True 15 16 9 1 8 4 1 1 1 7 12 0 0 0 70.0 17.0 A 0.0 Green Mild 97.7 False False True True False False False False NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN train [] False 54886 medical 4 3/28/2031 (9, 30) 53554 14820 F 35-44 Public Trans majors 4 375 107 57 7 False [] True False False True False False False True False True 16 17 10 1 9 5 1 1 1 8 12 0 0 0 65.0 17.0 A 0.0 Green Mild 97.7 False False True True False False True False 68.0 0.379 4.1 1.6 139.0 4.00 7.536 13.03 NaN NaN train [] False 6265 medical <p>The dates for training, validation and test sets that match this dataset are defined in the config file in the root directory of <code>patientflow</code>.</p> <pre><code>#  \nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set = params[\"start_training_set\"]\nprint(f\"Training set starts: {start_training_set}\")\n\nstart_validation_set = params[\"start_validation_set\"]\nprint(f\"Validation set starts: {start_validation_set}\")\n\nstart_test_set = params[\"start_test_set\"] \nprint(f\"Test set starts: {start_test_set}\")\n\nend_test_set = params[\"end_test_set\"]\nprint(f\"Test set ends: {end_test_set}\")\n\n</code></pre> <pre><code>Training set starts: 2031-03-01\nValidation set starts: 2031-09-01\nTest set starts: 2031-10-01\nTest set ends: 2032-01-01\n</code></pre>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#train-one-model-for-each-prediction-time","title":"Train one model for each prediction time","text":"<p>First, we apply the temporal splits as shown in the previous notebook. </p> <pre><code>\n\nfrom datetime import date   \nfrom patientflow.prepare import create_temporal_splits\n\n# create the temporal splits\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\", # states which column contains the date to use when making the splits \n    visit_col=\"visit_number\", # states which column contains the visit number to use when making the splits \n\n)\n\n</code></pre> <pre><code>Split sizes: [53801, 6519, 19494]\n</code></pre> <p>Next we train a model for each prediction time.</p> <pre><code>prediction_times = [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)] \n\nprint(\"\\nNumber of observations for each prediction time\")\nprint(ed_visits.prediction_time.value_counts())\n</code></pre> <pre><code>Number of observations for each prediction time\nprediction_time\n(15, 30)    22279\n(12, 0)     19075\n(22, 0)     18842\n(9, 30)     11421\n(6, 0)       8197\nName: count, dtype: int64\n</code></pre> <p>As shown in the previous notebook, we define ordinal mappings where appropriate. These include:</p> <ul> <li><code>age_group</code> - Age on arrival at the ED, defined in groups</li> <li><code>latest_obs_manchester_triage_acuity</code> - Manchester Triage Score (where blue is the lowest acuity and red the highest)</li> <li><code>latest_obs_objective_pain_score</code> - ranging from nil to very severe </li> <li><code>latest_obs_level_of_consciousness</code> the ACVPU measure of consciousness, where A (aware) and U (unconscious) at are the extremes. </li> </ul> <pre><code>ordinal_mappings = {\n    \"age_group\": [\n        \"0-17\",\n        \"18-24\",\n        \"25-34\",\n        \"35-44\",\n        \"45-54\",\n        \"55-64\",\n        \"65-74\",\n        \"75-102\",\n    ],\n    \"latest_obs_manchester_triage_acuity\": [\n        \"Blue\",\n        \"Green\",\n        \"Yellow\",\n        \"Orange\",\n        \"Red\",\n    ],\n    \"latest_obs_objective_pain_score\": [\n        \"Nil\",\n        \"Mild\",\n        \"Moderate\",\n        \"Severe_Very Severe\",\n    ],\n    \"latest_obs_level_of_consciousness\": [\n        \"A\", #alert\n        \"C\", #confused\n        \"V\", #voice - responds to voice stimulus\n        \"P\", #pain - responds to pain stimulus\n        \"U\" #unconscious - no response to pain or voice stimulus\n    ]    }\n\n</code></pre> <p>In the real data, there are some columns that will be used for predicting admission to specialty, if admitted, that we don't use here. </p> <pre><code>exclude_from_training_data = [ 'snapshot_date', 'prediction_time','visit_number', 'consultation_sequence', 'specialty', 'final_sequence', ]\n</code></pre> <p>We loop through each prediction time, training a model. To start with, we will not balance the dataset. </p> <pre><code>from patientflow.train.classifiers import train_classifier\n\ntrained_models = []  \n\n# Loop through each prediction time\nfor prediction_time in prediction_times:\n    print(f\"Training model for {prediction_time}\")\n    model = train_classifier(\n        train_visits=train_visits,\n        valid_visits=valid_visits,\n        test_visits=test_visits,\n        grid={\"n_estimators\": [20, 30, 40]},\n        exclude_from_training_data=exclude_from_training_data,\n        ordinal_mappings=ordinal_mappings,\n        prediction_time=prediction_time,\n        visit_col=\"visit_number\",\n        calibrate_probabilities=False,\n        use_balanced_training=False,\n    )\n\n    trained_models.append(model)\n</code></pre> <pre><code>(6, 0)\n(9, 30)\n(12, 0)\n(15, 30)\n(22, 0)\n</code></pre>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#inspecting-the-base-model","title":"Inspecting the base model","text":"<p>Below I show three different charts, all showing the calibration and distribution of the models, in slightly different ways. </p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#distribution-plots","title":"Distribution plots","text":"<p>A distribution plot shows the spread of predicted probabilities for positive and negative cases.</p> <ul> <li>X-axis (Predicted Probability): Represents the model's predicted probabilities from 0 to 1.</li> <li>Y-axis (Density): Shows the relative frequency of each probability value.</li> </ul> <p>The plot displays two histograms:</p> <ul> <li>Blue line/area: Distribution of predicted probabilities for negative cases (patients who weren't admitted)</li> <li>Orange line/area: Distribution of predicted probabilities for positive cases (patients who were admitted)</li> </ul> <p>Ideal separation between these distributions indicates a well-performing model:</p> <ul> <li>Negative cases (blue) should cluster toward lower probabilities (left side)</li> <li>Positive cases (orange) should cluster toward higher probabilities (right side)</li> </ul> <p>The degree of overlap between distributions helps assess model discrimination ability. Less overlap suggests the model effectively distinguishes between positive and negative cases, while significant overlap indicates areas where the model struggles to differentiate between outcomes.</p> <p>From the plot below, we see that the model is discriminating poorly, with a high degree of overlap, and very few positive cases at the higher end. </p> <pre><code># without balanced training\nfrom patientflow.viz.distribution_plots import plot_prediction_distributions\nplot_prediction_distributions(\n    trained_models=trained_models,  # Convert dict values to list\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n\n</code></pre> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#calibration-plots","title":"Calibration plots","text":"<p>A calibration plot shows how well a model's predicted probabilities match actual outcomes.</p> <ul> <li>X-axis (Mean Predicted Probability): The model's predicted probabilities, ordered from 0 to 1, grouped into bins, either using the uniform or the quantile strategy (see below).</li> <li>Y-axis (Fraction of Positives): The observed proportion of admissions for visits in that group.</li> </ul> <p>A perfectly calibrated model would align its points along the diagonal line, meaning a 70% predicted probability means the event happens 70% of the time.</p> <p>Uniform vs Quantile Strategies: - Uniform: Divides predictions into equal-width probability bins (e.g., 0.0-0.1, 0.1-0.2), so some bins may have few or many points. - Quantile: Ensures each bin has the same number of predictions, regardless of how wide or narrow each bin's probability range is.</p> <p>Below, we see reasonable calibration at the lower end, but deteriorating towards the higher end.</p> <pre><code># without balanced training\nfrom patientflow.viz.calibration_plot import plot_calibration\n\nplot_calibration(\n    trained_models=trained_models,  # Convert dict values to list\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    strategy=\"quantile\",  # optional\n    suptitle=\"Base model with imbalanced training data\"  # optional\n)\n</code></pre> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#madcap-model-accuracy-diagnostic-calibration-plot","title":"MADCAP (Model Accuracy Diagnostic Calibration Plot)","text":"<p>A MADCAP (Model Accuracy Diagnostic Calibration Plot) visually compares the predicted probabilities from a model with the actual outcomes (e.g., admissions or events) in a dataset. This plot helps to assess how well the model's predicted probabilities align with the observed values.</p> <p>The blue line represents the cumulative predicted outcomes, which are derived by summing the predicted probabilities as we move through the test set, ordered by increasing probability. The orange line represents the cumulative observed outcomes, calculated based on the actual labels in the dataset, averaged over the same sorted order of predicted probabilities.</p> <p>If the model is well calibrated, these two lines will closely follow each other, and the curves will bow to the bottom left. </p> <p>Below, we see that the models under-predict the likelihood of admissions, as the blue line (predicted outcomes) consistently falls below the orange line (actual outcomes). The models are systematically assigning lower probabilities than it should, meaning that (later) we will under-predict the number of beds needed for these patients.</p> <pre><code>## without balanced training\nfrom patientflow.viz.madcap_plot import generate_madcap_plots\ngenerate_madcap_plots(\n    trained_models=trained_models,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n</code></pre> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#inspecting-a-balanced-and-calibrated-model","title":"Inspecting a balanced and calibrated model","text":"<p>In the previous notebook I showed that the <code>train_classifier()</code> function will balance the training set, by under-sampling the negative class, and then re-calibrate the data using the validation set. Below I train the models with these arguments set to true, and re-run the plots. </p> <pre><code>from patientflow.train.classifiers import train_classifier\n\ntrained_models = []  \n\n# Loop through each prediction time\nfor prediction_time in prediction_times:\n    print(f\"Training model for {prediction_time}\")\n    model = train_classifier(\n        train_visits=train_visits,\n        valid_visits=valid_visits,\n        test_visits=test_visits,\n        grid={\"n_estimators\": [20, 30, 40]},\n        exclude_from_training_data=exclude_from_training_data,\n        ordinal_mappings=ordinal_mappings,\n        prediction_time=prediction_time,\n        visit_col=\"visit_number\",\n        calibrate_probabilities=True,\n        calibration_method=\"sigmoid\",\n        use_balanced_training=True,\n    )\n\n    trained_models.append(model)\n\n\n</code></pre> <pre><code>Training model for (6, 0)\nTraining model for (9, 30)\nTraining model for (12, 0)\nTraining model for (15, 30)\nTraining model for (22, 0)\n</code></pre> <p>From the plots below, we see improved discrimination. There are positive cases clustered at the right hand end of the distribution plot, and the MADCAP lines are closer. The model slightly underpredicts at 06:00, 09:30 and 22:00, and slightly overpredicts at 12:00 and 15:30. These improvements have been achieved while maintaining good calibration.   </p> <pre><code>plot_prediction_distributions(\n    trained_models=trained_models,  # Convert dict values to list\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\nplot_calibration(\n    trained_models=trained_models,  # Convert dict values to list\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    strategy=\"quantile\",  # optional\n    suptitle=\"Base model with imbalanced training data\"  # optional\n)\n\ngenerate_madcap_plots(\n    trained_models=trained_models,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n</code></pre> <p></p> <p></p> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#madcap-plots-by-age","title":"MADCAP plots by age","text":"<p>It can be useful to look at sub-categories of patients, to understand whether models perform better for some groups. Here we show MADCAP plots by age group.</p> <p>The performance is worse for children over all. There are fewer of them in the data, which can be seen by comparing the y axis limits. The y axis maximum is the total number of snapshots in the test that were in at the prediction time. In general, there are twice as many adults as over 65s (except at 22:00), and very few children. The models perform poorly for children, and best for adults under 65. They tend to under-predict for older people, especially at 22:00 and 06:00.  </p> <p>Analysis like this helps understand the limitations of the modelling, and consider alternative approaches. For example, we might consider training a different model for older people, if there was enough data, or gathering more training data before deployment. </p> <pre><code>from patientflow.viz.madcap_plot import generate_madcap_plots_by_group\ngenerate_madcap_plots_by_group(\n    trained_models=list(trained_models),\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    grouping_var=\"age_group\",\n    grouping_var_name=\"Age Group\",\n    plot_difference=False\n)\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/2c_Evaluate_patient_snapshot_models/#conclusion","title":"Conclusion","text":"<p>Here I have shown how visualations within <code>patientflow</code> can help you</p> <ul> <li>assess the discrimination and calibration of your models</li> <li>identify areas of weakness in your models by comparing predictions across different patient groups</li> </ul> <p>I have also shown how using balanced training set, and re-calibrating using the validation set, can help to improve the discrimination of models where you start with imbalanced data. This is common in healthcare data. </p> <p>This notebook concludes the set covering patient snapshots. We have created predicted probabilities for each patient, based on what is known about them at the time of the snapshot. However, bed managers really want predictions for the whole cohort of patients at a time. This is where <code>patientflow</code> comes into its own. In the next notebook, I show how to create group snapshots. </p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/","title":"2. Explore the datasets provided","text":"<p>Two datasets have been provided with this repository.  - <code>ed_visits.csv</code>  - <code>inpatient_arrivals.csv</code></p> <p>These accompany my fully worked example of the modelling of emergency demand for beds. But they are also useful to illustrate what patient shapshots might be made up of. </p> <p>This notebook does some data exploration by plotting charts of all relevant variables in each dataset. </p> <p>The <code>inpatient_arrivals</code> dataset contains arrival times of all patients who visited the UCLH Emergency Department (ED) and the Same Day Emergency Care (SDEC) unit, over the period of the data, and were later admitted. It includes their sex, child status (whether adult or child), and a column to assign each one to training, validation and test sets.</p> <p>The <code>ed_visits</code> database contains a set of snapshots of patients who visited the ED and SDEC over the period of the data, including both admitted and discharged patients. Each snapshot includes information known at the time of the snapshot, and excludes anything that was recorded later, except the variables that serve a 'labels' for model training. These are:  - <code>is_admitted</code> - whether the visit ended in admission to a ward - <code>final_sequence</code> - the sequence of consultations the patient had during the visit - <code>specialty</code> - the specialty of the admission, if the patient was admitted</p> <p>See the data dictionaries for detailed information about the variables in the data provided.</p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#learn-more-about-the-data","title":"Learn more about the data","text":"<p>I recorded a webinar to demonstrate how we converted data from the UCLH Electronic Health Record in a form suitable for this modelling. If you click on the image below, the video will open at the point where I provide detail about the datasets </p> <p> </p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#set-up-the-notebook-environment","title":"Set up the notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#load-parameters-and-set-file-paths","title":"Load parameters and set file paths","text":"<p>Parameters are set in config.json and (for UCLH implementation in config-uclh.yaml). You can change these for your own purposes. I'll talk more about the role of each parameter as it becomes relevant. Here we are loading the pre-defned training, validation and test set dates.  </p> <p>For more information about parameters and file paths, see notebook 4a_Predict_probability_of_admission_from_ED.md</p> <pre><code>from patientflow.load import set_file_paths, load_config_file\n\n# indicate whether the notebook is being run locally for UCLH or with public datasets\nuclh = False\n\n# set file paths\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n        project_root, \n        data_folder_name='data-public',  # change this to data-synthetic if you don't have the public dataset\n        verbose=False\n        ) \n\n# load parameters\nparams = load_config_file(config_path)\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#load-data","title":"Load data","text":"<p>This notebook has been run using real data which you can download from Zenodo on request. </p> <p>Alternatively you can use the synthetic data that has been created from the distributions of real patient data. The method used to create the synthetic data was to generate sample values following the statistics reported in the data dictionaries. </p> <p>If you don't have the public data, change the argument in the cell above from <code>data_folder_name='data-public'</code> to <code>data_folder_name='data-synthetic'</code>.</p> <pre><code>import pandas as pd\nfrom patientflow.load import load_data\n\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n\ninpatient_arrivals = load_data(data_file_path, \n                    file_name='inpatient_arrivals.csv', \n                    index_column = 'snapshot_id',)\n\ned_visits.head()\n</code></pre> <pre><code>Warning: Index column 'snapshot_id' not found in dataframe\n</code></pre> snapshot_date prediction_time visit_number elapsed_los sex age_group arrival_method current_location_type total_locations_visited num_obs ... latest_lab_results_na latest_lab_results_pco2 latest_lab_results_ph latest_lab_results_wcc latest_lab_results_alb latest_lab_results_htrt final_sequence is_admitted random_number specialty snapshot_id 0 4/17/2031 (12, 0) 30767 1920 F 55-64 Ambulance majors 4 107 ... NaN NaN NaN NaN NaN NaN [] False 15795 medical 1 4/17/2031 (15, 30) 30767 14520 F 55-64 Ambulance majors 5 138 ... 138.0 4.61 7.474 8.77 NaN NaN [] False 860 medical 2 12/10/2031 (15, 30) 36297 9180 M 75-102 NaN majors 4 127 ... 140.0 4.82 7.433 6.59 NaN NaN [] False 76820 surgical 3 3/28/2031 (6, 0) 53554 2220 F 35-44 Public Trans rat 3 356 ... NaN NaN NaN NaN NaN NaN [] False 54886 medical 4 3/28/2031 (9, 30) 53554 14820 F 35-44 Public Trans majors 4 375 ... 139.0 4.00 7.536 13.03 NaN NaN [] False 6265 medical <p>5 rows \u00d7 68 columns</p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#explore-visits-dataset","title":"Explore visits dataset","text":"<p>Note that each snapshot has a date and a prediction time formatted separately. </p> <pre><code>ed_visits.head(10)\n</code></pre> snapshot_date prediction_time visit_number elapsed_los sex age_group arrival_method current_location_type total_locations_visited num_obs ... latest_lab_results_na latest_lab_results_pco2 latest_lab_results_ph latest_lab_results_wcc latest_lab_results_alb latest_lab_results_htrt final_sequence is_admitted random_number specialty snapshot_id 0 4/17/2031 (12, 0) 30767 1920 F 55-64 Ambulance majors 4 107 ... NaN NaN NaN NaN NaN NaN [] False 15795 medical 1 4/17/2031 (15, 30) 30767 14520 F 55-64 Ambulance majors 5 138 ... 138.0 4.61 7.474 8.77 NaN NaN [] False 860 medical 2 12/10/2031 (15, 30) 36297 9180 M 75-102 NaN majors 4 127 ... 140.0 4.82 7.433 6.59 NaN NaN [] False 76820 surgical 3 3/28/2031 (6, 0) 53554 2220 F 35-44 Public Trans rat 3 356 ... NaN NaN NaN NaN NaN NaN [] False 54886 medical 4 3/28/2031 (9, 30) 53554 14820 F 35-44 Public Trans majors 4 375 ... 139.0 4.00 7.536 13.03 NaN NaN [] False 6265 medical 5 03/05/2031 (22, 0) 60303 14880 M 65-74 NaN rat 6 19 ... NaN NaN NaN NaN NaN NaN ['haem_onc'] False 37194 haem/onc 8 7/17/2031 (12, 0) 62538 50340 F 25-34 Walk-in sdec 6 972 ... NaN NaN NaN NaN NaN NaN ['surgical'] False 16023 surgical 9 7/17/2031 (15, 30) 62538 62940 F 25-34 Walk-in sdec 6 989 ... NaN NaN NaN NaN NaN NaN ['surgical'] False 41090 surgical 6 7/17/2031 (6, 0) 62538 28740 F 25-34 Walk-in sdec 6 920 ... NaN NaN NaN NaN NaN NaN ['surgical'] False 44131 surgical 7 7/17/2031 (9, 30) 62538 41340 F 25-34 Walk-in sdec 6 953 ... NaN NaN NaN NaN NaN NaN ['surgical'] False 60263 surgical <p>10 rows \u00d7 68 columns</p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#grouping-of-columns-in-ed-visits-dataset","title":"Grouping of columns in ED visits dataset","text":"<p>The ED visits dataset contains variables of different types. </p> <p>For convenience, I use a function called <code>get_dict_cols()</code> to organise the charts below into different sections.</p> <pre><code>from patientflow.load import get_dict_cols\ndict_cols = get_dict_cols(ed_visits)\n\nfor key, value in dict_cols.items():\n    print(f\"\\nColumns in group called {key}:\")\n    print(value)\n\n\n</code></pre> <pre><code>Columns in group called not used in training:\n['snapshot_id', 'snapshot_date', 'prediction_time', 'visit_number', 'training_validation_test', 'random_number']\n\nColumns in group called arrival and demographic:\n['elapsed_los', 'sex', 'age_group', 'age_on_arrival', 'arrival_method']\n\nColumns in group called summary:\n['num_obs', 'num_obs_events', 'num_obs_types', 'num_lab_batteries_ordered']\n\nColumns in group called location:\n['current_location_type', 'total_locations_visited', 'visited_majors', 'visited_otf', 'visited_paeds', 'visited_rat', 'visited_resus', 'visited_sdec', 'visited_sdec_waiting', 'visited_unknown', 'visited_utc', 'visited_waiting']\n\nColumns in group called observations:\n['num_obs_blood_pressure', 'num_obs_pulse', 'num_obs_air_or_oxygen', 'num_obs_glasgow_coma_scale_best_motor_response', 'num_obs_level_of_consciousness', 'num_obs_news_score_result', 'num_obs_manchester_triage_acuity', 'num_obs_objective_pain_score', 'num_obs_subjective_pain_score', 'num_obs_temperature', 'num_obs_oxygen_delivery_method', 'num_obs_pupil_reaction_right', 'num_obs_oxygen_flow_rate', 'num_obs_uclh_sskin_areas_observed', 'latest_obs_pulse', 'latest_obs_respirations', 'latest_obs_level_of_consciousness', 'latest_obs_news_score_result', 'latest_obs_manchester_triage_acuity', 'latest_obs_objective_pain_score', 'latest_obs_temperature']\n\nColumns in group called lab orders and results:\n['lab_orders_bc', 'lab_orders_bon', 'lab_orders_crp', 'lab_orders_csnf', 'lab_orders_ddit', 'lab_orders_ncov', 'lab_orders_rflu', 'lab_orders_xcov', 'latest_lab_results_crea', 'latest_lab_results_hctu', 'latest_lab_results_k', 'latest_lab_results_lac', 'latest_lab_results_na', 'latest_lab_results_pco2', 'latest_lab_results_ph', 'latest_lab_results_wcc', 'latest_lab_results_alb', 'latest_lab_results_htrt']\n\nColumns in group called consults:\n['has_consultation', 'consultation_sequence', 'final_sequence', 'specialty']\n\nColumns in group called outcome:\n['is_admitted']\n</code></pre> <p>Also for the plots, I convert the boolean columns to text values.</p> <pre><code># Function to convert boolean columns to text values \"true\" or \"false\" - used for plotting format\ndef bool_to_text(df):\n    bool_cols = df.select_dtypes(include='bool').columns.drop('is_admitted')\n    for col in bool_cols:\n        df[col] = df[col].apply(lambda x: 'true' if x else 'false')\n    return df\n\n# Apply the function\ned_visits = bool_to_text(ed_visits)\n\n# temporarily add a is_admitted column to arrivals \ninpatient_arrivals['is_admitted'] = True\ninpatient_arrivals = bool_to_text(inpatient_arrivals)\n</code></pre> <p>As some variables are ordinal, I create a dictionary to record the ordering of the values. </p> <pre><code>ordinal_mappings = {\n    # age group\n    \"age_group\": [\n        \"0-17\",\n        \"18-24\",\n        \"25-34\",\n        \"35-44\",\n        \"45-54\",\n        \"55-64\",\n        \"65-74\",\n        \"75-102\",\n    ],\n    # triage score\n    \"latest_obs_manchester_triage_acuity\": [\"Blue\", \"Green\", \"Yellow\", \"Orange\", \"Red\"],\n    # pain score\n    \"latest_obs_objective_pain_score\": [\n        r\"Nil\",\n        r\"Mild\",\n        r\"Moderate\",\n        r\"Severe\\E\\Very Severe\",\n    ],\n    # level of consciousness\n    \"latest_obs_level_of_consciousness\": [\n        \"A\", #alert\n        \"C\", #confused\n        \"V\", #voice - responds to voice stimulus\n        \"P\", #pain - responds to pain stimulus\n        \"U\" #unconscious - no response to pain or voice stimulus\n    ]\n}\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#arrival-and-demographic-variables","title":"Arrival and demographic variables","text":"<p>Here I import a function called plot_data_distributions to provide a convenient way of requesting each plot without multiple lines of code for each.</p> <pre><code>from patientflow.viz.distribution_plots import plot_data_distributions\n\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#elapsed-length-of-stay","title":"Elapsed Length of Stay","text":"<p>Both admitted and not admitted visits appear to have a long tail of visits lasting more than 24 hours. Note that the data extraction that has created this dataset has not included any snapshots where the ED visit has lasted more than 72 hours. </p> <pre><code>ed_visits['elapsed_los_hrs'] = ed_visits['elapsed_los']/3600\nplot_data_distributions(df=ed_visits, col_name='elapsed_los_hrs', grouping_var='is_admitted', grouping_var_name='whether patient admitted', plot_type='both',\n                        title = 'Distribution of elapsed length of stay by whether patient admitted')\n</code></pre> <p></p> <p>Note that each record in the snapshots dataframe is indexed by a unique snapshot_id. </p> <p>Plotting only the snapshots where the elapsed visit duration is less than 10 hours shows a jump at around 1 hour. The reason for this is unclear. </p> <pre><code>plot_data_distributions(ed_visits[ed_visits.elapsed_los_hrs &lt; 10], 'elapsed_los_hrs', 'is_admitted', 'whether patient admitted', plot_type='both', \n                        title = 'Distribution of elapsed length of stay by whether patient admitted (where elapsed length of stay &lt; 10 hours)')\n</code></pre> <p></p> <p>Below, I plot the snapshots where the elapsed visit duration is greater than 24 hours. We can see that the long tail of longer visits is more numerous for discharged than for admitted patients. We are not sure why that would be the case. </p> <pre><code>if ed_visits[ed_visits.elapsed_los_hrs &gt;= 24].shape[0] &gt; 0:\n    plot_data_distributions(ed_visits[ed_visits.elapsed_los_hrs &gt;= 24], 'elapsed_los_hrs', 'is_admitted', 'whether patient admitted', plot_type='both',\n                        title = 'Distribution of elapsed length of stay by whether patient admitted (where elapsed length of stay &gt;= 24 hours)')\n</code></pre> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#sex-age-group-and-arrival-method","title":"Sex, age group and arrival method","text":"<p>The charts below show distributions between admitted and not admitted patients for sex, age group and arrival method. More older people are admitted. Most walk-ins are discharged.</p> <pre><code>plot_data_distributions(ed_visits, 'sex', 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p> <pre><code>if 'age_group' in ed_visits.columns:\n    plot_data_distributions(ed_visits, 'age_group', 'is_admitted', 'whether patient admitted', plot_type='hist', ordinal_order=ordinal_mappings['age_group'], rotate_x_labels = True)\nelse:\n    plot_data_distributions(ed_visits, 'age_on_arrival', 'is_admitted', 'whether patient admitted', plot_type='hist')\n\n</code></pre> <p></p> <pre><code>plot_data_distributions(ed_visits, 'arrival_method', 'is_admitted', 'whether patient admitted', plot_type='hist', rotate_x_labels = True)\n</code></pre> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#count-variables","title":"Count variables","text":"<p>The counts variables record the following, up to the moment of the snapshot * the number of observations recorded * the number of events at which observations were recorded (if heart rate and respiratory rate have the same timestamp in the original data, this is one event) * the number of different types of observations (heart rate and respiratory would be two types) * the number of lab test batteries ordered</p> <pre><code>for col_name in dict_cols['summary']:\n    plot_data_distributions(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', is_discrete = True)\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p>There are some extreme values of num_obs and num_obs_events. I might consider removing the outliers, depending on what model is to be applied to the data</p> <pre><code>print(ed_visits.num_obs.max())\nprint(ed_visits.num_obs_events.max())\n</code></pre> <pre><code>989\n266\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#location-variables","title":"Location variables","text":"<p>The variable <code>current_location_type</code> records the location of the patient at the time of the snapshot. Refer to the data dictionary for more information about what each location type means. Patients who visit the UTC (Urgent Treatment Centre) are more likely to be discharged than admitted. The UTC provides care for patients with minor injuries and illnesses.</p> <pre><code>plot_data_distributions(ed_visits, 'current_location_type', 'is_admitted', 'whether patient admitted', plot_type='hist', rotate_x_labels = True)\n</code></pre> <p></p> <pre><code>for col_name in dict_cols['location'][1:]:\n    plot_data_distributions(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#observations-variables","title":"Observations variables","text":"<p>The variables in the observations group record vital signs, triage scores, and also the number of times certain observations have been recorded, up to the moment of the snapshot.</p> <pre><code>dict_cols['observations']\n</code></pre> <pre><code>['num_obs_blood_pressure',\n 'num_obs_pulse',\n 'num_obs_air_or_oxygen',\n 'num_obs_glasgow_coma_scale_best_motor_response',\n 'num_obs_level_of_consciousness',\n 'num_obs_news_score_result',\n 'num_obs_manchester_triage_acuity',\n 'num_obs_objective_pain_score',\n 'num_obs_subjective_pain_score',\n 'num_obs_temperature',\n 'num_obs_oxygen_delivery_method',\n 'num_obs_pupil_reaction_right',\n 'num_obs_oxygen_flow_rate',\n 'num_obs_uclh_sskin_areas_observed',\n 'latest_obs_pulse',\n 'latest_obs_respirations',\n 'latest_obs_level_of_consciousness',\n 'latest_obs_news_score_result',\n 'latest_obs_manchester_triage_acuity',\n 'latest_obs_objective_pain_score',\n 'latest_obs_temperature']\n</code></pre> <p>I first plot the variables that count the number of times something was recorded. </p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#count-variables_1","title":"Count variables","text":"<pre><code>for col_name in [item for item in dict_cols['observations'] if str(item).startswith('num')]:\n    plot_data_distributions(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', is_discrete = True)\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#news-scores-and-manchester-triage-score-values","title":"News Scores and Manchester Triage score values","text":"<p>News Scores are commonly used to track the acuity of a patient, and Manchester Triage scores are used at the door of the ED to prioritise patients</p> <pre><code>for col_name in [item for item in dict_cols['observations'] if ('manchester' in str(item) ) and str(item).startswith('latest')]:\n    plot_data_distributions(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', rotate_x_labels = True, ordinal_order=ordinal_mappings['latest_obs_manchester_triage_acuity'])\n</code></pre> <p></p> <pre><code>plot_data_distributions(ed_visits, 'latest_obs_objective_pain_score', 'is_admitted', 'whether patient admitted', plot_type='hist', rotate_x_labels = True, ordinal_order=ordinal_mappings['latest_obs_objective_pain_score'])\n\n</code></pre> <p></p> <pre><code>\nfor col_name in [item for item in dict_cols['observations'] if 'news' in str(item) and str(item).startswith('latest')]:\n    plot_data_distributions(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', is_discrete = True)\n</code></pre> <p></p> <p>The ACVPU score is commonly used to track states of consciousness</p> <pre><code>for col_name in [item for item in dict_cols['observations'] if 'consciousness' in str(item) and str(item).startswith('latest')]:\n    plot_data_distributions(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', ordinal_order=ordinal_mappings['latest_obs_level_of_consciousness'])\n</code></pre> <p></p> <p>Temporarily excluding the most common value of A from the ACVPU score, we can see the spread of other values</p> <pre><code>for col_name in [item for item in dict_cols['observations'] if 'consciousness' in str(item) and str(item).startswith('latest')]:\n    plot_data_distributions(ed_visits[~(ed_visits.latest_obs_level_of_consciousness == 'A')].copy(), col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', ordinal_order=ordinal_mappings['latest_obs_level_of_consciousness'])\n</code></pre> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#vital-signs-values","title":"Vital signs values","text":"<p>I now plot the distributions of the vital signs values.</p> <pre><code>for col_name in [item for item in dict_cols['observations'] if str(item).startswith('latest') and ('pulse' in str(item) or 'resp' in str(item) or 'temp' in str(item))]:\n    plot_data_distributions(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist', is_discrete = True)\n</code></pre> <p></p> <p></p> <p></p> <p>Above, the temperature range goes as low as 40 degrees, which suggests that the date contain both Celsius and Fahrenheit values. I will need to correct this in the data cleaning process.</p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#lab-variables","title":"Lab variables","text":"<p>The lab variables include boolean values for whether a lab battery was ordered, and the results of certain lab test. The data include only a small a subset of the lab battery orders and test results that might be requested for a patient in the ED. </p> <pre><code>dict_cols['lab orders and results']\n</code></pre> <pre><code>['lab_orders_bc',\n 'lab_orders_bon',\n 'lab_orders_crp',\n 'lab_orders_csnf',\n 'lab_orders_ddit',\n 'lab_orders_ncov',\n 'lab_orders_rflu',\n 'lab_orders_xcov',\n 'latest_lab_results_crea',\n 'latest_lab_results_hctu',\n 'latest_lab_results_k',\n 'latest_lab_results_lac',\n 'latest_lab_results_na',\n 'latest_lab_results_pco2',\n 'latest_lab_results_ph',\n 'latest_lab_results_wcc',\n 'latest_lab_results_alb',\n 'latest_lab_results_htrt']\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#lab-orders","title":"Lab orders","text":"<p>It is notable in the charts below, which show whether a lab battery was ordered, that battery CRP (for markers of inflammation) is very commonly ordered for admitted patients; among the patients later admitted the majority have a CRP battery ordered whereas among the non-admitted patients only a minority have it. This difference between admitted and non-admitted (where the majority of admitted have something while the majority of discharged patients do not) only applies to this lab battery order. It will show up later as a strong predictor of admission.</p> <pre><code>for col_name in [item for item in dict_cols['lab orders and results'] if str(item).startswith('lab') ]:\n    plot_data_distributions(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#lab-results","title":"Lab results","text":"<pre><code>for col_name in [item for item in dict_cols['lab orders and results'] if str(item).startswith('latest') ]:\n    plot_data_distributions(ed_visits, col_name, 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#consults-variables","title":"Consults variables","text":"<p>The <code>has_consultation</code> variable records whether a referral request was made to another service or specialty up to the point of the snapshot. The sequence of referrals up to that point is recorded in <code>consultation_sequence</code> and the final sequence, at the end of the ED visit in <code>final_sequence</code>. <code>specialty</code> records the specialty that the patient was admitted under, if admitted. </p> <p>The first plot shows that the number of admitted patients with consult requests at the time of the snapshots is about the same as those without. The group without consult requests will have their later in the visit, after the snapshot was recorded.</p> <pre><code>plot_data_distributions(ed_visits, 'has_consultation', 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p> <p>A very small number of non-admitted patients have a specialty of admission recorded. These are most likely patients referred from ED to SDEC, which we don't include in the admitted patients.</p> <pre><code>plot_data_distributions(ed_visits, 'specialty', 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#explore-inpatient-arrivals-dataset","title":"Explore inpatient arrivals dataset","text":"<p>The inpatient_arrivals dataset records all of the arrival dates and and times of patients who were later admitted to a ward. Other information is also recorded, such as sex and child status, as will as specialty of admission. This dataset will be used to predict the number of patients yet-to-arrive at the time of prediction. </p> <pre><code>inpatient_arrivals.head()\n</code></pre> training_validation_test arrival_datetime sex specialty is_child is_admitted 0 train 2031-04-24 19:21:00+00:00 M haem/onc false True 1 train 2031-04-25 12:42:00+00:00 F medical false True 2 train 2031-03-20 19:54:00+00:00 F haem/onc false True 3 train 2031-03-04 22:03:00+00:00 F haem/onc false True 4 train 2031-03-01 11:10:44+00:00 M surgical false True <pre><code># temporarily add is_admitted column to arrivals dataset, to be able to use the plot_data_distributions function\ninpatient_arrivals['is_admitted'] = True\nplot_data_distributions(inpatient_arrivals, 'specialty', 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p> <pre><code>plot_data_distributions(inpatient_arrivals, 'is_child', 'is_admitted', 'whether patient admitted', plot_type='hist')\n</code></pre> <p></p>"},{"location":"notebooks/2d_Explore_the_datasets_provided/#summary","title":"Summary","text":"<p>This notebook has shown how to load files that have been provided, and shows some plots of the variables included. This is an illustrative dataset, showing the type of variables that were used for the analysis at UCLH. Other sites will have different data. </p>"},{"location":"notebooks/3a_Prepare_group_snapshots/","title":"Create group snapshots","text":""},{"location":"notebooks/3a_Prepare_group_snapshots/#about-snapshots","title":"About snapshots","text":"<p>Collecting patient snapshots together into a group snapshot is useful when predicting a bed count distribution at a point in time. A group snapshot is a subset of patients who were in the ED on a single snapshot date, at a prediction time.</p> <p>In this notebook, I show how <code>patientflow</code> is designed to work with group snapshots. <code>patientflow</code> divides patient snapshots into their groups, and stores the group snapshots as dictionary with: * <code>snapshot_date</code> as the key * <code>snapshot_ids</code> of each patient snapshot as the values </p> <p>This structure is a convenient way to organise the data when making bed count predictions for different snapshot dates and prediction times, and especially when evaluating those predictions (see next notebook).</p>"},{"location":"notebooks/3a_Prepare_group_snapshots/#about-the-examples-in-this-notebook","title":"About the examples in this notebook","text":"<p>In this notebook I use fake data that resembles visits to the Emergency Department (ED). The dataset covers mutiple snapshot dates and prediction times.</p> <p>To start with a very simple example, I apply a series of Bernoulli trials to one group snapshot and visualise the bed count distribution. In that simple example, every patient has the same probability of the outcome.</p> <p>I then train a model that predicts a probability of admission for each patient. This is a more realistic example, as each patient can have a different probability of admission, based on their data. I apply Bernoulli trials to visualise the predicted distribution of beds needed for those patients. </p> <p>I demonstrate functions in <code>patientflow</code> that handle the preparation of group snapshots for inference. </p> <pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre>"},{"location":"notebooks/3a_Prepare_group_snapshots/#set-up-prediction-times","title":"Set up prediction times","text":"<p>The first step is to specify the times of day at which we want to create predictions. </p> <pre><code>prediction_times = [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)] # each time is expressed as a tuple of (hour, minute)\n</code></pre>"},{"location":"notebooks/3a_Prepare_group_snapshots/#create-patient-snapshots","title":"Create patient snapshots","text":"<p>First I generate some fake data on patients in an Emergency Department (ED). See the 2a_Create_patient_snapshots notebook for more information about to convert finished hospital visits into snapshots. </p> <pre><code>from patientflow.generate import create_fake_snapshots\nprediction_times = [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)] \nsnapshots_df=create_fake_snapshots(prediction_times=prediction_times, \n                                   start_date='2023-01-01', \n                                   end_date='2023-04-01',\n                                   mean_patients_per_day=100)\nsnapshots_df.head()\n\n</code></pre> snapshot_date prediction_time patient_id visit_number is_admitted age latest_triage_score num_cbc_orders num_troponin_orders num_urinalysis_orders num_bmp_orders num_d-dimer_orders snapshot_id 0 2023-01-01 (6, 0) 270 1 0 47 5.0 1 0 0 0 0 1 2023-01-01 (6, 0) 3678 12 1 44 2.0 0 1 1 0 0 2 2023-01-01 (9, 30) 6514 86 0 43 4.0 1 1 0 1 0 3 2023-01-01 (9, 30) 4956 26 0 53 5.0 1 0 1 0 0 4 2023-01-01 (9, 30) 3741 9 1 66 4.0 1 0 0 0 0 <p>Note that each record in the snapshots dataframe is indexed by a unique snapshot_id. </p>"},{"location":"notebooks/3a_Prepare_group_snapshots/#prepare-group-snapshots","title":"Prepare group snapshots","text":"<p><code>patientflow</code> includes a <code>prepare_group_snapshot_dict()</code> function. As input, it requires a pandas dataframe with a <code>snapshot_date</code> column. If a start date and end date are provided, the function will check for any intervening snapshot dates that are missing, and create an empty group snapshot for this date</p> <p>Here I create a group snapshot dictionary, for patients in the ED at 09.30.</p> <pre><code>from patientflow.prepare import prepare_group_snapshot_dict\n\n# select the snapshots to include in the probability distribution, \ngroup_snapshots_dict = prepare_group_snapshot_dict(\n    snapshots_df[snapshots_df.prediction_time == (9,30)]\n    )\n</code></pre> <p>The keys of the dictionary are the <code>snapshot_date</code>. The values are a list of patients in the ED at that time, identified by their unique <code>snapshot_id</code>.</p> <pre><code>print(\"First 10 keys in the snapshots dictionary\")\nprint(list(group_snapshots_dict.keys())[0:10])\n\n</code></pre> <pre><code>First 10 keys in the snapshots dictionary\n[datetime.date(2023, 1, 1), datetime.date(2023, 1, 2), datetime.date(2023, 1, 3), datetime.date(2023, 1, 4), datetime.date(2023, 1, 5), datetime.date(2023, 1, 6), datetime.date(2023, 1, 7), datetime.date(2023, 1, 8), datetime.date(2023, 1, 9), datetime.date(2023, 1, 10)]\n</code></pre> <p>From the first key in the dictionary, we can see the patients belonging to this first snapshot. </p> <pre><code>first_group_snapshot_key = list(group_snapshots_dict.keys())[0]\nfirst_group_snapshot_values = group_snapshots_dict[first_group_snapshot_key]\n\nprint(f\"\\nThere are {len(first_group_snapshot_values)} patients in the first group snapshot\")\n\nprint(\"\\nUnique snapshot_ids in the first group snapshot:\")\nprint(first_group_snapshot_values)\n\n# print(\"\\nPatient snapshots belonging to the first group snapshot:\")\n# snapshots_df.loc[first_group_snapshot_values]\n</code></pre> <pre><code>There are 12 patients in the first group snapshot\n\nUnique snapshot_ids in the first group snapshot:\n[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n</code></pre> <p>We can use the indices to identify the full patient snapshots. </p> <pre><code>snapshots_df.loc[first_group_snapshot_values]\n</code></pre> snapshot_date prediction_time patient_id visit_number is_admitted age latest_triage_score num_cbc_orders num_troponin_orders num_urinalysis_orders num_bmp_orders num_d-dimer_orders snapshot_id 2 2023-01-01 (9, 30) 6514 86 0 43 4.0 1 1 0 1 0 3 2023-01-01 (9, 30) 4956 26 0 53 5.0 1 0 1 0 0 4 2023-01-01 (9, 30) 3741 9 1 66 4.0 1 0 0 0 0 5 2023-01-01 (9, 30) 5287 41 0 60 4.0 1 0 0 0 0 6 2023-01-01 (9, 30) 872 16 0 59 3.0 1 0 0 0 0 7 2023-01-01 (9, 30) 2108 20 1 68 3.0 0 0 0 1 0 8 2023-01-01 (9, 30) 6748 67 0 43 2.0 0 0 1 0 0 9 2023-01-01 (9, 30) 2282 28 1 73 1.0 0 1 1 0 1 10 2023-01-01 (9, 30) 2502 50 0 63 3.0 0 0 0 0 0 11 2023-01-01 (9, 30) 6078 31 1 34 2.0 0 0 0 0 0 12 2023-01-01 (9, 30) 2832 84 1 32 3.0 0 0 0 0 0 13 2023-01-01 (9, 30) 6357 74 0 20 NaN 0 0 0 0 0 <p>More useful is to return not just the indices, but also the data for each visit in the group snapshot. This can be done with the <code>prepare_patient_snapshots</code>, which makes the data ready for processing in groups. This will:</p> <ul> <li>filter out visits to include only those at the requested prediction time</li> <li>randomly select one snapshot per visit, if requested. If <code>single_snapshot_per_visit</code> is set to True, a <code>visit_col</code> argument must be used, given the name of the column containing visit identifiers</li> <li>return a tuple of (X, y) matrices, ready for inference. The column containing the outcome (ie the label) is specified in the <code>label_col</code> argument.  </li> </ul> <pre><code>from patientflow.prepare import prepare_patient_snapshots\n\nfirst_snapshot_X, first_snapshot_y = prepare_patient_snapshots(\n    df=snapshots_df.loc[first_group_snapshot_values], \n    prediction_time=(9,30),\n    single_snapshot_per_visit=False,\n    label_col=\"is_admitted\"\n)\nfirst_snapshot_X\n</code></pre> snapshot_date prediction_time patient_id visit_number age latest_triage_score num_cbc_orders num_troponin_orders num_urinalysis_orders num_bmp_orders num_d-dimer_orders snapshot_id 2 2023-01-01 (9, 30) 6514 86 43 4.0 1 1 0 1 0 3 2023-01-01 (9, 30) 4956 26 53 5.0 1 0 1 0 0 4 2023-01-01 (9, 30) 3741 9 66 4.0 1 0 0 0 0 5 2023-01-01 (9, 30) 5287 41 60 4.0 1 0 0 0 0 6 2023-01-01 (9, 30) 872 16 59 3.0 1 0 0 0 0 7 2023-01-01 (9, 30) 2108 20 68 3.0 0 0 0 1 0 8 2023-01-01 (9, 30) 6748 67 43 2.0 0 0 1 0 0 9 2023-01-01 (9, 30) 2282 28 73 1.0 0 1 1 0 1 10 2023-01-01 (9, 30) 2502 50 63 3.0 0 0 0 0 0 11 2023-01-01 (9, 30) 6078 31 34 2.0 0 0 0 0 0 12 2023-01-01 (9, 30) 2832 84 32 3.0 0 0 0 0 0 13 2023-01-01 (9, 30) 6357 74 20 NaN 0 0 0 0 0"},{"location":"notebooks/3a_Prepare_group_snapshots/#very-simple-example-of-making-a-prediction-for-a-group-snapshot","title":"Very simple example of making a prediction for a group snapshot","text":"<p>Let's make some predictions for this group, in the simplest possible way. We'll give each of them a probability of being admitted of 0.2. </p> <p>This is equivalent to computing the probable outcome of 12 coin flips, with probability of heads of 0.2.</p> <pre><code>from scipy import stats\nprob_dist_data = stats.binom.pmf(range(13), 12, 0.2)\nprob_dist_data\n\n</code></pre> <pre><code>array([6.87194767e-02, 2.06158430e-01, 2.83467842e-01, 2.36223201e-01,\n       1.32875551e-01, 5.31502203e-02, 1.55021476e-02, 3.32188877e-03,\n       5.19045120e-04, 5.76716800e-05, 4.32537600e-06, 1.96608000e-07,\n       4.09600000e-09])\n</code></pre> <pre><code>prob_admission_first_group_snapshot = 0.2*len(first_group_snapshot_values)\n\nfrom patientflow.viz.prob_dist_plot import prob_dist_plot\nfrom patientflow.viz.utils import format_prediction_time\ntitle = (\n    f'Probability distribution for number of beds needed by the '\n    f'{len(first_group_snapshot_values)} patients\\n'\n    f'in the ED at {format_prediction_time((9,30))} '\n    f'on {first_group_snapshot_key} if each patient has a probability of admission of 0.2'\n)\nprob_dist_plot(prob_dist_data, title,  \n    include_titles=True)\n</code></pre> <p></p>"},{"location":"notebooks/3a_Prepare_group_snapshots/#more-realistic-example","title":"More realistic example","text":"<p>In the cell below, I'm using <code>create_temporal_splits()</code> to create a training, validation and test set and <code>train_classifier()</code> to prepare a XGBoost classifier. This classifier will be used to make predictions. See the 2b_Predict_using_patient_snapshots notebook for more on the functions shown here.</p> <pre><code>from datetime import date   \nfrom patientflow.prepare import create_temporal_splits\nfrom patientflow.train.classifiers import train_classifier\n\n# set the temporal split\nstart_training_set = date(2023, 1, 1) \nstart_validation_set = date(2023, 2, 15) # 6 week training set \nstart_test_set = date(2023, 3, 1) # 2 week validation set \nend_test_set = date(2023, 4, 1) # 1 month test set\n\n# create the temporal splits\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    snapshots_df,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\", # states which column contains the date, for use when making the splits \n    patient_id=\"patient_id\", # states which column contains the patient id, for use when making the splits \n    visit_col=\"visit_number\", # states which column contains the visit number to use when making the splits \n\n)\n# exclude columns that are not needed for training\nexclude_from_training_data=['visit_number', 'snapshot_date', 'prediction_time']\n\n# train the patient-level model\nmodel = train_classifier(\n    train_visits,\n    valid_visits,\n    test_visits,\n    grid={\"n_estimators\": [30]},\n    prediction_time=(9, 30),\n    exclude_from_training_data=exclude_from_training_data,\n    ordinal_mappings={'latest_triage_score': [1, 2, 3, 4, 5]},\n    visit_col='visit_number',\n    use_balanced_training=True,\n    calibrate_probabilities=True\n)\n\n</code></pre> <pre><code>Patient Set Overlaps (before random assignment):\nTrain-Valid: 0 of 4338\nValid-Test: 75 of 3019\nTrain-Test: 226 of 5084\nAll Sets: 0 of 6070 total patients\nSplit sizes: [3717, 1216, 2467]\n</code></pre> <p>Now, using the trained model, I will predict a bed count distribution for one snapshot using <code>get_prob_dist_for_prediction_moment()</code>. That function expects the following: </p> <ul> <li><code>X_test</code> - the dataset of patient snapshots to be passed to the model</li> <li><code>y_test</code> - the vector containing the outcome for each patient snapshot</li> <li><code>model</code> - a trained model</li> <li><code>inference_time</code> (defaults to True) - if set to False, the function will calculate the observed outcome for the group snapshot; set this to True if the outcomes for each patient as as yet unknown</li> <li><code>weights</code> - an optional parameter to weight the probabilities returned by the model. This will be demonstrated in later examples</li> </ul> <p>The function returns a dictionary with two keys:</p> <ul> <li><code>agg_predicted</code> contains a predicted probability distribution - in this example, for number of admissions among the patients in the snapshot</li> <li><code>agg_observed</code> counts the number of times the outcome was observed - in this case number of admissions observed</li> </ul> <pre><code>from patientflow.aggregate import get_prob_dist_for_prediction_moment\n\nbed_count_prob_dist = get_prob_dist_for_prediction_moment(\n    first_snapshot_X, \n    model, \n    inference_time=False, \n    y_test=first_snapshot_y\n)\n\nbed_count_prob_dist.keys()\n\n</code></pre> <pre><code>dict_keys(['agg_predicted', 'agg_observed'])\n</code></pre> <p>Using the <code>agg_predicted</code> key, we can plot the probability distribution:</p> <pre><code>from patientflow.viz.prob_dist_plot import prob_dist_plot\nfrom patientflow.viz.utils import format_prediction_time\ntitle = (\n    f'Probability distribution for number of beds needed by the '\n    f'{len(first_snapshot_X)} patients\\n'\n    f'in the ED at {format_prediction_time((9,30))} '\n    f'on {first_group_snapshot_key} using the trained model for prediction'\n)\nprob_dist_plot(bed_count_prob_dist['agg_predicted'], title,  \n    include_titles=True)\n\n</code></pre> <p></p> <p>The <code>prob_dist_plot</code> function will return the figure if requested. For example below, I have added the observed number of admissions for this group snapshot to the figure. </p> <pre><code>fig = prob_dist_plot(bed_count_prob_dist['agg_predicted'], title,  \n    include_titles=True, return_figure=True)\nax = fig.gca()  \nax.axvline(x=bed_count_prob_dist['agg_observed'], color='red', linestyle='--', label='Observed')\nax.legend();\n\n</code></pre> <p></p>"},{"location":"notebooks/3a_Prepare_group_snapshots/#make-predictions-for-group-snapshots","title":"Make predictions for group snapshots","text":"<p>Now we'll make predictions for the whole test set. </p> <pre><code>X_test, y_test = prepare_patient_snapshots(\n    df=snapshots_df, \n    prediction_time=(9,30), \n    single_snapshot_per_visit=False,\n    exclude_columns=exclude_from_training_data, \n    visit_col='visit_number'\n)\n</code></pre> <p>The <code>get_prob_dist</code> function is set up to receive as input a dictionary of group snapshots, created using the <code>prepare_group_snapshot_dict</code> function demonstrated above. It calls <code>get_prob_dist_for_prediction_moment()</code> for each entry in the dictionary. The arguments to <code>get_prob_dist</code> are: </p> <ul> <li><code>snapshots_dict</code> - a snapshots dictionary</li> <li><code>X_test</code> - the dataset of patient snapshots to be passed to the model</li> <li><code>y_test</code> - the vector containing the outcome for each patient snapshot</li> <li><code>model</code> - a trained model</li> <li><code>weights</code> - an optional parameter to weight the probabilities returned by the model. This will be demonstrated in later examples</li> </ul> <p>When calling <code>get_prob_dist_for_prediction_moment</code> the function will set the <code>inference_time</code> parameter to false. </p> <pre><code>from patientflow.aggregate import get_prob_dist\n\ngroup_snapshots_dict = prepare_group_snapshot_dict(\n    test_visits[test_visits.prediction_time == (9,30)]\n    )\n# get probability distribution for this time of day\nprob_dists_for_group_snapshots = get_prob_dist(\n        group_snapshots_dict, X_test, y_test, model\n    )\n</code></pre> <pre><code>Calculating probability distributions for 31 snapshot dates\nThis may take a minute or more\nProcessed 10 snapshot dates\nProcessed 20 snapshot dates\nProcessed 30 snapshot dates\nProcessed 31 snapshot dates\n</code></pre> <p>In the next cell I pick a key at random and visualise the predicted distribution. </p> <pre><code>import random\nrandom_snapshot_date = random.choice(list(prob_dists_for_group_snapshots.keys()))\ntitle = (\n    f'Probability distribution for number of beds needed by the '\n    f'{len(prob_dists_for_group_snapshots[random_snapshot_date][\"agg_predicted\"])} patients\\n'\n    f'in the ED at {format_prediction_time((9,30))} '\n    f'on {random_snapshot_date} using the trained model for prediction'\n)\nfig = prob_dist_plot(prob_dists_for_group_snapshots[random_snapshot_date]['agg_predicted'], title,  \n    include_titles=True, return_figure=True)\nax = fig.gca()  \nax.axvline(x=prob_dists_for_group_snapshots[random_snapshot_date]['agg_observed'], color='red', linestyle='--', label='Observed')\nax.legend();\n</code></pre> <p></p> <p>The returned object is now ready for evaluation, which I cover in the next notebook. </p>"},{"location":"notebooks/3a_Prepare_group_snapshots/#conclusion","title":"Conclusion","text":"<p>In this notebook I have demonstrated the functions in <code>patientflow</code> that handle the preparation of group snapshots. These include: </p> <ul> <li><code>prepare_patient_snapshots</code>, which makes the data ready for processing in groups.</li> <li><code>get_prob_dist_for_prediction_moment</code>, which computes predicted and observed probabilities for a specific snapshot date and prediction time.</li> <li><code>get_prob_dist</code> which computes probability distributions for multiple snapshot dates.</li> </ul> <p>I have also shown the use of <code>prob_dist_plot</code> which can be used to visualise the predicted distribution for one group snapshot.</p>"},{"location":"notebooks/4_Specify_emergency_demand_model/","title":"Specify an emergency demand model","text":"<p>In the first notebook I introduced bed managers and their work. Here I talk about what they need from predictions of emergency demand, and explain choices we made to make the model useful to them.</p>"},{"location":"notebooks/4_Specify_emergency_demand_model/#what-is-emergency-demand-for-beds","title":"What is 'emergency demand for beds'?","text":"<p>There are two ways people are admitted to hospital: </p> <ul> <li>planned (or elective) admissions </li> <li>emergency admissions, typically through the Accident &amp; Emergency Department, which is referred to by hospitals as the ED (Emergency Department). Some patients are admitted after visiting Same Day Emergency Care (SDEC). Here, we refer to the combined ED and SDEC as the ED, since this what UK hospitals typically refer to. </li> </ul> <p>Emergencies are, by definition, unplanned. Most people are discharged after visiting the ED or SDEC, but about 10% are admitted to an emergency bed. This is referred to as 'emergency demand for beds'</p>"},{"location":"notebooks/4_Specify_emergency_demand_model/#why-is-modelling-emergency-demand-for-beds-important","title":"Why is modelling emergency demand for beds important?","text":"<p>Hospitals find it useful to predict how many beds they need on a given day because: * they must make sure they do not admit more people than they can safely care for. If they think they can no longer provide safe care, they take measures like diverting ambulances to other hospitals or cancelling planned procedures * this planning has to take account of emergency patients who have not arrived yet as well as those currently in the ED or SDEC who will need admission * knowing levels of demand helps plan for best use of resources like staffing * if they know which specialties are in demand, they can take steps to discharge more patients from those areas</p> <p>The demand for emergency beds varies: * by time of day, day of week and season * in terms of the acuity of the patients - how sick they are * in terms of which specialty they need to be admitted to - medical, surgical, paediatric etc</p> <p>Hospitals typically predict emergency demand using simple heuristics eg taking yesterday's emergency bed numbers and assuming today will be the same.</p> <p>However, now that hospitals have Electronic Health Records (EHRs) patient records, they could do more with real-time data. Typically, bed planners know about new demand only when a staff member in the ED creates a bed request for an incoming patients. By that time, the patient may have been in the ED for hours. Real-time data means that bed planners could be notified much earlier</p>"},{"location":"notebooks/4_Specify_emergency_demand_model/#what-are-our-users-needs-from-predictive-models-of-emergency-demand","title":"What are our users' needs from predictive models of emergency demand?","text":"<p>Over the years of working with the bed managers in the UCLH Coordination Centre, I have come to understand what works best for them in predicting emergency demand. </p> <ul> <li>They want information at specific times of day to coincide with their flow huddles, with an 8-hour view of incoming demand at these times</li> <li>The 8-hour view needs to take account of patients who are yet to arrive, who should be admitted within that time</li> <li>The predictions should be based on the assumption that the ED is meeting its 4-hour targets for performance (for example, 78% of patients are to be admitted within 4 hours of arriving at the front door)</li> <li>The predictions should exclude patients who already have decisions to admit under a specialty, since these should be counted as known demand for that specialty</li> <li>That they are more concerned about overall bed numbers than whether any individual patient will be admitted</li> <li>A breakdown by speciality of admission is more actionable than overall numbers for the whole hospital</li> <li>They use email and spreadsheets for communication, both to receive information, and to communicate to others about the hospital bed state </li> </ul> <p>In our conversations about the predicted number of beds needed, our users said they wanted certainty. In reality, the number of admissions has a natural variation from one day to the next; mathmeticians refer to it as a stochastic process. My Operational Research colleagues use probability distributions to describe this variation. Our users are not interested in seeing whole probability distributions, but they do want a sense of confidence in the predictions. We needed to find a middle ground between showing the whole distribution and showing a single number. </p> <p>For more information about these requirements, and how we tailored the UCLH application to meet them, check out this talk by me, with Craig Wood, bed manager at UCLH, at the Health and Care Analytics Conference 2023:</p> <p> </p>"},{"location":"notebooks/4_Specify_emergency_demand_model/#how-did-i-implement-these-requirements-in-the-uclh-application","title":"How did I implement these requirements in the UCLH application?","text":"<p>Based on the requirements above, my colleagues and I made the following decisions about the modelling. </p> <ul> <li>Train the models such that they are tailored to the times of day at which the bed managers issue their situation reports</li> <li>Show output at aggregate level rather than individual </li> <li>Differentiate between patients with and without a decision to admit </li> <li>Provide separate predictions for patients in the ED and SDEC now, and those yet to arrive</li> <li>Break down the output by speciality, and by sex</li> <li>For the yet to arrive, assume that the time it takes to admit them is achieved by the ED within the target time of 4 hours for a specified percentage of patients (currently UK targets are 78%)</li> <li>Give some sense of uncertainty in the predictions (but, because bed managers are not that interested in seeing whole probability distributions, keep this minimal)</li> </ul> <p>The annotated figure below shows the output that our application currently generates at UCLH</p> <pre><code>from IPython.display import Image\nImage(filename='img/thumbnail_UCLH_application.jpg')\n</code></pre> <p></p> <p>This output</p> <ul> <li>Is sent at five times per day, to coincide with the preparation of the situation reports</li> <li>Shows aggregate level rather than individual predictions</li> <li>Differentiates between patients with a decision to admit (columns B:C) and those without (columns D:G)</li> <li>Provides separate predictions for patients in the ED and SDEC now (columns D:E), and those yet to arrive (columns F:G)</li> <li>Breaks down the output by speciality (rows 4:7); a forthcoming version will break down by sex</li> <li>For the yet to arrive, assumes that the time it takes to admit them is achieved by the ED within the target time of 4 hours for a specified percentage of patients (currently UK targets are 78% but we are using the former target of 95% currently)</li> <li>Gives some sense of uncertainty in the predictions but showing the minimum number of beds needed with 90% probability (columns D and F) and with 70% probability (columns E and G)</li> </ul> <p>The remaining notebooks will break down each step showing how this has been done. </p>"},{"location":"notebooks/4_Specify_emergency_demand_model/#learn-more-about-the-modelling-approach","title":"Learn more about the modelling approach","text":"<p>I recorded this webinar to demonstrate how we converted data from the UCLH Electronic Health Record in a form suitable for this modelling. I provide detail about all the modelling steps mentioned above. </p> <p> </p>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/","title":"Predict ED admission probability","text":"<p>This notebook demonstrates the first stage of prediction, to generate a probability of admission for each patient in the ED. </p> <p>As one of the modelling decisions is to send predictions at specified times of day, we tailor the models to these times and train one model for each time. The dataset used for this modelling is derived from snapshots of visits at each time of day. The times of day are set in config.json file in the root directory of this repo. </p> <p>A patient episode (visit) may well span more than one of these times, so we need to consider how we will deal with the occurence of multiple snapshots per episode. At each of these times of day, we will use only one training sample from each hospital episode.</p> <p>Separation of the visits into training, validation and test sets will be done chronologically into a training, validation and test set.</p> <p>Here the logic for training a model is hidden in a function which uses an XGBoost classifier. We show how to call the function, and how to interrogate the results. You may have your own trained models, in which case skip this notebook and move onto to the one showing the aggregation to bed level 4b_Predict_demand_from_patients_in_ED.md</p>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#set-up-the-notebook-environment","title":"Set up the notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#set-file-paths-and-load-data","title":"Set file paths and load data","text":"<p>File paths are defined in <code>set_file_paths()</code>. Here, the files are loaded from <code>data-public</code> in the root of the repository. When you first download or install this repository, this folder will be empty. You have two options: </p> <ul> <li>Copy the two files from the <code>data-synthetic</code> folder into the <code>data-public</code> folder. Note that, if you run these notebooks with synthetic data, you will get artificially good performance of the models</li> <li>Request files that contain real patient data to put in the <code>data-public</code> folder; contact the owner of the repository; see the README in the root of the repository</li> </ul> <pre><code>from patientflow.load import set_file_paths\n\n# set file paths\ndata_folder_name = 'data-public'\ndata_file_path = project_root / data_folder_name\n\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n    project_root, \n    data_folder_name=data_folder_name,\n    config_file = 'config.yaml')\n</code></pre> <pre><code>Configuration will be loaded from: /Users/zellaking/Repos/patientflow/config.yaml\nData files will be loaded from: /Users/zellaking/Repos/patientflow/data-public\nTrained models will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public\nImages will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public/media\n</code></pre> <pre><code>import pandas as pd\nfrom patientflow.load import load_data\n\n# load data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n</code></pre> <p>Note that, in the output below, each row has a snapshot_id as an index. In the notebooks that follow, we retain the same values of snapshot_id throughout, meaning that they are consistent across the original dataset visits and the training, validation and test subsets of visits. At any point, when looking at output (eg the predicted probability of admission for a patient), you should be able to track that output back to the original row in the ed_visits dataset.</p> <pre><code>ed_visits.head()\n</code></pre> snapshot_date prediction_time visit_number elapsed_los sex age_group arrival_method current_location_type total_locations_visited num_obs ... latest_lab_results_pco2 latest_lab_results_ph latest_lab_results_wcc latest_lab_results_alb latest_lab_results_htrt training_validation_test final_sequence is_admitted random_number specialty snapshot_id 0 4/17/2031 (12, 0) 30767 1920 F 55-64 Ambulance majors 4 107 ... NaN NaN NaN NaN NaN train [] False 15795 medical 1 4/17/2031 (15, 30) 30767 14520 F 55-64 Ambulance majors 5 138 ... 4.61 7.474 8.77 NaN NaN train [] False 860 medical 2 12/10/2031 (15, 30) 36297 9180 M 75-102 NaN majors 4 127 ... 4.82 7.433 6.59 NaN NaN test [] False 76820 surgical 3 3/28/2031 (6, 0) 53554 2220 F 35-44 Public Trans rat 3 356 ... NaN NaN NaN NaN NaN train [] False 54886 medical 4 3/28/2031 (9, 30) 53554 14820 F 35-44 Public Trans majors 4 375 ... 4.00 7.536 13.03 NaN NaN train [] False 6265 medical <p>5 rows \u00d7 69 columns</p> <p>If you are looking at synthetic or public data, the date have been shifted into the future, as shown below. This is to minimise any risk of a patient being identifiable. </p> <pre><code># print start and end dates\nprint(ed_visits.snapshot_date.min())\nprint(ed_visits.snapshot_date.max())\n</code></pre> <pre><code>10/1/2031\n9/9/2031\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#set-modelling-parameters","title":"Set modelling parameters","text":"<p>The parameters are used in training or inference. They are set in config.json in the root of the repository and loaded by <code>load_config_file()</code></p> <pre><code># load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n\nprint(f'\\nTraining set starts {start_training_set} and ends on {start_validation_set - pd.Timedelta(days=1)} inclusive')\nprint(f'Validation set starts on {start_validation_set} and ends on {start_test_set - pd.Timedelta(days=1)} inclusive' )\nprint(f'Test set starts on {start_test_set} and ends on {end_test_set- pd.Timedelta(days=1)} inclusive' )\n</code></pre> <pre><code>Training set starts 2031-03-01 and ends on 2031-08-31 inclusive\nValidation set starts on 2031-09-01 and ends on 2031-09-30 inclusive\nTest set starts on 2031-10-01 and ends on 2031-12-31 inclusive\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#prediction-times","title":"Prediction times","text":"<p>The data has been prepared as a series of snapshots of each patient's data at five moments during the day. These five moments are the times when the bed managers wish to receive predictive models of emergency demand. If a patient arrives in the ED at 4 am, and leaves at 11 am, they will be represented in the 06:00 and 09:30 prediction times. Everything known about a patient is included up until that moment is included in that snapshot.</p> <p>The predition times are presented as tuples in the form (hour, minute). </p> <p>From the output below we can see that there are most snapshots at 15:30 - since afternoons are typically the busiest times in the ED - and least at 06:00. </p> <pre><code>print(\"\\nTimes of day at which predictions will be made\")\nprint(ed_visits.prediction_time.unique())\n</code></pre> <pre><code>Times of day at which predictions will be made\n[(12, 0) (15, 30) (6, 0) (9, 30) (22, 0)]\n</code></pre> <pre><code>print(\"\\nNumber of observations for each prediction time\")\nprint(ed_visits.prediction_time.value_counts())\n</code></pre> <pre><code>Number of observations for each prediction time\nprediction_time\n(15, 30)    22279\n(12, 0)     19075\n(22, 0)     18842\n(9, 30)     11421\n(6, 0)       8197\nName: count, dtype: int64\n</code></pre> <p>If you use different data, check that the prediction times in your dataset aligns with the specified times of day set in the parameters file config.yaml. That is because, later, we will use these times of day to evaluate the predictions. The evaluation will fail if the data loaded does not match. </p>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#separate-into-training-validation-and-test-sets","title":"Separate into training, validation and test sets","text":"<p>The first task in model development is to split the dataset into a training, validation and test set using a temporal split. Using a using a temporal split (rather than randomly assigning visits to each set) is appropriate for tasks where the model needs to be validated on unseen, future data.</p> <p>The training set is used to fit the model parameters, the validation set helps tune hyperparameters and evaluate the model during development to prevent overfitting, and the test set provides an unbiased evaluation of the final model's performance on completely unseen data.</p> <p>I first load the training, validation and test set dates from the configuration file</p> <pre><code># load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n\nprint(f'\\nTraining set starts {start_training_set} and ends on {start_validation_set - pd.Timedelta(days=1)} inclusive')\nprint(f'Validation set starts on {start_validation_set} and ends on {start_test_set - pd.Timedelta(days=1)} inclusive' )\nprint(f'Test set starts on {start_test_set} and ends on {end_test_set- pd.Timedelta(days=1)} inclusive' )\n</code></pre> <pre><code>Training set starts 2031-03-01 and ends on 2031-08-31 inclusive\nValidation set starts on 2031-09-01 and ends on 2031-09-30 inclusive\nTest set starts on 2031-10-01 and ends on 2031-12-31 inclusive\n</code></pre> <pre><code>from patientflow.prepare import create_temporal_splits\n\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\",\n)\n</code></pre> <pre><code>Split sizes: [53801, 6519, 19494]\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#train-a-xgboost-classifier-for-each-time-of-day-and-save-the-best-model","title":"Train a XGBoost Classifier for each time of day, and save the best model","text":""},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#about-the-approach-to-model-training","title":"About the approach to model training","text":"<p>The first step is to load a transformer for the training data to turn it into a format that our ML classifier can read. This is done using a custom function (written for this package) called <code>create_column_transformer()</code> which in turn calls <code>ColumnTransfomer()</code>, a standard method in scikit-learn. </p> <p>The <code>ColumnTransformer</code> in scikit-learn is a tool that applies different transformations or preprocessing steps to different columns of a dataset in a single operation. OneHotEncoder converts categorical data into a format that can be provided to machine learning algorithms; without this, the model might interpret the categorical data as numerical, which would lead to incorrect results. OrdinalEncoder converts categorical data into ordered numerical values to reflect the inherent order in the age groups. It is the job of the modeller to indicate to the model how to handle each variables, based on your knowledge of what they represent. Here, <code>age_group</code>, <code>latest_obs_manchester_triage_acuity</code>, <code>latest_obs_objective_pain_score</code> and <code>latest_obs_level_of_consciousness</code> are all marked as ordered categories. </p> <pre><code>\nordinal_mappings = {\n    \"age_group\": [\n        \"0-17\",\n        \"18-24\",\n        \"25-34\",\n        \"35-44\",\n        \"45-54\",\n        \"55-64\",\n        \"65-74\",\n        \"75-102\",\n    ],\n    \"latest_acvpu\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n    \"latest_obs_manchester_triage_acuity\": [\n        \"Blue\",\n        \"Green\",\n        \"Yellow\",\n        \"Orange\",\n        \"Red\",\n    ],\n    \"latest_obs_objective_pain_score\": [\n        \"Nil\",\n        \"Mild\",\n        \"Moderate\",\n        \"Severe\\\\E\\\\Very Severe\",\n    ],\n    \"latest_obs_level_of_consciousness\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n    }\n\n\n\n</code></pre> <p>Certain columns in the dataset provided are not used in training the admissions model. I specify them here</p> <pre><code>exclude_from_training_data = [ 'snapshot_date', 'prediction_time','consultation_sequence', 'visit_number', 'specialty', 'final_sequence', 'training_validation_test']\n</code></pre> <p>I also specify a grid of hyperparameters; the classifier will iterate though them to find the best fitting model. </p> <pre><code># # minimal grid for expediency\n# grid = {\"n_estimators\": [30], \n#         \"subsample\": [0.7], \n#         \"colsample_bytree\": [0.7],\n# }\n\n\n# grid for hyperparameter tuning\ngrid = {\n    'n_estimators':[30, 40, 50],\n    'subsample':[0.7,0.8,0.9],\n    'colsample_bytree': [0.7,0.8,0.9],\n\n}\n</code></pre> <p>We are interested in predictions at different times of day. So we will train a model for each time of day. We will filter each visit so that it only appears once in the training data. </p> <p>We iterate through the hyperparameter grid defined above to find the best model for each time of day, keeping track of the best model and its results. When evaluating the best configuration from among the range of hyperparameter options, we will save common ML metrics (AUC, AUPRC and logloss) and compare each configuration for the best (lowest) logloss. This is done by looking at performance on a validation set. </p> <p>The best model is saved, as is a dictionary of its metadata, including</p> <ul> <li>the parameters used in this version of training</li> <li>how many visits were in training, validation and test sets</li> <li>class balance in each set - the proportion of positive (ie visit ended in admission) to negative (visit ended in discharge) </li> <li>area under ROC curve and log loss (performance metrics) for training (based on 5-fold cross validation), validation and test sets</li> <li>List of features and their importances in the model</li> </ul> <pre><code>train_visits.prediction_time.value_counts()\n</code></pre> <pre><code>prediction_time\n(15, 30)    15054\n(12, 0)     12764\n(22, 0)     12642\n(9, 30)      7671\n(6, 0)       5670\nName: count, dtype: int64\n</code></pre> <p>Note that the classes are imbalanced. The admitted patients range from 12% to 17% of the total visits.  </p> <pre><code>train_visits.groupby('prediction_time')['is_admitted'].mean()\n</code></pre> <pre><code>prediction_time\n(6, 0)      0.172134\n(9, 30)     0.130752\n(12, 0)     0.124021\n(15, 30)    0.154975\n(22, 0)     0.164610\nName: is_admitted, dtype: float64\n</code></pre> <pre><code># train admissions model\nfrom patientflow.train.classifiers import train_multiple_classifiers\nfrom patientflow.train.utils import save_model\n\nprediction_times = ed_visits.prediction_time.unique()\nmodel_name = 'admissions'\n\ntrained_models = train_multiple_classifiers(\n    train_visits=train_visits,\n    valid_visits=valid_visits,\n    test_visits=test_visits,\n    grid=grid,\n    exclude_from_training_data=exclude_from_training_data,\n    ordinal_mappings=ordinal_mappings,\n    prediction_times=prediction_times,\n    model_name=model_name,\n    calibrate_probabilities=False,\n    calibration_method='sigmoid',\n    use_balanced_training=False,\n    visit_col='visit_number' # visit_col is needed to ensure we get only one snapshot for each visit in the training set; snapshots are randomly sampled\n)\n\n# save models \nsave_model(trained_models, \"admissions\", model_file_path)\nprint(f\"Models have been saved to {model_file_path}\")\n</code></pre> <pre><code>Processing: (12, 0)\n\nProcessing: (15, 30)\n\nProcessing: (6, 0)\n\nProcessing: (9, 30)\n\nProcessing: (22, 0)\nModels have been saved to /Users/zellaking/Repos/patientflow/trained-models/public\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#inspecting-the-output-from-model-training","title":"Inspecting the output from model training","text":"<p>Five models have been trained, each saved under a key which is the name of the model passed into train_all_models() (default value is 'admissions'), with the prediction time appended</p> <pre><code>print(trained_models.keys())\n\n</code></pre> <pre><code>dict_keys(['admissions_1200', 'admissions_1530', 'admissions_0600', 'admissions_0930', 'admissions_2200'])\n</code></pre> <p>If we display the values for one of the items in the dictionary of trained_models, we see that a trained classifer has been returned by the function. </p> <pre><code>type(trained_models['admissions_1530'])\n</code></pre> <pre><code>patientflow.metrics.TrainedClassifier\n</code></pre> <p>Within the object that is returned, various metrics have been saved, including - how many observations were in th training, validation and test sets - the class balance (proportion of admitted patients in the whole dataset) - the best parameters of all combinations tried - results on training and validation sets - results on test set - the model features</p> <pre><code>trained_models['admissions_1530'].training_results\n</code></pre> <pre><code>TrainingResults(prediction_time=(15, 30), training_info={'best_hyperparameters': {'colsample_bytree': 0.7, 'n_estimators': 30, 'subsample': 0.9}, 'cv_trials': [HyperParameterTrial(parameters={'colsample_bytree': 0.7, 'n_estimators': 30, 'subsample': 0.7}, cv_results={'train_auc': np.float64(0.9580444574749587), 'train_logloss': np.float64(0.17128741291716607), 'train_auprc': np.float64(0.8715806541831641), 'valid_auc': np.float64(0.8185838772831474), 'valid_logloss': np.float64(0.35776512326952187), 'valid_auprc': np.float64(0.49339818684816883)}), HyperParameterTrial(parameters={'colsample_bytree': 0.7, 'n_estimators': 30, 'subsample': 0.8}, cv_results={'train_auc': np.float64(0.9608349568241314), 'train_logloss': np.float64(0.16742416684695283), 'train_auprc': np.float64(0.882931124248984), 'valid_auc': np.float64(0.822116547223759), 'valid_logloss': np.float64(0.35205162513739036), 'valid_auprc': np.float64(0.5043328103662739)}), HyperParameterTrial(parameters={'colsample_bytree': 0.7, 'n_estimators': 30, 'subsample': 0.9}, cv_results={'train_auc': np.float64(0.9598064524398104), 'train_logloss': np.float64(0.17022840144891377), 'train_auprc': np.float64(0.87777765815176), 'valid_auc': np.float64(0.8247641678471854), 'valid_logloss': np.float64(0.34924519090362005), 'valid_auprc': np.float64(0.5074360419229299)}), HyperParameterTrial(parameters={'colsample_bytree': 0.7, 'n_estimators': 40, 'subsample': 0.7}, cv_results={'train_auc': np.float64(0.9692443638232101), 'train_logloss': np.float64(0.14865393562155715), 'train_auprc': np.float64(0.9087734492031064), 'valid_auc': np.float64(0.8121986406595069), 'valid_logloss': np.float64(0.3684489567791951), 'valid_auprc': np.float64(0.4849689907988184)}), HyperParameterTrial(parameters={'colsample_bytree': 0.7, 'n_estimators': 40, 'subsample': 0.8}, cv_results={'train_auc': np.float64(0.9710228713540963), 'train_logloss': np.float64(0.14699313553863402), 'train_auprc': np.float64(0.9147567021018306), 'valid_auc': np.float64(0.8193077419226252), 'valid_logloss': np.float64(0.3592349996978693), 'valid_auprc': np.float64(0.49806947859320305)}), HyperParameterTrial(parameters={'colsample_bytree': 0.7, 'n_estimators': 40, 'subsample': 0.9}, cv_results={'train_auc': np.float64(0.9691513680511268), 'train_logloss': np.float64(0.15104868908420951), 'train_auprc': np.float64(0.909170981419507), 'valid_auc': np.float64(0.8209588586801381), 'valid_logloss': np.float64(0.356456334988685), 'valid_auprc': np.float64(0.5012065512221315)}), HyperParameterTrial(parameters={'colsample_bytree': 0.7, 'n_estimators': 50, 'subsample': 0.7}, cv_results={'train_auc': np.float64(0.9754563248111626), 'train_logloss': np.float64(0.13288738885594306), 'train_auprc': np.float64(0.9281149470128899), 'valid_auc': np.float64(0.8096349174456348), 'valid_logloss': np.float64(0.377019522300244), 'valid_auprc': np.float64(0.479819468091331)}), HyperParameterTrial(parameters={'colsample_bytree': 0.7, 'n_estimators': 50, 'subsample': 0.8}, cv_results={'train_auc': np.float64(0.9774629975386757), 'train_logloss': np.float64(0.13016884797762782), 'train_auprc': np.float64(0.9347452833694614), 'valid_auc': np.float64(0.8172446924602526), 'valid_logloss': np.float64(0.3662449650267632), 'valid_auprc': np.float64(0.49704858829900667)}), HyperParameterTrial(parameters={'colsample_bytree': 0.7, 'n_estimators': 50, 'subsample': 0.9}, cv_results={'train_auc': np.float64(0.9761153362492024), 'train_logloss': np.float64(0.13452344588064163), 'train_auprc': np.float64(0.9310445097310222), 'valid_auc': np.float64(0.8190570465706817), 'valid_logloss': np.float64(0.36242036948112594), 'valid_auprc': np.float64(0.49848185066078765)}), HyperParameterTrial(parameters={'colsample_bytree': 0.8, 'n_estimators': 30, 'subsample': 0.7}, cv_results={'train_auc': np.float64(0.9575966336851891), 'train_logloss': np.float64(0.17221388353993197), 'train_auprc': np.float64(0.8697242486589554), 'valid_auc': np.float64(0.8215121382050729), 'valid_logloss': np.float64(0.35355391464605573), 'valid_auprc': np.float64(0.5025811558888195)}), HyperParameterTrial(parameters={'colsample_bytree': 0.8, 'n_estimators': 30, 'subsample': 0.8}, cv_results={'train_auc': np.float64(0.9613572848523688), 'train_logloss': np.float64(0.16609720661125424), 'train_auprc': np.float64(0.8839334990368076), 'valid_auc': np.float64(0.8211516096065401), 'valid_logloss': np.float64(0.35352202514808706), 'valid_auprc': np.float64(0.5037399330017573)}), HyperParameterTrial(parameters={'colsample_bytree': 0.8, 'n_estimators': 30, 'subsample': 0.9}, cv_results={'train_auc': np.float64(0.9612197695738036), 'train_logloss': np.float64(0.16786813558249167), 'train_auprc': np.float64(0.8819262315667638), 'valid_auc': np.float64(0.8229450570916768), 'valid_logloss': np.float64(0.3498415351977358), 'valid_auprc': np.float64(0.510734679488184)}), HyperParameterTrial(parameters={'colsample_bytree': 0.8, 'n_estimators': 40, 'subsample': 0.7}, cv_results={'train_auc': np.float64(0.969381536323513), 'train_logloss': np.float64(0.14913349612326793), 'train_auprc': np.float64(0.9066869770558401), 'valid_auc': np.float64(0.817453330373526), 'valid_logloss': np.float64(0.36259422267672653), 'valid_auprc': np.float64(0.495675611613409)}), HyperParameterTrial(parameters={'colsample_bytree': 0.8, 'n_estimators': 40, 'subsample': 0.8}, cv_results={'train_auc': np.float64(0.9723492479266348), 'train_logloss': np.float64(0.1444252786169537), 'train_auprc': np.float64(0.9177285397857797), 'valid_auc': np.float64(0.8180471650866726), 'valid_logloss': np.float64(0.3591630393393653), 'valid_auprc': np.float64(0.5017773287085623)}), HyperParameterTrial(parameters={'colsample_bytree': 0.8, 'n_estimators': 40, 'subsample': 0.9}, cv_results={'train_auc': np.float64(0.9708461000402444), 'train_logloss': np.float64(0.14846540852173842), 'train_auprc': np.float64(0.9122144963405245), 'valid_auc': np.float64(0.8186979549340385), 'valid_logloss': np.float64(0.3563048237918468), 'valid_auprc': np.float64(0.5058499039908038)}), HyperParameterTrial(parameters={'colsample_bytree': 0.8, 'n_estimators': 50, 'subsample': 0.7}, cv_results={'train_auc': np.float64(0.9760730709584294), 'train_logloss': np.float64(0.13215909902301967), 'train_auprc': np.float64(0.9281286653342111), 'valid_auc': np.float64(0.8155560696782997), 'valid_logloss': np.float64(0.3691008860710845), 'valid_auprc': np.float64(0.49521959174136754)}), HyperParameterTrial(parameters={'colsample_bytree': 0.8, 'n_estimators': 50, 'subsample': 0.8}, cv_results={'train_auc': np.float64(0.9778727029069616), 'train_logloss': np.float64(0.1281988760192599), 'train_auprc': np.float64(0.9358940020395858), 'valid_auc': np.float64(0.8164993603588429), 'valid_logloss': np.float64(0.3663614510899075), 'valid_auprc': np.float64(0.5003884377800455)}), HyperParameterTrial(parameters={'colsample_bytree': 0.8, 'n_estimators': 50, 'subsample': 0.9}, cv_results={'train_auc': np.float64(0.9770524273204056), 'train_logloss': np.float64(0.1326286731781076), 'train_auprc': np.float64(0.9326235819201699), 'valid_auc': np.float64(0.8166351586602891), 'valid_logloss': np.float64(0.362835187448866), 'valid_auprc': np.float64(0.49938972574190477)}), HyperParameterTrial(parameters={'colsample_bytree': 0.9, 'n_estimators': 30, 'subsample': 0.7}, cv_results={'train_auc': np.float64(0.9587195588023907), 'train_logloss': np.float64(0.17032587443038633), 'train_auprc': np.float64(0.8736492871060602), 'valid_auc': np.float64(0.8223120263384989), 'valid_logloss': np.float64(0.35403002043463105), 'valid_auprc': np.float64(0.5002372008506849)}), HyperParameterTrial(parameters={'colsample_bytree': 0.9, 'n_estimators': 30, 'subsample': 0.8}, cv_results={'train_auc': np.float64(0.9616915338990724), 'train_logloss': np.float64(0.16669441740964946), 'train_auprc': np.float64(0.8818769205248029), 'valid_auc': np.float64(0.8210045591086317), 'valid_logloss': np.float64(0.35333147730144987), 'valid_auprc': np.float64(0.50126181865915)}), HyperParameterTrial(parameters={'colsample_bytree': 0.9, 'n_estimators': 30, 'subsample': 0.9}, cv_results={'train_auc': np.float64(0.9630450675445494), 'train_logloss': np.float64(0.16495354959691733), 'train_auprc': np.float64(0.8842299626908368), 'valid_auc': np.float64(0.8241810528407454), 'valid_logloss': np.float64(0.3504599607812959), 'valid_auprc': np.float64(0.5080164834038613)}), HyperParameterTrial(parameters={'colsample_bytree': 0.9, 'n_estimators': 40, 'subsample': 0.7}, cv_results={'train_auc': np.float64(0.9701352465081156), 'train_logloss': np.float64(0.14806973718414185), 'train_auprc': np.float64(0.9087807651605763), 'valid_auc': np.float64(0.8169164756443813), 'valid_logloss': np.float64(0.364023632546598), 'valid_auprc': np.float64(0.4916922092906617)}), HyperParameterTrial(parameters={'colsample_bytree': 0.9, 'n_estimators': 40, 'subsample': 0.8}, cv_results={'train_auc': np.float64(0.9725269487052615), 'train_logloss': np.float64(0.14466950788358884), 'train_auprc': np.float64(0.9164418710374193), 'valid_auc': np.float64(0.816365888636766), 'valid_logloss': np.float64(0.3624987777657173), 'valid_auprc': np.float64(0.49368484958032954)}), HyperParameterTrial(parameters={'colsample_bytree': 0.9, 'n_estimators': 40, 'subsample': 0.9}, cv_results={'train_auc': np.float64(0.9723265688132766), 'train_logloss': np.float64(0.14520084746470563), 'train_auprc': np.float64(0.9147273368169351), 'valid_auc': np.float64(0.8180853921714757), 'valid_logloss': np.float64(0.35982675392316926), 'valid_auprc': np.float64(0.49955569744201006)}), HyperParameterTrial(parameters={'colsample_bytree': 0.9, 'n_estimators': 50, 'subsample': 0.7}, cv_results={'train_auc': np.float64(0.9770441304896635), 'train_logloss': np.float64(0.13011561597637503), 'train_auprc': np.float64(0.9318968412342847), 'valid_auc': np.float64(0.8145408316189766), 'valid_logloss': np.float64(0.3713820723635733), 'valid_auprc': np.float64(0.4905006082084631)}), HyperParameterTrial(parameters={'colsample_bytree': 0.9, 'n_estimators': 50, 'subsample': 0.8}, cv_results={'train_auc': np.float64(0.9780830536636665), 'train_logloss': np.float64(0.129304555259721), 'train_auprc': np.float64(0.9344493917029153), 'valid_auc': np.float64(0.8140243107652976), 'valid_logloss': np.float64(0.3700875125835403), 'valid_auprc': np.float64(0.49198646174320376)}), HyperParameterTrial(parameters={'colsample_bytree': 0.9, 'n_estimators': 50, 'subsample': 0.9}, cv_results={'train_auc': np.float64(0.9775949270091541), 'train_logloss': np.float64(0.13112836217597798), 'train_auprc': np.float64(0.9321150905413849), 'valid_auc': np.float64(0.8162584044026705), 'valid_logloss': np.float64(0.3655153671708106), 'valid_auprc': np.float64(0.4995022293772326)})], 'features': {'names': ['elapsed_los', 'sex_F', 'sex_M', 'age_group', 'arrival_method_Amb no medic', 'arrival_method_Ambulance', 'arrival_method_Custodial se', 'arrival_method_Non-emergenc', 'arrival_method_Police', 'arrival_method_Public Trans', 'arrival_method_Walk-in', 'arrival_method_nan', 'current_location_type_majors', 'current_location_type_otf', 'current_location_type_paeds', 'current_location_type_rat', 'current_location_type_resus', 'current_location_type_sdec', 'current_location_type_sdec_waiting', 'current_location_type_utc', 'current_location_type_waiting', 'total_locations_visited', 'num_obs', 'num_obs_events', 'num_obs_types', 'num_lab_batteries_ordered', 'has_consultation_False', 'has_consultation_True', 'visited_majors_False', 'visited_majors_True', 'visited_otf_False', 'visited_otf_True', 'visited_paeds_False', 'visited_paeds_True', 'visited_rat_False', 'visited_rat_True', 'visited_resus_False', 'visited_resus_True', 'visited_sdec_False', 'visited_sdec_True', 'visited_sdec_waiting_False', 'visited_sdec_waiting_True', 'visited_unknown_False', 'visited_unknown_True', 'visited_utc_False', 'visited_utc_True', 'visited_waiting_False', 'visited_waiting_True', 'num_obs_blood_pressure', 'num_obs_pulse', 'num_obs_air_or_oxygen', 'num_obs_glasgow_coma_scale_best_motor_response', 'num_obs_level_of_consciousness', 'num_obs_news_score_result', 'num_obs_manchester_triage_acuity', 'num_obs_objective_pain_score', 'num_obs_subjective_pain_score', 'num_obs_temperature', 'num_obs_oxygen_delivery_method', 'num_obs_pupil_reaction_right', 'num_obs_oxygen_flow_rate', 'num_obs_uclh_sskin_areas_observed', 'latest_obs_pulse', 'latest_obs_respirations', 'latest_obs_level_of_consciousness', 'latest_obs_news_score_result', 'latest_obs_manchester_triage_acuity', 'latest_obs_objective_pain_score', 'latest_obs_temperature', 'lab_orders_bc_False', 'lab_orders_bc_True', 'lab_orders_bon_False', 'lab_orders_bon_True', 'lab_orders_crp_False', 'lab_orders_crp_True', 'lab_orders_csnf_False', 'lab_orders_csnf_True', 'lab_orders_ddit_False', 'lab_orders_ddit_True', 'lab_orders_ncov_False', 'lab_orders_ncov_True', 'lab_orders_rflu_False', 'lab_orders_rflu_True', 'lab_orders_xcov_False', 'lab_orders_xcov_True', 'latest_lab_results_crea', 'latest_lab_results_hctu', 'latest_lab_results_k', 'latest_lab_results_lac', 'latest_lab_results_na', 'latest_lab_results_pco2', 'latest_lab_results_ph', 'latest_lab_results_wcc', 'latest_lab_results_alb', 'latest_lab_results_htrt'], 'importances': [0.008522354066371918, 0.008131534792482853, 0.005864954087883234, 0.01838778890669346, 0.008991928771138191, 0.05714333429932594, 0.0, 0.0, 0.0, 0.004175173118710518, 0.0029791926499456167, 0.005155919585376978, 0.00883033312857151, 0.0, 0.0, 0.0060632373206317425, 0.03788682445883751, 0.0308400709182024, 0.024043474346399307, 0.07728108763694763, 0.0, 0.0059556374326348305, 0.006368630100041628, 0.003310894127935171, 0.005870932247489691, 0.07313118875026703, 0.02008918859064579, 0.013537026010453701, 0.004102907609194517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003809602465480566, 0.0, 0.011287982575595379, 0.0027528777718544006, 0.0067667667753994465, 0.004753147251904011, 0.016880907118320465, 0.005798147991299629, 0.012107975780963898, 0.005574553273618221, 0.03745686635375023, 0.0, 0.010590678080916405, 0.0, 0.007848676294088364, 0.0034012245014309883, 0.007608588319271803, 0.003733427496626973, 0.0034718795213848352, 0.0022597843781113625, 0.06949556618928909, 0.0019915185403078794, 0.007285783067345619, 0.0035581011325120926, 0.0, 0.004668738227337599, 0.02521573193371296, 0.0, 0.005630819126963615, 0.0068956115283071995, 0.002723122015595436, 0.016431091353297234, 0.01504108402878046, 0.007177324965596199, 0.005190321709960699, 0.030588064342737198, 0.004908763337880373, 0.007758032996207476, 0.0, 0.025546306744217873, 0.0, 0.005771547090262175, 0.052093591541051865, 0.009660473093390465, 0.0086259376257658, 0.0, 0.0, 0.006003187503665686, 0.018534807488322258, 0.003805062035098672, 0.0, 0.005595318507403135, 0.006606217939406633, 0.006749584339559078, 0.005568852182477713, 0.006685983389616013, 0.0065507483668625355, 0.007634185254573822, 0.010091325268149376, 0.006409717258065939, 0.010740851052105427], 'has_importance_values': True}, 'dataset_info': {'train_valid_test_set_no': {'train_set_no': 14969, 'valid_set_no': 1691, 'test_set_no': 5519}, 'train_valid_test_class_balance': {'y_train_class_balance': {0: 0.8446121985436569, 1: 0.15538780145634312}, 'y_valid_class_balance': {0: 0.7983441750443524, 1: 0.20165582495564754}, 'y_test_class_balance': {0: 0.812103641964124, 1: 0.18789635803587607}}}}, calibration_info={}, test_results={'test_auc': np.float64(0.7931831257312546), 'test_logloss': 0.40706388956815903, 'test_auprc': np.float64(0.4912035432847283)}, balance_info={'is_balanced': False, 'original_size': 14969, 'balanced_size': 14969, 'original_positive_rate': np.float64(0.15538780145634312), 'balanced_positive_rate': np.float64(0.15538780145634312), 'majority_to_minority_ratio': 1.0})\n</code></pre> <p>To get a better view of the same output</p> <pre><code>from dataclasses import fields\nprint(\"\\nDataclass fields in TrainingResults:\")\nfor field in fields(trained_models['admissions_1530'].training_results):\n    print(field.name)\n</code></pre> <pre><code>Dataclass fields in TrainingResults:\nprediction_time\ntraining_info\ncalibration_info\ntest_results\nbalance_info\n</code></pre> <p>The prediction time for this model has also been saved.</p> <pre><code># See the prediction time for this model\ntrained_models['admissions_1530'].training_results.prediction_time\n</code></pre> <pre><code>(15, 30)\n</code></pre> <p>Within the training_results, a training_info object contains information related to model training</p> <pre><code>metrics_dict = trained_models['admissions_1530'].training_results.training_info\nmetrics_dict.keys()\n</code></pre> <pre><code>dict_keys(['best_hyperparameters', 'cv_trials', 'features', 'dataset_info'])\n</code></pre> <pre><code>for key, value in trained_models['admissions_1530'].training_results.training_info.items():\n    print(key)\n</code></pre> <pre><code>best_hyperparameters\ncv_trials\nfeatures\ndataset_info\n</code></pre> <pre><code>\n</code></pre> <pre><code>\n\nprediction_time_model_name = 'admissions_1530'\n\n# Get the results dictionary from cross validation trials\nresults = trained_models[prediction_time_model_name].training_results.training_info['cv_trials']\n\n# Show the first trial results\nresults[0].cv_results\n</code></pre> <pre><code>{'train_auc': np.float64(0.9580444574749587),\n 'train_logloss': np.float64(0.17128741291716607),\n 'train_auprc': np.float64(0.8715806541831641),\n 'valid_auc': np.float64(0.8185838772831474),\n 'valid_logloss': np.float64(0.35776512326952187),\n 'valid_auprc': np.float64(0.49339818684816883)}\n</code></pre> <pre><code>\ntraining_info = trained_models[prediction_time_model_name].training_results.training_info\n\ndef find_best_trial(trials_list):\n    \"\"\"Find the trial with the lowest validation logloss.\"\"\"\n    return min(trials_list, key=lambda trial: trial.cv_results['valid_logloss'])\n\nbest_trial = find_best_trial(training_info[\"cv_trials\"])\n\n# print the best parameters\nbest_parameters = best_trial.parameters\nbest_parameters\n</code></pre> <pre><code>{'colsample_bytree': 0.7, 'n_estimators': 30, 'subsample': 0.9}\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#retreiving-saved-information-about-the-number-of-training-validation-and-test-set-samples-and-the-class-balance","title":"Retreiving saved information about the number of training, validation and test set samples, and the class balance","text":"<pre><code>model_metadata = trained_models[prediction_time_model_name].training_results.training_info\nprint(f\"Number in each set for model called {prediction_time_model_name}:\\n{model_metadata['dataset_info']['train_valid_test_set_no']}\")\n\ndef print_class_balance(d):\n    for k in d:\n        print(f\"{k.split('_')[1]}: {d[k][0]:.1%} neg, {d[k][1]:.1%} pos\")\n\n\nprint_class_balance(model_metadata['dataset_info']['train_valid_test_class_balance'])\n\n</code></pre> <pre><code>Number in each set for model called admissions_1530:\n{'train_set_no': 14969, 'valid_set_no': 1691, 'test_set_no': 5519}\ntrain: 84.5% neg, 15.5% pos\nvalid: 79.8% neg, 20.2% pos\ntest: 81.2% neg, 18.8% pos\n</code></pre> <p>Class balance information is also saved in this key, which will store information about the differences between the class balance when forcing the training set to be balanced</p> <pre><code>trained_models[prediction_time_model_name].training_results.balance_info\n</code></pre> <pre><code>{'is_balanced': False,\n 'original_size': 14969,\n 'balanced_size': 14969,\n 'original_positive_rate': np.float64(0.15538780145634312),\n 'balanced_positive_rate': np.float64(0.15538780145634312),\n 'majority_to_minority_ratio': 1.0}\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#retreiving-saved-information-about-the-best-parameters-for-each-model","title":"Retreiving saved information about the best parameters for each model","text":"<pre><code>from patientflow.load import get_model_key\n\n\n\ndef find_best_trial(trials_list):\n    \"\"\"Find the trial with the lowest validation logloss.\"\"\"\n    return min(trials_list, key=lambda trial: trial.cv_results['valid_logloss'])\n\nbest_trial = find_best_trial(training_info[\"cv_trials\"])\n\n\nfor prediction_time in train_visits.prediction_time.unique():\n    prediction_time_model_name = get_model_key(\"admissions\", prediction_time)\n    training_info = trained_models[prediction_time_model_name].training_results.training_info\n    best_trial = find_best_trial(training_info[\"cv_trials\"])\n    hour, minute = prediction_time\n    print(f\"Best hyperparameters for {hour:02d}:{minute:02d} model: {best_trial.parameters}\")\n</code></pre> <pre><code>Best hyperparameters for 12:00 model: {'colsample_bytree': 0.8, 'n_estimators': 30, 'subsample': 0.9}\nBest hyperparameters for 15:30 model: {'colsample_bytree': 0.7, 'n_estimators': 30, 'subsample': 0.9}\nBest hyperparameters for 06:00 model: {'colsample_bytree': 0.7, 'n_estimators': 30, 'subsample': 0.9}\nBest hyperparameters for 09:30 model: {'colsample_bytree': 0.7, 'n_estimators': 30, 'subsample': 0.9}\nBest hyperparameters for 22:00 model: {'colsample_bytree': 0.7, 'n_estimators': 30, 'subsample': 0.9}\n</code></pre> <p>Plot the performance of each training run.</p> <pre><code>from patientflow.viz.training_results import plot_trial_results\nfig = plot_trial_results(trained_models[prediction_time_model_name].training_results.training_info['cv_trials'])\n\n</code></pre> <p></p> <pre><code># After sigmoid calibration\nprint(f\"Results for each training run are saved using the hyperparameters as keys:\")\n\nfor key, value in trained_models[prediction_time_model_name].training_results.test_results.items():\n    print(f\"{key}: {value:.2f}\")\n\n</code></pre> <pre><code>Results for each training run are saved using the hyperparameters as keys:\ntest_auc: 0.84\ntest_logloss: 0.41\ntest_auprc: 0.60\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#plot-feature-importances-and-shap-plots-for-each-of-the-five-models","title":"Plot feature importances and shap plots for each of the five models","text":"<p>The following cells show Shap plots and feature importance plots for each of the five prediction times.</p> <ul> <li> <p>Feature Importance Plot A feature importance plot is a visual representation that shows the significance of each feature (or variable) in a machine learning model. It helps to understand which features contribute most to the model's predictions. The importance of a feature is typically determined by how much it improves the model's performance. The plot tells you which inputs, in overall terms, have the most influence on the output of the model. This plot is particularly useful for model interpretation, and gaining insights into the underlying data.</p> </li> <li> <p>SHAP Plot A SHAP (SHapley Additive exPlanations) plot provides a detailed view of the impact each feature has on the prediction of a machine learning model on a particular dataset, which in the case is the test set. Unlike the feature importance plot, SHAP values explain the contribution of each feature for each individual hospital visit in the test set (with each observation being represented as a dot in the plot). SHAP plots combine game theory and local explanations to show how much each feature increases or decreases the prediction for a given visit. This helps to interpret not only the overall model behavior but also the specific decisions for individual visits, offering a more granular and transparent view of model predictions.</p> </li> </ul>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#feature-plots","title":"Feature plots","text":"<p>The cell below shows feature plots for the main model. To see the same for the minimal model, change the model name to 'admissions_minimal'</p> <pre><code>from patientflow.viz.feature_plot import plot_features\n\n\nplot_features(\n    trained_models=list(trained_models.values()),  # Convert dict values to list\n    media_file_path=media_file_path,\n    top_n=20  # optional, showing default value\n)\n</code></pre> <p></p>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#inspecting-the-base-model","title":"Inspecting the base model","text":"<pre><code># without balanced training\nfrom patientflow.viz.distribution_plots import plot_prediction_distributions\nplot_prediction_distributions(\n    trained_models=list(trained_models.values()),  # Convert dict values to list\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n\n\n</code></pre> <pre><code># without balanced training\nfrom patientflow.viz.calibration_plot import plot_calibration\n\nplot_calibration(\n    trained_models=list(trained_models.values()),  # Convert dict values to list\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    strategy=\"uniform\",  # optional\n    suptitle=\"Base model with imbalanced training data\"  # optional\n)\n</code></pre> <pre><code>## without balanced training\nfrom patientflow.viz.madcap_plot import generate_madcap_plots\ngenerate_madcap_plots(\n    trained_models=list(trained_models.values()),\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#trying-with-balanced-samples","title":"Trying with balanced samples","text":"<pre><code># train admissions model\nfrom patientflow.train.classifiers import train_multiple_classifiers\n\nprediction_times = ed_visits.prediction_time.unique()\n\nmodel_name = 'admissions_balanced'\ntrained_models_balanced = train_multiple_classifiers(\n    train_visits=train_visits,\n    valid_visits=valid_visits,\n    test_visits=test_visits,\n    grid=grid,\n    exclude_from_training_data=exclude_from_training_data,\n    ordinal_mappings=ordinal_mappings,\n    prediction_times=prediction_times,\n    model_name=model_name,\n    calibrate_probabilities=False,\n    calibration_method='sigmoid',\n    use_balanced_training=True,\n    visit_col='visit_number' # visit_col is needed to ensure we get only one snapshot for each visit in the training set; snapshots are randomly sampled\n)\n\n# save models and metadata\nfrom patientflow.train.utils import save_model\n\nsave_model(trained_models_balanced, model_name, model_file_path)\n\nprint(f\"Models have been saved to {model_file_path}\")\n</code></pre> <pre><code>Processing: (12, 0)\n\nProcessing: (15, 30)\n\nProcessing: (6, 0)\n\nProcessing: (9, 30)\n\nProcessing: (22, 0)\nModels have been saved to /Users/zellaking/Repos/patientflow/trained-models/public\n</code></pre> <pre><code>for key, value in trained_models_balanced[\"admissions_balanced_1530\"].training_results.balance_info.items():\n    print(f\"{key}: {value}\")\n</code></pre> <pre><code>is_balanced: True\noriginal_size: 14969\nbalanced_size: 4652\noriginal_positive_rate: 0.15538780145634312\nbalanced_positive_rate: 0.5\nmajority_to_minority_ratio: 1.0\n</code></pre> <pre><code># with balanced training, not calibrated\nfrom patientflow.viz.distribution_plots import plot_prediction_distributions\nplot_prediction_distributions(\n    trained_models=list(trained_models_balanced.values()),  # Convert dict values to list\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n</code></pre> <pre><code># with balanced training, not calibrated\nfrom patientflow.viz.calibration_plot import plot_calibration\n\nplot_calibration(\n    trained_models=list(trained_models_balanced.values()),  # Convert dict values to list\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    strategy=\"uniform\",  # optional\n    suptitle=\"Balanced model prior to calibration\"  # optional\n)\n</code></pre> <pre><code># with balanced training, not calibrated\nfrom patientflow.viz.madcap_plot import generate_madcap_plots\ngenerate_madcap_plots(\n    trained_models=list(trained_models_balanced.values()),\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    suptitle=\"Balanced model prior to calibration\"  \n)\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#adding-calibration","title":"Adding calibration","text":"<pre><code># train admissions model\nfrom patientflow.train.classifiers import train_multiple_classifiers\n\nprediction_times = ed_visits.prediction_time.unique()\n\nmodel_name = 'admissions_balanced_calibrated'\ntrained_models_balanced_calibrated = train_multiple_classifiers(\n    train_visits=train_visits,\n    valid_visits=valid_visits,\n    test_visits=test_visits,\n    grid=grid,\n    exclude_from_training_data=exclude_from_training_data,\n    ordinal_mappings=ordinal_mappings,\n    prediction_times=prediction_times,\n    model_name=model_name,\n    calibrate_probabilities=True,\n    calibration_method='sigmoid', # Platt scaling\n    use_balanced_training=True,\n    visit_col='visit_number' # visit_col is needed to ensure we get only one snapshot for each visit in the training set; snapshots are randomly sampled\n)\n\n# save models and metadata\nfrom patientflow.train.utils import save_model\n\nsave_model(trained_models_balanced_calibrated, model_name, model_file_path)\n\nprint(f\"Models have been saved to {model_file_path}\")\n</code></pre> <pre><code>Processing: (12, 0)\n\nProcessing: (15, 30)\n\nProcessing: (6, 0)\n\nProcessing: (9, 30)\n\nProcessing: (22, 0)\nModels have been saved to /Users/zellaking/Repos/patientflow/trained-models/public\n</code></pre> <pre><code>for key, value in trained_models_balanced_calibrated[\"admissions_balanced_calibrated_1530\"].training_results.balance_info.items():\n    print(f\"{key}: {value}\")\n</code></pre> <pre><code>is_balanced: True\noriginal_size: 14969\nbalanced_size: 4652\noriginal_positive_rate: 0.15538780145634312\nbalanced_positive_rate: 0.5\nmajority_to_minority_ratio: 1.0\n</code></pre> <pre><code>from patientflow.viz.distribution_plots import plot_prediction_distributions\nplot_prediction_distributions(\n    trained_models=list(trained_models_balanced_calibrated.values()),  # Convert dict values to list\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n</code></pre> <pre><code># with balanced training, calibrated\nfrom patientflow.viz.calibration_plot import plot_calibration\nplot_calibration(\n    trained_models=list(trained_models_balanced_calibrated.values()),  # Convert dict values to list\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    strategy=\"uniform\",  # optional\n    suptitle=\"Balanced model after calibration\"  # optional\n)\n</code></pre> <pre><code># with balanced training, calibrated\nfrom patientflow.viz.madcap_plot import generate_madcap_plots\ngenerate_madcap_plots(\n    trained_models=list(trained_models_balanced_calibrated.values()),\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    suptitle=\"Balanced model after calibration\"  \n)\n</code></pre> <pre><code>from patientflow.viz.madcap_plot import generate_madcap_plots_by_group\ngenerate_madcap_plots_by_group(\n    trained_models=list(trained_models_balanced_calibrated.values()),\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data,\n    grouping_var=\"age_group\",\n    grouping_var_name=\"Age Group\",\n    plot_difference=False\n)\n\n\n</code></pre> <pre><code>from patientflow.viz.feature_plot import plot_features\n\nplot_features(\n    list(trained_models_balanced_calibrated.values()),\n    media_file_path,\n    suptitle=\"Feature Importance for balanced and calibrated model\",\n)\n</code></pre>"},{"location":"notebooks/4a_Predict_probability_of_admission_from_ED/#shap-plots-main-model","title":"Shap plots - main model","text":"<p>The cell below shows SHAP plots for the balanced and calibrated model at each prediction time. </p> <pre><code>from patientflow.viz.shap_plot import plot_shap\n\nplot_shap(\n    trained_models=list(trained_models_balanced_calibrated.values()),\n    media_file_path=media_file_path,\n    test_visits=test_visits,\n    exclude_from_training_data=exclude_from_training_data\n)\n</code></pre> <pre><code>Predicted classification (not admitted, admitted):  [1089  743]\n</code></pre> <p></p> <pre><code>Predicted classification (not admitted, admitted):  [1781  993]\n</code></pre> <p></p> <pre><code>Predicted classification (not admitted, admitted):  [3059 1678]\n</code></pre> <p></p> <pre><code>Predicted classification (not admitted, admitted):  [3501 2025]\n</code></pre> <p></p> <pre><code>Predicted classification (not admitted, admitted):  [2876 1749]\n</code></pre> <p></p> <pre><code>\n</code></pre> <pre><code>\n</code></pre>"},{"location":"notebooks/4b_Predict_demand_from_patients_in_ED/","title":"Turning individual patient-level predictions into predictions of how many beds will be needed","text":"<p>In the previous notebook 4a_Predict_probability_of_admission_from_ED.md, we created a model that will generate a probability of admission for each individual patient in the ED or SDEC. Since the objective of this modelling is to predict number of beds needed for a group of patients in the ED at a prediction moment, this notebook shows how to convert the individual-level probabilities into aggregate predictions.</p> <p>The patientflow python package includes a function called <code>get_prob_dist()</code> in a script called <code>aggregate.py</code> that will do the aggregating step. For each prediction moment, at which a set of patients were in ED or SDEC, this function generates a probability distribution showing how many beds will be needed by those patients. </p> <p>The function expects several inputs, including a dictionary - here called <code>snapshots_dict</code> - in which each key is a snapshot datetime and the values are an array of <code>snapshot_id</code> for each patient in the ED/SDEC at that snapshot datetime. </p> <p>The aspiration can be plotted as an inverted survival curve, as shown below. </p> <p>The aspiration can be plotted as an inverted survival curve, as shown below. </p>"},{"location":"notebooks/4b_Predict_demand_from_patients_in_ED/#set-up-the-notebook-environment","title":"Set up the notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/4b_Predict_demand_from_patients_in_ED/#load-parameters-and-set-file-paths-and-load-data","title":"Load parameters and set file paths, and load data","text":"<pre><code>import pandas as pd\nfrom patientflow.load import load_data, set_file_paths\nfrom patientflow.prepare import create_temporal_splits\n\n\n# set file paths\ndata_folder_name = 'data-public'\ndata_file_path = project_root / data_folder_name\n\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(project_root, \n               data_folder_name=data_folder_name)\n\n# load data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n\n# load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n\n# load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n\n# get test set from the original data\n_, _, test_visits = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\",\n)\n</code></pre> <pre><code>Configuration will be loaded from: /Users/zellaking/Repos/patientflow/config.yaml\nData files will be loaded from: /Users/zellaking/Repos/patientflow/data-public\nTrained models will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public\nImages will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public/media\nSplit sizes: [53801, 6519, 19494]\n</code></pre>"},{"location":"notebooks/4b_Predict_demand_from_patients_in_ED/#generate-aggregate-predictions-for-one-time-of-day-1530","title":"Generate aggregate predictions for one time of day 15:30","text":"<p>In the previous step, shown in notebook 4a_Predict_probability_of_admission_from_ED.md, we trained five models, one for each prediction time. Here we'll focus on the 15:30 prediction time. </p> <p>The first step is to retrieve data on patients in the ED at that time of day, and use a saved model to make a prediction for each of them. </p> <p>The function in the cell below formats the name of the model based on the time of day</p> <pre><code>from patientflow.load import get_model_key\nprediction_time = tuple([15,30])\nmodel_name = 'admissions_balanced_calibrated'\nmodel_key = get_model_key(model_name, prediction_time)\nprint(f'The name of the model to be loaded is {model_key}. It will be loaded from {model_file_path}')\n</code></pre> <pre><code>The name of the model to be loaded is admissions_balanced_calibrated_1530. It will be loaded from /Users/zellaking/Repos/patientflow/trained-models/public\n</code></pre> <p>Next we use the <code>prepare_for_inference()</code> function. This does several things:</p> <ul> <li>loads the trained model into a variable called <code>model</code></li> <li>reloads the original data, selects the test set records only and takes the subset of snaphots at 15:30 in the afternoon</li> <li>prepares this subset for input into the trained model, which is returned in a variable called <code>X_test</code>. (Note that here we are not using X_test for training the model, but for inference - inference means that we are asking atrained   model to make predictions. The model will expect the input data to be in the same format as it received when it was trained)</li> <li>returns an array of values <code>y_test</code> which is a binary variable whether each patient was actually admitted. This will be used to evaluate the model. </li> </ul> <pre><code>from patientflow.prepare import prepare_for_inference\n\nexclude_from_training_data = [ 'snapshot_date', 'prediction_time','consultation_sequence', 'visit_number', 'specialty', 'final_sequence', 'training_validation_test']\n\nX_test, y_test, pipeline = prepare_for_inference(\n    model_file_path, \n    model_name,\n    prediction_time,\n    model_only=False,\n    df=test_visits,\n    single_snapshot_per_visit=False,\n    exclude_from_training_data=exclude_from_training_data)\n</code></pre> <p>We can also view the data that was loaded for running inference on the model</p> <pre><code>X_test.head()\n</code></pre> elapsed_los sex age_group arrival_method current_location_type total_locations_visited num_obs num_obs_events num_obs_types num_lab_batteries_ordered ... latest_lab_results_crea latest_lab_results_hctu latest_lab_results_k latest_lab_results_lac latest_lab_results_na latest_lab_results_pco2 latest_lab_results_ph latest_lab_results_wcc latest_lab_results_alb latest_lab_results_htrt snapshot_id 2 9180 M 75-102 NaN majors 4 127 12 37 8 ... 97.0 0.483 4.1 1.2 140.0 4.82 7.433 6.59 NaN NaN 59741 25080 F 18-24 NaN sdec 5 10 1 10 5 ... 79.0 0.375 3.9 NaN 140.0 NaN NaN 8.41 39.0 NaN 60002 11160 F 65-74 NaN sdec_waiting 4 14 2 14 0 ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 60261 16680 F 35-44 NaN sdec_waiting 3 20 2 20 0 ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 60278 24060 F 75-102 Ambulance majors 5 67 7 27 8 ... 71.0 0.421 4.4 1.2 138.0 6.44 7.394 5.48 NaN NaN <p>5 rows \u00d7 60 columns</p> <p>Next we prepare a dictionary of snapshots (which is the term used here to refer to moments in time when we want to make predictions). The key for each dictionary entry is a snapshot datetime. The values are snapshot_ids for patients in the ED or SDEC at that time.</p> <p>The output of the following cell shows the first 10 keys, and the first set of values - simply a list of snapshot_ids</p> <pre><code>from patientflow.prepare import prepare_group_snapshot_dict\n\n# select the snapshots to include in the probability distribution, \nsnapshots_dict = prepare_group_snapshot_dict(\n    test_visits[test_visits.prediction_time == prediction_time]\n    )\n\nprint(\"First 10 keys in the snapshots dictionary\")\nprint(list(snapshots_dict.keys())[0:10])\n\nfirst_record_key = list(snapshots_dict.keys())[0]\nfirst_record_values = snapshots_dict[first_record_key]\n\nprint(\"\\nRecord associated with the first key\")\nprint(first_record_values)\n</code></pre> <pre><code>First 10 keys in the snapshots dictionary\n['10/1/2031', '10/10/2031', '10/11/2031', '10/12/2031', '10/13/2031', '10/14/2031', '10/15/2031', '10/16/2031', '10/17/2031', '10/18/2031']\n\nRecord associated with the first key\n[59741, 60002, 60261, 60278, 60317, 60324, 60335, 60351, 60358, 60363, 60375, 60380, 60383, 60385, 60387, 60389, 60400, 60405, 60408, 60409, 60410, 60411, 60412, 60413, 60414, 60415, 60416, 60417, 60418, 60419, 60420, 60421, 60422, 60423, 60424, 60425, 60426, 60427, 60428, 60429, 60430, 60431, 60432, 60433, 60434, 60435, 60436, 60437, 60438, 60443, 60444, 60445, 60448, 60449, 60451, 60452, 60453, 60454, 60455, 60456]\n</code></pre> <p>To see the snapshots associated with this first key in the snapshots dictionary, use the values it returns to retrieve the relevant rows in the original visits dataset.</p> <pre><code>ed_visits.loc[first_record_values].head()\n</code></pre> snapshot_date prediction_time visit_number elapsed_los sex age_group arrival_method current_location_type total_locations_visited num_obs ... latest_lab_results_pco2 latest_lab_results_ph latest_lab_results_wcc latest_lab_results_alb latest_lab_results_htrt training_validation_test final_sequence is_admitted random_number specialty snapshot_id 59741 10/1/2031 (15, 30) 135639 25080 F 18-24 NaN sdec 5 10 ... NaN NaN 8.41 39.0 NaN test ['medical'] True 15383 medical 60002 10/1/2031 (15, 30) 135923 11160 F 65-74 NaN sdec_waiting 4 14 ... NaN NaN NaN NaN NaN test ['ambulatory'] False 71795 NaN 60261 10/1/2031 (15, 30) 136201 16680 F 35-44 NaN sdec_waiting 3 20 ... NaN NaN NaN NaN NaN test ['ambulatory'] False 200 NaN 60278 10/1/2031 (15, 30) 136221 24060 F 75-102 Ambulance majors 5 67 ... 6.44 7.394 5.48 NaN NaN test ['acute'] True 37734 medical 60317 10/1/2031 (15, 30) 136275 51810 M 45-54 NaN sdec 12 84 ... NaN NaN NaN NaN NaN test ['surgical'] False 21593 NaN <p>5 rows \u00d7 69 columns</p> <p>The following cell shows the number of patients who were in the ED at that snapshot datetime</p> <pre><code>print(len(ed_visits.loc[first_record_values]))\n</code></pre> <pre><code>60\n</code></pre> <p>With the model, the snapshot dictionary, X_test and y_test as inputs, the get_prob_dist() function is called. It returns a dictionary, with the same keys as before, and with a probability distribution for each snapshot date in the test set. As this processes each snapshot date separately, it may take some time. </p> <pre><code>from patientflow.aggregate import get_prob_dist\n# get probability distribution for this time of day\nprob_dist = get_prob_dist(\n        snapshots_dict, X_test, y_test, pipeline\n    )\n</code></pre> <pre><code>Calculating probability distributions for 92 snapshot dates\nThis may take a minute or more\nProcessed 10 snapshot dates\nProcessed 20 snapshot dates\nProcessed 30 snapshot dates\nProcessed 40 snapshot dates\nProcessed 50 snapshot dates\nProcessed 60 snapshot dates\nProcessed 70 snapshot dates\nProcessed 80 snapshot dates\nProcessed 90 snapshot dates\nProcessed 92 snapshot dates\n</code></pre> <p>The cell below shows the entry in the <code>prob_dist</code> dictionary (which is the first snapshot date in the test set) and the probability distribution associated with that date. </p> <pre><code>\nprint(\"First key in the prob dist dictionary\")\nprint(list(prob_dist.keys())[0])\n\nprint(\"Probability distribution for first snapshot datetime\")\nprob_dist[first_record_key]\n</code></pre> <pre><code>First key in the prob dist dictionary\n10/1/2031\nProbability distribution for first snapshot datetime\n\n\n\n\n\n{'agg_predicted':                agg_proba\n 0    3.83000095709416e-8\n 1    8.91447105034246e-7\n 2    9.96474713480853e-6\n 3    7.12986776280389e-5\n 4   0.000367215548706615\n ..                   ...\n 56  2.70016724906273e-41\n 57  2.17495414369041e-43\n 58  1.27411141069909e-45\n 59  4.82803167661050e-48\n 60  8.88078644945381e-51\n\n [61 rows x 1 columns],\n 'agg_observed': 11}\n</code></pre> <p>To make this output more readable, we can redisplay it like this</p> <pre><code>first_date_prob_dist = prob_dist[first_record_key]['agg_predicted'].rename(columns = {'agg_proba': 'probability'})\nfirst_date_prob_dist.index.name = 'number of beds'\n\nprint(f\"Probability of needing this number of beds on {first_record_key} at {prediction_time} based on EHR data from patients in the ED at that time\")\ndisplay(first_date_prob_dist.head(15))\n\n</code></pre> <pre><code>Probability of needing this number of beds on 10/1/2031 at (15, 30) based on EHR data from patients in the ED at that time\n</code></pre> probability number of beds 0 3.83000095709416e-8 1 8.91447105034246e-7 2 9.96474713480853e-6 3 7.12986776280389e-5 4 0.000367215548706615 5 0.00145156182973333 6 0.00458531140812794 7 0.0119004455059500 8 0.0258924729749449 9 0.0479546989485299 10 0.0765094618936776 11 0.106161370669358 12 0.129109543666885 13 0.138509425956049 14 0.131784140162024 <p>We can plot this probability distribution using a function from the patientflow package</p> <pre><code>from patientflow.viz.prob_dist_plot import prob_dist_plot\n\ntitle_ = f'Probability distribution for number of beds needed by patients in ED at {first_record_key} {prediction_time[0]:02d}:{prediction_time[1]:02d}'\nprob_dist_plot(prob_dist_data=prob_dist[first_record_key]['agg_predicted'], \n    title=title_,  \n    include_titles=True)\n</code></pre> <p></p> <p>From the output above, we can see how many beds are predicted to be needed by the patients in the ED/SDEC at this particular snapshot. It gives a range of probability, rather than a single estimate.</p>"},{"location":"notebooks/4b_Predict_demand_from_patients_in_ED/#reading-a-minimum-number-of-beds-needed-from-the-probability-distribution","title":"Reading a minimum number of beds needed from the probability distribution","text":"<p>Our input for the UCLH output does not show a probability distribution like this. It shows 'at least this number of beds needed' with 90% and 70% probability. (Check back to notebook 2 for this). To calculate this from the distribution given, we illustrate first by added a cumulative probability to the dataframe created earlier.</p> <pre><code>first_date_prob_dist['cumulative probability'] = first_date_prob_dist['probability'].cumsum()\nfirst_date_prob_dist['probability of needing at least this number or beds'] = first_date_prob_dist['cumulative probability'].apply(lambda x: 1 -x)\ndisplay(first_date_prob_dist.head(20))\n</code></pre> probability cumulative probability probability of needing at least this number or beds number of beds 0 3.83000095709416e-8 3.83000095709416e-8 0.999999961699990 1 8.91447105034246e-7 9.29747114605188e-7 0.999999070252885 2 9.96474713480853e-6 1.08944942494137e-5 0.999989105505751 3 7.12986776280389e-5 8.21931718774526e-5 0.999917806828123 4 0.000367215548706615 0.000449408720584068 0.999550591279416 5 0.00145156182973333 0.00190097055031739 0.998099029449683 6 0.00458531140812794 0.00648628195844533 0.993513718041555 7 0.0119004455059500 0.0183867274643953 0.981613272535605 8 0.0258924729749449 0.0442792004393402 0.955720799560660 9 0.0479546989485299 0.0922338993878701 0.907766100612130 10 0.0765094618936776 0.168743361281548 0.831256638718452 11 0.106161370669358 0.274904731950905 0.725095268049095 12 0.129109543666885 0.404014275617790 0.595985724382210 13 0.138509425956049 0.542523701573839 0.457476298426161 14 0.131784140162024 0.674307841735864 0.325692158264136 15 0.111707503010854 0.786015344746718 0.213984655253282 16 0.0846872810065416 0.870702625753259 0.129297374246741 17 0.0576121112605319 0.928314737013791 0.0716852629862087 18 0.0352707916903104 0.963585528704102 0.0364144712958984 19 0.0194806642771849 0.983066192981287 0.0169338070187135 <p>From this cumulative probability we can read off the number of beds where there is a 90% chance of needing at least this number</p> <pre><code>row_indicating_at_least_90_pc = first_date_prob_dist[first_date_prob_dist['probability of needing at least this number or beds'] &lt; 0.9].index[0]\nprint(f\"There is a 90% chance of needing at least {row_indicating_at_least_90_pc} beds\")\n</code></pre> <pre><code>There is a 90% chance of needing at least 10 beds\n</code></pre> <p>The predict module has a function for reading off the cdf in this way </p> <pre><code>from patientflow.predict.emergency_demand import index_of_sum\n??index_of_sum\n</code></pre> <pre><code>\u001b[0;31mSignature:\u001b[0m \u001b[0mindex_of_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sum\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-&gt;\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mSource:\u001b[0m   \n\u001b[0;32mdef\u001b[0m \u001b[0mindex_of_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sum\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-&gt;\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns the index where the cumulative sum of a sequence of probabilities exceeds max_sum.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mcumulative_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mcumulative_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mcumulative_sum\u001b[0m \u001b[0;34m&gt;=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_sum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# Return the last index if the sum doesn't exceed max_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mFile:\u001b[0m      ~/Repos/patientflow/src/patientflow/predict/emergency_demand.py\n\u001b[0;31mType:\u001b[0m      function\n</code></pre> <pre><code>sequence = first_date_prob_dist['probability'].values\nprint(f\"There is a 90% chance of needing at least {index_of_sum(sequence, 0.9)} beds, using the index_of_sum function\")\n\n</code></pre> <pre><code>There is a 90% chance of needing at least 10 beds, using the index_of_sum function\n</code></pre> <p>And this can be done from the original probability distribution</p> <pre><code>sequence = prob_dist[first_record_key]['agg_predicted']['agg_proba'].values\ncdf_cut_points = [0.9, 0.7]\nfor cut_point in cdf_cut_points:\n    num_beds = index_of_sum(sequence, cut_point)\n    print(f\"At least {num_beds} beds needed with {int(cut_point*100)}% probability\")\n\n</code></pre> <pre><code>At least 10 beds needed with 90% probability\nAt least 12 beds needed with 70% probability\n</code></pre> <pre><code>\n</code></pre> <pre><code>\n</code></pre>"},{"location":"notebooks/4c_Predict_probability_of_admission_to_specialty/","title":"Modelling probability of admission to specialty, if admitted","text":"<p>This notebook demonstrates the second stage of prediction, to generate a probability of admission to a specialty for each patient in the ED if they are admitted. </p> <p>Here consult sequences provide the input to prediction, and the model is trained only on visits by adult patients that ended in admission. Patients less than 18 at the time of arrival to the ED are assumed to be admitted to paediatric wards. This assumption could be relaxed by changing the training data to include children, and changing how the inference stage is done. </p> <p>This approach assumes that, if admitted, a patient's probability of admission to any particular specialty is independent of their probability of admission to hospital. </p>"},{"location":"notebooks/4c_Predict_probability_of_admission_to_specialty/#set-up-the-notebook-environment","title":"Set up the notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n\n\n\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/4c_Predict_probability_of_admission_to_specialty/#load-parameters-and-set-file-paths-and-load-data","title":"Load parameters and set file paths, and load data","text":"<pre><code>import pandas as pd\nfrom patientflow.load import load_data\nfrom patientflow.load import set_file_paths\n\n# set file paths\ndata_folder_name = 'data-public'\ndata_file_path = project_root / data_folder_name\n\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(project_root, \n               data_folder_name=data_folder_name)\n\n# load data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n\n# load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n</code></pre> <pre><code>Configuration will be loaded from: /Users/zellaking/Repos/patientflow/config.yaml\nData files will be loaded from: /Users/zellaking/Repos/patientflow/data-public\nTrained models will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public\nImages will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public/media\n</code></pre>"},{"location":"notebooks/4c_Predict_probability_of_admission_to_specialty/#train-the-model","title":"Train the model","text":"<p>This is the function that trains the specialty model, loaded from a file. Below we will break it down step-by-step.</p> <pre><code>from patientflow.train.sequence_predictor import train_sequence_predictor, get_default_visits\n??train_sequence_predictor\n</code></pre> <pre><code>\u001b[0;31mSignature:\u001b[0m\n\u001b[0mtrain_sequence_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mtrain_visits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mvisit_col\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0minput_var\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mgrouping_var\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0moutcome_var\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-&gt;\u001b[0m \u001b[0mpatientflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequencePredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mSource:\u001b[0m   \n\u001b[0;32mdef\u001b[0m \u001b[0mtrain_sequence_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mtrain_visits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mvisit_col\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0minput_var\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mgrouping_var\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0moutcome_var\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-&gt;\u001b[0m \u001b[0mSequencePredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Train a specialty prediction model.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Args:\u001b[0m\n\u001b[0;34m        train_visits: Training data containing visit information\u001b[0m\n\u001b[0;34m        model_name: Name identifier for the model\u001b[0m\n\u001b[0;34m        visit_col: Column name containing visit identifiers\u001b[0m\n\u001b[0;34m        input_var: Column name for input sequence\u001b[0m\n\u001b[0;34m        grouping_var: Column name for grouping sequence\u001b[0m\n\u001b[0;34m        outcome_var: Column name for target variable\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Returns:\u001b[0m\n\u001b[0;34m        Trained SequencePredictor model\u001b[0m\n\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mvisits_single\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_one_snapshot_per_visit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_visits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisit_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0madmitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisits_single\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0mvisits_single\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_admitted\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&amp;\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisits_single\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecialty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mfiltered_admitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_visits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madmitted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mfiltered_admitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_var\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_admitted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mfiltered_admitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouping_var\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_admitted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrouping_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mspec_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequencePredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0minput_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mgrouping_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrouping_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0moutcome_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutcome_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mspec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_admitted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mspec_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mFile:\u001b[0m      ~/Repos/patientflow/src/patientflow/train/sequence_predictor.py\n\u001b[0;31mType:\u001b[0m      function\n</code></pre> <p>The first step in the function above is to handle the fact that there are multiple snapshots per visit and we only want one for each visit in the training set. </p> <pre><code>from patientflow.prepare import select_one_snapshot_per_visit\n\nvisits_single = select_one_snapshot_per_visit(ed_visits, visit_col = 'visit_number')\n\nprint(ed_visits.shape)\nprint(visits_single.shape)\n</code></pre> <pre><code>(79814, 69)\n(64497, 68)\n</code></pre> <p>To train the specialty model, we only use a subset of the columns. Here we can see the relevant columns</p> <pre><code>display(visits_single[['consultation_sequence', 'final_sequence', 'specialty', 'is_admitted', 'age_group']].head(10))\n\n</code></pre> consultation_sequence final_sequence specialty is_admitted age_group snapshot_id 0 [] [] medical False 55-64 2 [] [] surgical False 75-102 3 [] [] medical False 35-44 5 ['haem_onc'] ['haem_onc'] haem/onc False 65-74 7 ['surgical'] ['surgical'] surgical False 25-34 10 [] ['haem_onc'] medical False 65-74 11 ['haem_onc'] ['haem_onc'] medical False 75-102 12 ['haem_onc'] ['haem_onc'] haem/onc False 75-102 13 [] [] haem/onc False 75-102 15 ['ambulatory'] ['ambulatory'] NaN False 0-17 <p>We filter down to only include admitted patients, and remove any with a null value for the specialty column, since this is the model aims to predict. </p> <pre><code>admitted = visits_single[\n    (visits_single.is_admitted) &amp; ~(visits_single.specialty.isnull())\n]\n</code></pre> <p>Note that some visits that ended in admission had no consult request at the time they were sampled, as we can see below, where visits have an empty tuple</p> <pre><code>display(admitted[['consultation_sequence', 'final_sequence', 'specialty', 'is_admitted', 'age_group']].head(10))\n\n\n</code></pre> consultation_sequence final_sequence specialty is_admitted age_group snapshot_id 20 ['surgical'] ['surgical', 'surgical'] surgical True 45-54 58 ['surgical'] ['surgical'] surgical True 35-44 77 [] ['acute'] medical True 65-74 117 [] ['surgical'] surgical True 35-44 125 ['surgical'] ['surgical'] surgical True 25-34 128 ['surgical'] ['surgical'] surgical True 75-102 141 [] ['surgical'] surgical True 65-74 163 ['acute'] ['acute'] medical True 65-74 176 [] ['surgical'] medical True 75-102 227 [] ['paeds'] paediatric True 0-17 <p>The UCLH data (not shared publicly) includes more detailed data on consult type, as shown in the <code>code</code> column in the dataset below. The public data has been simplified to a higher level (identified in the mapping below as <code>type</code>). </p> <pre><code>from pathlib import Path\nmodel_input_path = project_root / 'src' /  'patientflow'/ 'model-input'\nname_mapping = pd.read_csv(str(model_input_path) + '/consults-mapping.csv')\nname_mapping\n</code></pre> id code name type 0 1 CON124 Inpatient consult to Neuro Ophthalmology neuro 1 2 CON9 Inpatient consult to Neurology neuro 2 3 CON34 Inpatient consult to Dietetics (N&amp;D) - Not TPN allied 3 4 CON134 Inpatient consult to PERRT icu 4 5 CON163 IP Consult to MCC Complementary Therapy Team pain ... ... ... ... ... 111 112 CON77 Inpatient consult to Paediatric Allergy paeds 112 113 CON168 Inpatient consult to Acute Oncology Service haem_onc 113 114 CON84 Inpatient consult to Paediatric Hematology - C... haem_onc 114 115 CON122 Inpatient consult to Paediatric Epilepsy Service paeds 115 116 CON74 Inpatient consult to Smoking Cessation Program other <p>116 rows \u00d7 4 columns</p> <p>For example, the code for a consult with Acute Medicine is convered to a more general category in the public dataset</p> <pre><code>name_mapping[name_mapping.code == 'CON157']\n</code></pre> id code name type 14 15 CON157 Inpatient consult to Acute Medicine acute <p>The medical group includes many of the more specific types</p> <pre><code>name_mapping[name_mapping.type == 'medical']\n</code></pre> id code name type 7 8 CON165 Inpatient consult to Nutrition Team (TPN) medical 10 11 CON54 Inpatient consult to Respiratory Medicine medical 12 13 CON43 Inpatient consult to Cardiology medical 15 16 CON5 Inpatient consult to Infectious Diseases medical 17 18 CON132 Inpatient consult to Adult Diabetes CNS medical 33 34 CON68 Inpatient consult to Gastroenterology medical 37 38 CON60 Inpatient consult to Endocrinology medical 48 49 CON156 Inpatient consult to Adult Endocrine &amp; Diabetes medical 62 63 CON44 Inpatient consult to Rheumatology medical 66 67 CON147 Inpatient consult to Cardiac Rehabilitation medical 70 71 CON62 Inpatient consult to Internal Medicine medical 71 72 CON127 Inpatient consult to Hepato-Biliary Medicine medical 76 77 CON171 Inpatient consult to Tropical Medicine medical 91 92 CON153 Inpatient consult to Clinical Biochemistry medical 95 96 CON8 Inpatient consult to Renal Medicine medical 98 99 CON81 Inpatient consult to Paediatric Endocrinology medical 101 102 CON151 Inpatient consult to Virology medical 106 107 CON28 Inpatient consult to Integrative Medicine medical"},{"location":"notebooks/4c_Predict_probability_of_admission_to_specialty/#separate-into-training-validation-and-test-sets","title":"Separate into training, validation and test sets","text":"<p>As part of preparing the data, each visit has already been allocated into one of three sets - training, vaidation and test sets. </p> <pre><code>from patientflow.prepare import create_temporal_splits\n\n# note that we derive the training set from visits_single, as the SequencePredictor() does the preprocessing mentioned above\ntrain_visits, _, _ = create_temporal_splits(\n    visits_single,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\",\n)\n</code></pre> <pre><code>Split sizes: [42852, 5405, 16240]\n</code></pre>"},{"location":"notebooks/4c_Predict_probability_of_admission_to_specialty/#train-the-model_1","title":"Train the model","text":"<p>Here, we load the SequencePredictor(), a function that takes a sequence as input (in this case consultation_sequence), a grouping variable (in this case final_sequence) and a outcome variable (in this case specialty), and uses a grouping variable to create a rooted directed tree. Each new consult in the sequence is a branching node of the tree. The grouping variable, final sequence, serves as the terminal nodes of the tree. The function maps the probability of each part-complete sequence of consults ending (via each final_sequence) in each specialty of admission.</p> <pre><code>from patientflow.predictors.sequence_predictor import SequencePredictor\n\nspec_model = SequencePredictor(\n    input_var=\"consultation_sequence\",\n    grouping_var=\"final_sequence\",\n    outcome_var=\"specialty\",\n    apply_special_category_filtering=False,\n)\n\nspec_model.fit(train_visits)\n\n\n</code></pre> <pre>SequencePredictor(\n    input_var='consultation_sequence',\n    grouping_var='final_sequence',\n    outcome_var='specialty',\n    apply_special_category_filtering=False,\n    admit_col='is_admitted'\n)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u00a0SequencePredictoriNot fitted<pre>SequencePredictor(\n    input_var='consultation_sequence',\n    grouping_var='final_sequence',\n    outcome_var='specialty',\n    apply_special_category_filtering=False,\n    admit_col='is_admitted'\n)</pre> <p>Meta data about the model can be viewed in the metrics object</p> <pre><code>spec_model.metrics\n</code></pre> <pre><code>{'train_dttm': '2025-03-20 16:30',\n 'train_set_no': 42852,\n 'start_date': '3/1/2031',\n 'end_date': '8/9/2031'}\n</code></pre> <p>Passing an empty tuple to the trained model shows the probability of ending in each specialty, if a visit has had no consults yet. </p> <pre><code>print(\"For a visit which has no consult at the time of a snapsnot, the probabilities of ending up under a medical, surgical or haem/onc specialty are shown below\")\nprint({k: round(v, 3) for k, v in spec_model.predict(tuple()) .items()})\n\n\n\n</code></pre> <pre><code>For a visit which has no consult at the time of a snapsnot, the probabilities of ending up under a medical, surgical or haem/onc specialty are shown below\n{'surgical': 0.258, 'medical': 0.574, 'paediatric': 0.078, 'haem/onc': 0.09}\n</code></pre> <p>The probabilities for each consult sequence ending in a given observed specialty have been saved in the model. These can be accessed as follows: </p> <pre><code>spec_model.weights[()].keys()\n</code></pre> <pre><code>dict_keys(['surgical', 'medical', 'paediatric', 'haem/onc'])\n</code></pre> <pre><code>weights = spec_model.weights\nprint(\"For a visit which has one consult to acute medicine at the time of a snapsnot, the probabilities of ending up under a medical, surgical or haem/onc specialty are shown below\")\nprint({k: round(v, 3) for k, v in weights[tuple(['acute'])].items()})\n\n</code></pre> <pre><code>For a visit which has one consult to acute medicine at the time of a snapsnot, the probabilities of ending up under a medical, surgical or haem/onc specialty are shown below\n{'surgical': 0.013, 'medical': 0.946, 'paediatric': 0.002, 'haem/onc': 0.039}\n</code></pre> <p>The intermediate mapping of consultation_sequence to final_sequence can be accessed from the trained model like this. The first row shows the probability of a null sequence (ie no consults yet) ending in any of the final_sequence options. </p> <pre><code>spec_model.input_to_grouping_probs\n</code></pre> final_sequence () ('acute',) ('acute', 'acute') ('acute', 'acute', 'medical') ('acute', 'acute', 'medical', 'surgical') ('acute', 'acute', 'mental_health') ('acute', 'acute', 'palliative') ('acute', 'acute', 'surgical') ('acute', 'allied') ('acute', 'allied', 'acute') ... ('surgical', 'surgical') ('surgical', 'surgical', 'acute') ('surgical', 'surgical', 'acute', 'mental_health', 'discharge', 'discharge') ('surgical', 'surgical', 'acute', 'surgical') ('surgical', 'surgical', 'icu') ('surgical', 'surgical', 'medical') ('surgical', 'surgical', 'obs_gyn') ('surgical', 'surgical', 'other') ('surgical', 'surgical', 'surgical') probability_of_grouping_sequence consultation_sequence () 0.009819 0.458837 0.013218 0.000755 0.000378 0.000755 0.000000 0.000378 0.005665 0.000378 ... 0.007553 0.000755 0.000000 0.0 0.0 0.000000 0.000000 0.000000 0.000378 0.534194 ('acute',) 0.000000 0.830409 0.005848 0.000000 0.000000 0.000000 0.000000 0.000000 0.014620 0.000000 ... 0.000000 0.000000 0.000000 0.0 0.0 0.000000 0.000000 0.000000 0.000000 0.206980 ('acute', 'acute') 0.000000 0.000000 0.909091 0.045455 0.000000 0.000000 0.045455 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000 0.0 0.0 0.000000 0.000000 0.000000 0.000000 0.004438 ('acute', 'allied') 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 ... 0.000000 0.000000 0.000000 0.0 0.0 0.000000 0.000000 0.000000 0.000000 0.000202 ('acute', 'ambulatory') 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000 0.0 0.0 0.000000 0.000000 0.000000 0.000000 0.000403 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ('surgical', 'medical') 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000 0.0 0.0 0.000000 0.000000 0.000000 0.000000 0.000403 ('surgical', 'obs_gyn') 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000 0.0 0.0 0.000000 0.000000 0.000000 0.000000 0.000403 ('surgical', 'surgical') 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.814815 0.000000 0.037037 0.0 0.0 0.037037 0.037037 0.037037 0.037037 0.005447 ('surgical', 'surgical', 'acute') 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.500000 0.000000 0.5 0.0 0.000000 0.000000 0.000000 0.000000 0.000403 ('surgical', 'surgical', 'icu') 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000 0.0 1.0 0.000000 0.000000 0.000000 0.000000 0.000202 <p>81 rows \u00d7 275 columns</p> <pre><code># save models and metadata\nfrom patientflow.train.utils import save_model\n\nsave_model(spec_model, \"specialty_no_filtering\", model_file_path)\nprint(f\"Model has been saved to {model_file_path}\")\n</code></pre> <pre><code>Model has been saved to /Users/zellaking/Repos/patientflow/trained-models/public\n</code></pre>"},{"location":"notebooks/4c_Predict_probability_of_admission_to_specialty/#handle-special-categories","title":"Handle special categories","text":"<p>At UCLH, we assume that all under 18s will be admitted to a paediatric specialty. Their visits are therefore used to train the specialty predictor. An <code>apply_special_category_filtering</code> parameter can be set in the <code>SequencePredictor</code> to handle certain categories differently. When this is set, the <code>SequencePredictor</code> will retrieve the relevant logic that has been defined in a class called <code>SpecialCategoryParams</code>. </p> <pre><code>train_visits.snapshot_date.min()\n</code></pre> <pre><code>'3/1/2031'\n</code></pre> <pre><code>spec_model= SequencePredictor(\n    input_var=\"consultation_sequence\",\n    grouping_var=\"final_sequence\",\n    outcome_var=\"specialty\",\n    apply_special_category_filtering=True,\n)\n\nspec_model.fit(train_visits)\n\nweights = spec_model.weights\nprint(\"For a visit which has no consult at the time of a snapsnot, the probabilities of ending up under a medical, surgical or haem/onc specialty are shown below\")\nprint({k: round(v, 3) for k, v in spec_model.predict(tuple()) .items()})\nprint(\"For a visit which has one consult to acute medicine at the time of a snapsnot, the probabilities of ending up under a medical, surgical or haem/onc specialty are shown below\")\nprint({k: round(v, 3) for k, v in weights[tuple(['acute'])].items()})\n\nsave_model(spec_model, \"specialty\", model_file_path)\n\n\n</code></pre> <pre><code>---------------------------------------------------------------------------\n\nTypeError                                 Traceback (most recent call last)\n\nCell In[128], line 8\n      1 spec_model= SequencePredictor(\n      2     input_var=\"consultation_sequence\",\n      3     grouping_var=\"final_sequence\",\n      4     outcome_var=\"specialty\",\n      5     apply_special_category_filtering=True,\n      6 )\n----&gt; 8 spec_model.fit(train_visits)\n     10 weights = spec_model.weights\n     11 print(\"For a visit which has no consult at the time of a snapsnot, the probabilities of ending up under a medical, surgical or haem/onc specialty are shown below\")\n\n\nFile ~/Repos/patientflow/src/patientflow/predictors/sequence_predictor.py:178, in SequencePredictor.fit(self, X)\n    176     self.metrics[\"end_date\"] = X[\"snapshot_date\"].max()\n    177     self.metrics[\"unique_outcomes\"] = len(X[self.outcome_var].unique())\n--&gt; 178     self.metrics[\"unique_input_sequences\"] = len(X[self.input_var].unique())\n    179     self.metrics[\"unique_grouping_sequences\"] = len(X[self.grouping_var].unique())\n    181 # Preprocess the data\n\n\nFile ~/miniconda3/envs/patientflow/lib/python3.12/site-packages/pandas/core/series.py:2407, in Series.unique(self)\n   2344 def unique(self) -&gt; ArrayLike:  # pylint: disable=useless-parent-delegation\n   2345     \"\"\"\n   2346     Return unique values of Series object.\n   2347 \n   (...)\n   2405     Categories (3, object): ['a' &lt; 'b' &lt; 'c']\n   2406     \"\"\"\n-&gt; 2407     return super().unique()\n\n\nFile ~/miniconda3/envs/patientflow/lib/python3.12/site-packages/pandas/core/base.py:1025, in IndexOpsMixin.unique(self)\n   1023     result = values.unique()\n   1024 else:\n-&gt; 1025     result = algorithms.unique1d(values)\n   1026 return result\n\n\nFile ~/miniconda3/envs/patientflow/lib/python3.12/site-packages/pandas/core/algorithms.py:401, in unique(values)\n    307 def unique(values):\n    308     \"\"\"\n    309     Return unique values based on a hash table.\n    310 \n   (...)\n    399     array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\n    400     \"\"\"\n--&gt; 401     return unique_with_mask(values)\n\n\nFile ~/miniconda3/envs/patientflow/lib/python3.12/site-packages/pandas/core/algorithms.py:440, in unique_with_mask(values, mask)\n    438 table = hashtable(len(values))\n    439 if mask is None:\n--&gt; 440     uniques = table.unique(values)\n    441     uniques = _reconstruct_data(uniques, original.dtype, original)\n    442     return uniques\n\n\nFile pandas/_libs/hashtable_class_helper.pxi:7248, in pandas._libs.hashtable.PyObjectHashTable.unique()\n\n\nFile pandas/_libs/hashtable_class_helper.pxi:7195, in pandas._libs.hashtable.PyObjectHashTable._unique()\n\n\nTypeError: unhashable type: 'list'\n</code></pre> <p>The handling of special categories is saved as an attribute of the trained model as shown below.</p> <pre><code>spec_model.special_params\n</code></pre> <pre><code>{'special_category_func': &lt;bound method SpecialCategoryParams.special_category_func of &lt;patientflow.prepare.SpecialCategoryParams object at 0x28a867ef0&gt;&gt;,\n 'special_category_dict': {'medical': 0.0,\n  'surgical': 0.0,\n  'haem/onc': 0.0,\n  'paediatric': 1.0},\n 'special_func_map': {'paediatric': &lt;bound method SpecialCategoryParams.special_category_func of &lt;patientflow.prepare.SpecialCategoryParams object at 0x28a867ef0&gt;&gt;,\n  'default': &lt;bound method SpecialCategoryParams.opposite_special_category_func of &lt;patientflow.prepare.SpecialCategoryParams object at 0x28a867ef0&gt;&gt;}}\n</code></pre> <pre><code>\n</code></pre>"},{"location":"notebooks/4d_Predict_demand_from_patients_yet_to_arrive/","title":"Predict yet to arrive","text":"<p>The notebook shows how to prepare a model that will predict the number of patients yet to arrive.</p> <p>Inputs - A series of times in the day at which we want to make these predictions is set, saved in an array called prediction_times. Each prediction time is saved as a tuple. Eg 6 am is saved as (6,0) - A series of dates on which we want to make these predictions - A window after the prediction time, within which we are interested in predicting a number of patients (eg 8 hours)</p>"},{"location":"notebooks/4d_Predict_demand_from_patients_yet_to_arrive/#set-up-the-notebook-environment","title":"Set up the notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/4d_Predict_demand_from_patients_yet_to_arrive/#load-parameters-and-set-file-paths-and-load-data","title":"Load parameters and set file paths, and load data","text":"<pre><code>import pandas as pd\nfrom patientflow.load import load_data\nfrom patientflow.load import set_file_paths\n\n# set file paths\ndata_folder_name = 'data-public'\ndata_file_path = project_root / data_folder_name\n\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(project_root, \n               data_folder_name=data_folder_name)\n\n# load data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n\ninpatient_arrivals = load_data(data_file_path, \n                    file_name='inpatient_arrivals.csv')\n\n# load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n</code></pre> <pre><code>Configuration will be loaded from: /Users/zellaking/Repos/patientflow/config.yaml\nData files will be loaded from: /Users/zellaking/Repos/patientflow/data-public\nTrained models will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public\nImages will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public/media\n</code></pre> <pre><code>inpatient_arrivals.head()\n</code></pre> training_validation_test arrival_datetime sex specialty is_child 0 train 2031-04-24 19:21:00+00:00 M haem/onc False 1 train 2031-04-25 12:42:00+00:00 F medical False 2 train 2031-03-20 19:54:00+00:00 F haem/onc False 3 train 2031-03-04 22:03:00+00:00 F haem/onc False 4 train 2031-03-01 11:10:44+00:00 M surgical False"},{"location":"notebooks/4d_Predict_demand_from_patients_yet_to_arrive/#separate-into-training-validation-and-test-sets","title":"Separate into training, validation and test sets","text":"<pre><code>from patientflow.prepare import create_temporal_splits\n\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    inpatient_arrivals,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"arrival_datetime\",\n)\n</code></pre> <pre><code>Split sizes: [7730, 1244, 3701]\n</code></pre> <p>The Weighted Poisson model requires as input a dataframe with the index set as the arrival datetimes of each visit. We set that here</p> <pre><code>train_visits['arrival_datetime'] = pd.to_datetime(train_visits['arrival_datetime'], utc = True)\ntrain_visits.set_index('arrival_datetime', inplace=True)\n</code></pre>"},{"location":"notebooks/4d_Predict_demand_from_patients_yet_to_arrive/#train-the-weighted-poisson-model","title":"Train the Weighted Poisson model","text":"<p>The weighted Poisson model provides a way to predict yet to arrive patients under the assumption that the ED/SDEC is meeting targets for how long it takes to admit patients. The aspirational targets are set as parameters in config.yaml and have been loaded at the top of this notebook. </p> <p>To load the parameters:</p> <pre><code>x1, y1, x2, y2 = params[\"x1\"], params[\"y1\"], params[\"x2\"], params[\"y2\"]\nprediction_window = params[\"prediction_window\"]\nepsilon = float(params[\"epsilon\"])\nyta_time_interval = params[\"yta_time_interval\"]\nprediction_times = params[\"prediction_times\"]\n\n</code></pre> <pre><code>print(f'The aspiration is that within {str(x1)} hours of arrival, {str(y1*100)}% of patients will have been admitted, and that witin {str(x2)} hours of arrival, {str(y2*100)}% of patients will have been admitted')\n</code></pre> <pre><code>The aspiration is that within 4.0 hours of arrival, 76.0% of patients will have been admitted, and that witin 12.0 hours of arrival, 99.0% of patients will have been admitted\n</code></pre> <p>The aspiration can be plotted as a curve to see the shape of the curve. Here we have assumed that the majority of admissions happen between 3 and 4 hours of arrival, where the slope of the curve is steepest. </p> <pre><code>from patientflow.viz.aspirational_curve_plot import plot_curve\n\nfigsize = (6,3)\n\nplot_curve(\n    title = 'Aspirational curve reflecting a ' + str(int(x1)) + ' hour target for ' + str(int(y1*100)) + \\\n        '% of patients\\nand a '+ str(int(x2)) + ' hour target for ' + str(int(y2*100)) + '% of patients',\n    x1 = x1,\n    y1 = y1,\n    x2 = x2,\n    y2 = y2,\n    include_titles=True,\n)\n\n</code></pre> <p></p>"},{"location":"notebooks/4d_Predict_demand_from_patients_yet_to_arrive/#predict-for-all-admissions-irrespective-of-specialty-of-admission","title":"Predict for all admissions, irrespective of specialty of admission","text":"<pre><code>from patientflow.predictors.weighted_poisson_predictor import WeightedPoissonPredictor\nfrom joblib import dump, load\n\nmodel =  WeightedPoissonPredictor(verbose=True)\nnum_days = (start_validation_set - start_training_set).days\n\n\nmodel.fit(train_visits, prediction_window, yta_time_interval, prediction_times, num_days)\n\nmodel_name = 'ed_yet_to_arrive_all_' + str(int(prediction_window/60)) + '_hours'\nfull_path = model_file_path / model_name \nfull_path = full_path.with_suffix('.joblib')\n\ndump(model, full_path)\n</code></pre> <pre><code>Calculating time-varying arrival rates for data provided, which spans 184 unique dates\nPoisson Binomial Predictor trained for these times: [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)]\nusing prediction window of 480 minutes after the time of prediction\nand time interval of 15 minutes within the prediction window.\nThe error value for prediction will be 1e-07\nTo see the weights saved by this model, used the get_weights() method\n\n\n\n\n\n['/Users/zellaking/Repos/patientflow/trained-models/public/ed_yet_to_arrive_all_8_hours.joblib']\n</code></pre> <pre><code>model.metrics\n</code></pre> <pre><code>{'train_dttm': '2025-03-20-14-49',\n 'train_set_no': 7730,\n 'start_date': datetime.date(2031, 3, 1),\n 'end_date': datetime.date(2031, 8, 31),\n 'num_days': 184}\n</code></pre> <p>To see the predicted distribution of patients yet-to-arrive at 15:30, call the model as follows:</p> <pre><code>prediction_time = tuple([15, 30])\n</code></pre> <pre><code>prediction_context = {\n    'default': {\n        'prediction_time': prediction_time\n    }\n}\n\nmodel_name = 'ed_yet_to_arrive_all_' + str(int(prediction_window/60)) + '_hours'\nfull_path = model_file_path / model_name \nfull_path = full_path.with_suffix('.joblib')\n\nmodel = load(full_path)\n\npreds = model.predict(prediction_context, x1, y1, x2, y2)\npreds\n</code></pre> <pre><code>{'default':      agg_proba\n sum           \n 0     0.000033\n 1     0.000344\n 2     0.001774\n 3     0.006095\n 4     0.015706\n ..         ...\n 252   0.000000\n 253   0.000000\n 254   0.000000\n 255   0.000000\n 256   0.000000\n\n [257 rows x 1 columns]}\n</code></pre> <p>To make this more readable:</p> <pre><code>yta_prob_dist = preds['default'].rename(columns = {'agg_proba': 'probability'})\nyta_prob_dist.index.name = 'number of beds'\n\nprint(f\"Probability of needing this number of beds needed at {prediction_time} based on patients yet to arrive ED at that time\")\ndisplay(yta_prob_dist.head(15))\n</code></pre> <pre><code>Probability of needing this number of beds needed at (15, 30) based on patients yet to arrive ED at that time\n</code></pre> probability number of beds 0 0.000033 1 0.000344 2 0.001774 3 0.006095 4 0.015706 5 0.032377 6 0.055617 7 0.081891 8 0.105505 9 0.120826 10 0.124534 11 0.116687 12 0.100224 13 0.079461 14 0.058500 <p>To see the output visually we can plot this using the prob_dist_plot from the <code>viz</code> module</p> <pre><code>from patientflow.viz.prob_dist_plot import prob_dist_plot\n\nhour, minute = prediction_context['default']['prediction_time']\nstart_time = f\"{hour:02}:{minute:02}\"\nend_time = f\"{int(hour + prediction_window / 60):02}:{minute:02}\"\n\ntitle = f\"Predicted number of beds needed for patients arriving after {start_time} and before {end_time}\\nassuming the ED meets aspirational targets\"\n\nprob_dist_plot(preds['default'], \n               title=title, \n               include_titles=True)\n</code></pre> <p></p> <p>If the model is asked to predict for a time it hasn't been trained for (eg 14:30) it will revert to the most recent prediction time. (Note the warning message below.)</p> <pre><code>prediction_context = {\n    'default': {\n        'prediction_time': tuple([14,30])\n    }\n}\n\nmodel_name = 'ed_yet_to_arrive_all_' + str(int(prediction_window/60)) + '_hours'\nfull_path = model_file_path / model_name \nfull_path = full_path.with_suffix('.joblib')\n\nmodel = load(full_path)\n\npreds = model.predict(prediction_context, x1, y1, x2, y2)\n\n</code></pre> <pre><code>/Users/zellaking/Repos/patientflow/src/patientflow/predictors/weighted_poisson_predictor.py:210: UserWarning: Time of day requested of (14, 30) was not in model training. Reverting to predictions for (12, 0).\n  warnings.warn(\n</code></pre>"},{"location":"notebooks/4d_Predict_demand_from_patients_yet_to_arrive/#predict-within-specialty","title":"Predict within specialty","text":"<p>To train a model of yet-to-arrive patients within specialty, we can use filters as shown below. Here, if an arrival is a child, we assume they will be admitted to a paediatric specialty by default</p> <pre><code>train_visits.head()\n</code></pre> training_validation_test sex specialty is_child arrival_datetime 2031-04-24 19:21:00+00:00 train M haem/onc False 2031-04-25 12:42:00+00:00 train F medical False 2031-03-20 19:54:00+00:00 train F haem/onc False 2031-03-04 22:03:00+00:00 train F haem/onc False 2031-03-01 11:10:44+00:00 train M surgical False <pre><code>from patientflow.predictors.weighted_poisson_predictor import WeightedPoissonPredictor\nfrom joblib import dump, load\nfrom patientflow.prepare import create_yta_filters\n\nspecialty_filters = create_yta_filters(ed_visits)\nmodel_by_spec =  WeightedPoissonPredictor(filters = specialty_filters, verbose=True)\nnum_days = (start_validation_set - start_training_set).days\n\nmodel_by_spec.fit(train_visits, \n                  prediction_window=prediction_window, \n                  yta_time_interval=yta_time_interval, \n                  prediction_times= prediction_times,\n                  num_days=num_days)\n\n\nmodel_name = 'ed_yet_to_arrive_by_spec_' + str(int(prediction_window/60)) + '_hours'\nfull_path = model_file_path / model_name \nfull_path = full_path.with_suffix('.joblib')\n\ndump(model_by_spec, full_path)\n</code></pre> <pre><code>Calculating time-varying arrival rates for data provided, which spans 184 unique dates\nCalculating time-varying arrival rates for data provided, which spans 184 unique dates\n\n\nCalculating time-varying arrival rates for data provided, which spans 184 unique dates\nCalculating time-varying arrival rates for data provided, which spans 184 unique dates\nPoisson Binomial Predictor trained for these times: [(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)]\nusing prediction window of 480 minutes after the time of prediction\nand time interval of 15 minutes within the prediction window.\nThe error value for prediction will be 1e-07\nTo see the weights saved by this model, used the get_weights() method\n\n\n\n\n\n['/Users/zellaking/Repos/patientflow/trained-models/public/ed_yet_to_arrive_by_spec_8_hours.joblib']\n</code></pre> <pre><code>model_name = 'ed_yet_to_arrive_by_spec_' + str(int(prediction_window/60)) + '_hours'\nfull_path = model_file_path / model_name \nfull_path = full_path.with_suffix('.joblib')\n\nmodel_by_spec = load(full_path)\n\nprediction_context = {\n    'medical': {\n        'prediction_time': tuple(prediction_time)  \n    }\n}\n\npreds = model_by_spec.predict(prediction_context, x1, y1, x2, y2)\n\n\nyta_prob_dist_medical = preds['medical'].rename(columns = {'agg_proba': 'probability'})\nyta_prob_dist_medical.index.name = 'number of beds'\n\nprint(f\"Probability of needing this number of medical beds in the next 8 hours after {prediction_time} for patients yet to arrive at the ED\")\ndisplay(yta_prob_dist_medical.head(15))\n</code></pre> <pre><code>Probability of needing this number of medical beds in the next 8 hours after (15, 30) for patients yet to arrive at the ED\n</code></pre> probability number of beds 0 0.004088 1 0.022482 2 0.061823 3 0.113336 4 0.155830 5 0.171405 6 0.157114 7 0.123440 8 0.084861 9 0.051857 10 0.028520 11 0.014259 12 0.006535 13 0.002765 14 0.001086 <p>Plotting the predicted number of beds needed</p> <pre><code>from patientflow.viz.prob_dist_plot import prob_dist_plot\n\nfor spec in specialty_filters:\n    prediction_context = {\n    spec: {\n        'prediction_time': tuple([6, 0])  \n        }\n    }\n\n    preds = model_by_spec.predict(prediction_context, x1, y1, x2, y2)\n\n    hour, minute = prediction_context[spec]['prediction_time']\n    start_time = f\"{hour:02}:{minute:02}\"\n    end_time = f\"{int(hour + prediction_window / 60):02}:{minute:02}\"\n\n    title = f\"Predicted number of {spec} beds needed for patients arriving after {start_time} and before {end_time}\\nassuming the ED meets aspirational targets\"\n\n    prob_dist_plot(preds[spec], \n                title=title, \n                include_titles=True) \n</code></pre> <p></p> <p></p> <p></p> <p></p> <pre><code>\n</code></pre> <pre><code>model_by_spec.filters.keys()\n</code></pre> <pre><code>dict_keys(['medical', 'surgical', 'haem/onc', 'paediatric'])\n</code></pre> <pre><code>model_by_spec.prediction_window\n</code></pre> <pre><code>480\n</code></pre> <pre><code>\n</code></pre>"},{"location":"notebooks/4e_Predict_probabiity_of_admission_using_minimal_data/","title":"Predict Probabiity of Admission Using Minimal Data","text":"<p>What if a hospital has only minimal data available in real-time. Is it still feasible to make predictions?</p> <p>Here I report the results of using a very limited dataset.</p> <p>I have taken data elements from two datasets used in management of emergency care nationally. </p> <ul> <li>The Emergency Care Data Set (ECDS), a standardised national dataset that sends information collected during an ED visit to NHS England on a daily basis.</li> <li>The Operational Pressures Escalation Levels (OPEL) Framework, a national framework used by the NHS to track daily operational pressures. OPEL data is not reported at patient level, but it does require preparation of metrics based on patient-level data (eg number in ED)</li> </ul>"},{"location":"notebooks/4e_Predict_probabiity_of_admission_using_minimal_data/#data-elements-found-in-ecds","title":"Data elements found in ECDS","text":"<p>I picked a subset of variables from the UCLH dataaset which have reasonable completion rates in ECDS, according to information shared with me by NHS England. These are listed below with a link to the NHS Data Dictionary </p> Data Element NHS Data Dictionary Link Activity start date and time https://www.datadictionary.nhs.uk/data_elements/urgent_and_emergency_care_activity_start_date_and_time.html Activity end date and time https://www.datadictionary.nhs.uk/data_elements/urgent_and_emergency_care_activity_end_date_and_time.html Arrival mode https://www.datadictionary.nhs.uk/data_elements/urgent_and_emergency_care_arrival_mode__snomed_ct_.html Age https://www.datadictionary.nhs.uk/data_elements/age_at_cds_activity_date.html Gender\u00b9 https://www.datadictionary.nhs.uk/data_elements/emergency_care_expected_date.html Acuity\u00b2 https://www.datadictionary.nhs.uk/data_elements/urgent_and_emergency_care_acuity__snomed_ct_.html Discharge status https://www.datadictionary.nhs.uk/data_elements/urgent_and_emergency_care_discharge_status__snomed_ct_.html <p>\u00b9 Regarding gender, there are two fields in the NHSE data dictionary: stated gender and phenotypic sex. My data is slighly different; I have recorded categories of male or female. \u00b2 Regarding acuity, I have used Manchester Triage Scores. These may not directly map to the Acuity levels in ECDS. </p>"},{"location":"notebooks/4e_Predict_probabiity_of_admission_using_minimal_data/#data-elements-found-in-opel","title":"Data elements found in OPEL","text":"<p>OPEL requires providers to report the following parameters about their current Emergency Department (ED):  </p> <ol> <li>Average ambulance handover since midnight (minutes)</li> <li>Current 4-hour ED performance percentage (percentage)</li> <li>Current ED majors and resus occupancy (percentage)</li> <li>Current median time to treatment since midnight (minutes)</li> <li>Patients in ED over 12 hours (percentage)</li> <li>Patients in ED referred to service (percentage)</li> </ol> <p>I have used the following elements in my dataset:</p> Data Element Use in OPEL Patient in Majors Numerator of current ED majors and resus occupancy (percentage) Patient in Resus Numerator of current ED majors and resus occupancy (percentage) Length of stay Patients in ED over 12 hours (percentage) Has consult request Patients in ED referred to service (percentage) <p>This notebook shows the results of modelling using only the elements covered above. </p>"},{"location":"notebooks/4e_Predict_probabiity_of_admission_using_minimal_data/#set-up-the-notebook-environment","title":"Set up the notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/4e_Predict_probabiity_of_admission_using_minimal_data/#load-parameters-and-set-file-paths-and-load-data","title":"Load parameters and set file paths, and load data","text":"<pre><code>import pandas as pd\nfrom patientflow.load import load_data\nfrom patientflow.load import set_file_paths\n\n# set file paths\ndata_folder_name = 'data-public'\ndata_file_path = project_root / data_folder_name\n\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(\n    project_root, \n    data_folder_name=data_folder_name,\n    config_file = 'config.yaml')\n\n# load data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n\n# load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\n\n</code></pre> <pre><code>Configuration will be loaded from: /Users/zellaking/Repos/patientflow/config.yaml\nData files will be loaded from: /Users/zellaking/Repos/patientflow/data-public\nTrained models will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public\nImages will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public/media\n</code></pre>"},{"location":"notebooks/4e_Predict_probabiity_of_admission_using_minimal_data/#train-models","title":"Train models","text":"<pre><code># Reduce data to minimum\nfrom datetime import timedelta\n\nminimum_data_cols = ['snapshot_date', 'prediction_time', 'visit_number', 'elapsed_los', 'latest_obs_manchester_triage_acuity',\n       'sex', 'age_group', 'arrival_method', 'has_consultation', 'current_location_type', 'is_admitted']\n\ned_visits_minimal= ed_visits[minimum_data_cols].copy()\n\n# create majors resus column\ned_visits_minimal['is_majors_resus'] = ed_visits_minimal['current_location_type'].isin(['majors', 'resus'])\n\n# create over 12 hours column\ned_visits_minimal.loc[:, 'over_12_hours'] = ed_visits_minimal['elapsed_los'] &gt; timedelta(hours=12).total_seconds()\n\n# drop other columns\ned_visits_minimal.drop(columns=['current_location_type', 'elapsed_los'], inplace=True)\n\n# Save ed_visits_minimal to CSV\ned_visits_minimal.to_csv(data_file_path / 'ed_visits_minimal.csv')\n\n</code></pre> <pre><code>from patientflow.prepare import create_temporal_splits\n\ntrain_visits, valid_visits, test_visits = create_temporal_splits(\n    ed_visits_minimal,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\",\n)\n\n_, _, test_visits_full = create_temporal_splits(\n    ed_visits,\n    start_training_set,\n    start_validation_set,\n    start_test_set,\n    end_test_set,\n    col_name=\"snapshot_date\",\n)\n</code></pre> <pre><code>Split sizes: [53801, 6519, 19494]\nSplit sizes: [53801, 6519, 19494]\n</code></pre> <pre><code>ordinal_mappings = {\n\n    \"latest_obs_manchester_triage_acuity\": [\n        \"Blue\",\n        \"Green\",\n        \"Yellow\",\n        \"Orange\",\n        \"Red\",\n    ],\n\n    }\nexclude_from_training_data = [ 'snapshot_date', 'prediction_time','visit_number']\n</code></pre> <pre><code>from datetime import datetime\n\n# Create metadata dictionary\ntrain_dttm = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\nmodel_metadata = {\n    \"train_dttm\": train_dttm,\n}\n\n# grid for hyperparameter tuning\ngrid = {\n    'n_estimators':[30, 40, 50],\n    'subsample':[0.7,0.8,0.9],\n    'colsample_bytree': [0.7,0.8,0.9]\n}\n\n# # minimal grid for expediency\n# grid = {\"n_estimators\": [30], \"subsample\": [0.7], \"colsample_bytree\": [0.7]}\n\n\n</code></pre> <pre><code># train admissions model\nfrom patientflow.train.classifiers import train_multiple_classifiers\n\nprediction_times = ed_visits.prediction_time.unique()\n\nmodel_name = \"admissions_minimal_balanced_calibrated\"\nmodel_metadata, trained_models = train_multiple_classifiers(\n    train_visits=train_visits,\n    valid_visits=valid_visits,\n    test_visits=test_visits,\n    grid=grid,\n    exclude_from_training_data=exclude_from_training_data,\n    ordinal_mappings=ordinal_mappings,\n    prediction_times=prediction_times,\n    model_name=model_name,\n    model_metadata=model_metadata,\n    calibrate_probabilities=True,\n    use_balanced_training=True,\n    visit_col='visit_number' \n)\n\n# save models and metadata\nfrom patientflow.train.utils import save_model\n\nsave_model(trained_models, model_name, model_file_path)\n\nprint(f\"Models have been saved to {model_file_path}\")\n</code></pre> <pre><code>Processing: (12, 0)\n\nProcessing: (15, 30)\n\nProcessing: (6, 0)\n\nProcessing: (9, 30)\n\nProcessing: (22, 0)\nModels have been saved to /Users/zellaking/Repos/patientflow/trained-models/public\n</code></pre>"},{"location":"notebooks/4e_Predict_probabiity_of_admission_using_minimal_data/#compare-miminal-model-with-full-model","title":"Compare miminal model with full model","text":"<p>How does this minimal model compare with a full model? </p> <p>To answer this question, I first use some standard Machine Learning metrics to see how consistent model's predictions were for each patient with the numbers actually admitted. </p> <p>I'm dealing with what is known as an 'imbalanced' class problem in Machine Learning. The Area under the Precision-Recall Curve (AUPRC) is informative for imbalanced datasets. It shows how well the model identifies true positive cases (admissions) while minimizing false positives. The AUPRC score should be higher than the proportion of admissions in the dataset. </p> <p>In my case, a higher AUPRC indicates that the model can better identify patients who will need admission while minimising any excess effort to prepare beds for patients who will not be admitted. </p> <p>From the output below, both the minimal model and the full model improve over the baseline class balance, but the full model does better. Using a minimal dataset mean less good predictions, but only to a marginal extent.</p> <pre><code>from patientflow.viz.model_comparison import plot_model_comparisons, load_model_results, print_model_results\n\n\nprediction_times = ed_visits.prediction_time.unique()\nmodels = {\n    'admissions_minimal_balanced_calibrated': 'minimal_model_metadata.json',\n    'admissions_balanced_calibrated': 'model_metadata_balanced_calibrated.json'\n}\nresults = load_model_results(model_file_path, prediction_times, models)\nprint_model_results(results, metrics_keys=[\"original_positive_rate\", \"test_auprc\"])\n\n\n</code></pre> <pre><code>Results for admissions_minimal_balanced_calibrated model\n\nModel: admissions_minimal_balanced_calibrated_0600; class balance: 0.172; auprc: 0.412\n\nModel: admissions_minimal_balanced_calibrated_0930; class balance: 0.131; auprc: 0.300\n\nModel: admissions_minimal_balanced_calibrated_1200; class balance: 0.124; auprc: 0.327\n\nModel: admissions_minimal_balanced_calibrated_1530; class balance: 0.155; auprc: 0.383\n\nModel: admissions_minimal_balanced_calibrated_2200; class balance: 0.165; auprc: 0.528\n\n\n\nResults for admissions_balanced_calibrated model\n\nModel: admissions_balanced_calibrated_0600; class balance: 0.172; auprc: 0.476\n\nModel: admissions_balanced_calibrated_0930; class balance: 0.131; auprc: 0.398\n\nModel: admissions_balanced_calibrated_1200; class balance: 0.124; auprc: 0.422\n\nModel: admissions_balanced_calibrated_1530; class balance: 0.155; auprc: 0.470\n\nModel: admissions_balanced_calibrated_2200; class balance: 0.165; auprc: 0.587\n</code></pre> <p>The AUPRC ranges printed above represent an improvement over the positive class proportion. </p> <p>Here, the XGBoost classifier models used have been optimised to minimize log loss (also known as cross-entropy loss), as our primary goal is to obtain well-calibrated probability estimates rather than binary classifications. Log loss is particularly suitable for this purpose as it heavily penalizes predictions that are both wrong and made with high confidence, encouraging the model to produce well-calibrated probability estimates. For example, predicting a 90% chance of admission for a patient who is ultimately discharged would incur a much higher penalty than predicting a 60% chance. A focus on probability calibration through log loss minimization provides more informative outputs than simple binary predictions, giving us richer understanding of the model's certainty about each prediction. </p> <p>To look at the model's calibration, let's compare both the minimal and the full model</p> <pre><code>from patientflow.viz.calibration_plot import plot_calibration\nfrom patientflow.load import load_saved_model, get_model_key\n\nexclude_from_training_data = [ 'snapshot_date', 'prediction_time','consultation_sequence', 'visit_number', 'specialty', 'final_sequence', 'training_validation_test']\n\n# calibration plot for minimal model\nplot_calibration(\n    prediction_times,\n    media_file_path,\n    trained_models,\n    test_visits,\n    exclude_from_training_data,\n    strategy=\"quantile\",\n    model_group_name='admissions_minimal_balanced_calibrated',\n    suptitle=\"Calibration plot for minimal model\"\n)\n\n# calibration plot for full model\nplot_calibration(\n    prediction_times,\n    media_file_path,\n    trained_models=None,\n    test_visits=test_visits_full,\n    exclude_from_training_data=exclude_from_training_data,\n    strategy=\"quantile\",\n    model_group_name='admissions_balanced_calibrated',\n    suptitle=\"Calibration plot for full model\",\n    model_file_path=model_file_path\n)\n\n\n</code></pre> <p></p> <p></p>"},{"location":"notebooks/4e_Predict_probabiity_of_admission_using_minimal_data/#evaluation-predictions-of-bed-numbers","title":"Evaluation predictions of bed numbers","text":"<pre><code>###\u00a0TO FOLLOW\n\n\n</code></pre>"},{"location":"notebooks/4e_Predict_probabiity_of_admission_using_minimal_data/#conclusion","title":"Conclusion","text":"<p>I have demonstrated here that a minimal dataset, using a small number of data points that NHS trusts would be collecting routinely, could be used to predict emergency demand for beds. </p> <p>I have assumed that a hospital can access this data in real-time, and has a way to run predictive models using those data. </p>"},{"location":"notebooks/4e_Predict_probabiity_of_admission_using_minimal_data/#would-hospitals-really-be-able-to-run-models-using-these-data-in-real-time","title":"Would hospitals really be able to run models using these data in real-time?","text":"<p>The answer depends on the each provider's own data infrastructure. Such data are certainly captured in EHR, PAS or other systems, and they are sent to the SUS+ with some degree of lag. We understand from NHSE that some hospitals send updates with lags of a day or two, and/or send Type 1 acuity (the most acute) daily but not others.  </p> <p>NHS England has invested in a Federated Data Platform, so there is the possibility that such models could be run on that platforn. </p>"},{"location":"notebooks/4f_Bring_it_all_together/","title":"Putting it all together","text":"<p>This notebook shows an example of how to convert data from the saved datasets, plus models trained earlier, into the output show below in columns D-G.  [WORK IN PROGRESS] </p> <pre><code>from IPython.display import Image\nImage(filename='img/UCLH application with annotation.jpg')\n</code></pre> <p></p> <p>In order to recreate the output this notebook, prior steps are</p> <ul> <li>train a model predicting admission to ED (this is done in notebook 4a_Predict_probability_of_admission_from_ED.md)</li> <li>train a model predicting admisson to each specialty if admitted (this is done in notebook 4c_Predict_probability_of_admission_to_specialty.md)</li> <li>train a model predicting demand from patients yet-to-arrive (this is done in notebook 4d_Predict_demand_from_patients_yet_to_arrive.md)</li> </ul>"},{"location":"notebooks/4f_Bring_it_all_together/#set-up-notebook-environment","title":"Set up notebook environment","text":"<pre><code># Reload functions every time\n%load_ext autoreload \n%autoreload 2\n</code></pre> <pre><code>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</code></pre> <pre><code>from patientflow.load import set_project_root\nproject_root = set_project_root()\n\n</code></pre> <pre><code>Inferred project root: /Users/zellaking/Repos/patientflow\n</code></pre>"},{"location":"notebooks/4f_Bring_it_all_together/#load-parameters-and-set-file-paths","title":"Load parameters and set file paths","text":"<pre><code>import pandas as pd\nfrom patientflow.load import load_data\nfrom patientflow.load import set_file_paths\n\n# set file paths\ndata_folder_name = 'data-public'\ndata_file_path = project_root / data_folder_name\n\ndata_file_path, media_file_path, model_file_path, config_path = set_file_paths(project_root, \n               data_folder_name=data_folder_name)\n\n\n# load data\ned_visits = load_data(data_file_path, \n                    file_name='ed_visits.csv', \n                    index_column = 'snapshot_id',\n                    sort_columns = [\"visit_number\", \"snapshot_date\", \"prediction_time\"], \n                    eval_columns = [\"prediction_time\", \"consultation_sequence\", \"final_sequence\"])\n\n# load params\nfrom patientflow.load import load_config_file\nparams = load_config_file(config_path)\n\nstart_training_set, start_validation_set, start_test_set, end_test_set = params[\"start_training_set\"], params[\"start_validation_set\"], params[\"start_test_set\"], params[\"end_test_set\"]\nprediction_times = params[\"prediction_times\"]\n\nx1, y1, x2, y2 = params[\"x1\"], params[\"y1\"], params[\"x2\"], params[\"y2\"]\nprediction_window = params[\"prediction_window\"]\nepsilon = float(params[\"epsilon\"])\nyta_time_interval = params[\"yta_time_interval\"]\n\nprint(f'\\nTraining set starts {start_training_set} and ends on {start_validation_set - pd.Timedelta(days=1)} inclusive')\nprint(f'Validation set starts on {start_validation_set} and ends on {start_test_set - pd.Timedelta(days=1)} inclusive' )\nprint(f'Test set starts on {start_test_set} and ends on {end_test_set- pd.Timedelta(days=1)} inclusive' )\n\nprint(f'\\nThe coordinates used to derive the aspirational curve are ({int(x1)},{y1}) and ({int(x2)},{y2})')\nprint(f'The prediction window over which prediction will be made is {prediction_window/60} hours')\nprint(f'In order to calculate yet-to-arrive rates of arrival, the prediction window will be divied into intervals of {yta_time_interval} minutes')\n</code></pre> <pre><code>Configuration will be loaded from: /Users/zellaking/Repos/patientflow/config.yaml\nData files will be loaded from: /Users/zellaking/Repos/patientflow/data-public\nTrained models will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public\nImages will be saved to: /Users/zellaking/Repos/patientflow/trained-models/public/media\n\nTraining set starts 2031-03-01 and ends on 2031-08-31 inclusive\nValidation set starts on 2031-09-01 and ends on 2031-09-30 inclusive\nTest set starts on 2031-10-01 and ends on 2031-12-31 inclusive\n\nThe coordinates used to derive the aspirational curve are (4,0.76) and (12,0.99)\nThe prediction window over which prediction will be made is 8.0 hours\nIn order to calculate yet-to-arrive rates of arrival, the prediction window will be divied into intervals of 15 minutes\n</code></pre>"},{"location":"notebooks/4f_Bring_it_all_together/#pick-a-random-row-to-simulate-the-real-time-environment","title":"Pick a random row to simulate the real-time environment","text":"<pre><code>from datetime import datetime, time\n\n# Set seed\nimport numpy as np\nnp.random.seed(2404)\n\n# Randomly pick a prediction moment to do inference on\nrandom_row = ed_visits[ed_visits.training_validation_test == 'test'].sample(n=1)\nprediction_time = random_row.prediction_time.values[0]\nprediction_date = random_row.snapshot_date.values[0]\nprediction_moment = datetime.combine(pd.to_datetime(prediction_date).date(), datetime.min.time()).replace(hour=prediction_time[0], minute=prediction_time[1])\n\nprediction_snapshots = ed_visits[(ed_visits.prediction_time == prediction_time) &amp; \\\n            (ed_visits.snapshot_date == prediction_date)]\nprediction_snapshots\n</code></pre> snapshot_date prediction_time visit_number elapsed_los sex age_group arrival_method current_location_type total_locations_visited num_obs ... latest_lab_results_pco2 latest_lab_results_ph latest_lab_results_wcc latest_lab_results_alb latest_lab_results_htrt training_validation_test final_sequence is_admitted random_number specialty snapshot_id 77829 12/23/2031 (15, 30) 153328 80793 M 75-102 Ambulance sdec 7 112 ... 5.78 7.392 10.31 46.0 NaN test ['acute'] True 63866 medical 77935 12/23/2031 (15, 30) 153425 33893 F 25-34 Public Trans sdec 5 34 ... 4.84 7.394 9.71 49.0 NaN test ['obs_gyn'] False 25439 NaN 77947 12/23/2031 (15, 30) 153435 9900 F 35-44 NaN sdec 4 16 ... 6.34 7.353 9.25 NaN NaN test ['obs_gyn'] False 36175 NaN 77951 12/23/2031 (15, 30) 153437 28398 F 25-34 Walk-in majors 4 79 ... 5.39 7.402 15.27 46.0 NaN test ['obs_gyn'] False 65532 NaN 77960 12/23/2031 (15, 30) 153445 26421 F 75-102 Ambulance majors 4 56 ... 5.31 7.410 3.96 37.0 NaN test ['acute'] True 57328 medical ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 78129 12/23/2031 (15, 30) 153611 3973 M 35-44 Walk-in waiting 2 7 ... NaN NaN NaN NaN NaN test [] False 57945 NaN 78130 12/23/2031 (15, 30) 153612 3839 F 25-34 Walk-in waiting 2 16 ... NaN NaN NaN NaN NaN test [] False 78438 NaN 78131 12/23/2031 (15, 30) 153613 3733 M 35-44 Walk-in waiting 2 5 ... NaN NaN NaN NaN NaN test [] False 75014 NaN 78132 12/23/2031 (15, 30) 153614 3644 F 55-64 Walk-in waiting 1 16 ... NaN NaN NaN NaN NaN test ['surgical'] False 4122 NaN 78133 12/23/2031 (15, 30) 153615 3629 F 0-17 Walk-in waiting 1 0 ... NaN NaN NaN NaN NaN test [] False 74758 NaN <p>92 rows \u00d7 69 columns</p>"},{"location":"notebooks/4f_Bring_it_all_together/#generate-predictions","title":"Generate predictions","text":"<p>The predictions for input into the spreadsheet output are generated by the create_predictions() function</p> <pre><code>from patientflow.predict.emergency_demand import create_predictions\n\n</code></pre> <p>We will load previously created models from disk and save to a dictionary of models</p> <pre><code>yta_model_name = f\"ed_yet_to_arrive_by_spec_{int(prediction_window/60)}_hours\"\n\n\nmodel_names = {\n    \"admissions\": \"admissions\",\n    \"specialty\": \"ed_specialty\",\n    \"yet_to_arrive\": yta_model_name\n}\n\nmodels = dict.fromkeys(model_names)\n\n\n\n</code></pre> <pre><code>model_file_path\n</code></pre> <pre><code>PosixPath('/Users/zellaking/Repos/patientflow/trained-models/public')\n</code></pre> <pre><code>from patientflow.load import load_saved_model, get_model_key\n\n# as the admissions models are a dictionary of models, we need to load each one\nmodels[\"admissions\"] = {}\nfor prediction_time in ed_visits.prediction_time.unique():\n\n    model_name_for_prediction_time = get_model_key(\"admissions\", prediction_time)\n    models[\"admissions\"][model_name_for_prediction_time]  = load_saved_model(model_file_path, \"admissions\", prediction_time)\n\nmodels[\"ed_specialty\"] = load_saved_model(model_file_path, \"specialty\")\nmodels[model_names[\"yet_to_arrive\"]] = load_saved_model(model_file_path, yta_model_name)\n\n</code></pre> <pre><code>type(models[\"admissions\"][model_name_for_prediction_time])\n</code></pre> <pre><code>patientflow.train.emergency_demand.ModelResults\n</code></pre> <p>In the cell below we create the predictions for this randomly chosen moment in time: </p> <pre><code>from patientflow.predict.emergency_demand import create_predictions\n\n\ncreate_predictions(\n    models = models,\n    model_names=model_names,\n    prediction_time = prediction_time,\n    prediction_snapshots = prediction_snapshots,\n    specialties = ['surgical', 'haem/onc', 'medical', 'paediatric'],\n    prediction_window_hrs = prediction_window/60,\n    cdf_cut_points =  [0.9, 0.7], \n    x1 = x1,\n    y1 = y1,\n    x2 = x2, \n    y2 = y2)\n</code></pre> <pre><code>{'surgical': {'in_ed': [2, 3], 'yet_to_arrive': [0, 0]},\n 'haem/onc': {'in_ed': [0, 1], 'yet_to_arrive': [0, 0]},\n 'medical': {'in_ed': [6, 8], 'yet_to_arrive': [0, 1]},\n 'paediatric': {'in_ed': [0, 0], 'yet_to_arrive': [0, 0]}}\n</code></pre> <pre><code>\n</code></pre>"},{"location":"src/patientflow/","title":"PatientFlow: A forthcoming Python package","text":"<p>Our intention is to release this repository as a Python package that can be installed using common methods like <code>pip install</code></p> <p>The package will support predictions of bed demand and discharges by providing functions that</p> <ul> <li>predict patient-level probabilities of admission and discharge, by specialty</li> <li>create probability distributions predicting number of beds needed for or vacated by those patients, at different levels of aggregation</li> <li>return a net bed position by combining predictions of demand and supply of beds</li> <li>evaluate and provide visualisation of the performance of these predictions</li> </ul> <p>The package is intended to serve as a wrapper of the functions typically used for such purposes in the <code>sklearn</code> and <code>scipy</code> python packages, with additional context to support their application and evaluation in bed management in healthcare</p>"},{"location":"src/patientflow/#modules-overview-in-order-of-their-use-in-a-typical-modelling-workflow","title":"Modules Overview (in order of their use in a typical modelling workflow)","text":"<ul> <li><code>load</code>: A module for loading configuration files, saved data and trained models</li> <li><code>prepare</code>: A module for preparing saved data prior to input into model training</li> <li><code>train</code>: A module and submodules for training predictive models</li> <li><code>calculate</code>: A module for calculating time-varying arrival rates, used in one of the custom predictors and in some of the visualisation functions</li> <li><code>predictors</code>: A module and submodules containing custom predictors developed for the <code>patientflow</code> package</li> <li><code>predict</code>: A module using trained models for predicting various aspects of bed demand and discharges</li> <li><code>aggregate</code>: A module that turns patient-level probabilities into aggregate distributions of bed numbers</li> <li><code>viz</code>: A module containing convenient plotting functions to examine the outputs from the above functions</li> </ul> <p>Other modules may follow in future</p>"},{"location":"src/patientflow/#deployment","title":"Deployment","text":"<p>This package is designed for use in hospital data projects analysing patient flow and bed capacity in short time horizons. The modules can be customised to align with specific hospital requirements</p>"}]}